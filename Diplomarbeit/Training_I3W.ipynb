{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING I3W\n",
    "\n",
    "\n",
    "# A) Create Envorinment, Vehicles etc\n",
    "\n",
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scenarios:\n",
      "['Scenario', 'BayBridgeScenario', 'BayBridgeTollScenario', 'BottleneckScenario', 'Figure8Scenario', 'SimpleGridScenario', 'HighwayScenario', 'LoopScenario', 'MergeScenario', 'TwoLoopsOneMergingScenario', 'MultiLoopScenario', 'IntersectionScenario', 'IntersectionScenarioTW']\n",
      "\n",
      "Available environments:\n",
      "['Env', 'AccelEnv', 'LaneChangeAccelEnv', 'LaneChangeAccelPOEnv', 'LaneChangeAccelEnv_speed', 'GreenWaveTestEnv', 'GreenWaveTestEnv', 'WaveAttenuationMergePOEnv', 'TwoLoopsMergePOEnv', 'BottleneckEnv', 'BottleNeckAccelEnv', 'WaveAttenuationEnv', 'WaveAttenuationPOEnv', 'TrafficLightGridEnv', 'PO_TrafficLightGridEnv', 'DesiredVelocityEnv', 'TestEnv', 'BayBridgeEnv', 'IntersectionEnv']\n"
     ]
    }
   ],
   "source": [
    "# Define horizon as a variable to ensure consistent use across notebook (length of one rollout)\n",
    "HORIZON=500\n",
    "\n",
    "# name of the experiment\n",
    "experiment_name = \"IntersectionExample\"\n",
    "\n",
    "# scenario class\n",
    "import flow.scenarios as scenarios\n",
    "print(\"Available scenarios:\")\n",
    "print(scenarios.__all__)\n",
    "scenario_name = \"IntersectionTWScenario\"\n",
    "\n",
    "# environment class\n",
    "import flow.envs as flowenvs\n",
    "print(\"\\nAvailable environments:\")\n",
    "print(flowenvs.__all__)\n",
    "env_name = \"IntersectionEnv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import NetParams\n",
    "from flow.scenarios.intersection import ADDITIONAL_NET_PARAMS\n",
    "\n",
    "additionalNetParams = {\n",
    "            \"edge_length\": 40,\n",
    "            \"lanes\": 1,\n",
    "            \"speed_limit\": 30\n",
    "        }\n",
    "\n",
    "net_params = NetParams( no_internal_links=False,                  #default: True   !! damit Kreuzungen nicht Ã¼berspr. werden\n",
    "                        inflows=None,                             #default: None\n",
    "                        osm_path=None,                            #default: None\n",
    "                        netfile=None,                             #default: None\n",
    "                        additional_params=additionalNetParams     #default: None   !!\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitialConfig Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import InitialConfig\n",
    "\n",
    "initial_config = InitialConfig( shuffle=True,                            #default: False         !!\n",
    "                                spacing=\"custom\",                        #default: \"uniform\"     !!\n",
    "                                min_gap=10,                              #default: 0\n",
    "                                perturbation=30.0,                       #default: 0.0            !!        \n",
    "                                x0=0,                                    #default: 0\n",
    "                                bunching=0,                              #default: 0\n",
    "                                lanes_distribution=float(\"inf\"),         #default: float(\"inf\")\n",
    "                                edges_distribution=\"all\",                #default: \"all\"\n",
    "                                additional_params=None )                 #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMO Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sumo_params = SumoParams( port = None,                  #default: None\n",
    "                          sim_step=0.1,                 #default: 0.1\n",
    "                          emission_path=None,           #default: None\n",
    "                          lateral_resolution=None,      #default: None\n",
    "                          no_step_log=True,             #default: True\n",
    "                          render=False,                 #default: False\n",
    "                          save_render=False,            #default: False\n",
    "                          sight_radius=25,              #default: 25\n",
    "                          show_radius=False,            #default: False\n",
    "                          pxpm=2,                       #default: 2\n",
    "                          overtake_right=False,         #default: False    \n",
    "                          seed=None,                    #default: None\n",
    "                          restart_instance=False,       #default: False\n",
    "                          print_warnings=True,          #default: True\n",
    "                          teleport_time=-1,             #default: -1\n",
    "                          num_clients=1,                #default: 1\n",
    "                          sumo_binary=None )            #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "additionalEnvParams = {\n",
    "        # maximum acceleration of autonomous vehicles\n",
    "        \"max_accel\": 3,\n",
    "        # maximum deceleration of autonomous vehicles\n",
    "        \"max_decel\": 3,\n",
    "        \"target_velocity\": 30\n",
    "    }\n",
    "\n",
    "env_params = EnvParams( additional_params=additionalEnvParams, #default: None    !!\n",
    "                        horizon=HORIZON,                       #default: 500     !!\n",
    "                        warmup_steps=0,                        #default: 0       \n",
    "                        sims_per_step=1,                       #default: 1\n",
    "                        evaluate=False )                       #default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import VehicleParams\n",
    "\n",
    "# import vehicles dynamics models\n",
    "#from flow.controllers import SumoCarFollowingController\n",
    "from flow.controllers import ContinuousRouter\n",
    "#from flow.controllers.lane_change_controllers import SumoLaneChangeController\n",
    "from flow.controllers.lane_change_controllers import StaticLaneChanger\n",
    "from flow.controllers import RLController\n",
    "from flow.core.params import SumoLaneChangeParams\n",
    "from flow.core.params import SumoCarFollowingParams\n",
    "from random import *\n",
    "\n",
    "vehicles = VehicleParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add RL-Agent controlled vehicles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car following parameters, default: None\n",
    "cf_parameter = SumoCarFollowingParams(\n",
    "                speed_mode=\"aggressive\")\n",
    "# lane change parameters, default: None\n",
    "lc_parameter =  None\n",
    "\n",
    "vehicles.add( # name of the vehicle\n",
    "                veh_id = \"rl\",\n",
    "              # acceleration controller, default: (SumoCarFollowingController, {})\n",
    "                acceleration_controller=(RLController, {}),\n",
    "              # lane_change_controller, default: (SumoLaneChangeController, {})\n",
    "                lane_change_controller=(StaticLaneChanger,{}),\n",
    "              # routing controller, default: None\n",
    "                routing_controller=(ContinuousRouter, {}),\n",
    "              # initial speed, default: 0\n",
    "                initial_speed=0,\n",
    "              # number of vehicles, default: 1 \n",
    "                num_vehicles=2,\n",
    "                \n",
    "                car_following_params=cf_parameter\n",
    "              # speed mode, default: \"right_of_way\"\n",
    "                #speed_mode=\"aggressive\",\n",
    "              # lane change mode, default: \"no_lat_collide\"\n",
    "                #lane_change_mode=\"aggressive\", \n",
    "              # car following parameter, default: None\n",
    "                #sumo_car_following_params=cf_parameter,\n",
    "              # lane change parameter, default: None\n",
    "                #sumo_lc_params=lc_parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict( # name of the experiment\n",
    "                      exp_tag=experiment_name,\n",
    "                    # name of the flow environment the experiment is running on\n",
    "                      env_name=env_name,\n",
    "                    # name of the scenario class the experiment uses\n",
    "                      scenario=scenario_name,\n",
    "                    # simulator that is used by the experiment\n",
    "                      simulator='traci',\n",
    "                    # sumo-related parameters (see flow.core.params.SumoParams)\n",
    "                      sim=sumo_params,\n",
    "                    # environment related parameters (see flow.core.params.EnvParams)\n",
    "                      env=env_params,\n",
    "                    # network-related parameters (see flow.core.params.NetParams and\n",
    "                    # the scenario's documentation or ADDITIONAL_NET_PARAMS component)\n",
    "                      net=net_params,\n",
    "                    # vehicles to be placed in the network at the start of a rollout \n",
    "                    # (see flow.core.vehicles.Vehicles)\n",
    "                      veh=vehicles,\n",
    "                   # (optional) parameters affecting the positioning of vehicles upon \n",
    "                   # initialization/reset (see flow.core.params.InitialConfig)\n",
    "                      initial=initial_config\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-02-19_23-46-01_11033/logs.\n",
      "Waiting for redis server at 127.0.0.1:15920 to respond...\n",
      "Waiting for redis server at 127.0.0.1:47122 to respond...\n",
      "Starting the Plasma object store with 6.554658406 GB memory using /dev/shm.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=7e65830e1a33e479a0c15cfe28be83250a74accd79dd1994\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.2.102',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-02-19_23-46-01_11033/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-02-19_23-46-01_11033/sockets/raylet'],\n",
       " 'redis_address': '192.168.2.102:15920',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui.ipynb?token=7e65830e1a33e479a0c15cfe28be83250a74accd79dd1994'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "N_CPUS = 2\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 20\n",
    "\n",
    "ray.init(redirect_output=True, num_cpus=N_CPUS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm or model to train. This may refer to \"\n",
    "#      \"the name of a built-on algorithm (e.g. RLLib's DQN \"\n",
    "#      \"or PPO), or a user-defined trainable function or \"\n",
    "#      \"class registered in the tune registry.\")\n",
    "alg_run = \"PPO\"\n",
    "\n",
    "agent_cls = get_agent_class(alg_run)\n",
    "config = agent_cls._default_config.copy()\n",
    "config[\"num_workers\"] = N_CPUS  # number of parallel workers\n",
    "config[\"train_batch_size\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.999  # discount rate\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [64, 32]})  # size of hidden layers in network\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "#config[\"sgd_minibatch_size\"] = min(16 * 1024, config[\"train_batch_size\"])  # stochastic gradient descent\n",
    "#config[\"sample_batch_size\"] = config[\"train_batch_size\"]/config[\"num_workers\"] # 200 default, trotzdem zu hoch?\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "config['env_config']['run'] = alg_run\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, gym_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(gym_name, create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "\n",
      "Created LogSyncer for /home/thorsten/ray_results/IntersectionExample/PPO_IntersectionEnv-v0_0_2019-02-19_23-46-024o7i5y8k -> \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-47-32\n",
      "  done: false\n",
      "  episode_len_mean: 450.14285714285717\n",
      "  episode_reward_max: 148.8779501735844\n",
      "  episode_reward_mean: 44.48329615873053\n",
      "  episode_reward_min: -61.94444688976626\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 21\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.833007335662842\n",
      "      kl: 0.002080637961626053\n",
      "      policy_loss: -0.003560446435585618\n",
      "      total_loss: 132.37210083007812\n",
      "      vf_explained_var: 0.03901923447847366\n",
      "      vf_loss: 132.37527465820312\n",
      "    grad_time_ms: 2445.468\n",
      "    load_time_ms: 44.915\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    sample_time_ms: 31682.925\n",
      "    update_time_ms: 567.383\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 34.79918074607849\n",
      "  time_this_iter_s: 34.79918074607849\n",
      "  time_total_s: 34.79918074607849\n",
      "  timestamp: 1550616452\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 34 s, 1 iter, 10000 ts, 44.5 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-47-57\n",
      "  done: false\n",
      "  episode_len_mean: 448.75\n",
      "  episode_reward_max: 211.90144700999463\n",
      "  episode_reward_mean: 72.73616415291035\n",
      "  episode_reward_min: -61.94444688976626\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 44\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.10000000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.827303409576416\n",
      "      kl: 0.004646646790206432\n",
      "      policy_loss: -0.0053735459223389626\n",
      "      total_loss: 110.16143035888672\n",
      "      vf_explained_var: 0.1056874617934227\n",
      "      vf_loss: 110.16635131835938\n",
      "    grad_time_ms: 2131.293\n",
      "    load_time_ms: 23.466\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    sample_time_ms: 27489.269\n",
      "    update_time_ms: 285.83\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 59.93182682991028\n",
      "  time_this_iter_s: 25.132646083831787\n",
      "  time_total_s: 59.93182682991028\n",
      "  timestamp: 1550616477\n",
      "  timesteps_since_restore: 20000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 59 s, 2 iter, 20000 ts, 72.7 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-48-16\n",
      "  done: false\n",
      "  episode_len_mean: 442.9850746268657\n",
      "  episode_reward_max: 211.90144700999463\n",
      "  episode_reward_mean: 77.06698732741063\n",
      "  episode_reward_min: -61.94444688976626\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 67\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.05000000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.8359761238098145\n",
      "      kl: 0.005060865078121424\n",
      "      policy_loss: -0.004938088357448578\n",
      "      total_loss: 164.45176696777344\n",
      "      vf_explained_var: 0.13866989314556122\n",
      "      vf_loss: 164.4564208984375\n",
      "    grad_time_ms: 1953.421\n",
      "    load_time_ms: 16.088\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "    sample_time_ms: 23882.446\n",
      "    update_time_ms: 192.576\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 78.21755313873291\n",
      "  time_this_iter_s: 18.285726308822632\n",
      "  time_total_s: 78.21755313873291\n",
      "  timestamp: 1550616496\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 3\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 78 s, 3 iter, 30000 ts, 77.1 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-48-33\n",
      "  done: false\n",
      "  episode_len_mean: 422.031914893617\n",
      "  episode_reward_max: 216.27887754635654\n",
      "  episode_reward_mean: 74.32798009437344\n",
      "  episode_reward_min: -61.94444688976626\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 94\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.02500000037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.836475372314453\n",
      "      kl: 0.0029024137184023857\n",
      "      policy_loss: -0.0033187835942953825\n",
      "      total_loss: 230.29164123535156\n",
      "      vf_explained_var: 0.1438371241092682\n",
      "      vf_loss: 230.2948760986328\n",
      "    grad_time_ms: 1866.39\n",
      "    load_time_ms: 12.397\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "    sample_time_ms: 21790.284\n",
      "    update_time_ms: 145.548\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 95.35595202445984\n",
      "  time_this_iter_s: 17.13839888572693\n",
      "  time_total_s: 95.35595202445984\n",
      "  timestamp: 1550616513\n",
      "  timesteps_since_restore: 40000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 4\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 95 s, 4 iter, 40000 ts, 74.3 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-48-50\n",
      "  done: false\n",
      "  episode_len_mean: 389.31\n",
      "  episode_reward_max: 231.8733811690149\n",
      "  episode_reward_mean: 92.06269778060546\n",
      "  episode_reward_min: -61.339734374354414\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 124\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.012500000186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.8364479541778564\n",
      "      kl: 0.004934235941618681\n",
      "      policy_loss: -0.004169761203229427\n",
      "      total_loss: 218.98727416992188\n",
      "      vf_explained_var: 0.13826926052570343\n",
      "      vf_loss: 218.9913787841797\n",
      "    grad_time_ms: 1817.087\n",
      "    load_time_ms: 10.25\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 50000\n",
      "    sample_time_ms: 20525.961\n",
      "    update_time_ms: 118.204\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 112.46885108947754\n",
      "  time_this_iter_s: 17.1128990650177\n",
      "  time_total_s: 112.46885108947754\n",
      "  timestamp: 1550616530\n",
      "  timesteps_since_restore: 50000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 5\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 112 s, 5 iter, 50000 ts, 92.1 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-49-08\n",
      "  done: false\n",
      "  episode_len_mean: 342.96\n",
      "  episode_reward_max: 231.8733811690149\n",
      "  episode_reward_mean: 89.88470053595609\n",
      "  episode_reward_min: -61.339734374354414\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 156\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.0062500000931322575\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.828568696975708\n",
      "      kl: 0.009038717485964298\n",
      "      policy_loss: -0.0056582228280603886\n",
      "      total_loss: 271.73095703125\n",
      "      vf_explained_var: 0.1356581598520279\n",
      "      vf_loss: 271.7365417480469\n",
      "    grad_time_ms: 1782.93\n",
      "    load_time_ms: 8.822\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "    sample_time_ms: 19775.493\n",
      "    update_time_ms: 99.264\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 130.1245982646942\n",
      "  time_this_iter_s: 17.655747175216675\n",
      "  time_total_s: 130.1245982646942\n",
      "  timestamp: 1550616548\n",
      "  timesteps_since_restore: 60000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 6\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 130 s, 6 iter, 60000 ts, 89.9 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-49-25\n",
      "  done: false\n",
      "  episode_len_mean: 311.34\n",
      "  episode_reward_max: 231.8733811690149\n",
      "  episode_reward_mean: 97.41129425941595\n",
      "  episode_reward_min: -60.91913766565617\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 191\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.0031250000465661287\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.8212931156158447\n",
      "      kl: 0.009107247926294804\n",
      "      policy_loss: -0.004174435045570135\n",
      "      total_loss: 337.58843994140625\n",
      "      vf_explained_var: 0.2222345769405365\n",
      "      vf_loss: 337.59259033203125\n",
      "    grad_time_ms: 1761.715\n",
      "    load_time_ms: 7.814\n",
      "    num_steps_sampled: 70000\n",
      "    num_steps_trained: 70000\n",
      "    sample_time_ms: 19201.301\n",
      "    update_time_ms: 85.658\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 147.5331666469574\n",
      "  time_this_iter_s: 17.408568382263184\n",
      "  time_total_s: 147.5331666469574\n",
      "  timestamp: 1550616565\n",
      "  timesteps_since_restore: 70000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 70000\n",
      "  training_iteration: 7\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 147 s, 7 iter, 70000 ts, 97.4 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-49-43\n",
      "  done: false\n",
      "  episode_len_mean: 251.94\n",
      "  episode_reward_max: 236.2359534010364\n",
      "  episode_reward_mean: 86.83905836495477\n",
      "  episode_reward_min: -60.91913766565617\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 238\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.0015625000232830644\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.811964511871338\n",
      "      kl: 0.00756938336417079\n",
      "      policy_loss: -0.005096163600683212\n",
      "      total_loss: 548.6947021484375\n",
      "      vf_explained_var: 0.07281165570020676\n",
      "      vf_loss: 548.6997680664062\n",
      "    grad_time_ms: 1741.172\n",
      "    load_time_ms: 7.005\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "    sample_time_ms: 18801.704\n",
      "    update_time_ms: 75.658\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 165.15698838233948\n",
      "  time_this_iter_s: 17.62382173538208\n",
      "  time_total_s: 165.15698838233948\n",
      "  timestamp: 1550616583\n",
      "  timesteps_since_restore: 80000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 8\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 165 s, 8 iter, 80000 ts, 86.8 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-50-01\n",
      "  done: false\n",
      "  episode_len_mean: 213.59\n",
      "  episode_reward_max: 236.2359534010364\n",
      "  episode_reward_mean: 95.26029683170074\n",
      "  episode_reward_min: -54.749285396023424\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 286\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.0007812500116415322\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.790856122970581\n",
      "      kl: 0.007546908687800169\n",
      "      policy_loss: -0.0029338570311665535\n",
      "      total_loss: 587.7955322265625\n",
      "      vf_explained_var: 0.060635700821876526\n",
      "      vf_loss: 587.7984008789062\n",
      "    grad_time_ms: 1727.296\n",
      "    load_time_ms: 6.362\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "    sample_time_ms: 18525.001\n",
      "    update_time_ms: 67.779\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 183.1027216911316\n",
      "  time_this_iter_s: 17.945733308792114\n",
      "  time_total_s: 183.1027216911316\n",
      "  timestamp: 1550616601\n",
      "  timesteps_since_restore: 90000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 9\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 183 s, 9 iter, 90000 ts, 95.3 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-50-19\n",
      "  done: false\n",
      "  episode_len_mean: 190.32\n",
      "  episode_reward_max: 219.42263593084417\n",
      "  episode_reward_mean: 100.50000914569546\n",
      "  episode_reward_min: -56.4397855485147\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 342\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.0003906250058207661\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.781438112258911\n",
      "      kl: 0.005223715212196112\n",
      "      policy_loss: -0.0024096700362861156\n",
      "      total_loss: 652.5258178710938\n",
      "      vf_explained_var: 0.028135662898421288\n",
      "      vf_loss: 652.5281982421875\n",
      "    grad_time_ms: 1715.656\n",
      "    load_time_ms: 5.842\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "    sample_time_ms: 18318.413\n",
      "    update_time_ms: 61.565\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 201.19319653511047\n",
      "  time_this_iter_s: 18.090474843978882\n",
      "  time_total_s: 201.19319653511047\n",
      "  timestamp: 1550616619\n",
      "  timesteps_since_restore: 100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 10\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 201 s, 10 iter, 100000 ts, 101 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-50-36\n",
      "  done: false\n",
      "  episode_len_mean: 188.7\n",
      "  episode_reward_max: 219.88914814412271\n",
      "  episode_reward_mean: 123.52962058642079\n",
      "  episode_reward_min: -58.110683525345834\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 394\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 0.00019531250291038305\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7776503562927246\n",
      "      kl: 0.007371246814727783\n",
      "      policy_loss: -0.004513176158070564\n",
      "      total_loss: 562.880859375\n",
      "      vf_explained_var: 0.014257901348173618\n",
      "      vf_loss: 562.8853759765625\n",
      "    grad_time_ms: 1632.645\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 110000\n",
      "    num_steps_trained: 110000\n",
      "    sample_time_ms: 16682.772\n",
      "    update_time_ms: 5.309\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 218.153888463974\n",
      "  time_this_iter_s: 16.960691928863525\n",
      "  time_total_s: 218.153888463974\n",
      "  timestamp: 1550616636\n",
      "  timesteps_since_restore: 110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 110000\n",
      "  training_iteration: 11\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 218 s, 11 iter, 110000 ts, 124 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 184.89\n",
      "  episode_reward_max: 219.88914814412271\n",
      "  episode_reward_mean: 126.52066114147885\n",
      "  episode_reward_min: -58.76608713157784\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 449\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.765625145519152e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7833094596862793\n",
      "      kl: 0.005872819572687149\n",
      "      policy_loss: -0.0034034703858196735\n",
      "      total_loss: 672.9286499023438\n",
      "      vf_explained_var: 0.06640627235174179\n",
      "      vf_loss: 672.9320678710938\n",
      "    grad_time_ms: 1612.185\n",
      "    load_time_ms: 1.442\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "    sample_time_ms: 15970.472\n",
      "    update_time_ms: 5.489\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 235.9614279270172\n",
      "  time_this_iter_s: 17.807539463043213\n",
      "  time_total_s: 235.9614279270172\n",
      "  timestamp: 1550616654\n",
      "  timesteps_since_restore: 120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 12\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 235 s, 12 iter, 120000 ts, 127 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-51-12\n",
      "  done: false\n",
      "  episode_len_mean: 190.04\n",
      "  episode_reward_max: 208.45330724732423\n",
      "  episode_reward_mean: 106.70133355772091\n",
      "  episode_reward_min: -58.76608713157784\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 499\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.882812572759576e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.8064470291137695\n",
      "      kl: 0.005517065990716219\n",
      "      policy_loss: -0.003812932875007391\n",
      "      total_loss: 553.7919921875\n",
      "      vf_explained_var: 0.32349953055381775\n",
      "      vf_loss: 553.7957763671875\n",
      "    grad_time_ms: 1613.379\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 130000\n",
      "    num_steps_trained: 130000\n",
      "    sample_time_ms: 15950.779\n",
      "    update_time_ms: 5.342\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 254.06112909317017\n",
      "  time_this_iter_s: 18.099701166152954\n",
      "  time_total_s: 254.06112909317017\n",
      "  timestamp: 1550616672\n",
      "  timesteps_since_restore: 130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 130000\n",
      "  training_iteration: 13\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 254 s, 13 iter, 130000 ts, 107 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-51-29\n",
      "  done: false\n",
      "  episode_len_mean: 210.39\n",
      "  episode_reward_max: 208.45330724732423\n",
      "  episode_reward_mean: 111.9902331413615\n",
      "  episode_reward_min: -66.59062439046743\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 545\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.441406286379788e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7799978256225586\n",
      "      kl: 0.014492066577076912\n",
      "      policy_loss: -0.005009093321859837\n",
      "      total_loss: 416.57415771484375\n",
      "      vf_explained_var: 0.5086616277694702\n",
      "      vf_loss: 416.57928466796875\n",
      "    grad_time_ms: 1614.958\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "    sample_time_ms: 15980.152\n",
      "    update_time_ms: 5.366\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 271.5090687274933\n",
      "  time_this_iter_s: 17.44793963432312\n",
      "  time_total_s: 271.5090687274933\n",
      "  timestamp: 1550616689\n",
      "  timesteps_since_restore: 140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 14\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 271 s, 14 iter, 140000 ts, 112 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-51-47\n",
      "  done: false\n",
      "  episode_len_mean: 208.4\n",
      "  episode_reward_max: 195.0072533416741\n",
      "  episode_reward_mean: 119.71689550789102\n",
      "  episode_reward_min: -66.59062439046743\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 596\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.441406286379788e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7724497318267822\n",
      "      kl: 0.003845549887046218\n",
      "      policy_loss: -0.0016921013593673706\n",
      "      total_loss: 521.1860961914062\n",
      "      vf_explained_var: 0.43588143587112427\n",
      "      vf_loss: 521.1878051757812\n",
      "    grad_time_ms: 1614.896\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "    sample_time_ms: 16045.112\n",
      "    update_time_ms: 4.92\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 289.26487708091736\n",
      "  time_this_iter_s: 17.755808353424072\n",
      "  time_total_s: 289.26487708091736\n",
      "  timestamp: 1550616707\n",
      "  timesteps_since_restore: 150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 15\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 289 s, 15 iter, 150000 ts, 120 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-52-05\n",
      "  done: false\n",
      "  episode_len_mean: 196.26\n",
      "  episode_reward_max: 192.61673927281302\n",
      "  episode_reward_mean: 115.29482054508108\n",
      "  episode_reward_min: -57.94918057242696\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 646\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.220703143189894e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.762556552886963\n",
      "      kl: 0.010972949676215649\n",
      "      policy_loss: -0.004072160460054874\n",
      "      total_loss: 416.69439697265625\n",
      "      vf_explained_var: 0.5311524271965027\n",
      "      vf_loss: 416.6984558105469\n",
      "    grad_time_ms: 1616.34\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "    sample_time_ms: 16024.606\n",
      "    update_time_ms: 4.948\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 306.7293469905853\n",
      "  time_this_iter_s: 17.46446990966797\n",
      "  time_total_s: 306.7293469905853\n",
      "  timestamp: 1550616725\n",
      "  timesteps_since_restore: 160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 16\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 306 s, 16 iter, 160000 ts, 115 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-52-22\n",
      "  done: false\n",
      "  episode_len_mean: 179.63\n",
      "  episode_reward_max: 172.69617590086875\n",
      "  episode_reward_mean: 125.60826744373118\n",
      "  episode_reward_min: -52.71279526401387\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 704\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.220703143189894e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6985533237457275\n",
      "      kl: 0.00525748310610652\n",
      "      policy_loss: -0.0031626462005078793\n",
      "      total_loss: 478.6788330078125\n",
      "      vf_explained_var: 0.2508963346481323\n",
      "      vf_loss: 478.68212890625\n",
      "    grad_time_ms: 1616.444\n",
      "    load_time_ms: 1.407\n",
      "    num_steps_sampled: 170000\n",
      "    num_steps_trained: 170000\n",
      "    sample_time_ms: 16013.261\n",
      "    update_time_ms: 5.078\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 324.02825450897217\n",
      "  time_this_iter_s: 17.29890751838684\n",
      "  time_total_s: 324.02825450897217\n",
      "  timestamp: 1550616742\n",
      "  timesteps_since_restore: 170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 170000\n",
      "  training_iteration: 17\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 324 s, 17 iter, 170000 ts, 126 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-52-39\n",
      "  done: false\n",
      "  episode_len_mean: 178.42\n",
      "  episode_reward_max: 174.37027804026076\n",
      "  episode_reward_mean: 124.79520723499836\n",
      "  episode_reward_min: -63.72936416539349\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 758\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.10351571594947e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7347168922424316\n",
      "      kl: 0.0054762098006904125\n",
      "      policy_loss: -0.0022577394265681505\n",
      "      total_loss: 472.1639709472656\n",
      "      vf_explained_var: 0.47181236743927\n",
      "      vf_loss: 472.166259765625\n",
      "    grad_time_ms: 1617.146\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "    sample_time_ms: 15989.494\n",
      "    update_time_ms: 4.948\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 341.4185495376587\n",
      "  time_this_iter_s: 17.390295028686523\n",
      "  time_total_s: 341.4185495376587\n",
      "  timestamp: 1550616759\n",
      "  timesteps_since_restore: 180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 18\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 341 s, 18 iter, 180000 ts, 125 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-52-57\n",
      "  done: false\n",
      "  episode_len_mean: 179.29\n",
      "  episode_reward_max: 170.6275329234709\n",
      "  episode_reward_mean: 133.74612213180018\n",
      "  episode_reward_min: -61.834554337361666\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 815\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.051757857974735e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6840670108795166\n",
      "      kl: 0.008621570654213428\n",
      "      policy_loss: -0.003413783386349678\n",
      "      total_loss: 393.6387634277344\n",
      "      vf_explained_var: 0.48050636053085327\n",
      "      vf_loss: 393.6422119140625\n",
      "    grad_time_ms: 1616.137\n",
      "    load_time_ms: 1.422\n",
      "    num_steps_sampled: 190000\n",
      "    num_steps_trained: 190000\n",
      "    sample_time_ms: 15968.697\n",
      "    update_time_ms: 4.909\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 359.1459538936615\n",
      "  time_this_iter_s: 17.727404356002808\n",
      "  time_total_s: 359.1459538936615\n",
      "  timestamp: 1550616777\n",
      "  timesteps_since_restore: 190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 190000\n",
      "  training_iteration: 19\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 359 s, 19 iter, 190000 ts, 134 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-53-15\n",
      "  done: false\n",
      "  episode_len_mean: 163.7\n",
      "  episode_reward_max: 174.5656739696899\n",
      "  episode_reward_mean: 133.98913691453984\n",
      "  episode_reward_min: -56.32356876518371\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 881\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5258789289873675e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.640265941619873\n",
      "      kl: 0.005636495538055897\n",
      "      policy_loss: -0.003049992024898529\n",
      "      total_loss: 578.32861328125\n",
      "      vf_explained_var: 0.2709636092185974\n",
      "      vf_loss: 578.3316040039062\n",
      "    grad_time_ms: 1617.473\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "    sample_time_ms: 15905.637\n",
      "    update_time_ms: 4.979\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 376.6198127269745\n",
      "  time_this_iter_s: 17.47385883331299\n",
      "  time_total_s: 376.6198127269745\n",
      "  timestamp: 1550616795\n",
      "  timesteps_since_restore: 200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 20\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 376 s, 20 iter, 200000 ts, 134 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-53-33\n",
      "  done: false\n",
      "  episode_len_mean: 149.2\n",
      "  episode_reward_max: 178.26966698711635\n",
      "  episode_reward_mean: 124.72511841532379\n",
      "  episode_reward_min: -67.37828830037881\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 943\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.629394644936838e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.672466516494751\n",
      "      kl: 0.008008460514247417\n",
      "      policy_loss: -0.0036604739725589752\n",
      "      total_loss: 598.1690063476562\n",
      "      vf_explained_var: 0.3683069348335266\n",
      "      vf_loss: 598.1726684570312\n",
      "    grad_time_ms: 1616.504\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "    sample_time_ms: 16017.793\n",
      "    update_time_ms: 4.9\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 394.692551612854\n",
      "  time_this_iter_s: 18.072738885879517\n",
      "  time_total_s: 394.692551612854\n",
      "  timestamp: 1550616813\n",
      "  timesteps_since_restore: 210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 21\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 394 s, 21 iter, 210000 ts, 125 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-53-51\n",
      "  done: false\n",
      "  episode_len_mean: 155.33\n",
      "  episode_reward_max: 186.5693360697663\n",
      "  episode_reward_mean: 137.34504248794957\n",
      "  episode_reward_min: -54.832473934877044\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 1012\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.814697322468419e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.632188558578491\n",
      "      kl: 0.00617150217294693\n",
      "      policy_loss: -0.003191831288859248\n",
      "      total_loss: 571.2957763671875\n",
      "      vf_explained_var: 0.3201911449432373\n",
      "      vf_loss: 571.2988891601562\n",
      "    grad_time_ms: 1617.204\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "    sample_time_ms: 16039.326\n",
      "    update_time_ms: 4.869\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 412.7206664085388\n",
      "  time_this_iter_s: 18.028114795684814\n",
      "  time_total_s: 412.7206664085388\n",
      "  timestamp: 1550616831\n",
      "  timesteps_since_restore: 220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 22\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 412 s, 22 iter, 220000 ts, 137 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-54-09\n",
      "  done: false\n",
      "  episode_len_mean: 157.54\n",
      "  episode_reward_max: 186.5693360697663\n",
      "  episode_reward_mean: 134.64597909398742\n",
      "  episode_reward_min: -61.36259916002176\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 1075\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9073486612342094e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6670196056365967\n",
      "      kl: 0.012080770917236805\n",
      "      policy_loss: -0.004184394609183073\n",
      "      total_loss: 523.3251342773438\n",
      "      vf_explained_var: 0.45988714694976807\n",
      "      vf_loss: 523.3292236328125\n",
      "    grad_time_ms: 1617.535\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 230000\n",
      "    num_steps_trained: 230000\n",
      "    sample_time_ms: 16019.88\n",
      "    update_time_ms: 4.801\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 430.63017416000366\n",
      "  time_this_iter_s: 17.909507751464844\n",
      "  time_total_s: 430.63017416000366\n",
      "  timestamp: 1550616849\n",
      "  timesteps_since_restore: 230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 230000\n",
      "  training_iteration: 23\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 430 s, 23 iter, 230000 ts, 135 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-54-26\n",
      "  done: false\n",
      "  episode_len_mean: 150.44\n",
      "  episode_reward_max: 179.55091763415965\n",
      "  episode_reward_mean: 124.04008292854897\n",
      "  episode_reward_min: -61.36259916002176\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 1143\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9073486612342094e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6664319038391113\n",
      "      kl: 0.003598123788833618\n",
      "      policy_loss: -0.002976629650220275\n",
      "      total_loss: 666.5830078125\n",
      "      vf_explained_var: 0.3435177803039551\n",
      "      vf_loss: 666.5859985351562\n",
      "    grad_time_ms: 1617.655\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "    sample_time_ms: 16001.563\n",
      "    update_time_ms: 4.732\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 447.8961913585663\n",
      "  time_this_iter_s: 17.266017198562622\n",
      "  time_total_s: 447.8961913585663\n",
      "  timestamp: 1550616866\n",
      "  timesteps_since_restore: 240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 24\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 447 s, 24 iter, 240000 ts, 124 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-54-44\n",
      "  done: false\n",
      "  episode_len_mean: 146.87\n",
      "  episode_reward_max: 185.19235873923145\n",
      "  episode_reward_mean: 131.20924362184655\n",
      "  episode_reward_min: -63.58489935308091\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 1209\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.536743306171047e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6573469638824463\n",
      "      kl: 0.011125963181257248\n",
      "      policy_loss: -0.003384200157597661\n",
      "      total_loss: 609.048095703125\n",
      "      vf_explained_var: 0.39044174551963806\n",
      "      vf_loss: 609.0514526367188\n",
      "    grad_time_ms: 1618.5\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 250000\n",
      "    num_steps_trained: 250000\n",
      "    sample_time_ms: 15998.712\n",
      "    update_time_ms: 4.695\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 465.6330840587616\n",
      "  time_this_iter_s: 17.736892700195312\n",
      "  time_total_s: 465.6330840587616\n",
      "  timestamp: 1550616884\n",
      "  timesteps_since_restore: 250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 250000\n",
      "  training_iteration: 25\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 465 s, 25 iter, 250000 ts, 131 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-55-02\n",
      "  done: false\n",
      "  episode_len_mean: 137.02\n",
      "  episode_reward_max: 184.4502833010536\n",
      "  episode_reward_mean: 118.86186067038709\n",
      "  episode_reward_min: -63.58489935308091\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1281\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.536743306171047e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.611311674118042\n",
      "      kl: 0.009489347226917744\n",
      "      policy_loss: -0.0038272924721240997\n",
      "      total_loss: 790.4217529296875\n",
      "      vf_explained_var: 0.23851875960826874\n",
      "      vf_loss: 790.4255981445312\n",
      "    grad_time_ms: 1620.756\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "    sample_time_ms: 16034.551\n",
      "    update_time_ms: 4.75\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 483.47923707962036\n",
      "  time_this_iter_s: 17.846153020858765\n",
      "  time_total_s: 483.47923707962036\n",
      "  timestamp: 1550616902\n",
      "  timesteps_since_restore: 260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 26\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 483 s, 26 iter, 260000 ts, 119 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 142.69\n",
      "  episode_reward_max: 177.77461143796984\n",
      "  episode_reward_mean: 121.23532300197093\n",
      "  episode_reward_min: -58.941795708602015\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 1351\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.7683716530855236e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6479434967041016\n",
      "      kl: 0.006705703679472208\n",
      "      policy_loss: -0.002875542500987649\n",
      "      total_loss: 620.0236206054688\n",
      "      vf_explained_var: 0.35559967160224915\n",
      "      vf_loss: 620.026611328125\n",
      "    grad_time_ms: 1616.751\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "    sample_time_ms: 16100.594\n",
      "    update_time_ms: 4.789\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 501.4002470970154\n",
      "  time_this_iter_s: 17.92101001739502\n",
      "  time_total_s: 501.4002470970154\n",
      "  timestamp: 1550616920\n",
      "  timesteps_since_restore: 270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 27\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 501 s, 27 iter, 270000 ts, 121 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-55-37\n",
      "  done: false\n",
      "  episode_len_mean: 157.82\n",
      "  episode_reward_max: 171.03904677632417\n",
      "  episode_reward_mean: 140.04441313546286\n",
      "  episode_reward_min: -58.941795708602015\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 1414\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3841858265427618e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6919567584991455\n",
      "      kl: 0.01545063965022564\n",
      "      policy_loss: -0.005198120139539242\n",
      "      total_loss: 439.8354797363281\n",
      "      vf_explained_var: 0.6708852052688599\n",
      "      vf_loss: 439.84063720703125\n",
      "    grad_time_ms: 1622.764\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "    sample_time_ms: 16072.995\n",
      "    update_time_ms: 4.738\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 518.5755307674408\n",
      "  time_this_iter_s: 17.175283670425415\n",
      "  time_total_s: 518.5755307674408\n",
      "  timestamp: 1550616937\n",
      "  timesteps_since_restore: 280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 28\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 518 s, 28 iter, 280000 ts, 140 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-55-54\n",
      "  done: false\n",
      "  episode_len_mean: 149.5\n",
      "  episode_reward_max: 171.21321317774823\n",
      "  episode_reward_mean: 132.40229813271216\n",
      "  episode_reward_min: -56.957133142517336\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 1478\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3841858265427618e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6986284255981445\n",
      "      kl: 0.005380215123295784\n",
      "      policy_loss: -0.002369235036894679\n",
      "      total_loss: 494.8749084472656\n",
      "      vf_explained_var: 0.5719696283340454\n",
      "      vf_loss: 494.8773498535156\n",
      "    grad_time_ms: 1622.975\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 290000\n",
      "    num_steps_trained: 290000\n",
      "    sample_time_ms: 16033.155\n",
      "    update_time_ms: 4.788\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 535.9077117443085\n",
      "  time_this_iter_s: 17.332180976867676\n",
      "  time_total_s: 535.9077117443085\n",
      "  timestamp: 1550616954\n",
      "  timesteps_since_restore: 290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 290000\n",
      "  training_iteration: 29\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 535 s, 29 iter, 290000 ts, 132 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-56-12\n",
      "  done: false\n",
      "  episode_len_mean: 139.67\n",
      "  episode_reward_max: 176.26940844949385\n",
      "  episode_reward_mean: 136.2056843103438\n",
      "  episode_reward_min: -65.13971208128385\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 1551\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.1920929132713809e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6025445461273193\n",
      "      kl: 0.004572031553834677\n",
      "      policy_loss: -0.002586327027529478\n",
      "      total_loss: 598.9781494140625\n",
      "      vf_explained_var: 0.4161022901535034\n",
      "      vf_loss: 598.9808349609375\n",
      "    grad_time_ms: 1620.465\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "    sample_time_ms: 16035.932\n",
      "    update_time_ms: 4.721\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 553.3838925361633\n",
      "  time_this_iter_s: 17.47618079185486\n",
      "  time_total_s: 553.3838925361633\n",
      "  timestamp: 1550616972\n",
      "  timesteps_since_restore: 300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 30\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 553 s, 30 iter, 300000 ts, 136 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-56-30\n",
      "  done: false\n",
      "  episode_len_mean: 153.18\n",
      "  episode_reward_max: 173.9534662070472\n",
      "  episode_reward_mean: 133.1175105554813\n",
      "  episode_reward_min: -62.03793023984031\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 1614\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.9604645663569045e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.666256904602051\n",
      "      kl: 0.003599870717152953\n",
      "      policy_loss: -0.0015823348658159375\n",
      "      total_loss: 518.300537109375\n",
      "      vf_explained_var: 0.6211780905723572\n",
      "      vf_loss: 518.3021850585938\n",
      "    grad_time_ms: 1621.72\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 310000\n",
      "    num_steps_trained: 310000\n",
      "    sample_time_ms: 16000.45\n",
      "    update_time_ms: 4.715\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 571.1127979755402\n",
      "  time_this_iter_s: 17.72890543937683\n",
      "  time_total_s: 571.1127979755402\n",
      "  timestamp: 1550616990\n",
      "  timesteps_since_restore: 310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 310000\n",
      "  training_iteration: 31\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 571 s, 31 iter, 310000 ts, 133 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-56-47\n",
      "  done: false\n",
      "  episode_len_mean: 166.26\n",
      "  episode_reward_max: 177.25955874799766\n",
      "  episode_reward_mean: 142.40957736266762\n",
      "  episode_reward_min: -64.48551660382026\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 1677\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.9802322831784522e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6853978633880615\n",
      "      kl: 0.0051764920353889465\n",
      "      policy_loss: -0.0020992138888686895\n",
      "      total_loss: 445.62579345703125\n",
      "      vf_explained_var: 0.6906864047050476\n",
      "      vf_loss: 445.6279602050781\n",
      "    grad_time_ms: 1622.622\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "    sample_time_ms: 15960.864\n",
      "    update_time_ms: 4.721\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 588.7562201023102\n",
      "  time_this_iter_s: 17.64342212677002\n",
      "  time_total_s: 588.7562201023102\n",
      "  timestamp: 1550617007\n",
      "  timesteps_since_restore: 320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 32\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 588 s, 32 iter, 320000 ts, 142 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-57-05\n",
      "  done: false\n",
      "  episode_len_mean: 150.09\n",
      "  episode_reward_max: 177.25955874799766\n",
      "  episode_reward_mean: 143.8458617729066\n",
      "  episode_reward_min: -64.48551660382026\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 1744\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.4901161415892261e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.594778060913086\n",
      "      kl: 0.004859589971601963\n",
      "      policy_loss: -0.002270548837259412\n",
      "      total_loss: 396.9275207519531\n",
      "      vf_explained_var: 0.7226393818855286\n",
      "      vf_loss: 396.9298095703125\n",
      "    grad_time_ms: 1621.93\n",
      "    load_time_ms: 1.688\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "    sample_time_ms: 15955.251\n",
      "    update_time_ms: 4.795\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 606.60311460495\n",
      "  time_this_iter_s: 17.84689450263977\n",
      "  time_total_s: 606.60311460495\n",
      "  timestamp: 1550617025\n",
      "  timesteps_since_restore: 330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 33\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 606 s, 33 iter, 330000 ts, 144 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-57-23\n",
      "  done: false\n",
      "  episode_len_mean: 152.63\n",
      "  episode_reward_max: 176.1468229594797\n",
      "  episode_reward_mean: 141.14032507215958\n",
      "  episode_reward_min: -58.02212288350152\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 1811\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.450580707946131e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6519615650177\n",
      "      kl: 0.007696331478655338\n",
      "      policy_loss: -0.0031884198542684317\n",
      "      total_loss: 507.8411560058594\n",
      "      vf_explained_var: 0.6562362313270569\n",
      "      vf_loss: 507.8443908691406\n",
      "    grad_time_ms: 1621.131\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "    sample_time_ms: 15978.511\n",
      "    update_time_ms: 4.846\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 624.0941903591156\n",
      "  time_this_iter_s: 17.49107575416565\n",
      "  time_total_s: 624.0941903591156\n",
      "  timestamp: 1550617043\n",
      "  timesteps_since_restore: 340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 34\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 624 s, 34 iter, 340000 ts, 141 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-57-41\n",
      "  done: false\n",
      "  episode_len_mean: 150.34\n",
      "  episode_reward_max: 176.73332087843147\n",
      "  episode_reward_mean: 140.8471760958327\n",
      "  episode_reward_min: -58.02212288350152\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 1877\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.7252903539730653e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.651543378829956\n",
      "      kl: 0.006745447870343924\n",
      "      policy_loss: -0.0032041643280535936\n",
      "      total_loss: 395.9202575683594\n",
      "      vf_explained_var: 0.7449455261230469\n",
      "      vf_loss: 395.9234924316406\n",
      "    grad_time_ms: 1619.932\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 350000\n",
      "    num_steps_trained: 350000\n",
      "    sample_time_ms: 16016.667\n",
      "    update_time_ms: 4.946\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 642.2003185749054\n",
      "  time_this_iter_s: 18.106128215789795\n",
      "  time_total_s: 642.2003185749054\n",
      "  timestamp: 1550617061\n",
      "  timesteps_since_restore: 350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 350000\n",
      "  training_iteration: 35\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 642 s, 35 iter, 350000 ts, 141 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-57-59\n",
      "  done: false\n",
      "  episode_len_mean: 141.12\n",
      "  episode_reward_max: 173.98327219866147\n",
      "  episode_reward_mean: 140.93205732529094\n",
      "  episode_reward_min: -44.21880484350244\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 1950\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.8626451769865326e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.574763298034668\n",
      "      kl: 0.01809857413172722\n",
      "      policy_loss: -0.007446601055562496\n",
      "      total_loss: 363.5426940917969\n",
      "      vf_explained_var: 0.7444436550140381\n",
      "      vf_loss: 363.55010986328125\n",
      "    grad_time_ms: 1616.939\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "    sample_time_ms: 16048.303\n",
      "    update_time_ms: 4.845\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 660.3331570625305\n",
      "  time_this_iter_s: 18.132838487625122\n",
      "  time_total_s: 660.3331570625305\n",
      "  timestamp: 1550617079\n",
      "  timesteps_since_restore: 360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 36\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 660 s, 36 iter, 360000 ts, 141 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-58-17\n",
      "  done: false\n",
      "  episode_len_mean: 140.34\n",
      "  episode_reward_max: 171.38110992222113\n",
      "  episode_reward_mean: 138.09913600008073\n",
      "  episode_reward_min: -51.915089293429155\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 2020\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.8626451769865326e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5978519916534424\n",
      "      kl: 0.00807875581085682\n",
      "      policy_loss: -0.002877181861549616\n",
      "      total_loss: 427.0375671386719\n",
      "      vf_explained_var: 0.7083578705787659\n",
      "      vf_loss: 427.0404052734375\n",
      "    grad_time_ms: 1619.12\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 370000\n",
      "    num_steps_trained: 370000\n",
      "    sample_time_ms: 16020.561\n",
      "    update_time_ms: 4.731\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 677.9955222606659\n",
      "  time_this_iter_s: 17.662365198135376\n",
      "  time_total_s: 677.9955222606659\n",
      "  timestamp: 1550617097\n",
      "  timesteps_since_restore: 370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 370000\n",
      "  training_iteration: 37\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 677 s, 37 iter, 370000 ts, 138 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-58-35\n",
      "  done: false\n",
      "  episode_len_mean: 150.46\n",
      "  episode_reward_max: 169.9586521781022\n",
      "  episode_reward_mean: 140.78799039794373\n",
      "  episode_reward_min: -46.12266268972123\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 2085\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.313225884932663e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.64198637008667\n",
      "      kl: 0.005571360234171152\n",
      "      policy_loss: -0.0038340426981449127\n",
      "      total_loss: 386.8708801269531\n",
      "      vf_explained_var: 0.753375232219696\n",
      "      vf_loss: 386.8747253417969\n",
      "    grad_time_ms: 1615.2\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "    sample_time_ms: 16082.042\n",
      "    update_time_ms: 4.784\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 695.7481956481934\n",
      "  time_this_iter_s: 17.752673387527466\n",
      "  time_total_s: 695.7481956481934\n",
      "  timestamp: 1550617115\n",
      "  timesteps_since_restore: 380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 38\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 695 s, 38 iter, 380000 ts, 141 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 161.17\n",
      "  episode_reward_max: 171.7888636831253\n",
      "  episode_reward_mean: 143.83096239540762\n",
      "  episode_reward_min: -46.12266268972123\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 2144\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.6566129424663316e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7409396171569824\n",
      "      kl: 0.02162069082260132\n",
      "      policy_loss: -0.006242979783564806\n",
      "      total_loss: 303.8108825683594\n",
      "      vf_explained_var: 0.848592221736908\n",
      "      vf_loss: 303.817138671875\n",
      "    grad_time_ms: 1618.382\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "    sample_time_ms: 16119.679\n",
      "    update_time_ms: 5.099\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 713.4938478469849\n",
      "  time_this_iter_s: 17.745652198791504\n",
      "  time_total_s: 713.4938478469849\n",
      "  timestamp: 1550617132\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 39\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 713 s, 39 iter, 390000 ts, 144 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-59-10\n",
      "  done: false\n",
      "  episode_len_mean: 161.16\n",
      "  episode_reward_max: 190.98928465266079\n",
      "  episode_reward_mean: 140.81259386822092\n",
      "  episode_reward_min: -58.0342396723457\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 2207\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.6566129424663316e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.690229654312134\n",
      "      kl: 0.008940448984503746\n",
      "      policy_loss: -0.0027822954580187798\n",
      "      total_loss: 457.05572509765625\n",
      "      vf_explained_var: 0.6946743130683899\n",
      "      vf_loss: 457.0585021972656\n",
      "    grad_time_ms: 1618.902\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "    sample_time_ms: 16130.39\n",
      "    update_time_ms: 4.953\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 731.0808744430542\n",
      "  time_this_iter_s: 17.587026596069336\n",
      "  time_total_s: 731.0808744430542\n",
      "  timestamp: 1550617150\n",
      "  timesteps_since_restore: 400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 40\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 731 s, 40 iter, 400000 ts, 141 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-59-28\n",
      "  done: false\n",
      "  episode_len_mean: 149.85\n",
      "  episode_reward_max: 182.05831402429556\n",
      "  episode_reward_mean: 144.03737958135548\n",
      "  episode_reward_min: -52.56857433310239\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 2281\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3283064712331658e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.494185447692871\n",
      "      kl: 0.012852011248469353\n",
      "      policy_loss: -0.004946217406541109\n",
      "      total_loss: 482.53460693359375\n",
      "      vf_explained_var: 0.6442403197288513\n",
      "      vf_loss: 482.53955078125\n",
      "    grad_time_ms: 1617.727\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 410000\n",
      "    num_steps_trained: 410000\n",
      "    sample_time_ms: 16131.932\n",
      "    update_time_ms: 4.958\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 748.8148994445801\n",
      "  time_this_iter_s: 17.73402500152588\n",
      "  time_total_s: 748.8148994445801\n",
      "  timestamp: 1550617168\n",
      "  timesteps_since_restore: 410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 410000\n",
      "  training_iteration: 41\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 748 s, 41 iter, 410000 ts, 144 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-19_23-59-46\n",
      "  done: false\n",
      "  episode_len_mean: 137.43\n",
      "  episode_reward_max: 182.05831402429556\n",
      "  episode_reward_mean: 134.8477105895625\n",
      "  episode_reward_min: -52.56857433310239\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 2350\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3283064712331658e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5760135650634766\n",
      "      kl: 0.011602641083300114\n",
      "      policy_loss: -0.005335856694728136\n",
      "      total_loss: 354.7747497558594\n",
      "      vf_explained_var: 0.7634619474411011\n",
      "      vf_loss: 354.7800598144531\n",
      "    grad_time_ms: 1617.377\n",
      "    load_time_ms: 1.451\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "    sample_time_ms: 16160.865\n",
      "    update_time_ms: 4.903\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 766.7418007850647\n",
      "  time_this_iter_s: 17.92690134048462\n",
      "  time_total_s: 766.7418007850647\n",
      "  timestamp: 1550617186\n",
      "  timesteps_since_restore: 420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 42\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 766 s, 42 iter, 420000 ts, 135 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-00-03\n",
      "  done: false\n",
      "  episode_len_mean: 136.06\n",
      "  episode_reward_max: 168.88472758735165\n",
      "  episode_reward_mean: 141.91601708723522\n",
      "  episode_reward_min: -46.00545134756825\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2422\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3283064712331658e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4612905979156494\n",
      "      kl: 0.027736421674489975\n",
      "      policy_loss: -0.00821602251380682\n",
      "      total_loss: 348.2488098144531\n",
      "      vf_explained_var: 0.8118891716003418\n",
      "      vf_loss: 348.25701904296875\n",
      "    grad_time_ms: 1618.349\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 430000\n",
      "    num_steps_trained: 430000\n",
      "    sample_time_ms: 16103.305\n",
      "    update_time_ms: 4.839\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 784.0230271816254\n",
      "  time_this_iter_s: 17.28122639656067\n",
      "  time_total_s: 784.0230271816254\n",
      "  timestamp: 1550617203\n",
      "  timesteps_since_restore: 430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 430000\n",
      "  training_iteration: 43\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 784 s, 43 iter, 430000 ts, 142 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-00-21\n",
      "  done: false\n",
      "  episode_len_mean: 134.33\n",
      "  episode_reward_max: 173.8205455612797\n",
      "  episode_reward_mean: 136.14013603870544\n",
      "  episode_reward_min: -51.83100875735037\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 2499\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3283064712331658e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4623539447784424\n",
      "      kl: 0.011366705410182476\n",
      "      policy_loss: -0.002047344809398055\n",
      "      total_loss: 464.18658447265625\n",
      "      vf_explained_var: 0.6911701560020447\n",
      "      vf_loss: 464.1885986328125\n",
      "    grad_time_ms: 1619.424\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "    sample_time_ms: 16110.671\n",
      "    update_time_ms: 4.896\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 801.6042416095734\n",
      "  time_this_iter_s: 17.581214427947998\n",
      "  time_total_s: 801.6042416095734\n",
      "  timestamp: 1550617221\n",
      "  timesteps_since_restore: 440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 44\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 801 s, 44 iter, 440000 ts, 136 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-00-39\n",
      "  done: false\n",
      "  episode_len_mean: 134.49\n",
      "  episode_reward_max: 179.84856032490694\n",
      "  episode_reward_mean: 145.58367263941344\n",
      "  episode_reward_min: -48.750827544691525\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 2569\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3283064712331658e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5178098678588867\n",
      "      kl: 0.009079817682504654\n",
      "      policy_loss: -0.0029101865366101265\n",
      "      total_loss: 329.8937683105469\n",
      "      vf_explained_var: 0.8450091481208801\n",
      "      vf_loss: 329.8966979980469\n",
      "    grad_time_ms: 1619.79\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "    sample_time_ms: 16117.328\n",
      "    update_time_ms: 4.832\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 819.7811005115509\n",
      "  time_this_iter_s: 18.17685890197754\n",
      "  time_total_s: 819.7811005115509\n",
      "  timestamp: 1550617239\n",
      "  timesteps_since_restore: 450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 45\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 819 s, 45 iter, 450000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-00-57\n",
      "  done: false\n",
      "  episode_len_mean: 151.41\n",
      "  episode_reward_max: 179.45019030387172\n",
      "  episode_reward_mean: 148.51816118308267\n",
      "  episode_reward_min: -41.62247625731003\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 2636\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.1641532356165829e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6231977939605713\n",
      "      kl: 0.0032076979987323284\n",
      "      policy_loss: -0.0019307824550196528\n",
      "      total_loss: 420.67041015625\n",
      "      vf_explained_var: 0.810194194316864\n",
      "      vf_loss: 420.6723327636719\n",
      "    grad_time_ms: 1619.114\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "    sample_time_ms: 16080.643\n",
      "    update_time_ms: 4.782\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 837.5391829013824\n",
      "  time_this_iter_s: 17.758082389831543\n",
      "  time_total_s: 837.5391829013824\n",
      "  timestamp: 1550617257\n",
      "  timesteps_since_restore: 460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 46\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 837 s, 46 iter, 460000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-01-15\n",
      "  done: false\n",
      "  episode_len_mean: 134.92\n",
      "  episode_reward_max: 180.47638951020662\n",
      "  episode_reward_mean: 144.713163819327\n",
      "  episode_reward_min: -56.63595226230008\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 2710\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.8207661780829145e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.476634979248047\n",
      "      kl: 0.01271022018045187\n",
      "      policy_loss: -0.0037498169112950563\n",
      "      total_loss: 398.4134216308594\n",
      "      vf_explained_var: 0.7900097966194153\n",
      "      vf_loss: 398.41717529296875\n",
      "    grad_time_ms: 1618.287\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 470000\n",
      "    num_steps_trained: 470000\n",
      "    sample_time_ms: 16099.836\n",
      "    update_time_ms: 4.757\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 855.3838152885437\n",
      "  time_this_iter_s: 17.844632387161255\n",
      "  time_total_s: 855.3838152885437\n",
      "  timestamp: 1550617275\n",
      "  timesteps_since_restore: 470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 470000\n",
      "  training_iteration: 47\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 855 s, 47 iter, 470000 ts, 145 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-01-33\n",
      "  done: false\n",
      "  episode_len_mean: 139.89\n",
      "  episode_reward_max: 181.94005489714021\n",
      "  episode_reward_mean: 142.70695425645482\n",
      "  episode_reward_min: -54.18269457586922\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 2779\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.8207661780829145e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6078832149505615\n",
      "      kl: 0.01656680926680565\n",
      "      policy_loss: -0.0038054788019508123\n",
      "      total_loss: 475.68157958984375\n",
      "      vf_explained_var: 0.765841007232666\n",
      "      vf_loss: 475.6853942871094\n",
      "    grad_time_ms: 1622.55\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "    sample_time_ms: 16113.638\n",
      "    update_time_ms: 4.72\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 873.315417766571\n",
      "  time_this_iter_s: 17.931602478027344\n",
      "  time_total_s: 873.315417766571\n",
      "  timestamp: 1550617293\n",
      "  timesteps_since_restore: 480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 48\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 873 s, 48 iter, 480000 ts, 143 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-01-51\n",
      "  done: false\n",
      "  episode_len_mean: 140.98\n",
      "  episode_reward_max: 184.96052307510138\n",
      "  episode_reward_mean: 146.58518087077672\n",
      "  episode_reward_min: -52.78293315579394\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 2850\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.8207661780829145e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5702857971191406\n",
      "      kl: 0.0028734924271702766\n",
      "      policy_loss: -0.0021859193220734596\n",
      "      total_loss: 424.85736083984375\n",
      "      vf_explained_var: 0.802794337272644\n",
      "      vf_loss: 424.8595275878906\n",
      "    grad_time_ms: 1621.686\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 490000\n",
      "    num_steps_trained: 490000\n",
      "    sample_time_ms: 16171.018\n",
      "    update_time_ms: 4.443\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 891.6249804496765\n",
      "  time_this_iter_s: 18.30956268310547\n",
      "  time_total_s: 891.6249804496765\n",
      "  timestamp: 1550617311\n",
      "  timesteps_since_restore: 490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 490000\n",
      "  training_iteration: 49\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 891 s, 49 iter, 490000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-02-09\n",
      "  done: false\n",
      "  episode_len_mean: 133.46\n",
      "  episode_reward_max: 185.1107780834954\n",
      "  episode_reward_mean: 140.74268758692233\n",
      "  episode_reward_min: -48.87468895699716\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 2927\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.9103830890414573e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5080935955047607\n",
      "      kl: 0.005965155083686113\n",
      "      policy_loss: -0.0015580746112391353\n",
      "      total_loss: 582.4149780273438\n",
      "      vf_explained_var: 0.6784688234329224\n",
      "      vf_loss: 582.41650390625\n",
      "    grad_time_ms: 1631.288\n",
      "    load_time_ms: 1.471\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "    sample_time_ms: 16197.139\n",
      "    update_time_ms: 4.623\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 909.5714778900146\n",
      "  time_this_iter_s: 17.946497440338135\n",
      "  time_total_s: 909.5714778900146\n",
      "  timestamp: 1550617329\n",
      "  timesteps_since_restore: 500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 50\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 909 s, 50 iter, 500000 ts, 141 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-02-29\n",
      "  done: false\n",
      "  episode_len_mean: 133.82\n",
      "  episode_reward_max: 185.1107780834954\n",
      "  episode_reward_mean: 139.98518918087655\n",
      "  episode_reward_min: -50.85678810707413\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 3004\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.4551915445207286e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4835915565490723\n",
      "      kl: 0.01158288773149252\n",
      "      policy_loss: -0.00305368285626173\n",
      "      total_loss: 437.5594482421875\n",
      "      vf_explained_var: 0.7665354609489441\n",
      "      vf_loss: 437.5625\n",
      "    grad_time_ms: 1642.254\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "    sample_time_ms: 16437.689\n",
      "    update_time_ms: 4.63\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 929.82479596138\n",
      "  time_this_iter_s: 20.253318071365356\n",
      "  time_total_s: 929.82479596138\n",
      "  timestamp: 1550617349\n",
      "  timesteps_since_restore: 510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 51\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 929 s, 51 iter, 510000 ts, 140 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-02-49\n",
      "  done: false\n",
      "  episode_len_mean: 136.54\n",
      "  episode_reward_max: 182.51210100100468\n",
      "  episode_reward_mean: 146.7078427406411\n",
      "  episode_reward_min: -48.233693706812204\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 3073\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.4551915445207286e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.588848352432251\n",
      "      kl: 0.01901896670460701\n",
      "      policy_loss: -0.004604866728186607\n",
      "      total_loss: 408.9245300292969\n",
      "      vf_explained_var: 0.8418949842453003\n",
      "      vf_loss: 408.92913818359375\n",
      "    grad_time_ms: 1666.796\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 520000\n",
      "    sample_time_ms: 16600.073\n",
      "    update_time_ms: 4.467\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 949.622936964035\n",
      "  time_this_iter_s: 19.79814100265503\n",
      "  time_total_s: 949.622936964035\n",
      "  timestamp: 1550617369\n",
      "  timesteps_since_restore: 520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 52\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 949 s, 52 iter, 520000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-03-12\n",
      "  done: false\n",
      "  episode_len_mean: 135.45\n",
      "  episode_reward_max: 186.0306156254051\n",
      "  episode_reward_mean: 152.77453257832389\n",
      "  episode_reward_min: -53.3509134847929\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 3151\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.4551915445207286e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4310154914855957\n",
      "      kl: 0.014354433864355087\n",
      "      policy_loss: -0.002985352883115411\n",
      "      total_loss: 420.9752502441406\n",
      "      vf_explained_var: 0.7743319869041443\n",
      "      vf_loss: 420.9781799316406\n",
      "    grad_time_ms: 1768.196\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 530000\n",
      "    num_steps_trained: 530000\n",
      "    sample_time_ms: 17028.974\n",
      "    update_time_ms: 4.556\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 972.209214925766\n",
      "  time_this_iter_s: 22.586277961730957\n",
      "  time_total_s: 972.209214925766\n",
      "  timestamp: 1550617392\n",
      "  timesteps_since_restore: 530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 530000\n",
      "  training_iteration: 53\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 972 s, 53 iter, 530000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-03-32\n",
      "  done: false\n",
      "  episode_len_mean: 139.2\n",
      "  episode_reward_max: 182.21208412384627\n",
      "  episode_reward_mean: 147.24863570820239\n",
      "  episode_reward_min: -53.3509134847929\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 3220\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.4551915445207286e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6163485050201416\n",
      "      kl: 0.009735002182424068\n",
      "      policy_loss: -0.0026241173036396503\n",
      "      total_loss: 434.1596984863281\n",
      "      vf_explained_var: 0.7922700047492981\n",
      "      vf_loss: 434.1622619628906\n",
      "    grad_time_ms: 1785.398\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "    sample_time_ms: 17316.22\n",
      "    update_time_ms: 4.5\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 992.8306922912598\n",
      "  time_this_iter_s: 20.621477365493774\n",
      "  time_total_s: 992.8306922912598\n",
      "  timestamp: 1550617412\n",
      "  timesteps_since_restore: 540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 54\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 992 s, 54 iter, 540000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-03-53\n",
      "  done: false\n",
      "  episode_len_mean: 141.61\n",
      "  episode_reward_max: 185.06364026097674\n",
      "  episode_reward_mean: 148.73428949037137\n",
      "  episode_reward_min: -58.22360251622624\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3292\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.275957722603643e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5250282287597656\n",
      "      kl: 0.00872498843818903\n",
      "      policy_loss: -0.0022731218487024307\n",
      "      total_loss: 444.1200866699219\n",
      "      vf_explained_var: 0.767185628414154\n",
      "      vf_loss: 444.1224060058594\n",
      "    grad_time_ms: 1795.013\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 550000\n",
      "    num_steps_trained: 550000\n",
      "    sample_time_ms: 17574.759\n",
      "    update_time_ms: 4.698\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1013.6923534870148\n",
      "  time_this_iter_s: 20.861661195755005\n",
      "  time_total_s: 1013.6923534870148\n",
      "  timestamp: 1550617433\n",
      "  timesteps_since_restore: 550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 550000\n",
      "  training_iteration: 55\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1013 s, 55 iter, 550000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-04-13\n",
      "  done: false\n",
      "  episode_len_mean: 138.73\n",
      "  episode_reward_max: 185.06364026097674\n",
      "  episode_reward_mean: 148.85255527475366\n",
      "  episode_reward_min: -59.93046711488525\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3364\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.6379788613018216e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5140323638916016\n",
      "      kl: 0.010771611705422401\n",
      "      policy_loss: -0.003908202983438969\n",
      "      total_loss: 370.7062683105469\n",
      "      vf_explained_var: 0.8447779417037964\n",
      "      vf_loss: 370.7101745605469\n",
      "    grad_time_ms: 1858.76\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "    sample_time_ms: 17760.813\n",
      "    update_time_ms: 4.793\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1033.9483301639557\n",
      "  time_this_iter_s: 20.255976676940918\n",
      "  time_total_s: 1033.9483301639557\n",
      "  timestamp: 1550617453\n",
      "  timesteps_since_restore: 560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 56\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1033 s, 56 iter, 560000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-04-40\n",
      "  done: false\n",
      "  episode_len_mean: 128.87\n",
      "  episode_reward_max: 187.28693400596106\n",
      "  episode_reward_mean: 134.28151576294445\n",
      "  episode_reward_min: -59.93046711488525\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 3443\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.6379788613018216e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3386809825897217\n",
      "      kl: 0.009987224824726582\n",
      "      policy_loss: -0.0031192933674901724\n",
      "      total_loss: 532.9047241210938\n",
      "      vf_explained_var: 0.6671484112739563\n",
      "      vf_loss: 532.9078979492188\n",
      "    grad_time_ms: 1894.875\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "    sample_time_ms: 18616.212\n",
      "    update_time_ms: 4.814\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1060.7124230861664\n",
      "  time_this_iter_s: 26.764092922210693\n",
      "  time_total_s: 1060.7124230861664\n",
      "  timestamp: 1550617480\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 57\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1060 s, 57 iter, 570000 ts, 134 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-05-08\n",
      "  done: false\n",
      "  episode_len_mean: 117.84\n",
      "  episode_reward_max: 181.45109310878973\n",
      "  episode_reward_mean: 131.5295331497548\n",
      "  episode_reward_min: -54.56728068997364\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 3528\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.8189894306509108e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.218170642852783\n",
      "      kl: 0.009706258773803711\n",
      "      policy_loss: -0.004313106648623943\n",
      "      total_loss: 564.1272583007812\n",
      "      vf_explained_var: 0.6355897188186646\n",
      "      vf_loss: 564.1315307617188\n",
      "    grad_time_ms: 2085.156\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "    sample_time_ms: 19389.804\n",
      "    update_time_ms: 5.109\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1088.2934262752533\n",
      "  time_this_iter_s: 27.581003189086914\n",
      "  time_total_s: 1088.2934262752533\n",
      "  timestamp: 1550617508\n",
      "  timesteps_since_restore: 580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 58\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1088 s, 58 iter, 580000 ts, 132 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-05-31\n",
      "  done: false\n",
      "  episode_len_mean: 118.87\n",
      "  episode_reward_max: 184.80174456064654\n",
      "  episode_reward_mean: 132.70302566838515\n",
      "  episode_reward_min: -50.06149948853077\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 3612\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.094947153254554e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3219079971313477\n",
      "      kl: 0.0230912696570158\n",
      "      policy_loss: -0.005395936779677868\n",
      "      total_loss: 599.3280029296875\n",
      "      vf_explained_var: 0.6134507060050964\n",
      "      vf_loss: 599.333251953125\n",
      "    grad_time_ms: 2151.136\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 590000\n",
      "    num_steps_trained: 590000\n",
      "    sample_time_ms: 19812.28\n",
      "    update_time_ms: 7.325\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1111.5110988616943\n",
      "  time_this_iter_s: 23.21767258644104\n",
      "  time_total_s: 1111.5110988616943\n",
      "  timestamp: 1550617531\n",
      "  timesteps_since_restore: 590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 590000\n",
      "  training_iteration: 59\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1111 s, 59 iter, 590000 ts, 133 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-06-07\n",
      "  done: false\n",
      "  episode_len_mean: 126.29\n",
      "  episode_reward_max: 180.62610495400318\n",
      "  episode_reward_mean: 140.02273274265315\n",
      "  episode_reward_min: -48.836063614871215\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 3691\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.094947153254554e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4206955432891846\n",
      "      kl: 0.008650057017803192\n",
      "      policy_loss: -0.0030639420729130507\n",
      "      total_loss: 447.210693359375\n",
      "      vf_explained_var: 0.7631505131721497\n",
      "      vf_loss: 447.21368408203125\n",
      "    grad_time_ms: 2315.035\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "    sample_time_ms: 21382.847\n",
      "    update_time_ms: 7.71\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1146.808667898178\n",
      "  time_this_iter_s: 35.297569036483765\n",
      "  time_total_s: 1146.808667898178\n",
      "  timestamp: 1550617567\n",
      "  timesteps_since_restore: 600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 60\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1146 s, 60 iter, 600000 ts, 140 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-06-32\n",
      "  done: false\n",
      "  episode_len_mean: 139.29\n",
      "  episode_reward_max: 185.92435926051417\n",
      "  episode_reward_mean: 148.57541098204447\n",
      "  episode_reward_min: -44.54472805692417\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 3764\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.547473576627277e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5436196327209473\n",
      "      kl: 0.02680007368326187\n",
      "      policy_loss: -0.005933642387390137\n",
      "      total_loss: 402.71746826171875\n",
      "      vf_explained_var: 0.8069671988487244\n",
      "      vf_loss: 402.7234191894531\n",
      "    grad_time_ms: 2348.963\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 610000\n",
      "    num_steps_trained: 610000\n",
      "    sample_time_ms: 21897.907\n",
      "    update_time_ms: 7.963\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1172.5517272949219\n",
      "  time_this_iter_s: 25.743059396743774\n",
      "  time_total_s: 1172.5517272949219\n",
      "  timestamp: 1550617592\n",
      "  timesteps_since_restore: 610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 610000\n",
      "  training_iteration: 61\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1172 s, 61 iter, 610000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-07-01\n",
      "  done: false\n",
      "  episode_len_mean: 139.47\n",
      "  episode_reward_max: 185.2567137021683\n",
      "  episode_reward_mean: 147.72955426104852\n",
      "  episode_reward_min: -50.01077888950263\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 3835\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.547473576627277e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5472240447998047\n",
      "      kl: 0.008109107613563538\n",
      "      policy_loss: -0.0025186962448060513\n",
      "      total_loss: 358.291259765625\n",
      "      vf_explained_var: 0.8266487121582031\n",
      "      vf_loss: 358.29376220703125\n",
      "    grad_time_ms: 2369.986\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "    sample_time_ms: 22793.873\n",
      "    update_time_ms: 8.09\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1201.5195152759552\n",
      "  time_this_iter_s: 28.967787981033325\n",
      "  time_total_s: 1201.5195152759552\n",
      "  timestamp: 1550617621\n",
      "  timesteps_since_restore: 620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 62\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1201 s, 62 iter, 620000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-07-28\n",
      "  done: false\n",
      "  episode_len_mean: 127.31\n",
      "  episode_reward_max: 185.94704553861135\n",
      "  episode_reward_mean: 141.6325840013428\n",
      "  episode_reward_min: -50.01077888950263\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 3915\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3590798377990723\n",
      "      kl: 0.022899381816387177\n",
      "      policy_loss: -0.005909775849431753\n",
      "      total_loss: 426.02264404296875\n",
      "      vf_explained_var: 0.7817772626876831\n",
      "      vf_loss: 426.0285949707031\n",
      "    grad_time_ms: 2403.272\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "    sample_time_ms: 23149.308\n",
      "    update_time_ms: 8.4\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1228.0073878765106\n",
      "  time_this_iter_s: 26.48787260055542\n",
      "  time_total_s: 1228.0073878765106\n",
      "  timestamp: 1550617648\n",
      "  timesteps_since_restore: 630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 63\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1228 s, 63 iter, 630000 ts, 142 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-07-59\n",
      "  done: false\n",
      "  episode_len_mean: 127.72\n",
      "  episode_reward_max: 191.57693183953222\n",
      "  episode_reward_mean: 149.75582541108253\n",
      "  episode_reward_min: -50.51613817887733\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 3993\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.370145082473755\n",
      "      kl: 0.02720227651298046\n",
      "      policy_loss: -0.005758683197200298\n",
      "      total_loss: 292.58892822265625\n",
      "      vf_explained_var: 0.868342399597168\n",
      "      vf_loss: 292.5947265625\n",
      "    grad_time_ms: 2670.013\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 640000\n",
      "    num_steps_trained: 640000\n",
      "    sample_time_ms: 23911.032\n",
      "    update_time_ms: 8.875\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1258.9240365028381\n",
      "  time_this_iter_s: 30.916648626327515\n",
      "  time_total_s: 1258.9240365028381\n",
      "  timestamp: 1550617679\n",
      "  timesteps_since_restore: 640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 640000\n",
      "  training_iteration: 64\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1258 s, 64 iter, 640000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-08-26\n",
      "  done: false\n",
      "  episode_len_mean: 123.0\n",
      "  episode_reward_max: 187.00549796762147\n",
      "  episode_reward_mean: 149.40660820554336\n",
      "  episode_reward_min: -51.41655939522355\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 4074\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2841427326202393\n",
      "      kl: 0.024303246289491653\n",
      "      policy_loss: -0.004525313153862953\n",
      "      total_loss: 332.4257507324219\n",
      "      vf_explained_var: 0.83377605676651\n",
      "      vf_loss: 332.4303283691406\n",
      "    grad_time_ms: 2730.0\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 650000\n",
      "    num_steps_trained: 650000\n",
      "    sample_time_ms: 24459.534\n",
      "    update_time_ms: 8.957\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1285.8726193904877\n",
      "  time_this_iter_s: 26.948582887649536\n",
      "  time_total_s: 1285.8726193904877\n",
      "  timestamp: 1550617706\n",
      "  timesteps_since_restore: 650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 650000\n",
      "  training_iteration: 65\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1285 s, 65 iter, 650000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-08-54\n",
      "  done: false\n",
      "  episode_len_mean: 124.12\n",
      "  episode_reward_max: 189.2915259146748\n",
      "  episode_reward_mean: 147.3475764237983\n",
      "  episode_reward_min: -51.41655939522355\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 4153\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3661839962005615\n",
      "      kl: 0.01907779648900032\n",
      "      policy_loss: -0.004606190603226423\n",
      "      total_loss: 353.4212341308594\n",
      "      vf_explained_var: 0.8223037719726562\n",
      "      vf_loss: 353.42584228515625\n",
      "    grad_time_ms: 2728.016\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "    sample_time_ms: 25203.876\n",
      "    update_time_ms: 9.061\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1313.5558278560638\n",
      "  time_this_iter_s: 27.683208465576172\n",
      "  time_total_s: 1313.5558278560638\n",
      "  timestamp: 1550617734\n",
      "  timesteps_since_restore: 660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 66\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1313 s, 66 iter, 660000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-09-18\n",
      "  done: false\n",
      "  episode_len_mean: 127.94\n",
      "  episode_reward_max: 187.32803986442855\n",
      "  episode_reward_mean: 157.0331248630315\n",
      "  episode_reward_min: -38.320853313006964\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 4231\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.379056692123413\n",
      "      kl: 0.0129982465878129\n",
      "      policy_loss: -0.004504282493144274\n",
      "      total_loss: 327.25970458984375\n",
      "      vf_explained_var: 0.8508366346359253\n",
      "      vf_loss: 327.2642517089844\n",
      "    grad_time_ms: 2859.095\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 670000\n",
      "    num_steps_trained: 670000\n",
      "    sample_time_ms: 24809.847\n",
      "    update_time_ms: 9.16\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1337.6994979381561\n",
      "  time_this_iter_s: 24.143670082092285\n",
      "  time_total_s: 1337.6994979381561\n",
      "  timestamp: 1550617758\n",
      "  timesteps_since_restore: 670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 670000\n",
      "  training_iteration: 67\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1337 s, 67 iter, 670000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-10-12\n",
      "  done: false\n",
      "  episode_len_mean: 128.56\n",
      "  episode_reward_max: 191.26831067456754\n",
      "  episode_reward_mean: 146.07715160790266\n",
      "  episode_reward_min: -52.89151511688044\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 4308\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4542276859283447\n",
      "      kl: 0.012067927978932858\n",
      "      policy_loss: -0.0016981827793642879\n",
      "      total_loss: 465.02252197265625\n",
      "      vf_explained_var: 0.7882174849510193\n",
      "      vf_loss: 465.0242004394531\n",
      "    grad_time_ms: 2919.501\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "    sample_time_ms: 27443.116\n",
      "    update_time_ms: 9.206\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1392.2248034477234\n",
      "  time_this_iter_s: 54.52530550956726\n",
      "  time_total_s: 1392.2248034477234\n",
      "  timestamp: 1550617812\n",
      "  timesteps_since_restore: 680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 68\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1392 s, 68 iter, 680000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 125.79\n",
      "  episode_reward_max: 190.78735067791277\n",
      "  episode_reward_mean: 149.6632842080799\n",
      "  episode_reward_min: -54.6959143033122\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 4390\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.186180353164673\n",
      "      kl: 0.006544156931340694\n",
      "      policy_loss: -0.004227679688483477\n",
      "      total_loss: 443.37554931640625\n",
      "      vf_explained_var: 0.7505916953086853\n",
      "      vf_loss: 443.3798522949219\n",
      "    grad_time_ms: 3041.411\n",
      "    load_time_ms: 1.828\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "    sample_time_ms: 27999.71\n",
      "    update_time_ms: 7.63\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1422.2161922454834\n",
      "  time_this_iter_s: 29.99138879776001\n",
      "  time_total_s: 1422.2161922454834\n",
      "  timestamp: 1550617842\n",
      "  timesteps_since_restore: 690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 69\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1422 s, 69 iter, 690000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 118.95\n",
      "  episode_reward_max: 182.74052971867062\n",
      "  episode_reward_mean: 144.49615518916028\n",
      "  episode_reward_min: -51.998414784669855\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 4474\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.1368683941568192e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.172262668609619\n",
      "      kl: 0.004429371561855078\n",
      "      policy_loss: -0.0016161802923306823\n",
      "      total_loss: 431.7911682128906\n",
      "      vf_explained_var: 0.7588833570480347\n",
      "      vf_loss: 431.7927551269531\n",
      "    grad_time_ms: 2888.931\n",
      "    load_time_ms: 1.838\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "    sample_time_ms: 27030.714\n",
      "    update_time_ms: 7.278\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1446.2952525615692\n",
      "  time_this_iter_s: 24.079060316085815\n",
      "  time_total_s: 1446.2952525615692\n",
      "  timestamp: 1550617867\n",
      "  timesteps_since_restore: 700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 70\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1446 s, 70 iter, 700000 ts, 144 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 122.68\n",
      "  episode_reward_max: 184.13765168278522\n",
      "  episode_reward_mean: 150.06289674691158\n",
      "  episode_reward_min: -51.998414784669855\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 4555\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.684341970784096e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.255596876144409\n",
      "      kl: 0.019440850242972374\n",
      "      policy_loss: -0.004750207532197237\n",
      "      total_loss: 326.04302978515625\n",
      "      vf_explained_var: 0.8438113331794739\n",
      "      vf_loss: 326.04779052734375\n",
      "    grad_time_ms: 2852.106\n",
      "    load_time_ms: 1.869\n",
      "    num_steps_sampled: 710000\n",
      "    num_steps_trained: 710000\n",
      "    sample_time_ms: 26426.792\n",
      "    update_time_ms: 7.183\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1465.6299245357513\n",
      "  time_this_iter_s: 19.33467197418213\n",
      "  time_total_s: 1465.6299245357513\n",
      "  timestamp: 1550617886\n",
      "  timesteps_since_restore: 710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 710000\n",
      "  training_iteration: 71\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1465 s, 71 iter, 710000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-11-50\n",
      "  done: false\n",
      "  episode_len_mean: 122.08\n",
      "  episode_reward_max: 182.5002404091382\n",
      "  episode_reward_mean: 151.02125832615175\n",
      "  episode_reward_min: -41.926493448491144\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 4637\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.684341970784096e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2407073974609375\n",
      "      kl: 0.004709223285317421\n",
      "      policy_loss: -0.0012553995475172997\n",
      "      total_loss: 320.8857727050781\n",
      "      vf_explained_var: 0.8316600322723389\n",
      "      vf_loss: 320.8869934082031\n",
      "    grad_time_ms: 2895.425\n",
      "    load_time_ms: 1.954\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "    sample_time_ms: 25848.678\n",
      "    update_time_ms: 7.158\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1489.2564301490784\n",
      "  time_this_iter_s: 23.626505613327026\n",
      "  time_total_s: 1489.2564301490784\n",
      "  timestamp: 1550617910\n",
      "  timesteps_since_restore: 720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 72\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1489 s, 72 iter, 720000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-12-09\n",
      "  done: false\n",
      "  episode_len_mean: 122.53\n",
      "  episode_reward_max: 186.38695931714958\n",
      "  episode_reward_mean: 152.57973099152707\n",
      "  episode_reward_min: -40.02450992653868\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 4718\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.842170985392048e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.229957103729248\n",
      "      kl: 0.029053082689642906\n",
      "      policy_loss: -0.004599397536367178\n",
      "      total_loss: 275.7268981933594\n",
      "      vf_explained_var: 0.8633512854576111\n",
      "      vf_loss: 275.7314758300781\n",
      "    grad_time_ms: 2758.735\n",
      "    load_time_ms: 1.954\n",
      "    num_steps_sampled: 730000\n",
      "    num_steps_trained: 730000\n",
      "    sample_time_ms: 25246.531\n",
      "    update_time_ms: 7.122\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1508.341561794281\n",
      "  time_this_iter_s: 19.085131645202637\n",
      "  time_total_s: 1508.341561794281\n",
      "  timestamp: 1550617929\n",
      "  timesteps_since_restore: 730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 730000\n",
      "  training_iteration: 73\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1508 s, 73 iter, 730000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-12-27\n",
      "  done: false\n",
      "  episode_len_mean: 123.13\n",
      "  episode_reward_max: 184.02648085665584\n",
      "  episode_reward_mean: 152.15758388987908\n",
      "  episode_reward_min: -42.73131159626612\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 4799\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.842170985392048e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2963204383850098\n",
      "      kl: 0.009588660672307014\n",
      "      policy_loss: -0.0024063081946223974\n",
      "      total_loss: 272.87005615234375\n",
      "      vf_explained_var: 0.8629879951477051\n",
      "      vf_loss: 272.8724670410156\n",
      "    grad_time_ms: 2473.794\n",
      "    load_time_ms: 1.936\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "    sample_time_ms: 24212.755\n",
      "    update_time_ms: 6.69\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1526.058462381363\n",
      "  time_this_iter_s: 17.71690058708191\n",
      "  time_total_s: 1526.058462381363\n",
      "  timestamp: 1550617947\n",
      "  timesteps_since_restore: 740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 74\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1526 s, 74 iter, 740000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-12-44\n",
      "  done: false\n",
      "  episode_len_mean: 121.7\n",
      "  episode_reward_max: 186.98946737357883\n",
      "  episode_reward_mean: 147.9712273141332\n",
      "  episode_reward_min: -48.533094711232884\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 4881\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.421085492696024e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.355278968811035\n",
      "      kl: 0.021802404895424843\n",
      "      policy_loss: -0.005521884188055992\n",
      "      total_loss: 363.85968017578125\n",
      "      vf_explained_var: 0.8080742359161377\n",
      "      vf_loss: 363.865234375\n",
      "    grad_time_ms: 2404.304\n",
      "    load_time_ms: 1.962\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "    sample_time_ms: 23382.311\n",
      "    update_time_ms: 6.354\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1544.001122713089\n",
      "  time_this_iter_s: 17.942660331726074\n",
      "  time_total_s: 1544.001122713089\n",
      "  timestamp: 1550617964\n",
      "  timesteps_since_restore: 750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 75\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1544 s, 75 iter, 750000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-13-02\n",
      "  done: false\n",
      "  episode_len_mean: 123.96\n",
      "  episode_reward_max: 184.71357883070363\n",
      "  episode_reward_mean: 145.70502340303426\n",
      "  episode_reward_min: -54.258929286262756\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 4963\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.421085492696024e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.385396718978882\n",
      "      kl: 0.02435961738228798\n",
      "      policy_loss: -0.006830213125795126\n",
      "      total_loss: 394.8532409667969\n",
      "      vf_explained_var: 0.7942879796028137\n",
      "      vf_loss: 394.8600769042969\n",
      "    grad_time_ms: 2343.26\n",
      "    load_time_ms: 1.964\n",
      "    num_steps_sampled: 760000\n",
      "    num_steps_trained: 760000\n",
      "    sample_time_ms: 22407.806\n",
      "    update_time_ms: 6.299\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1561.3270728588104\n",
      "  time_this_iter_s: 17.325950145721436\n",
      "  time_total_s: 1561.3270728588104\n",
      "  timestamp: 1550617982\n",
      "  timesteps_since_restore: 760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 760000\n",
      "  training_iteration: 76\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1561 s, 76 iter, 760000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-13-20\n",
      "  done: false\n",
      "  episode_len_mean: 124.39\n",
      "  episode_reward_max: 182.67749396291117\n",
      "  episode_reward_mean: 139.11303578986917\n",
      "  episode_reward_min: -50.0951667832266\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 5043\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.421085492696024e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3743185997009277\n",
      "      kl: 0.015436077490448952\n",
      "      policy_loss: -0.008147242479026318\n",
      "      total_loss: 433.6502990722656\n",
      "      vf_explained_var: 0.76643967628479\n",
      "      vf_loss: 433.6584167480469\n",
      "    grad_time_ms: 2174.701\n",
      "    load_time_ms: 1.985\n",
      "    num_steps_sampled: 770000\n",
      "    num_steps_trained: 770000\n",
      "    sample_time_ms: 21935.623\n",
      "    update_time_ms: 6.291\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1579.0515916347504\n",
      "  time_this_iter_s: 17.72451877593994\n",
      "  time_total_s: 1579.0515916347504\n",
      "  timestamp: 1550618000\n",
      "  timesteps_since_restore: 770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 770000\n",
      "  training_iteration: 77\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1579 s, 77 iter, 770000 ts, 139 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-13-38\n",
      "  done: false\n",
      "  episode_len_mean: 125.52\n",
      "  episode_reward_max: 181.02340133502918\n",
      "  episode_reward_mean: 146.6818055721649\n",
      "  episode_reward_min: -46.44718256120637\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 5124\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.421085492696024e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3325278759002686\n",
      "      kl: 0.009222337044775486\n",
      "      policy_loss: -0.002200876362621784\n",
      "      total_loss: 288.30291748046875\n",
      "      vf_explained_var: 0.8529782295227051\n",
      "      vf_loss: 288.3050842285156\n",
      "    grad_time_ms: 1917.29\n",
      "    load_time_ms: 1.908\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "    sample_time_ms: 18533.565\n",
      "    update_time_ms: 6.105\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1596.9647572040558\n",
      "  time_this_iter_s: 17.91316556930542\n",
      "  time_total_s: 1596.9647572040558\n",
      "  timestamp: 1550618018\n",
      "  timesteps_since_restore: 780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 78\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1596 s, 78 iter, 780000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-13-55\n",
      "  done: false\n",
      "  episode_len_mean: 124.32\n",
      "  episode_reward_max: 189.5757273124291\n",
      "  episode_reward_mean: 146.08844085768328\n",
      "  episode_reward_min: -40.87147138880031\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 5204\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.10542746348012e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4207592010498047\n",
      "      kl: 0.01647954247891903\n",
      "      policy_loss: -0.006901078391820192\n",
      "      total_loss: 277.7972106933594\n",
      "      vf_explained_var: 0.8584588170051575\n",
      "      vf_loss: 277.8040466308594\n",
      "    grad_time_ms: 1725.147\n",
      "    load_time_ms: 1.731\n",
      "    num_steps_sampled: 790000\n",
      "    num_steps_trained: 790000\n",
      "    sample_time_ms: 17504.273\n",
      "    update_time_ms: 5.387\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1614.7262649536133\n",
      "  time_this_iter_s: 17.761507749557495\n",
      "  time_total_s: 1614.7262649536133\n",
      "  timestamp: 1550618035\n",
      "  timesteps_since_restore: 790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 790000\n",
      "  training_iteration: 79\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1614 s, 79 iter, 790000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-14-13\n",
      "  done: false\n",
      "  episode_len_mean: 127.01\n",
      "  episode_reward_max: 186.6419316807595\n",
      "  episode_reward_mean: 151.57320506545904\n",
      "  episode_reward_min: -40.22631942812759\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 5282\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.10542746348012e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.398723602294922\n",
      "      kl: 0.011817743070423603\n",
      "      policy_loss: -0.004078551661223173\n",
      "      total_loss: 141.7427215576172\n",
      "      vf_explained_var: 0.9434909224510193\n",
      "      vf_loss: 141.74679565429688\n",
      "    grad_time_ms: 1699.896\n",
      "    load_time_ms: 1.75\n",
      "    num_steps_sampled: 800000\n",
      "    num_steps_trained: 800000\n",
      "    sample_time_ms: 16897.002\n",
      "    update_time_ms: 5.227\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1632.4770386219025\n",
      "  time_this_iter_s: 17.750773668289185\n",
      "  time_total_s: 1632.4770386219025\n",
      "  timestamp: 1550618053\n",
      "  timesteps_since_restore: 800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 800000\n",
      "  training_iteration: 80\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1632 s, 80 iter, 800000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-14-30\n",
      "  done: false\n",
      "  episode_len_mean: 125.11\n",
      "  episode_reward_max: 186.6419316807595\n",
      "  episode_reward_mean: 146.9773010716628\n",
      "  episode_reward_min: -44.167503325065745\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 5362\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.10542746348012e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.426072835922241\n",
      "      kl: 0.008835182525217533\n",
      "      policy_loss: -0.005785214714705944\n",
      "      total_loss: 340.8943176269531\n",
      "      vf_explained_var: 0.8318364024162292\n",
      "      vf_loss: 340.9001159667969\n",
      "    grad_time_ms: 1686.755\n",
      "    load_time_ms: 1.777\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "    sample_time_ms: 16700.952\n",
      "    update_time_ms: 5.099\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1649.7178182601929\n",
      "  time_this_iter_s: 17.240779638290405\n",
      "  time_total_s: 1649.7178182601929\n",
      "  timestamp: 1550618070\n",
      "  timesteps_since_restore: 810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 81\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1649 s, 81 iter, 810000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-14-48\n",
      "  done: false\n",
      "  episode_len_mean: 128.22\n",
      "  episode_reward_max: 185.6569789139056\n",
      "  episode_reward_mean: 150.7414494736427\n",
      "  episode_reward_min: -53.50556484572959\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 5440\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.55271373174006e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4991703033447266\n",
      "      kl: 0.0033301229123026133\n",
      "      policy_loss: -0.0019818264991045\n",
      "      total_loss: 214.71731567382812\n",
      "      vf_explained_var: 0.8974340558052063\n",
      "      vf_loss: 214.71932983398438\n",
      "    grad_time_ms: 1591.624\n",
      "    load_time_ms: 1.707\n",
      "    num_steps_sampled: 820000\n",
      "    num_steps_trained: 820000\n",
      "    sample_time_ms: 16165.931\n",
      "    update_time_ms: 5.147\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1667.0319511890411\n",
      "  time_this_iter_s: 17.314132928848267\n",
      "  time_total_s: 1667.0319511890411\n",
      "  timestamp: 1550618088\n",
      "  timesteps_since_restore: 820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 820000\n",
      "  training_iteration: 82\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1667 s, 82 iter, 820000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-15-05\n",
      "  done: false\n",
      "  episode_len_mean: 125.16\n",
      "  episode_reward_max: 185.08742545972973\n",
      "  episode_reward_mean: 152.23920374598208\n",
      "  episode_reward_min: -36.73234995166854\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 5520\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.77635686587003e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4186477661132812\n",
      "      kl: 0.028894448652863503\n",
      "      policy_loss: -0.003988963086158037\n",
      "      total_loss: 153.64566040039062\n",
      "      vf_explained_var: 0.9287627935409546\n",
      "      vf_loss: 153.649658203125\n",
      "    grad_time_ms: 1586.691\n",
      "    load_time_ms: 1.679\n",
      "    num_steps_sampled: 830000\n",
      "    num_steps_trained: 830000\n",
      "    sample_time_ms: 16009.351\n",
      "    update_time_ms: 4.774\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1684.497311592102\n",
      "  time_this_iter_s: 17.465360403060913\n",
      "  time_total_s: 1684.497311592102\n",
      "  timestamp: 1550618105\n",
      "  timesteps_since_restore: 830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 830000\n",
      "  training_iteration: 83\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1684 s, 83 iter, 830000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-15-23\n",
      "  done: false\n",
      "  episode_len_mean: 125.85\n",
      "  episode_reward_max: 189.93132337942558\n",
      "  episode_reward_mean: 149.1321942827275\n",
      "  episode_reward_min: -48.475260438010224\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 5600\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.77635686587003e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4232728481292725\n",
      "      kl: 0.004982746671885252\n",
      "      policy_loss: -0.0020356313325464725\n",
      "      total_loss: 256.21826171875\n",
      "      vf_explained_var: 0.8715318441390991\n",
      "      vf_loss: 256.22027587890625\n",
      "    grad_time_ms: 1580.533\n",
      "    load_time_ms: 1.74\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "    sample_time_ms: 16004.745\n",
      "    update_time_ms: 4.798\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1702.1085410118103\n",
      "  time_this_iter_s: 17.611229419708252\n",
      "  time_total_s: 1702.1085410118103\n",
      "  timestamp: 1550618123\n",
      "  timesteps_since_restore: 840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 84\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1702 s, 84 iter, 840000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-15-41\n",
      "  done: false\n",
      "  episode_len_mean: 132.03\n",
      "  episode_reward_max: 192.42622241554884\n",
      "  episode_reward_mean: 152.11824914413745\n",
      "  episode_reward_min: -42.53102931572068\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 5675\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.88178432935015e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.647909164428711\n",
      "      kl: 0.035060085356235504\n",
      "      policy_loss: -0.008283304050564766\n",
      "      total_loss: 145.16409301757812\n",
      "      vf_explained_var: 0.9359892010688782\n",
      "      vf_loss: 145.17237854003906\n",
      "    grad_time_ms: 1574.15\n",
      "    load_time_ms: 1.689\n",
      "    num_steps_sampled: 850000\n",
      "    num_steps_trained: 850000\n",
      "    sample_time_ms: 15982.981\n",
      "    update_time_ms: 4.873\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1719.7690954208374\n",
      "  time_this_iter_s: 17.6605544090271\n",
      "  time_total_s: 1719.7690954208374\n",
      "  timestamp: 1550618141\n",
      "  timesteps_since_restore: 850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 850000\n",
      "  training_iteration: 85\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1719 s, 85 iter, 850000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-15-58\n",
      "  done: false\n",
      "  episode_len_mean: 129.28\n",
      "  episode_reward_max: 176.14088890104003\n",
      "  episode_reward_mean: 145.39841723161575\n",
      "  episode_reward_min: -43.52306533715512\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 5752\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.88178432935015e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5567312240600586\n",
      "      kl: 0.026713356375694275\n",
      "      policy_loss: -0.0064431047067046165\n",
      "      total_loss: 249.7567138671875\n",
      "      vf_explained_var: 0.874542236328125\n",
      "      vf_loss: 249.76312255859375\n",
      "    grad_time_ms: 1567.674\n",
      "    load_time_ms: 1.656\n",
      "    num_steps_sampled: 860000\n",
      "    num_steps_trained: 860000\n",
      "    sample_time_ms: 16036.482\n",
      "    update_time_ms: 4.738\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1737.561951160431\n",
      "  time_this_iter_s: 17.792855739593506\n",
      "  time_total_s: 1737.561951160431\n",
      "  timestamp: 1550618158\n",
      "  timesteps_since_restore: 860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 860000\n",
      "  training_iteration: 86\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1737 s, 86 iter, 860000 ts, 145 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-16-16\n",
      "  done: false\n",
      "  episode_len_mean: 130.38\n",
      "  episode_reward_max: 184.93769249703618\n",
      "  episode_reward_mean: 147.17622860174419\n",
      "  episode_reward_min: -41.172346894988905\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 5829\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.88178432935015e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.664407968521118\n",
      "      kl: 0.011755494400858879\n",
      "      policy_loss: -0.0030962820164859295\n",
      "      total_loss: 236.7538299560547\n",
      "      vf_explained_var: 0.8826270699501038\n",
      "      vf_loss: 236.7568817138672\n",
      "    grad_time_ms: 1563.263\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "    sample_time_ms: 16059.775\n",
      "    update_time_ms: 4.691\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1755.476190328598\n",
      "  time_this_iter_s: 17.914239168167114\n",
      "  time_total_s: 1755.476190328598\n",
      "  timestamp: 1550618176\n",
      "  timesteps_since_restore: 870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 87\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1755 s, 87 iter, 870000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-16-34\n",
      "  done: false\n",
      "  episode_len_mean: 129.34\n",
      "  episode_reward_max: 184.93769249703618\n",
      "  episode_reward_mean: 149.5975845900085\n",
      "  episode_reward_min: -46.20809376711894\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 5906\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.88178432935015e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.545715570449829\n",
      "      kl: 0.013794837519526482\n",
      "      policy_loss: -0.004021192900836468\n",
      "      total_loss: 125.90805053710938\n",
      "      vf_explained_var: 0.9409815669059753\n",
      "      vf_loss: 125.91205596923828\n",
      "    grad_time_ms: 1559.796\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "    sample_time_ms: 16010.107\n",
      "    update_time_ms: 4.6\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1772.855923652649\n",
      "  time_this_iter_s: 17.379733324050903\n",
      "  time_total_s: 1772.855923652649\n",
      "  timestamp: 1550618194\n",
      "  timesteps_since_restore: 880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 88\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1772 s, 88 iter, 880000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-16-51\n",
      "  done: false\n",
      "  episode_len_mean: 133.87\n",
      "  episode_reward_max: 184.5329291994619\n",
      "  episode_reward_mean: 151.98299939696508\n",
      "  episode_reward_min: -38.69886627232673\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 5979\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.88178432935015e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6962506771087646\n",
      "      kl: 0.026002859696745872\n",
      "      policy_loss: -0.004333518445491791\n",
      "      total_loss: 159.69285583496094\n",
      "      vf_explained_var: 0.929544985294342\n",
      "      vf_loss: 159.6971893310547\n",
      "    grad_time_ms: 1555.2\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 890000\n",
      "    num_steps_trained: 890000\n",
      "    sample_time_ms: 15981.36\n",
      "    update_time_ms: 4.631\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1790.2843072414398\n",
      "  time_this_iter_s: 17.428383588790894\n",
      "  time_total_s: 1790.2843072414398\n",
      "  timestamp: 1550618211\n",
      "  timesteps_since_restore: 890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 890000\n",
      "  training_iteration: 89\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1790 s, 89 iter, 890000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 133.1\n",
      "  episode_reward_max: 193.55641682160908\n",
      "  episode_reward_mean: 148.67804910787095\n",
      "  episode_reward_min: -53.17063299264057\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 6054\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.88178432935015e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.761963129043579\n",
      "      kl: 0.007679959759116173\n",
      "      policy_loss: -0.002192230662330985\n",
      "      total_loss: 314.6773986816406\n",
      "      vf_explained_var: 0.8558259606361389\n",
      "      vf_loss: 314.6795654296875\n",
      "    grad_time_ms: 1554.676\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "    sample_time_ms: 15972.955\n",
      "    update_time_ms: 4.54\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1807.9444062709808\n",
      "  time_this_iter_s: 17.660099029541016\n",
      "  time_total_s: 1807.9444062709808\n",
      "  timestamp: 1550618229\n",
      "  timesteps_since_restore: 900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 90\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1807 s, 90 iter, 900000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-17-26\n",
      "  done: false\n",
      "  episode_len_mean: 128.85\n",
      "  episode_reward_max: 183.39141287765298\n",
      "  episode_reward_mean: 148.9214701275963\n",
      "  episode_reward_min: -43.869388278168\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 6132\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.440892164675075e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.584242820739746\n",
      "      kl: 0.018537741154432297\n",
      "      policy_loss: -0.0027568156365305185\n",
      "      total_loss: 173.9114990234375\n",
      "      vf_explained_var: 0.9164601564407349\n",
      "      vf_loss: 173.9142303466797\n",
      "    grad_time_ms: 1551.592\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 910000\n",
      "    num_steps_trained: 910000\n",
      "    sample_time_ms: 15974.355\n",
      "    update_time_ms: 4.612\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1825.1689283847809\n",
      "  time_this_iter_s: 17.22452211380005\n",
      "  time_total_s: 1825.1689283847809\n",
      "  timestamp: 1550618246\n",
      "  timesteps_since_restore: 910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 910000\n",
      "  training_iteration: 91\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1825 s, 91 iter, 910000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-17-44\n",
      "  done: false\n",
      "  episode_len_mean: 128.39\n",
      "  episode_reward_max: 188.21195973079688\n",
      "  episode_reward_mean: 154.55985798349045\n",
      "  episode_reward_min: -41.89905190792415\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 6210\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.440892164675075e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5109283924102783\n",
      "      kl: 0.014475102536380291\n",
      "      policy_loss: -0.006966618355363607\n",
      "      total_loss: 122.44490051269531\n",
      "      vf_explained_var: 0.9442083835601807\n",
      "      vf_loss: 122.45187377929688\n",
      "    grad_time_ms: 1552.082\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "    sample_time_ms: 16039.217\n",
      "    update_time_ms: 4.603\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1843.138985157013\n",
      "  time_this_iter_s: 17.970056772232056\n",
      "  time_total_s: 1843.138985157013\n",
      "  timestamp: 1550618264\n",
      "  timesteps_since_restore: 920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 92\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1843 s, 92 iter, 920000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-18-02\n",
      "  done: false\n",
      "  episode_len_mean: 129.13\n",
      "  episode_reward_max: 198.6231867753635\n",
      "  episode_reward_mean: 152.33677587641148\n",
      "  episode_reward_min: -43.54507191848047\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 6287\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.440892164675075e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6281254291534424\n",
      "      kl: 0.006851318757981062\n",
      "      policy_loss: -0.003151965094730258\n",
      "      total_loss: 219.4890899658203\n",
      "      vf_explained_var: 0.8984361290931702\n",
      "      vf_loss: 219.49221801757812\n",
      "    grad_time_ms: 1553.252\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "    sample_time_ms: 16045.251\n",
      "    update_time_ms: 4.646\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1860.678284406662\n",
      "  time_this_iter_s: 17.539299249649048\n",
      "  time_total_s: 1860.678284406662\n",
      "  timestamp: 1550618282\n",
      "  timesteps_since_restore: 930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 93\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1860 s, 93 iter, 930000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-18-19\n",
      "  done: false\n",
      "  episode_len_mean: 129.12\n",
      "  episode_reward_max: 184.4038943698501\n",
      "  episode_reward_mean: 152.2355017768963\n",
      "  episode_reward_min: -52.34904400605966\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 6364\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2204460823375376e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6413841247558594\n",
      "      kl: 0.01769520901143551\n",
      "      policy_loss: -0.0035664737224578857\n",
      "      total_loss: 110.07747650146484\n",
      "      vf_explained_var: 0.9492356777191162\n",
      "      vf_loss: 110.08101654052734\n",
      "    grad_time_ms: 1554.485\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 940000\n",
      "    num_steps_trained: 940000\n",
      "    sample_time_ms: 16002.892\n",
      "    update_time_ms: 4.57\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1877.8746929168701\n",
      "  time_this_iter_s: 17.19640851020813\n",
      "  time_total_s: 1877.8746929168701\n",
      "  timestamp: 1550618299\n",
      "  timesteps_since_restore: 940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 940000\n",
      "  training_iteration: 94\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1877 s, 94 iter, 940000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-18-36\n",
      "  done: false\n",
      "  episode_len_mean: 130.0\n",
      "  episode_reward_max: 192.99832143582927\n",
      "  episode_reward_mean: 150.8508826068189\n",
      "  episode_reward_min: -54.47545201560058\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 6440\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2204460823375376e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6776316165924072\n",
      "      kl: 0.015181326307356358\n",
      "      policy_loss: -0.0025575037579983473\n",
      "      total_loss: 133.2393341064453\n",
      "      vf_explained_var: 0.9414044618606567\n",
      "      vf_loss: 133.24188232421875\n",
      "    grad_time_ms: 1553.076\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 950000\n",
      "    num_steps_trained: 950000\n",
      "    sample_time_ms: 15971.929\n",
      "    update_time_ms: 4.515\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1895.2116537094116\n",
      "  time_this_iter_s: 17.336960792541504\n",
      "  time_total_s: 1895.2116537094116\n",
      "  timestamp: 1550618316\n",
      "  timesteps_since_restore: 950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 950000\n",
      "  training_iteration: 95\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1895 s, 95 iter, 950000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-18-54\n",
      "  done: false\n",
      "  episode_len_mean: 128.31\n",
      "  episode_reward_max: 191.71496906581493\n",
      "  episode_reward_mean: 147.9890473933179\n",
      "  episode_reward_min: -50.55127905353463\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 6519\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2204460823375376e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5920629501342773\n",
      "      kl: 0.01079384982585907\n",
      "      policy_loss: -0.004851993173360825\n",
      "      total_loss: 399.60675048828125\n",
      "      vf_explained_var: 0.8280826210975647\n",
      "      vf_loss: 399.6116638183594\n",
      "    grad_time_ms: 1554.109\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "    sample_time_ms: 15941.026\n",
      "    update_time_ms: 4.521\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1912.7063617706299\n",
      "  time_this_iter_s: 17.49470806121826\n",
      "  time_total_s: 1912.7063617706299\n",
      "  timestamp: 1550618334\n",
      "  timesteps_since_restore: 960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 96\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1912 s, 96 iter, 960000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-19-11\n",
      "  done: false\n",
      "  episode_len_mean: 129.43\n",
      "  episode_reward_max: 194.10354167518045\n",
      "  episode_reward_mean: 154.0586615803788\n",
      "  episode_reward_min: -50.55127905353463\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 6596\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.2204460823375376e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6263999938964844\n",
      "      kl: 0.00889586377888918\n",
      "      policy_loss: -0.0028682409320026636\n",
      "      total_loss: 108.34199523925781\n",
      "      vf_explained_var: 0.9507274031639099\n",
      "      vf_loss: 108.34487915039062\n",
      "    grad_time_ms: 1553.96\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 970000\n",
      "    num_steps_trained: 970000\n",
      "    sample_time_ms: 15897.868\n",
      "    update_time_ms: 4.594\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1930.1870334148407\n",
      "  time_this_iter_s: 17.480671644210815\n",
      "  time_total_s: 1930.1870334148407\n",
      "  timestamp: 1550618351\n",
      "  timesteps_since_restore: 970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 970000\n",
      "  training_iteration: 97\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1930 s, 97 iter, 970000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-19-29\n",
      "  done: false\n",
      "  episode_len_mean: 132.98\n",
      "  episode_reward_max: 194.1537020082521\n",
      "  episode_reward_mean: 150.66175108152822\n",
      "  episode_reward_min: -41.26410317598001\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 6670\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.1102230411687688e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.880388021469116\n",
      "      kl: 0.007951385341584682\n",
      "      policy_loss: -0.0023192139342427254\n",
      "      total_loss: 261.6145935058594\n",
      "      vf_explained_var: 0.8831140398979187\n",
      "      vf_loss: 261.616943359375\n",
      "    grad_time_ms: 1552.913\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 980000\n",
      "    num_steps_trained: 980000\n",
      "    sample_time_ms: 15887.227\n",
      "    update_time_ms: 4.45\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1947.4497117996216\n",
      "  time_this_iter_s: 17.262678384780884\n",
      "  time_total_s: 1947.4497117996216\n",
      "  timestamp: 1550618369\n",
      "  timesteps_since_restore: 980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 980000\n",
      "  training_iteration: 98\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1947 s, 98 iter, 980000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-19-47\n",
      "  done: false\n",
      "  episode_len_mean: 131.09\n",
      "  episode_reward_max: 194.1537020082521\n",
      "  episode_reward_mean: 152.2859184692521\n",
      "  episode_reward_min: -45.42482221008528\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 6747\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.551115205843844e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7580723762512207\n",
      "      kl: 0.010832984931766987\n",
      "      policy_loss: -0.003871609689667821\n",
      "      total_loss: 108.59593963623047\n",
      "      vf_explained_var: 0.9517939686775208\n",
      "      vf_loss: 108.59983825683594\n",
      "    grad_time_ms: 1552.238\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "    sample_time_ms: 15916.631\n",
      "    update_time_ms: 4.497\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1965.1648888587952\n",
      "  time_this_iter_s: 17.715177059173584\n",
      "  time_total_s: 1965.1648888587952\n",
      "  timestamp: 1550618387\n",
      "  timesteps_since_restore: 990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 99\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1965 s, 99 iter, 990000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-20-04\n",
      "  done: false\n",
      "  episode_len_mean: 127.17\n",
      "  episode_reward_max: 195.35060771148983\n",
      "  episode_reward_mean: 151.01311961626723\n",
      "  episode_reward_min: -41.37303967729651\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 6826\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.551115205843844e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5467302799224854\n",
      "      kl: 0.008043289184570312\n",
      "      policy_loss: -0.003578910371288657\n",
      "      total_loss: 222.67933654785156\n",
      "      vf_explained_var: 0.8959344625473022\n",
      "      vf_loss: 222.68292236328125\n",
      "    grad_time_ms: 1552.362\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "    sample_time_ms: 15864.32\n",
      "    update_time_ms: 4.508\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1982.3048787117004\n",
      "  time_this_iter_s: 17.139989852905273\n",
      "  time_total_s: 1982.3048787117004\n",
      "  timestamp: 1550618404\n",
      "  timesteps_since_restore: 1000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 100\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1982 s, 100 iter, 1000000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-20-21\n",
      "  done: false\n",
      "  episode_len_mean: 128.73\n",
      "  episode_reward_max: 195.35060771148983\n",
      "  episode_reward_mean: 153.74535502111746\n",
      "  episode_reward_min: -38.41789176292935\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 6904\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.775557602921922e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6506972312927246\n",
      "      kl: 0.012122300453484058\n",
      "      policy_loss: -0.0032464356627315283\n",
      "      total_loss: 92.08456420898438\n",
      "      vf_explained_var: 0.9590263366699219\n",
      "      vf_loss: 92.08780670166016\n",
      "    grad_time_ms: 1555.038\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 1010000\n",
      "    num_steps_trained: 1010000\n",
      "    sample_time_ms: 15833.469\n",
      "    update_time_ms: 4.391\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 1999.2457809448242\n",
      "  time_this_iter_s: 16.94090223312378\n",
      "  time_total_s: 1999.2457809448242\n",
      "  timestamp: 1550618421\n",
      "  timesteps_since_restore: 1010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1010000\n",
      "  training_iteration: 101\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 1999 s, 101 iter, 1010000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-20-39\n",
      "  done: false\n",
      "  episode_len_mean: 123.41\n",
      "  episode_reward_max: 183.02507951560594\n",
      "  episode_reward_mean: 145.69916566981112\n",
      "  episode_reward_min: -50.325778154748505\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 6985\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.775557602921922e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4686408042907715\n",
      "      kl: 0.010362059809267521\n",
      "      policy_loss: -0.0016479423502460122\n",
      "      total_loss: 346.5101013183594\n",
      "      vf_explained_var: 0.8473894000053406\n",
      "      vf_loss: 346.5117492675781\n",
      "    grad_time_ms: 1552.965\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "    sample_time_ms: 15819.723\n",
      "    update_time_ms: 4.267\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2017.05682015419\n",
      "  time_this_iter_s: 17.811039209365845\n",
      "  time_total_s: 2017.05682015419\n",
      "  timestamp: 1550618439\n",
      "  timesteps_since_restore: 1020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 102\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2017 s, 102 iter, 1020000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 129.46\n",
      "  episode_reward_max: 196.22198990400486\n",
      "  episode_reward_mean: 150.33106331813403\n",
      "  episode_reward_min: -43.55571829416965\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 7061\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.775557602921922e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.685199737548828\n",
      "      kl: 0.013039901852607727\n",
      "      policy_loss: -0.004296127241104841\n",
      "      total_loss: 150.71038818359375\n",
      "      vf_explained_var: 0.9330543875694275\n",
      "      vf_loss: 150.7146759033203\n",
      "    grad_time_ms: 1552.8\n",
      "    load_time_ms: 1.391\n",
      "    num_steps_sampled: 1030000\n",
      "    num_steps_trained: 1030000\n",
      "    sample_time_ms: 15835.378\n",
      "    update_time_ms: 4.24\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2034.7488687038422\n",
      "  time_this_iter_s: 17.6920485496521\n",
      "  time_total_s: 2034.7488687038422\n",
      "  timestamp: 1550618456\n",
      "  timesteps_since_restore: 1030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1030000\n",
      "  training_iteration: 103\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2034 s, 103 iter, 1030000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-21-13\n",
      "  done: false\n",
      "  episode_len_mean: 127.01\n",
      "  episode_reward_max: 190.231974993602\n",
      "  episode_reward_mean: 148.1690609646659\n",
      "  episode_reward_min: -44.692888523682505\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 7140\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.775557602921922e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6311655044555664\n",
      "      kl: 0.01140038762241602\n",
      "      policy_loss: -0.0012203666847199202\n",
      "      total_loss: 206.536865234375\n",
      "      vf_explained_var: 0.9052487015724182\n",
      "      vf_loss: 206.53807067871094\n",
      "    grad_time_ms: 1551.297\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "    sample_time_ms: 15815.869\n",
      "    update_time_ms: 4.28\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2051.735320329666\n",
      "  time_this_iter_s: 16.986451625823975\n",
      "  time_total_s: 2051.735320329666\n",
      "  timestamp: 1550618473\n",
      "  timesteps_since_restore: 1040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 104\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2051 s, 104 iter, 1040000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-21-31\n",
      "  done: false\n",
      "  episode_len_mean: 128.54\n",
      "  episode_reward_max: 190.231974993602\n",
      "  episode_reward_mean: 145.31199468533075\n",
      "  episode_reward_min: -46.167757651888486\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 7218\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.775557602921922e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7080860137939453\n",
      "      kl: 0.016938377171754837\n",
      "      policy_loss: -0.004212459083646536\n",
      "      total_loss: 269.015380859375\n",
      "      vf_explained_var: 0.8791090846061707\n",
      "      vf_loss: 269.01959228515625\n",
      "    grad_time_ms: 1553.959\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "    sample_time_ms: 15831.141\n",
      "    update_time_ms: 4.221\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2069.251614332199\n",
      "  time_this_iter_s: 17.51629400253296\n",
      "  time_total_s: 2069.251614332199\n",
      "  timestamp: 1550618491\n",
      "  timesteps_since_restore: 1050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 105\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2069 s, 105 iter, 1050000 ts, 145 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-21-48\n",
      "  done: false\n",
      "  episode_len_mean: 129.03\n",
      "  episode_reward_max: 192.7394963541243\n",
      "  episode_reward_mean: 148.96968365459773\n",
      "  episode_reward_min: -46.167757651888486\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 7295\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.775557602921922e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7169408798217773\n",
      "      kl: 0.008441387675702572\n",
      "      policy_loss: -0.0025123192463070154\n",
      "      total_loss: 82.18094635009766\n",
      "      vf_explained_var: 0.962072491645813\n",
      "      vf_loss: 82.1834716796875\n",
      "    grad_time_ms: 1552.641\n",
      "    load_time_ms: 1.362\n",
      "    num_steps_sampled: 1060000\n",
      "    num_steps_trained: 1060000\n",
      "    sample_time_ms: 15838.142\n",
      "    update_time_ms: 4.248\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2086.802534341812\n",
      "  time_this_iter_s: 17.550920009613037\n",
      "  time_total_s: 2086.802534341812\n",
      "  timestamp: 1550618508\n",
      "  timesteps_since_restore: 1060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1060000\n",
      "  training_iteration: 106\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2086 s, 106 iter, 1060000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-22-06\n",
      "  done: false\n",
      "  episode_len_mean: 132.24\n",
      "  episode_reward_max: 197.03843493066213\n",
      "  episode_reward_mean: 156.7982138992671\n",
      "  episode_reward_min: -37.8374266494619\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 7370\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.387778801460961e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7937076091766357\n",
      "      kl: 0.01693410612642765\n",
      "      policy_loss: -0.005721000488847494\n",
      "      total_loss: 88.79090881347656\n",
      "      vf_explained_var: 0.9601597785949707\n",
      "      vf_loss: 88.79664611816406\n",
      "    grad_time_ms: 1552.599\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 1070000\n",
      "    num_steps_trained: 1070000\n",
      "    sample_time_ms: 15853.429\n",
      "    update_time_ms: 4.037\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2104.433254003525\n",
      "  time_this_iter_s: 17.630719661712646\n",
      "  time_total_s: 2104.433254003525\n",
      "  timestamp: 1550618526\n",
      "  timesteps_since_restore: 1070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1070000\n",
      "  training_iteration: 107\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2104 s, 107 iter, 1070000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-22-24\n",
      "  done: false\n",
      "  episode_len_mean: 129.7\n",
      "  episode_reward_max: 187.42597783511812\n",
      "  episode_reward_mean: 148.7343141420425\n",
      "  episode_reward_min: -49.34676860995814\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 7448\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.387778801460961e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.680039644241333\n",
      "      kl: 0.009224051609635353\n",
      "      policy_loss: -0.0024899302516132593\n",
      "      total_loss: 319.9681091308594\n",
      "      vf_explained_var: 0.8637165427207947\n",
      "      vf_loss: 319.9706115722656\n",
      "    grad_time_ms: 1551.477\n",
      "    load_time_ms: 1.372\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "    sample_time_ms: 15886.342\n",
      "    update_time_ms: 4.174\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2122.015287399292\n",
      "  time_this_iter_s: 17.582033395767212\n",
      "  time_total_s: 2122.015287399292\n",
      "  timestamp: 1550618544\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 108\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2122 s, 108 iter, 1080000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-22-41\n",
      "  done: false\n",
      "  episode_len_mean: 129.18\n",
      "  episode_reward_max: 192.49710702763343\n",
      "  episode_reward_mean: 153.33829316228474\n",
      "  episode_reward_min: -47.601686163703995\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 7525\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.938894007304805e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.654223918914795\n",
      "      kl: 0.006934914272278547\n",
      "      policy_loss: -0.00410702358931303\n",
      "      total_loss: 148.9091339111328\n",
      "      vf_explained_var: 0.9317088723182678\n",
      "      vf_loss: 148.9132537841797\n",
      "    grad_time_ms: 1551.319\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 1090000\n",
      "    num_steps_trained: 1090000\n",
      "    sample_time_ms: 15854.549\n",
      "    update_time_ms: 4.111\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2139.4112849235535\n",
      "  time_this_iter_s: 17.395997524261475\n",
      "  time_total_s: 2139.4112849235535\n",
      "  timestamp: 1550618561\n",
      "  timesteps_since_restore: 1090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1090000\n",
      "  training_iteration: 109\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2139 s, 109 iter, 1090000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-22-58\n",
      "  done: false\n",
      "  episode_len_mean: 126.72\n",
      "  episode_reward_max: 189.2296894213349\n",
      "  episode_reward_mean: 153.61055732917688\n",
      "  episode_reward_min: -51.56336731131713\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 7604\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.4694470036524025e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.46626877784729\n",
      "      kl: 0.009132377803325653\n",
      "      policy_loss: -0.0033581883180886507\n",
      "      total_loss: 193.00965881347656\n",
      "      vf_explained_var: 0.9168190360069275\n",
      "      vf_loss: 193.01300048828125\n",
      "    grad_time_ms: 1550.256\n",
      "    load_time_ms: 1.364\n",
      "    num_steps_sampled: 1100000\n",
      "    num_steps_trained: 1100000\n",
      "    sample_time_ms: 15853.486\n",
      "    update_time_ms: 4.346\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2156.529457092285\n",
      "  time_this_iter_s: 17.11817216873169\n",
      "  time_total_s: 2156.529457092285\n",
      "  timestamp: 1550618578\n",
      "  timesteps_since_restore: 1100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1100000\n",
      "  training_iteration: 110\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2156 s, 110 iter, 1100000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-23-15\n",
      "  done: false\n",
      "  episode_len_mean: 131.04\n",
      "  episode_reward_max: 206.83644953915984\n",
      "  episode_reward_mean: 150.9969316450639\n",
      "  episode_reward_min: -45.44495478449481\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 7680\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.7347235018262012e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.774923324584961\n",
      "      kl: 0.006834389176219702\n",
      "      policy_loss: -0.004015155136585236\n",
      "      total_loss: 249.4469451904297\n",
      "      vf_explained_var: 0.8957455158233643\n",
      "      vf_loss: 249.45094299316406\n",
      "    grad_time_ms: 1550.39\n",
      "    load_time_ms: 1.316\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "    sample_time_ms: 15863.411\n",
      "    update_time_ms: 4.366\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2173.56990814209\n",
      "  time_this_iter_s: 17.040451049804688\n",
      "  time_total_s: 2173.56990814209\n",
      "  timestamp: 1550618595\n",
      "  timesteps_since_restore: 1110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 111\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2173 s, 111 iter, 1110000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-23-33\n",
      "  done: false\n",
      "  episode_len_mean: 131.99\n",
      "  episode_reward_max: 199.82535098817675\n",
      "  episode_reward_mean: 151.38271430518523\n",
      "  episode_reward_min: -45.44495478449481\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 7755\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.673617509131006e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.748838424682617\n",
      "      kl: 0.007153531536459923\n",
      "      policy_loss: -0.0013292854418978095\n",
      "      total_loss: 140.46192932128906\n",
      "      vf_explained_var: 0.9386061429977417\n",
      "      vf_loss: 140.4632568359375\n",
      "    grad_time_ms: 1551.083\n",
      "    load_time_ms: 1.268\n",
      "    num_steps_sampled: 1120000\n",
      "    num_steps_trained: 1120000\n",
      "    sample_time_ms: 15799.337\n",
      "    update_time_ms: 4.479\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2190.7457954883575\n",
      "  time_this_iter_s: 17.1758873462677\n",
      "  time_total_s: 2190.7457954883575\n",
      "  timestamp: 1550618613\n",
      "  timesteps_since_restore: 1120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1120000\n",
      "  training_iteration: 112\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2190 s, 112 iter, 1120000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-23-50\n",
      "  done: false\n",
      "  episode_len_mean: 132.37\n",
      "  episode_reward_max: 193.2934889842084\n",
      "  episode_reward_mean: 155.47784954000602\n",
      "  episode_reward_min: -51.70184783268684\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 7832\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.336808754565503e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7212893962860107\n",
      "      kl: 0.013602366670966148\n",
      "      policy_loss: -0.0015074929688125849\n",
      "      total_loss: 142.179931640625\n",
      "      vf_explained_var: 0.940747857093811\n",
      "      vf_loss: 142.1814422607422\n",
      "    grad_time_ms: 1550.362\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 1130000\n",
      "    num_steps_trained: 1130000\n",
      "    sample_time_ms: 15811.031\n",
      "    update_time_ms: 4.573\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2208.5515484809875\n",
      "  time_this_iter_s: 17.805752992630005\n",
      "  time_total_s: 2208.5515484809875\n",
      "  timestamp: 1550618630\n",
      "  timesteps_since_restore: 1130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1130000\n",
      "  training_iteration: 113\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2208 s, 113 iter, 1130000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-24-08\n",
      "  done: false\n",
      "  episode_len_mean: 129.61\n",
      "  episode_reward_max: 188.87598247427758\n",
      "  episode_reward_mean: 145.94652860359818\n",
      "  episode_reward_min: -48.665722887483554\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 7909\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.336808754565503e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6953704357147217\n",
      "      kl: 0.01025803480297327\n",
      "      policy_loss: -0.001401176443323493\n",
      "      total_loss: 343.96539306640625\n",
      "      vf_explained_var: 0.862742006778717\n",
      "      vf_loss: 343.966796875\n",
      "    grad_time_ms: 1550.803\n",
      "    load_time_ms: 1.395\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "    sample_time_ms: 15852.044\n",
      "    update_time_ms: 4.61\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2225.9561064243317\n",
      "  time_this_iter_s: 17.404557943344116\n",
      "  time_total_s: 2225.9561064243317\n",
      "  timestamp: 1550618648\n",
      "  timesteps_since_restore: 1140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 114\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2225 s, 114 iter, 1140000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-24-25\n",
      "  done: false\n",
      "  episode_len_mean: 125.95\n",
      "  episode_reward_max: 193.77141576950038\n",
      "  episode_reward_mean: 138.1187138007557\n",
      "  episode_reward_min: -53.61018095158116\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 7989\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.336808754565503e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6229074001312256\n",
      "      kl: 0.009359125047922134\n",
      "      policy_loss: -0.003200493985787034\n",
      "      total_loss: 370.6396789550781\n",
      "      vf_explained_var: 0.843515157699585\n",
      "      vf_loss: 370.642822265625\n",
      "    grad_time_ms: 1550.362\n",
      "    load_time_ms: 1.4\n",
      "    num_steps_sampled: 1150000\n",
      "    num_steps_trained: 1150000\n",
      "    sample_time_ms: 15838.371\n",
      "    update_time_ms: 4.721\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2243.3318359851837\n",
      "  time_this_iter_s: 17.37572956085205\n",
      "  time_total_s: 2243.3318359851837\n",
      "  timestamp: 1550618665\n",
      "  timesteps_since_restore: 1150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1150000\n",
      "  training_iteration: 115\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2243 s, 115 iter, 1150000 ts, 138 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-24-42\n",
      "  done: false\n",
      "  episode_len_mean: 129.47\n",
      "  episode_reward_max: 193.77141576950038\n",
      "  episode_reward_mean: 152.05730110019388\n",
      "  episode_reward_min: -50.82133810502468\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8066\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.1684043772827515e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6544365882873535\n",
      "      kl: 0.01267270091921091\n",
      "      policy_loss: -0.004251361358910799\n",
      "      total_loss: 110.80181121826172\n",
      "      vf_explained_var: 0.9528852701187134\n",
      "      vf_loss: 110.80607604980469\n",
      "    grad_time_ms: 1549.591\n",
      "    load_time_ms: 1.4\n",
      "    num_steps_sampled: 1160000\n",
      "    num_steps_trained: 1160000\n",
      "    sample_time_ms: 15801.023\n",
      "    update_time_ms: 4.792\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2260.5016491413116\n",
      "  time_this_iter_s: 17.16981315612793\n",
      "  time_total_s: 2260.5016491413116\n",
      "  timestamp: 1550618682\n",
      "  timesteps_since_restore: 1160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1160000\n",
      "  training_iteration: 116\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2260 s, 116 iter, 1160000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-25-00\n",
      "  done: false\n",
      "  episode_len_mean: 130.43\n",
      "  episode_reward_max: 197.13612072184517\n",
      "  episode_reward_mean: 151.99601795328678\n",
      "  episode_reward_min: -49.89178062326246\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 8142\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.1684043772827515e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.739492654800415\n",
      "      kl: 0.007879529148340225\n",
      "      policy_loss: -0.002084675244987011\n",
      "      total_loss: 94.40838623046875\n",
      "      vf_explained_var: 0.9620912075042725\n",
      "      vf_loss: 94.41046905517578\n",
      "    grad_time_ms: 1550.105\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "    sample_time_ms: 15744.415\n",
      "    update_time_ms: 4.879\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2277.571501016617\n",
      "  time_this_iter_s: 17.069851875305176\n",
      "  time_total_s: 2277.571501016617\n",
      "  timestamp: 1550618700\n",
      "  timesteps_since_restore: 1170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 117\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2277 s, 117 iter, 1170000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-25-17\n",
      "  done: false\n",
      "  episode_len_mean: 128.16\n",
      "  episode_reward_max: 197.13612072184517\n",
      "  episode_reward_mean: 152.22350314009415\n",
      "  episode_reward_min: -50.25006213843232\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 8220\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0842021886413758e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6477928161621094\n",
      "      kl: 0.013465662486851215\n",
      "      policy_loss: -0.002066556829959154\n",
      "      total_loss: 176.21498107910156\n",
      "      vf_explained_var: 0.9237704277038574\n",
      "      vf_loss: 176.217041015625\n",
      "    grad_time_ms: 1551.32\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 1180000\n",
      "    num_steps_trained: 1180000\n",
      "    sample_time_ms: 15709.231\n",
      "    update_time_ms: 4.868\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2294.8137435913086\n",
      "  time_this_iter_s: 17.242242574691772\n",
      "  time_total_s: 2294.8137435913086\n",
      "  timestamp: 1550618717\n",
      "  timesteps_since_restore: 1180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1180000\n",
      "  training_iteration: 118\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2294 s, 118 iter, 1180000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-25-34\n",
      "  done: false\n",
      "  episode_len_mean: 131.25\n",
      "  episode_reward_max: 196.6530602497627\n",
      "  episode_reward_mean: 155.3356072910441\n",
      "  episode_reward_min: -37.91487577749362\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 8295\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0842021886413758e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.659987211227417\n",
      "      kl: 0.008647329173982143\n",
      "      policy_loss: -0.0023485012352466583\n",
      "      total_loss: 75.38119506835938\n",
      "      vf_explained_var: 0.9682316184043884\n",
      "      vf_loss: 75.38353729248047\n",
      "    grad_time_ms: 1552.264\n",
      "    load_time_ms: 1.339\n",
      "    num_steps_sampled: 1190000\n",
      "    num_steps_trained: 1190000\n",
      "    sample_time_ms: 15681.37\n",
      "    update_time_ms: 4.785\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2311.9395439624786\n",
      "  time_this_iter_s: 17.125800371170044\n",
      "  time_total_s: 2311.9395439624786\n",
      "  timestamp: 1550618734\n",
      "  timesteps_since_restore: 1190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1190000\n",
      "  training_iteration: 119\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2311 s, 119 iter, 1190000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-25-52\n",
      "  done: false\n",
      "  episode_len_mean: 126.17\n",
      "  episode_reward_max: 193.56672531366328\n",
      "  episode_reward_mean: 146.7229674399405\n",
      "  episode_reward_min: -47.97609260088145\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 8377\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.421010943206879e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.416889190673828\n",
      "      kl: 0.008961163461208344\n",
      "      policy_loss: -0.004185445141047239\n",
      "      total_loss: 329.986572265625\n",
      "      vf_explained_var: 0.8650265336036682\n",
      "      vf_loss: 329.9907531738281\n",
      "    grad_time_ms: 1554.092\n",
      "    load_time_ms: 1.362\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "    sample_time_ms: 15750.792\n",
      "    update_time_ms: 4.611\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2329.767594575882\n",
      "  time_this_iter_s: 17.82805061340332\n",
      "  time_total_s: 2329.767594575882\n",
      "  timestamp: 1550618752\n",
      "  timesteps_since_restore: 1200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 120\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2329 s, 120 iter, 1200000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-26-09\n",
      "  done: false\n",
      "  episode_len_mean: 131.33\n",
      "  episode_reward_max: 193.16121611227788\n",
      "  episode_reward_mean: 149.55258525930466\n",
      "  episode_reward_min: -44.5731802202097\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 8452\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7105054716034394e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7774763107299805\n",
      "      kl: 0.009257528930902481\n",
      "      policy_loss: -0.0037197016645222902\n",
      "      total_loss: 138.0635528564453\n",
      "      vf_explained_var: 0.9438694715499878\n",
      "      vf_loss: 138.0672607421875\n",
      "    grad_time_ms: 1554.439\n",
      "    load_time_ms: 1.371\n",
      "    num_steps_sampled: 1210000\n",
      "    num_steps_trained: 1210000\n",
      "    sample_time_ms: 15762.308\n",
      "    update_time_ms: 4.559\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2346.9265422821045\n",
      "  time_this_iter_s: 17.158947706222534\n",
      "  time_total_s: 2346.9265422821045\n",
      "  timestamp: 1550618769\n",
      "  timesteps_since_restore: 1210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1210000\n",
      "  training_iteration: 121\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2346 s, 121 iter, 1210000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-26-26\n",
      "  done: false\n",
      "  episode_len_mean: 129.27\n",
      "  episode_reward_max: 188.00406215480058\n",
      "  episode_reward_mean: 149.90164177291442\n",
      "  episode_reward_min: -43.6814643268538\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8529\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.3552527358017197e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7997777462005615\n",
      "      kl: 0.017432983964681625\n",
      "      policy_loss: -0.00856623612344265\n",
      "      total_loss: 116.84976959228516\n",
      "      vf_explained_var: 0.9471758604049683\n",
      "      vf_loss: 116.85836029052734\n",
      "    grad_time_ms: 1554.042\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 1220000\n",
      "    num_steps_trained: 1220000\n",
      "    sample_time_ms: 15741.941\n",
      "    update_time_ms: 4.558\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2363.895716190338\n",
      "  time_this_iter_s: 16.969173908233643\n",
      "  time_total_s: 2363.895716190338\n",
      "  timestamp: 1550618786\n",
      "  timesteps_since_restore: 1220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1220000\n",
      "  training_iteration: 122\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2363 s, 122 iter, 1220000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-26-43\n",
      "  done: false\n",
      "  episode_len_mean: 129.94\n",
      "  episode_reward_max: 191.2147701757379\n",
      "  episode_reward_mean: 153.70056954462564\n",
      "  episode_reward_min: -50.82874563498662\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8606\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.3552527358017197e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.62597393989563\n",
      "      kl: 0.010140752419829369\n",
      "      policy_loss: -0.005199092905968428\n",
      "      total_loss: 137.26870727539062\n",
      "      vf_explained_var: 0.938081681728363\n",
      "      vf_loss: 137.27391052246094\n",
      "    grad_time_ms: 1556.461\n",
      "    load_time_ms: 1.324\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "    sample_time_ms: 15665.69\n",
      "    update_time_ms: 4.478\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2380.9612696170807\n",
      "  time_this_iter_s: 17.065553426742554\n",
      "  time_total_s: 2380.9612696170807\n",
      "  timestamp: 1550618803\n",
      "  timesteps_since_restore: 1230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 123\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2380 s, 123 iter, 1230000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-27-01\n",
      "  done: false\n",
      "  episode_len_mean: 127.58\n",
      "  episode_reward_max: 196.9257834190779\n",
      "  episode_reward_mean: 147.66810323071468\n",
      "  episode_reward_min: -50.82874563498662\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 8684\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.3552527358017197e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6114141941070557\n",
      "      kl: 0.010338670574128628\n",
      "      policy_loss: -0.002905009314417839\n",
      "      total_loss: 274.0682067871094\n",
      "      vf_explained_var: 0.8928529024124146\n",
      "      vf_loss: 274.0711364746094\n",
      "    grad_time_ms: 1561.107\n",
      "    load_time_ms: 1.376\n",
      "    num_steps_sampled: 1240000\n",
      "    num_steps_trained: 1240000\n",
      "    sample_time_ms: 15697.051\n",
      "    update_time_ms: 4.483\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2398.7251574993134\n",
      "  time_this_iter_s: 17.763887882232666\n",
      "  time_total_s: 2398.7251574993134\n",
      "  timestamp: 1550618821\n",
      "  timesteps_since_restore: 1240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1240000\n",
      "  training_iteration: 124\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2398 s, 124 iter, 1240000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-27-18\n",
      "  done: false\n",
      "  episode_len_mean: 129.3\n",
      "  episode_reward_max: 196.9257834190779\n",
      "  episode_reward_mean: 156.34613901517844\n",
      "  episode_reward_min: -44.600254736619405\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8761\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.3552527358017197e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6584458351135254\n",
      "      kl: 0.028127498924732208\n",
      "      policy_loss: 0.001574115245603025\n",
      "      total_loss: 142.4192657470703\n",
      "      vf_explained_var: 0.9372618198394775\n",
      "      vf_loss: 142.4176788330078\n",
      "    grad_time_ms: 1558.487\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 1250000\n",
      "    num_steps_trained: 1250000\n",
      "    sample_time_ms: 15676.649\n",
      "    update_time_ms: 4.386\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2415.8711943626404\n",
      "  time_this_iter_s: 17.146036863327026\n",
      "  time_total_s: 2415.8711943626404\n",
      "  timestamp: 1550618838\n",
      "  timesteps_since_restore: 1250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1250000\n",
      "  training_iteration: 125\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2415 s, 125 iter, 1250000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-27-36\n",
      "  done: false\n",
      "  episode_len_mean: 127.21\n",
      "  episode_reward_max: 186.9306850191389\n",
      "  episode_reward_mean: 150.18734374379176\n",
      "  episode_reward_min: -46.13817420719871\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 8839\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.3552527358017197e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6030209064483643\n",
      "      kl: 0.012329010292887688\n",
      "      policy_loss: -0.0016355315456166863\n",
      "      total_loss: 226.4841766357422\n",
      "      vf_explained_var: 0.904180645942688\n",
      "      vf_loss: 226.48582458496094\n",
      "    grad_time_ms: 1563.581\n",
      "    load_time_ms: 1.416\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "    sample_time_ms: 15698.576\n",
      "    update_time_ms: 4.429\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2433.31094789505\n",
      "  time_this_iter_s: 17.439753532409668\n",
      "  time_total_s: 2433.31094789505\n",
      "  timestamp: 1550618856\n",
      "  timesteps_since_restore: 1260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 126\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2433 s, 126 iter, 1260000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-27-54\n",
      "  done: false\n",
      "  episode_len_mean: 127.23\n",
      "  episode_reward_max: 192.10037973198567\n",
      "  episode_reward_mean: 154.9653513224285\n",
      "  episode_reward_min: -46.13817420719871\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 8918\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.3552527358017197e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4282922744750977\n",
      "      kl: 0.00859239511191845\n",
      "      policy_loss: 0.0018794414354488254\n",
      "      total_loss: 15.990320205688477\n",
      "      vf_explained_var: 0.9929774403572083\n",
      "      vf_loss: 15.98844051361084\n",
      "    grad_time_ms: 1572.515\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 1270000\n",
      "    num_steps_trained: 1270000\n",
      "    sample_time_ms: 15765.854\n",
      "    update_time_ms: 4.454\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2451.145114660263\n",
      "  time_this_iter_s: 17.834166765213013\n",
      "  time_total_s: 2451.145114660263\n",
      "  timestamp: 1550618874\n",
      "  timesteps_since_restore: 1270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1270000\n",
      "  training_iteration: 127\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2451 s, 127 iter, 1270000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 128.74\n",
      "  episode_reward_max: 199.90254597742074\n",
      "  episode_reward_mean: 150.18411764498228\n",
      "  episode_reward_min: -43.63813013103928\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8995\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.776263679008599e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6941492557525635\n",
      "      kl: 0.0076813530176877975\n",
      "      policy_loss: -0.001748768612742424\n",
      "      total_loss: 174.49266052246094\n",
      "      vf_explained_var: 0.9271782040596008\n",
      "      vf_loss: 174.49440002441406\n",
      "    grad_time_ms: 1570.337\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 1280000\n",
      "    num_steps_trained: 1280000\n",
      "    sample_time_ms: 15793.382\n",
      "    update_time_ms: 4.42\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2468.6387445926666\n",
      "  time_this_iter_s: 17.493629932403564\n",
      "  time_total_s: 2468.6387445926666\n",
      "  timestamp: 1550618891\n",
      "  timesteps_since_restore: 1280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1280000\n",
      "  training_iteration: 128\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2468 s, 128 iter, 1280000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-28-28\n",
      "  done: false\n",
      "  episode_len_mean: 131.07\n",
      "  episode_reward_max: 199.90254597742074\n",
      "  episode_reward_mean: 146.78743114036936\n",
      "  episode_reward_min: -52.94687288733993\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 9072\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.3881318395042993e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.65267014503479\n",
      "      kl: 0.013935885392129421\n",
      "      policy_loss: -0.00533351069316268\n",
      "      total_loss: 253.2920379638672\n",
      "      vf_explained_var: 0.8980105519294739\n",
      "      vf_loss: 253.29734802246094\n",
      "    grad_time_ms: 1569.951\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "    sample_time_ms: 15808.558\n",
      "    update_time_ms: 4.517\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2485.9121944904327\n",
      "  time_this_iter_s: 17.273449897766113\n",
      "  time_total_s: 2485.9121944904327\n",
      "  timestamp: 1550618908\n",
      "  timesteps_since_restore: 1290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 129\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2485 s, 129 iter, 1290000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-28-45\n",
      "  done: false\n",
      "  episode_len_mean: 130.47\n",
      "  episode_reward_max: 191.89955870084242\n",
      "  episode_reward_mean: 158.79636891262234\n",
      "  episode_reward_min: -42.033709422196495\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 9148\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.3881318395042993e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5944747924804688\n",
      "      kl: 0.007380175869911909\n",
      "      policy_loss: -0.0008448773878626525\n",
      "      total_loss: 16.2578125\n",
      "      vf_explained_var: 0.993057906627655\n",
      "      vf_loss: 16.258657455444336\n",
      "    grad_time_ms: 1567.984\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 1300000\n",
      "    num_steps_trained: 1300000\n",
      "    sample_time_ms: 15730.829\n",
      "    update_time_ms: 4.521\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2502.9448747634888\n",
      "  time_this_iter_s: 17.03268027305603\n",
      "  time_total_s: 2502.9448747634888\n",
      "  timestamp: 1550618925\n",
      "  timesteps_since_restore: 1300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1300000\n",
      "  training_iteration: 130\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2502 s, 130 iter, 1300000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-29-03\n",
      "  done: false\n",
      "  episode_len_mean: 128.86\n",
      "  episode_reward_max: 193.7683030089528\n",
      "  episode_reward_mean: 151.97285957588375\n",
      "  episode_reward_min: -47.666616714236746\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 9226\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6940659197521496e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.567960023880005\n",
      "      kl: 0.013492374680936337\n",
      "      policy_loss: -5.49413471162552e-06\n",
      "      total_loss: 232.25933837890625\n",
      "      vf_explained_var: 0.9059696793556213\n",
      "      vf_loss: 232.25933837890625\n",
      "    grad_time_ms: 1566.771\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 1310000\n",
      "    num_steps_trained: 1310000\n",
      "    sample_time_ms: 15748.005\n",
      "    update_time_ms: 4.554\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2520.264696121216\n",
      "  time_this_iter_s: 17.31982135772705\n",
      "  time_total_s: 2520.264696121216\n",
      "  timestamp: 1550618943\n",
      "  timesteps_since_restore: 1310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1310000\n",
      "  training_iteration: 131\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2520 s, 131 iter, 1310000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-29-20\n",
      "  done: false\n",
      "  episode_len_mean: 130.58\n",
      "  episode_reward_max: 191.68814827664062\n",
      "  episode_reward_mean: 156.3544885641185\n",
      "  episode_reward_min: -48.499164233998485\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 9303\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6940659197521496e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.573772430419922\n",
      "      kl: 0.015186942182481289\n",
      "      policy_loss: -0.0006968602538108826\n",
      "      total_loss: 131.27439880371094\n",
      "      vf_explained_var: 0.9446739554405212\n",
      "      vf_loss: 131.27511596679688\n",
      "    grad_time_ms: 1567.325\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "    sample_time_ms: 15789.265\n",
      "    update_time_ms: 4.505\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2537.653329372406\n",
      "  time_this_iter_s: 17.388633251190186\n",
      "  time_total_s: 2537.653329372406\n",
      "  timestamp: 1550618960\n",
      "  timesteps_since_restore: 1320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 132\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2537 s, 132 iter, 1320000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-29-37\n",
      "  done: false\n",
      "  episode_len_mean: 128.97\n",
      "  episode_reward_max: 209.98084829201798\n",
      "  episode_reward_mean: 156.25309148094505\n",
      "  episode_reward_min: -49.18715045505232\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 9380\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6940659197521496e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6141653060913086\n",
      "      kl: 0.008442633785307407\n",
      "      policy_loss: -0.00139722041785717\n",
      "      total_loss: 156.4242401123047\n",
      "      vf_explained_var: 0.9348983764648438\n",
      "      vf_loss: 156.42564392089844\n",
      "    grad_time_ms: 1564.333\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 1330000\n",
      "    num_steps_trained: 1330000\n",
      "    sample_time_ms: 15803.332\n",
      "    update_time_ms: 4.508\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2554.829308271408\n",
      "  time_this_iter_s: 17.175978899002075\n",
      "  time_total_s: 2554.829308271408\n",
      "  timestamp: 1550618977\n",
      "  timesteps_since_restore: 1330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1330000\n",
      "  training_iteration: 133\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2554 s, 133 iter, 1330000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 130.44\n",
      "  episode_reward_max: 210.23046033999123\n",
      "  episode_reward_mean: 156.52981256890862\n",
      "  episode_reward_min: -46.20343593353092\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 9456\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.470329598760748e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7212514877319336\n",
      "      kl: 0.013693652115762234\n",
      "      policy_loss: -0.004483310040086508\n",
      "      total_loss: 15.467653274536133\n",
      "      vf_explained_var: 0.9928271770477295\n",
      "      vf_loss: 15.472138404846191\n",
      "    grad_time_ms: 1558.475\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 1340000\n",
      "    num_steps_trained: 1340000\n",
      "    sample_time_ms: 15749.987\n",
      "    update_time_ms: 4.373\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2571.9983797073364\n",
      "  time_this_iter_s: 17.169071435928345\n",
      "  time_total_s: 2571.9983797073364\n",
      "  timestamp: 1550618995\n",
      "  timesteps_since_restore: 1340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1340000\n",
      "  training_iteration: 134\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2571 s, 134 iter, 1340000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-30-12\n",
      "  done: false\n",
      "  episode_len_mean: 127.16\n",
      "  episode_reward_max: 204.6436517129441\n",
      "  episode_reward_mean: 147.51356331455042\n",
      "  episode_reward_min: -44.16482622080511\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 9536\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.470329598760748e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.612952470779419\n",
      "      kl: 0.014370703138411045\n",
      "      policy_loss: -0.004116394091397524\n",
      "      total_loss: 260.3893127441406\n",
      "      vf_explained_var: 0.8925957083702087\n",
      "      vf_loss: 260.3934326171875\n",
      "    grad_time_ms: 1559.148\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "    sample_time_ms: 15786.991\n",
      "    update_time_ms: 4.419\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2589.520704984665\n",
      "  time_this_iter_s: 17.52232527732849\n",
      "  time_total_s: 2589.520704984665\n",
      "  timestamp: 1550619012\n",
      "  timesteps_since_restore: 1350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 135\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2589 s, 135 iter, 1350000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-30-30\n",
      "  done: false\n",
      "  episode_len_mean: 126.06\n",
      "  episode_reward_max: 190.3735872088092\n",
      "  episode_reward_mean: 149.52730292657742\n",
      "  episode_reward_min: -40.84654056081678\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 9615\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.470329598760748e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3950486183166504\n",
      "      kl: 0.01826699823141098\n",
      "      policy_loss: -0.0017917656805366278\n",
      "      total_loss: 213.95162963867188\n",
      "      vf_explained_var: 0.9116190671920776\n",
      "      vf_loss: 213.95343017578125\n",
      "    grad_time_ms: 1555.185\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 1360000\n",
      "    num_steps_trained: 1360000\n",
      "    sample_time_ms: 15806.907\n",
      "    update_time_ms: 4.305\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2607.123829603195\n",
      "  time_this_iter_s: 17.603124618530273\n",
      "  time_total_s: 2607.123829603195\n",
      "  timestamp: 1550619030\n",
      "  timesteps_since_restore: 1360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1360000\n",
      "  training_iteration: 136\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2607 s, 136 iter, 1360000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-30-47\n",
      "  done: false\n",
      "  episode_len_mean: 130.51\n",
      "  episode_reward_max: 193.9143344708303\n",
      "  episode_reward_mean: 156.2718079142288\n",
      "  episode_reward_min: -35.32907594135493\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 9691\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.470329598760748e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7306251525878906\n",
      "      kl: 0.009103967808187008\n",
      "      policy_loss: -0.0010454178554937243\n",
      "      total_loss: 17.788345336914062\n",
      "      vf_explained_var: 0.9920865297317505\n",
      "      vf_loss: 17.78938865661621\n",
      "    grad_time_ms: 1547.03\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 1370000\n",
      "    num_steps_trained: 1370000\n",
      "    sample_time_ms: 15748.856\n",
      "    update_time_ms: 4.339\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2624.293956756592\n",
      "  time_this_iter_s: 17.170127153396606\n",
      "  time_total_s: 2624.293956756592\n",
      "  timestamp: 1550619047\n",
      "  timesteps_since_restore: 1370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1370000\n",
      "  training_iteration: 137\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2624 s, 137 iter, 1370000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-31-04\n",
      "  done: false\n",
      "  episode_len_mean: 128.28\n",
      "  episode_reward_max: 209.61602896569977\n",
      "  episode_reward_mean: 153.63638006517778\n",
      "  episode_reward_min: -43.64129319314911\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 9770\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.235164799380374e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4946980476379395\n",
      "      kl: 0.009766371920704842\n",
      "      policy_loss: -0.0026192187797278166\n",
      "      total_loss: 104.77571868896484\n",
      "      vf_explained_var: 0.9552237391471863\n",
      "      vf_loss: 104.77833557128906\n",
      "    grad_time_ms: 1550.208\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "    sample_time_ms: 15714.742\n",
      "    update_time_ms: 4.37\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2641.4783594608307\n",
      "  time_this_iter_s: 17.18440270423889\n",
      "  time_total_s: 2641.4783594608307\n",
      "  timestamp: 1550619064\n",
      "  timesteps_since_restore: 1380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 138\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2641 s, 138 iter, 1380000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-31-21\n",
      "  done: false\n",
      "  episode_len_mean: 131.87\n",
      "  episode_reward_max: 201.19471484717764\n",
      "  episode_reward_mean: 154.14258276970088\n",
      "  episode_reward_min: -43.64129319314911\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 9845\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.117582399690187e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.732476234436035\n",
      "      kl: 0.013048668392002583\n",
      "      policy_loss: 4.575554339680821e-05\n",
      "      total_loss: 118.25558471679688\n",
      "      vf_explained_var: 0.9521071314811707\n",
      "      vf_loss: 118.25552368164062\n",
      "    grad_time_ms: 1551.932\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 1390000\n",
      "    num_steps_trained: 1390000\n",
      "    sample_time_ms: 15677.66\n",
      "    update_time_ms: 4.215\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2658.3981969356537\n",
      "  time_this_iter_s: 16.919837474822998\n",
      "  time_total_s: 2658.3981969356537\n",
      "  timestamp: 1550619081\n",
      "  timesteps_since_restore: 1390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1390000\n",
      "  training_iteration: 139\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2658 s, 139 iter, 1390000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-31-39\n",
      "  done: false\n",
      "  episode_len_mean: 130.97\n",
      "  episode_reward_max: 202.23002927846255\n",
      "  episode_reward_mean: 161.3208460747135\n",
      "  episode_reward_min: -40.04957453862276\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 9922\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.117582399690187e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.543102979660034\n",
      "      kl: 0.011881239712238312\n",
      "      policy_loss: 0.000262412300799042\n",
      "      total_loss: 14.614399909973145\n",
      "      vf_explained_var: 0.9935177564620972\n",
      "      vf_loss: 14.6141357421875\n",
      "    grad_time_ms: 1553.062\n",
      "    load_time_ms: 1.414\n",
      "    num_steps_sampled: 1400000\n",
      "    num_steps_trained: 1400000\n",
      "    sample_time_ms: 15731.878\n",
      "    update_time_ms: 4.13\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2675.9820923805237\n",
      "  time_this_iter_s: 17.583895444869995\n",
      "  time_total_s: 2675.9820923805237\n",
      "  timestamp: 1550619099\n",
      "  timesteps_since_restore: 1400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1400000\n",
      "  training_iteration: 140\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2675 s, 140 iter, 1400000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-31-56\n",
      "  done: false\n",
      "  episode_len_mean: 125.59\n",
      "  episode_reward_max: 202.23002927846255\n",
      "  episode_reward_mean: 154.76251876345535\n",
      "  episode_reward_min: -44.58913910418452\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 10002\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.117582399690187e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3281760215759277\n",
      "      kl: 0.025117866694927216\n",
      "      policy_loss: 0.0008224618504755199\n",
      "      total_loss: 185.08938598632812\n",
      "      vf_explained_var: 0.9246366620063782\n",
      "      vf_loss: 185.0885467529297\n",
      "    grad_time_ms: 1554.13\n",
      "    load_time_ms: 1.362\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "    sample_time_ms: 15724.487\n",
      "    update_time_ms: 4.231\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2693.239177465439\n",
      "  time_this_iter_s: 17.25708508491516\n",
      "  time_total_s: 2693.239177465439\n",
      "  timestamp: 1550619116\n",
      "  timesteps_since_restore: 1410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 141\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2693 s, 141 iter, 1410000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-32-13\n",
      "  done: false\n",
      "  episode_len_mean: 126.19\n",
      "  episode_reward_max: 184.1443271679749\n",
      "  episode_reward_mean: 146.8071238995011\n",
      "  episode_reward_min: -44.276080089040306\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 10081\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.117582399690187e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5657522678375244\n",
      "      kl: 0.011242345906794071\n",
      "      policy_loss: -0.0002874158963095397\n",
      "      total_loss: 195.38723754882812\n",
      "      vf_explained_var: 0.9168313145637512\n",
      "      vf_loss: 195.38751220703125\n",
      "    grad_time_ms: 1553.816\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 1420000\n",
      "    num_steps_trained: 1420000\n",
      "    sample_time_ms: 15706.664\n",
      "    update_time_ms: 4.18\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2710.4433414936066\n",
      "  time_this_iter_s: 17.204164028167725\n",
      "  time_total_s: 2710.4433414936066\n",
      "  timestamp: 1550619133\n",
      "  timesteps_since_restore: 1420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1420000\n",
      "  training_iteration: 142\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2710 s, 142 iter, 1420000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-32-31\n",
      "  done: false\n",
      "  episode_len_mean: 128.2\n",
      "  episode_reward_max: 207.91411140723383\n",
      "  episode_reward_mean: 150.05846068543988\n",
      "  episode_reward_min: -48.456581865501896\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 10158\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.117582399690187e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.624049186706543\n",
      "      kl: 0.010016580112278461\n",
      "      policy_loss: -0.002050848677754402\n",
      "      total_loss: 222.38034057617188\n",
      "      vf_explained_var: 0.9063949584960938\n",
      "      vf_loss: 222.38238525390625\n",
      "    grad_time_ms: 1553.236\n",
      "    load_time_ms: 1.33\n",
      "    num_steps_sampled: 1430000\n",
      "    num_steps_trained: 1430000\n",
      "    sample_time_ms: 15769.132\n",
      "    update_time_ms: 4.249\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2728.2400798797607\n",
      "  time_this_iter_s: 17.796738386154175\n",
      "  time_total_s: 2728.2400798797607\n",
      "  timestamp: 1550619151\n",
      "  timesteps_since_restore: 1430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1430000\n",
      "  training_iteration: 143\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2728 s, 143 iter, 1430000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-32-48\n",
      "  done: false\n",
      "  episode_len_mean: 129.33\n",
      "  episode_reward_max: 191.38624734667562\n",
      "  episode_reward_mean: 148.7608220143412\n",
      "  episode_reward_min: -48.456581865501896\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 10235\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.117582399690187e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.631317615509033\n",
      "      kl: 0.009868191555142403\n",
      "      policy_loss: -0.0013048495166003704\n",
      "      total_loss: 142.8404998779297\n",
      "      vf_explained_var: 0.9414645433425903\n",
      "      vf_loss: 142.841796875\n",
      "    grad_time_ms: 1555.663\n",
      "    load_time_ms: 1.379\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "    sample_time_ms: 15764.647\n",
      "    update_time_ms: 4.348\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2745.3911888599396\n",
      "  time_this_iter_s: 17.151108980178833\n",
      "  time_total_s: 2745.3911888599396\n",
      "  timestamp: 1550619168\n",
      "  timesteps_since_restore: 1440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 144\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2745 s, 144 iter, 1440000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-33-06\n",
      "  done: false\n",
      "  episode_len_mean: 132.81\n",
      "  episode_reward_max: 219.66014699526215\n",
      "  episode_reward_mean: 154.1026771711203\n",
      "  episode_reward_min: -49.11602378688236\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 10310\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.7970550060272217\n",
      "      kl: 0.02235987037420273\n",
      "      policy_loss: 0.0019009875832125545\n",
      "      total_loss: 121.07999420166016\n",
      "      vf_explained_var: 0.9503346681594849\n",
      "      vf_loss: 121.07807159423828\n",
      "    grad_time_ms: 1556.55\n",
      "    load_time_ms: 1.379\n",
      "    num_steps_sampled: 1450000\n",
      "    num_steps_trained: 1450000\n",
      "    sample_time_ms: 15774.644\n",
      "    update_time_ms: 4.436\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2763.0239264965057\n",
      "  time_this_iter_s: 17.632737636566162\n",
      "  time_total_s: 2763.0239264965057\n",
      "  timestamp: 1550619186\n",
      "  timesteps_since_restore: 1450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1450000\n",
      "  training_iteration: 145\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2763 s, 145 iter, 1450000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-33-24\n",
      "  done: false\n",
      "  episode_len_mean: 128.53\n",
      "  episode_reward_max: 196.92427214419504\n",
      "  episode_reward_mean: 153.88744544426524\n",
      "  episode_reward_min: -49.11602378688236\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 10387\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.566420316696167\n",
      "      kl: 0.012226401828229427\n",
      "      policy_loss: -0.002411310561001301\n",
      "      total_loss: 95.56539154052734\n",
      "      vf_explained_var: 0.9603816270828247\n",
      "      vf_loss: 95.56781768798828\n",
      "    grad_time_ms: 1569.695\n",
      "    load_time_ms: 1.378\n",
      "    num_steps_sampled: 1460000\n",
      "    num_steps_trained: 1460000\n",
      "    sample_time_ms: 15800.886\n",
      "    update_time_ms: 4.486\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2781.0194494724274\n",
      "  time_this_iter_s: 17.99552297592163\n",
      "  time_total_s: 2781.0194494724274\n",
      "  timestamp: 1550619204\n",
      "  timesteps_since_restore: 1460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1460000\n",
      "  training_iteration: 146\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2781 s, 146 iter, 1460000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-33-41\n",
      "  done: false\n",
      "  episode_len_mean: 127.28\n",
      "  episode_reward_max: 201.96160176573406\n",
      "  episode_reward_mean: 148.95238410945555\n",
      "  episode_reward_min: -43.417278106554896\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 10466\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.459440231323242\n",
      "      kl: 0.019328877329826355\n",
      "      policy_loss: -0.002062987070530653\n",
      "      total_loss: 218.4514923095703\n",
      "      vf_explained_var: 0.9130032658576965\n",
      "      vf_loss: 218.45355224609375\n",
      "    grad_time_ms: 1567.706\n",
      "    load_time_ms: 1.372\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "    sample_time_ms: 15820.061\n",
      "    update_time_ms: 4.404\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2798.3616058826447\n",
      "  time_this_iter_s: 17.342156410217285\n",
      "  time_total_s: 2798.3616058826447\n",
      "  timestamp: 1550619221\n",
      "  timesteps_since_restore: 1470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 147\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2798 s, 147 iter, 1470000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-33-59\n",
      "  done: false\n",
      "  episode_len_mean: 128.49\n",
      "  episode_reward_max: 191.46146177242298\n",
      "  episode_reward_mean: 153.17699805243106\n",
      "  episode_reward_min: -44.0695473542898\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 10543\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.631363868713379\n",
      "      kl: 0.01666279137134552\n",
      "      policy_loss: -0.0033004223369061947\n",
      "      total_loss: 91.93186950683594\n",
      "      vf_explained_var: 0.9609509706497192\n",
      "      vf_loss: 91.9351577758789\n",
      "    grad_time_ms: 1564.515\n",
      "    load_time_ms: 1.387\n",
      "    num_steps_sampled: 1480000\n",
      "    num_steps_trained: 1480000\n",
      "    sample_time_ms: 15842.668\n",
      "    update_time_ms: 4.455\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2815.74395775795\n",
      "  time_this_iter_s: 17.382351875305176\n",
      "  time_total_s: 2815.74395775795\n",
      "  timestamp: 1550619239\n",
      "  timesteps_since_restore: 1480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1480000\n",
      "  training_iteration: 148\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2815 s, 148 iter, 1480000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-34-16\n",
      "  done: false\n",
      "  episode_len_mean: 128.37\n",
      "  episode_reward_max: 203.5248957739607\n",
      "  episode_reward_mean: 152.95391653009972\n",
      "  episode_reward_min: -42.31848942643347\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 10621\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4613752365112305\n",
      "      kl: 0.02045324631035328\n",
      "      policy_loss: -0.003328692866489291\n",
      "      total_loss: 160.90611267089844\n",
      "      vf_explained_var: 0.9345533847808838\n",
      "      vf_loss: 160.90940856933594\n",
      "    grad_time_ms: 1563.437\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 1490000\n",
      "    num_steps_trained: 1490000\n",
      "    sample_time_ms: 15851.37\n",
      "    update_time_ms: 4.684\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2832.7398030757904\n",
      "  time_this_iter_s: 16.995845317840576\n",
      "  time_total_s: 2832.7398030757904\n",
      "  timestamp: 1550619256\n",
      "  timesteps_since_restore: 1490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1490000\n",
      "  training_iteration: 149\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2832 s, 149 iter, 1490000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-34-33\n",
      "  done: false\n",
      "  episode_len_mean: 127.39\n",
      "  episode_reward_max: 193.47040760694154\n",
      "  episode_reward_mean: 151.83248904177114\n",
      "  episode_reward_min: -45.2370063756952\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 10699\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.519444227218628\n",
      "      kl: 0.011485888622701168\n",
      "      policy_loss: -0.0024729238357394934\n",
      "      total_loss: 176.17149353027344\n",
      "      vf_explained_var: 0.9256578087806702\n",
      "      vf_loss: 176.17396545410156\n",
      "    grad_time_ms: 1563.023\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "    sample_time_ms: 15825.883\n",
      "    update_time_ms: 4.8\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2850.0660362243652\n",
      "  time_this_iter_s: 17.32623314857483\n",
      "  time_total_s: 2850.0660362243652\n",
      "  timestamp: 1550619273\n",
      "  timesteps_since_restore: 1500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 150\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2850 s, 150 iter, 1500000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-34-51\n",
      "  done: false\n",
      "  episode_len_mean: 131.16\n",
      "  episode_reward_max: 198.05439339917484\n",
      "  episode_reward_mean: 158.63470172835872\n",
      "  episode_reward_min: -45.2370063756952\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 10775\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.688638210296631\n",
      "      kl: 0.012226060964167118\n",
      "      policy_loss: -0.0019347436027601361\n",
      "      total_loss: 16.46474838256836\n",
      "      vf_explained_var: 0.9927075505256653\n",
      "      vf_loss: 16.466686248779297\n",
      "    grad_time_ms: 1561.34\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 1510000\n",
      "    num_steps_trained: 1510000\n",
      "    sample_time_ms: 15833.658\n",
      "    update_time_ms: 4.732\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2867.3841218948364\n",
      "  time_this_iter_s: 17.31808567047119\n",
      "  time_total_s: 2867.3841218948364\n",
      "  timestamp: 1550619291\n",
      "  timesteps_since_restore: 1510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1510000\n",
      "  training_iteration: 151\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2867 s, 151 iter, 1510000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-35-08\n",
      "  done: false\n",
      "  episode_len_mean: 130.93\n",
      "  episode_reward_max: 202.8221640303583\n",
      "  episode_reward_mean: 160.09118783963274\n",
      "  episode_reward_min: -45.16561256481871\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 10852\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.528795003890991\n",
      "      kl: 0.014022096991539001\n",
      "      policy_loss: 0.0002435995265841484\n",
      "      total_loss: 59.53246307373047\n",
      "      vf_explained_var: 0.9745023846626282\n",
      "      vf_loss: 59.53223419189453\n",
      "    grad_time_ms: 1561.531\n",
      "    load_time_ms: 1.333\n",
      "    num_steps_sampled: 1520000\n",
      "    num_steps_trained: 1520000\n",
      "    sample_time_ms: 15855.695\n",
      "    update_time_ms: 4.883\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2884.812388420105\n",
      "  time_this_iter_s: 17.428266525268555\n",
      "  time_total_s: 2884.812388420105\n",
      "  timestamp: 1550619308\n",
      "  timesteps_since_restore: 1520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1520000\n",
      "  training_iteration: 152\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2884 s, 152 iter, 1520000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-35-25\n",
      "  done: false\n",
      "  episode_len_mean: 126.86\n",
      "  episode_reward_max: 202.8221640303583\n",
      "  episode_reward_mean: 150.33522079409462\n",
      "  episode_reward_min: -50.14930223946524\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 10931\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4909534454345703\n",
      "      kl: 0.00870310515165329\n",
      "      policy_loss: -0.0007866228697821498\n",
      "      total_loss: 215.0936279296875\n",
      "      vf_explained_var: 0.9134252667427063\n",
      "      vf_loss: 215.09442138671875\n",
      "    grad_time_ms: 1563.266\n",
      "    load_time_ms: 1.349\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "    sample_time_ms: 15786.585\n",
      "    update_time_ms: 4.846\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2901.933734178543\n",
      "  time_this_iter_s: 17.12134575843811\n",
      "  time_total_s: 2901.933734178543\n",
      "  timestamp: 1550619325\n",
      "  timesteps_since_restore: 1530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 153\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2901 s, 153 iter, 1530000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-35-42\n",
      "  done: false\n",
      "  episode_len_mean: 127.46\n",
      "  episode_reward_max: 203.43452314457107\n",
      "  episode_reward_mean: 151.21942503229374\n",
      "  episode_reward_min: -50.14930223946524\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11009\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.293955999225468e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.556082248687744\n",
      "      kl: 0.03312917798757553\n",
      "      policy_loss: 0.007242240011692047\n",
      "      total_loss: 180.76187133789062\n",
      "      vf_explained_var: 0.925137460231781\n",
      "      vf_loss: 180.75460815429688\n",
      "    grad_time_ms: 1561.033\n",
      "    load_time_ms: 1.318\n",
      "    num_steps_sampled: 1540000\n",
      "    num_steps_trained: 1540000\n",
      "    sample_time_ms: 15789.038\n",
      "    update_time_ms: 4.797\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2919.0863423347473\n",
      "  time_this_iter_s: 17.152608156204224\n",
      "  time_total_s: 2919.0863423347473\n",
      "  timestamp: 1550619342\n",
      "  timesteps_since_restore: 1540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1540000\n",
      "  training_iteration: 154\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2919 s, 154 iter, 1540000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-36-00\n",
      "  done: false\n",
      "  episode_len_mean: 128.17\n",
      "  episode_reward_max: 203.43452314457107\n",
      "  episode_reward_mean: 152.88150545127144\n",
      "  episode_reward_min: -47.40322643297142\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11087\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.293955999225468e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.494738817214966\n",
      "      kl: 0.010090804658830166\n",
      "      policy_loss: -0.0018901156727224588\n",
      "      total_loss: 43.59150695800781\n",
      "      vf_explained_var: 0.9815464615821838\n",
      "      vf_loss: 43.59339141845703\n",
      "    grad_time_ms: 1562.395\n",
      "    load_time_ms: 1.284\n",
      "    num_steps_sampled: 1550000\n",
      "    num_steps_trained: 1550000\n",
      "    sample_time_ms: 15781.136\n",
      "    update_time_ms: 4.742\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2936.650980949402\n",
      "  time_this_iter_s: 17.56463861465454\n",
      "  time_total_s: 2936.650980949402\n",
      "  timestamp: 1550619360\n",
      "  timesteps_since_restore: 1550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1550000\n",
      "  training_iteration: 155\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2936 s, 155 iter, 1550000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-36-18\n",
      "  done: false\n",
      "  episode_len_mean: 126.85\n",
      "  episode_reward_max: 194.96576868868124\n",
      "  episode_reward_mean: 149.89407038240788\n",
      "  episode_reward_min: -42.82474012451595\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11165\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.293955999225468e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.400702953338623\n",
      "      kl: 0.011771985329687595\n",
      "      policy_loss: -0.00021134641428943723\n",
      "      total_loss: 149.92678833007812\n",
      "      vf_explained_var: 0.9394552707672119\n",
      "      vf_loss: 149.927001953125\n",
      "    grad_time_ms: 1546.154\n",
      "    load_time_ms: 1.29\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "    sample_time_ms: 15754.184\n",
      "    update_time_ms: 4.7\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2954.2124178409576\n",
      "  time_this_iter_s: 17.561436891555786\n",
      "  time_total_s: 2954.2124178409576\n",
      "  timestamp: 1550619378\n",
      "  timesteps_since_restore: 1560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 156\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2954 s, 156 iter, 1560000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-36-35\n",
      "  done: false\n",
      "  episode_len_mean: 130.02\n",
      "  episode_reward_max: 199.5281516658787\n",
      "  episode_reward_mean: 157.93851416938787\n",
      "  episode_reward_min: -42.82474012451595\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 11242\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.293955999225468e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.615016222000122\n",
      "      kl: 0.011620201170444489\n",
      "      policy_loss: 0.0009800211992114782\n",
      "      total_loss: 15.748137474060059\n",
      "      vf_explained_var: 0.9930339455604553\n",
      "      vf_loss: 15.74715805053711\n",
      "    grad_time_ms: 1545.864\n",
      "    load_time_ms: 1.291\n",
      "    num_steps_sampled: 1570000\n",
      "    num_steps_trained: 1570000\n",
      "    sample_time_ms: 15783.288\n",
      "    update_time_ms: 4.69\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2971.8409793376923\n",
      "  time_this_iter_s: 17.62856149673462\n",
      "  time_total_s: 2971.8409793376923\n",
      "  timestamp: 1550619395\n",
      "  timesteps_since_restore: 1570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1570000\n",
      "  training_iteration: 157\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2971 s, 157 iter, 1570000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-36-53\n",
      "  done: false\n",
      "  episode_len_mean: 128.38\n",
      "  episode_reward_max: 198.0342815128885\n",
      "  episode_reward_mean: 159.41748536827606\n",
      "  episode_reward_min: -40.66761839271772\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11320\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.293955999225468e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.432002067565918\n",
      "      kl: 0.009283510036766529\n",
      "      policy_loss: -0.0013730598147958517\n",
      "      total_loss: 54.39080047607422\n",
      "      vf_explained_var: 0.9781030416488647\n",
      "      vf_loss: 54.39216995239258\n",
      "    grad_time_ms: 1547.713\n",
      "    load_time_ms: 1.317\n",
      "    num_steps_sampled: 1580000\n",
      "    num_steps_trained: 1580000\n",
      "    sample_time_ms: 15763.775\n",
      "    update_time_ms: 4.624\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 2989.044286251068\n",
      "  time_this_iter_s: 17.203306913375854\n",
      "  time_total_s: 2989.044286251068\n",
      "  timestamp: 1550619413\n",
      "  timesteps_since_restore: 1580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1580000\n",
      "  training_iteration: 158\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 2989 s, 158 iter, 1580000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-37-10\n",
      "  done: false\n",
      "  episode_len_mean: 128.38\n",
      "  episode_reward_max: 212.34076822866294\n",
      "  episode_reward_mean: 158.9507400709571\n",
      "  episode_reward_min: -40.93846130843211\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11398\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.646977999612734e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5205085277557373\n",
      "      kl: 0.015918420627713203\n",
      "      policy_loss: -0.001479834085330367\n",
      "      total_loss: 66.5358657836914\n",
      "      vf_explained_var: 0.9726492166519165\n",
      "      vf_loss: 66.537353515625\n",
      "    grad_time_ms: 1549.514\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "    sample_time_ms: 15790.642\n",
      "    update_time_ms: 4.671\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3006.3297250270844\n",
      "  time_this_iter_s: 17.285438776016235\n",
      "  time_total_s: 3006.3297250270844\n",
      "  timestamp: 1550619430\n",
      "  timesteps_since_restore: 1590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 159\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3006 s, 159 iter, 1590000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-37-27\n",
      "  done: false\n",
      "  episode_len_mean: 128.45\n",
      "  episode_reward_max: 194.71999143432856\n",
      "  episode_reward_mean: 150.7025938060323\n",
      "  episode_reward_min: -49.116372476709955\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11476\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.646977999612734e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5681161880493164\n",
      "      kl: 0.008095870725810528\n",
      "      policy_loss: -0.0013404113706201315\n",
      "      total_loss: 187.3743438720703\n",
      "      vf_explained_var: 0.9306323528289795\n",
      "      vf_loss: 187.3756561279297\n",
      "    grad_time_ms: 1546.907\n",
      "    load_time_ms: 1.323\n",
      "    num_steps_sampled: 1600000\n",
      "    num_steps_trained: 1600000\n",
      "    sample_time_ms: 15745.624\n",
      "    update_time_ms: 4.603\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3023.1780166625977\n",
      "  time_this_iter_s: 16.848291635513306\n",
      "  time_total_s: 3023.1780166625977\n",
      "  timestamp: 1550619447\n",
      "  timesteps_since_restore: 1600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1600000\n",
      "  training_iteration: 160\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3023 s, 160 iter, 1600000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-37-44\n",
      "  done: false\n",
      "  episode_len_mean: 127.12\n",
      "  episode_reward_max: 194.71999143432856\n",
      "  episode_reward_mean: 156.80615840013976\n",
      "  episode_reward_min: -49.116372476709955\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11554\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3498313426971436\n",
      "      kl: 0.011016159318387508\n",
      "      policy_loss: 0.003536706091836095\n",
      "      total_loss: 10.802653312683105\n",
      "      vf_explained_var: 0.9954047799110413\n",
      "      vf_loss: 10.799118041992188\n",
      "    grad_time_ms: 1547.309\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 1610000\n",
      "    num_steps_trained: 1610000\n",
      "    sample_time_ms: 15738.235\n",
      "    update_time_ms: 4.567\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3040.425795316696\n",
      "  time_this_iter_s: 17.24777865409851\n",
      "  time_total_s: 3040.425795316696\n",
      "  timestamp: 1550619464\n",
      "  timesteps_since_restore: 1610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1610000\n",
      "  training_iteration: 161\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3040 s, 161 iter, 1610000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-38-02\n",
      "  done: false\n",
      "  episode_len_mean: 126.6\n",
      "  episode_reward_max: 204.78153959300255\n",
      "  episode_reward_mean: 156.55379517482623\n",
      "  episode_reward_min: -39.13579401344354\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 11633\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4099690914154053\n",
      "      kl: 0.021499214693903923\n",
      "      policy_loss: 0.0006640315405093133\n",
      "      total_loss: 166.35118103027344\n",
      "      vf_explained_var: 0.9326075911521912\n",
      "      vf_loss: 166.3505401611328\n",
      "    grad_time_ms: 1549.058\n",
      "    load_time_ms: 1.392\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "    sample_time_ms: 15737.906\n",
      "    update_time_ms: 4.438\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3057.869265794754\n",
      "  time_this_iter_s: 17.44347047805786\n",
      "  time_total_s: 3057.869265794754\n",
      "  timestamp: 1550619482\n",
      "  timesteps_since_restore: 1620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 162\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3057 s, 162 iter, 1620000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-38-19\n",
      "  done: false\n",
      "  episode_len_mean: 128.45\n",
      "  episode_reward_max: 191.70458895661466\n",
      "  episode_reward_mean: 151.8967003626001\n",
      "  episode_reward_min: -51.35545823479642\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11711\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5503792762756348\n",
      "      kl: 0.02158990502357483\n",
      "      policy_loss: 6.194412708282471e-05\n",
      "      total_loss: 157.9713592529297\n",
      "      vf_explained_var: 0.9394566416740417\n",
      "      vf_loss: 157.97129821777344\n",
      "    grad_time_ms: 1549.92\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 1630000\n",
      "    num_steps_trained: 1630000\n",
      "    sample_time_ms: 15759.886\n",
      "    update_time_ms: 4.532\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3075.218892812729\n",
      "  time_this_iter_s: 17.349627017974854\n",
      "  time_total_s: 3075.218892812729\n",
      "  timestamp: 1550619499\n",
      "  timesteps_since_restore: 1630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1630000\n",
      "  training_iteration: 163\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3075 s, 163 iter, 1630000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-38-36\n",
      "  done: false\n",
      "  episode_len_mean: 125.98\n",
      "  episode_reward_max: 212.54519580820994\n",
      "  episode_reward_mean: 148.7723287944621\n",
      "  episode_reward_min: -51.35545823479642\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11789\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.411557912826538\n",
      "      kl: 0.010526740923523903\n",
      "      policy_loss: -0.0017597625264897943\n",
      "      total_loss: 131.5564422607422\n",
      "      vf_explained_var: 0.9468403458595276\n",
      "      vf_loss: 131.55821228027344\n",
      "    grad_time_ms: 1549.704\n",
      "    load_time_ms: 1.328\n",
      "    num_steps_sampled: 1640000\n",
      "    num_steps_trained: 1640000\n",
      "    sample_time_ms: 15756.803\n",
      "    update_time_ms: 4.518\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3092.3374202251434\n",
      "  time_this_iter_s: 17.11852741241455\n",
      "  time_total_s: 3092.3374202251434\n",
      "  timestamp: 1550619516\n",
      "  timesteps_since_restore: 1640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1640000\n",
      "  training_iteration: 164\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3092 s, 164 iter, 1640000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-38-54\n",
      "  done: false\n",
      "  episode_len_mean: 127.31\n",
      "  episode_reward_max: 206.79134683384768\n",
      "  episode_reward_mean: 151.02787697738268\n",
      "  episode_reward_min: -45.476476097461024\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 11868\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3578155040740967\n",
      "      kl: 0.014419757761061192\n",
      "      policy_loss: 0.0003384130250196904\n",
      "      total_loss: 97.04035186767578\n",
      "      vf_explained_var: 0.9607809782028198\n",
      "      vf_loss: 97.04002380371094\n",
      "    grad_time_ms: 1555.959\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "    sample_time_ms: 15760.031\n",
      "    update_time_ms: 4.556\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3109.9992151260376\n",
      "  time_this_iter_s: 17.661794900894165\n",
      "  time_total_s: 3109.9992151260376\n",
      "  timestamp: 1550619534\n",
      "  timesteps_since_restore: 1650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 165\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3109 s, 165 iter, 1650000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-39-11\n",
      "  done: false\n",
      "  episode_len_mean: 126.85\n",
      "  episode_reward_max: 206.79134683384768\n",
      "  episode_reward_mean: 152.06700062411974\n",
      "  episode_reward_min: -46.900975494691636\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 11946\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.470160484313965\n",
      "      kl: 0.010650788433849812\n",
      "      policy_loss: -0.0016073181759566069\n",
      "      total_loss: 115.11373138427734\n",
      "      vf_explained_var: 0.9529034495353699\n",
      "      vf_loss: 115.11534881591797\n",
      "    grad_time_ms: 1559.858\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 1660000\n",
      "    num_steps_trained: 1660000\n",
      "    sample_time_ms: 15755.689\n",
      "    update_time_ms: 4.513\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3127.556830406189\n",
      "  time_this_iter_s: 17.557615280151367\n",
      "  time_total_s: 3127.556830406189\n",
      "  timestamp: 1550619551\n",
      "  timesteps_since_restore: 1660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1660000\n",
      "  training_iteration: 166\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3127 s, 166 iter, 1660000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-39-29\n",
      "  done: false\n",
      "  episode_len_mean: 127.3\n",
      "  episode_reward_max: 195.84499730036976\n",
      "  episode_reward_mean: 153.66981624405315\n",
      "  episode_reward_min: -42.41937489320736\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 12025\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4545211791992188\n",
      "      kl: 0.026877736672759056\n",
      "      policy_loss: 0.0012722330866381526\n",
      "      total_loss: 90.6582260131836\n",
      "      vf_explained_var: 0.9620245695114136\n",
      "      vf_loss: 90.65696716308594\n",
      "    grad_time_ms: 1561.128\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 1670000\n",
      "    num_steps_trained: 1670000\n",
      "    sample_time_ms: 15733.105\n",
      "    update_time_ms: 4.597\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3144.973185777664\n",
      "  time_this_iter_s: 17.41635537147522\n",
      "  time_total_s: 3144.973185777664\n",
      "  timestamp: 1550619569\n",
      "  timesteps_since_restore: 1670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1670000\n",
      "  training_iteration: 167\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3144 s, 167 iter, 1670000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-39-46\n",
      "  done: false\n",
      "  episode_len_mean: 126.61\n",
      "  episode_reward_max: 216.2126811479429\n",
      "  episode_reward_mean: 158.24185665260796\n",
      "  episode_reward_min: -37.130481818524935\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 12104\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3663299083709717\n",
      "      kl: 0.019645120948553085\n",
      "      policy_loss: 0.0028801311273127794\n",
      "      total_loss: 12.534932136535645\n",
      "      vf_explained_var: 0.994511604309082\n",
      "      vf_loss: 12.532051086425781\n",
      "    grad_time_ms: 1562.805\n",
      "    load_time_ms: 1.321\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "    sample_time_ms: 15750.06\n",
      "    update_time_ms: 4.559\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3162.3603506088257\n",
      "  time_this_iter_s: 17.3871648311615\n",
      "  time_total_s: 3162.3603506088257\n",
      "  timestamp: 1550619586\n",
      "  timesteps_since_restore: 1680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 168\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3162 s, 168 iter, 1680000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 127.68\n",
      "  episode_reward_max: 216.2126811479429\n",
      "  episode_reward_mean: 158.06955218067498\n",
      "  episode_reward_min: -42.671408607227946\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 12181\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.389310121536255\n",
      "      kl: 0.013738791458308697\n",
      "      policy_loss: -0.0016255840891972184\n",
      "      total_loss: 103.84416961669922\n",
      "      vf_explained_var: 0.9597044587135315\n",
      "      vf_loss: 103.8458023071289\n",
      "    grad_time_ms: 1563.238\n",
      "    load_time_ms: 1.37\n",
      "    num_steps_sampled: 1690000\n",
      "    num_steps_trained: 1690000\n",
      "    sample_time_ms: 15782.578\n",
      "    update_time_ms: 4.433\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3179.9763956069946\n",
      "  time_this_iter_s: 17.616044998168945\n",
      "  time_total_s: 3179.9763956069946\n",
      "  timestamp: 1550619604\n",
      "  timesteps_since_restore: 1690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1690000\n",
      "  training_iteration: 169\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3179 s, 169 iter, 1690000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-40-21\n",
      "  done: false\n",
      "  episode_len_mean: 129.25\n",
      "  episode_reward_max: 208.57111986084723\n",
      "  episode_reward_mean: 157.07878808425758\n",
      "  episode_reward_min: -42.400968648419536\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 12258\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5786826610565186\n",
      "      kl: 0.019640887156128883\n",
      "      policy_loss: -0.004912785720080137\n",
      "      total_loss: 98.81316375732422\n",
      "      vf_explained_var: 0.9607102870941162\n",
      "      vf_loss: 98.81807708740234\n",
      "    grad_time_ms: 1566.159\n",
      "    load_time_ms: 1.369\n",
      "    num_steps_sampled: 1700000\n",
      "    num_steps_trained: 1700000\n",
      "    sample_time_ms: 15806.776\n",
      "    update_time_ms: 4.453\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3197.0986683368683\n",
      "  time_this_iter_s: 17.122272729873657\n",
      "  time_total_s: 3197.0986683368683\n",
      "  timestamp: 1550619621\n",
      "  timesteps_since_restore: 1700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1700000\n",
      "  training_iteration: 170\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3197 s, 170 iter, 1700000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-40-38\n",
      "  done: false\n",
      "  episode_len_mean: 127.11\n",
      "  episode_reward_max: 198.86624671887654\n",
      "  episode_reward_mean: 148.6345938622957\n",
      "  episode_reward_min: -48.63851171968005\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 12338\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.425004243850708\n",
      "      kl: 0.014080388471484184\n",
      "      policy_loss: -0.0016720336861908436\n",
      "      total_loss: 213.8143310546875\n",
      "      vf_explained_var: 0.9169619679450989\n",
      "      vf_loss: 213.81597900390625\n",
      "    grad_time_ms: 1566.289\n",
      "    load_time_ms: 1.328\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "    sample_time_ms: 15819.334\n",
      "    update_time_ms: 4.552\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3214.4743115901947\n",
      "  time_this_iter_s: 17.375643253326416\n",
      "  time_total_s: 3214.4743115901947\n",
      "  timestamp: 1550619638\n",
      "  timesteps_since_restore: 1710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 171\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3214 s, 171 iter, 1710000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-40-56\n",
      "  done: false\n",
      "  episode_len_mean: 126.36\n",
      "  episode_reward_max: 193.58293528825325\n",
      "  episode_reward_mean: 146.46839476047194\n",
      "  episode_reward_min: -46.48460724094126\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 12417\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.51727032661438\n",
      "      kl: 0.013596124947071075\n",
      "      policy_loss: -7.963601092342287e-05\n",
      "      total_loss: 170.10531616210938\n",
      "      vf_explained_var: 0.9326188564300537\n",
      "      vf_loss: 170.1053924560547\n",
      "    grad_time_ms: 1565.833\n",
      "    load_time_ms: 1.342\n",
      "    num_steps_sampled: 1720000\n",
      "    num_steps_trained: 1720000\n",
      "    sample_time_ms: 15842.275\n",
      "    update_time_ms: 4.452\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3232.140337705612\n",
      "  time_this_iter_s: 17.66602611541748\n",
      "  time_total_s: 3232.140337705612\n",
      "  timestamp: 1550619656\n",
      "  timesteps_since_restore: 1720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1720000\n",
      "  training_iteration: 172\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3232 s, 172 iter, 1720000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-41-14\n",
      "  done: false\n",
      "  episode_len_mean: 125.84\n",
      "  episode_reward_max: 191.9686663386846\n",
      "  episode_reward_mean: 150.94942895959088\n",
      "  episode_reward_min: -46.48460724094126\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 12497\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.465177297592163\n",
      "      kl: 0.012593794614076614\n",
      "      policy_loss: -0.000777237699367106\n",
      "      total_loss: 83.2813949584961\n",
      "      vf_explained_var: 0.9663847088813782\n",
      "      vf_loss: 83.28217315673828\n",
      "    grad_time_ms: 1563.549\n",
      "    load_time_ms: 1.336\n",
      "    num_steps_sampled: 1730000\n",
      "    num_steps_trained: 1730000\n",
      "    sample_time_ms: 15857.795\n",
      "    update_time_ms: 4.325\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3249.622442960739\n",
      "  time_this_iter_s: 17.482105255126953\n",
      "  time_total_s: 3249.622442960739\n",
      "  timestamp: 1550619674\n",
      "  timesteps_since_restore: 1730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1730000\n",
      "  training_iteration: 173\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3249 s, 173 iter, 1730000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-41-31\n",
      "  done: false\n",
      "  episode_len_mean: 128.02\n",
      "  episode_reward_max: 196.84910888387145\n",
      "  episode_reward_mean: 158.98476407819598\n",
      "  episode_reward_min: -40.648673703764935\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 12575\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.460386276245117\n",
      "      kl: 10.830344200134277\n",
      "      policy_loss: 0.04236065596342087\n",
      "      total_loss: 64.63819885253906\n",
      "      vf_explained_var: 0.9728172421455383\n",
      "      vf_loss: 64.5958251953125\n",
      "    grad_time_ms: 1563.409\n",
      "    load_time_ms: 1.405\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "    sample_time_ms: 15865.353\n",
      "    update_time_ms: 4.257\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3266.8152968883514\n",
      "  time_this_iter_s: 17.192853927612305\n",
      "  time_total_s: 3266.8152968883514\n",
      "  timestamp: 1550619691\n",
      "  timesteps_since_restore: 1740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 174\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3266 s, 174 iter, 1740000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-41-48\n",
      "  done: false\n",
      "  episode_len_mean: 127.02\n",
      "  episode_reward_max: 193.8832533347725\n",
      "  episode_reward_mean: 155.41761944328616\n",
      "  episode_reward_min: -40.47981074216341\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 12654\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.985232957367678e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4952378273010254\n",
      "      kl: 0.03326348960399628\n",
      "      policy_loss: -0.0033863012213259935\n",
      "      total_loss: 90.47734832763672\n",
      "      vf_explained_var: 0.963230550289154\n",
      "      vf_loss: 90.4807357788086\n",
      "    grad_time_ms: 1554.255\n",
      "    load_time_ms: 1.379\n",
      "    num_steps_sampled: 1750000\n",
      "    num_steps_trained: 1750000\n",
      "    sample_time_ms: 15820.425\n",
      "    update_time_ms: 4.317\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3283.9351177215576\n",
      "  time_this_iter_s: 17.119820833206177\n",
      "  time_total_s: 3283.9351177215576\n",
      "  timestamp: 1550619708\n",
      "  timesteps_since_restore: 1750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1750000\n",
      "  training_iteration: 175\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3283 s, 175 iter, 1750000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-42-06\n",
      "  done: false\n",
      "  episode_len_mean: 125.91\n",
      "  episode_reward_max: 205.34579863672184\n",
      "  episode_reward_mean: 154.82224942457484\n",
      "  episode_reward_min: -48.97488092136855\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 12733\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.985232957367678e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4323692321777344\n",
      "      kl: 0.012402893975377083\n",
      "      policy_loss: -0.004051547963172197\n",
      "      total_loss: 129.75140380859375\n",
      "      vf_explained_var: 0.9496766328811646\n",
      "      vf_loss: 129.75546264648438\n",
      "    grad_time_ms: 1551.47\n",
      "    load_time_ms: 1.373\n",
      "    num_steps_sampled: 1760000\n",
      "    num_steps_trained: 1760000\n",
      "    sample_time_ms: 15818.318\n",
      "    update_time_ms: 4.425\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3301.444210290909\n",
      "  time_this_iter_s: 17.509092569351196\n",
      "  time_total_s: 3301.444210290909\n",
      "  timestamp: 1550619726\n",
      "  timesteps_since_restore: 1760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1760000\n",
      "  training_iteration: 176\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3301 s, 176 iter, 1760000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-42-23\n",
      "  done: false\n",
      "  episode_len_mean: 123.63\n",
      "  episode_reward_max: 194.1057760405659\n",
      "  episode_reward_mean: 150.85168385838074\n",
      "  episode_reward_min: -49.570481433431695\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 12815\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.985232957367678e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3357040882110596\n",
      "      kl: 0.10896308720111847\n",
      "      policy_loss: 0.01125333458185196\n",
      "      total_loss: 270.0379943847656\n",
      "      vf_explained_var: 0.8971933126449585\n",
      "      vf_loss: 270.0267333984375\n",
      "    grad_time_ms: 1573.977\n",
      "    load_time_ms: 1.371\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "    sample_time_ms: 15816.148\n",
      "    update_time_ms: 4.274\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3319.064504146576\n",
      "  time_this_iter_s: 17.620293855667114\n",
      "  time_total_s: 3319.064504146576\n",
      "  timestamp: 1550619743\n",
      "  timesteps_since_restore: 1770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 177\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3319 s, 177 iter, 1770000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-42-41\n",
      "  done: false\n",
      "  episode_len_mean: 124.28\n",
      "  episode_reward_max: 218.4164429566649\n",
      "  episode_reward_mean: 147.1941444383204\n",
      "  episode_reward_min: -46.867435055203956\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 12894\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4156947135925293\n",
      "      kl: 0.01418845821171999\n",
      "      policy_loss: -0.004116412252187729\n",
      "      total_loss: 205.1634521484375\n",
      "      vf_explained_var: 0.91741943359375\n",
      "      vf_loss: 205.16757202148438\n",
      "    grad_time_ms: 1569.935\n",
      "    load_time_ms: 1.367\n",
      "    num_steps_sampled: 1780000\n",
      "    num_steps_trained: 1780000\n",
      "    sample_time_ms: 15804.391\n",
      "    update_time_ms: 4.253\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3336.2934198379517\n",
      "  time_this_iter_s: 17.228915691375732\n",
      "  time_total_s: 3336.2934198379517\n",
      "  timestamp: 1550619761\n",
      "  timesteps_since_restore: 1780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1780000\n",
      "  training_iteration: 178\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3336 s, 178 iter, 1780000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-42-58\n",
      "  done: false\n",
      "  episode_len_mean: 125.46\n",
      "  episode_reward_max: 198.50252483740903\n",
      "  episode_reward_mean: 153.10397338363114\n",
      "  episode_reward_min: -44.1455011881224\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 12974\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4370276927948\n",
      "      kl: 0.022024372592568398\n",
      "      policy_loss: -0.0024172768462449312\n",
      "      total_loss: 148.51429748535156\n",
      "      vf_explained_var: 0.9415029883384705\n",
      "      vf_loss: 148.51675415039062\n",
      "    grad_time_ms: 1567.081\n",
      "    load_time_ms: 1.313\n",
      "    num_steps_sampled: 1790000\n",
      "    num_steps_trained: 1790000\n",
      "    sample_time_ms: 15792.907\n",
      "    update_time_ms: 4.192\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3353.7625551223755\n",
      "  time_this_iter_s: 17.469135284423828\n",
      "  time_total_s: 3353.7625551223755\n",
      "  timestamp: 1550619778\n",
      "  timesteps_since_restore: 1790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1790000\n",
      "  training_iteration: 179\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3353 s, 179 iter, 1790000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-43-16\n",
      "  done: false\n",
      "  episode_len_mean: 123.72\n",
      "  episode_reward_max: 195.08729890077421\n",
      "  episode_reward_mean: 144.99058604601043\n",
      "  episode_reward_min: -51.587508666928464\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 13053\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4594924449920654\n",
      "      kl: 0.018223203718662262\n",
      "      policy_loss: -0.001859016134403646\n",
      "      total_loss: 126.09375\n",
      "      vf_explained_var: 0.9475470185279846\n",
      "      vf_loss: 126.0955810546875\n",
      "    grad_time_ms: 1565.894\n",
      "    load_time_ms: 1.312\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "    sample_time_ms: 15846.066\n",
      "    update_time_ms: 4.239\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3371.4021396636963\n",
      "  time_this_iter_s: 17.6395845413208\n",
      "  time_total_s: 3371.4021396636963\n",
      "  timestamp: 1550619796\n",
      "  timesteps_since_restore: 1800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 180\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3371 s, 180 iter, 1800000 ts, 145 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-43-33\n",
      "  done: false\n",
      "  episode_len_mean: 124.86\n",
      "  episode_reward_max: 195.08729890077421\n",
      "  episode_reward_mean: 154.77156921170155\n",
      "  episode_reward_min: -41.52105804104911\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 13133\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.374425172805786\n",
      "      kl: 0.01869310811161995\n",
      "      policy_loss: 0.0012104971101507545\n",
      "      total_loss: 98.38607025146484\n",
      "      vf_explained_var: 0.9583505392074585\n",
      "      vf_loss: 98.38484954833984\n",
      "    grad_time_ms: 1565.924\n",
      "    load_time_ms: 1.347\n",
      "    num_steps_sampled: 1810000\n",
      "    num_steps_trained: 1810000\n",
      "    sample_time_ms: 15861.036\n",
      "    update_time_ms: 4.104\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3388.9261615276337\n",
      "  time_this_iter_s: 17.524021863937378\n",
      "  time_total_s: 3388.9261615276337\n",
      "  timestamp: 1550619813\n",
      "  timesteps_since_restore: 1810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1810000\n",
      "  training_iteration: 181\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3388 s, 181 iter, 1810000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-43-50\n",
      "  done: false\n",
      "  episode_len_mean: 124.59\n",
      "  episode_reward_max: 191.86234519918355\n",
      "  episode_reward_mean: 153.537428186607\n",
      "  episode_reward_min: -49.75675606934147\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 13214\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3698086738586426\n",
      "      kl: 0.018758131191134453\n",
      "      policy_loss: 0.002345325192436576\n",
      "      total_loss: 129.1112060546875\n",
      "      vf_explained_var: 0.9493477940559387\n",
      "      vf_loss: 129.10885620117188\n",
      "    grad_time_ms: 1563.586\n",
      "    load_time_ms: 1.303\n",
      "    num_steps_sampled: 1820000\n",
      "    num_steps_trained: 1820000\n",
      "    sample_time_ms: 15786.888\n",
      "    update_time_ms: 4.274\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3405.826597929001\n",
      "  time_this_iter_s: 16.900436401367188\n",
      "  time_total_s: 3405.826597929001\n",
      "  timestamp: 1550619830\n",
      "  timesteps_since_restore: 1820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1820000\n",
      "  training_iteration: 182\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3405 s, 182 iter, 1820000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-44-08\n",
      "  done: false\n",
      "  episode_len_mean: 128.08\n",
      "  episode_reward_max: 199.2089387860038\n",
      "  episode_reward_mean: 161.2586174023765\n",
      "  episode_reward_min: -49.48432662374901\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 13292\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.399505138397217\n",
      "      kl: 0.02000809647142887\n",
      "      policy_loss: 0.0032330809626728296\n",
      "      total_loss: 54.635841369628906\n",
      "      vf_explained_var: 0.9785743951797485\n",
      "      vf_loss: 54.63261795043945\n",
      "    grad_time_ms: 1562.653\n",
      "    load_time_ms: 1.311\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "    sample_time_ms: 15823.175\n",
      "    update_time_ms: 4.331\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3423.662801504135\n",
      "  time_this_iter_s: 17.836203575134277\n",
      "  time_total_s: 3423.662801504135\n",
      "  timestamp: 1550619848\n",
      "  timesteps_since_restore: 1830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 183\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3423 s, 183 iter, 1830000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-44-25\n",
      "  done: false\n",
      "  episode_len_mean: 127.4\n",
      "  episode_reward_max: 199.2089387860038\n",
      "  episode_reward_mean: 157.77369537604187\n",
      "  episode_reward_min: -40.108523437882404\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 13371\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5368056297302246\n",
      "      kl: 0.02052985318005085\n",
      "      policy_loss: -0.0010333823738619685\n",
      "      total_loss: 97.4658203125\n",
      "      vf_explained_var: 0.9599782228469849\n",
      "      vf_loss: 97.46685028076172\n",
      "    grad_time_ms: 1563.62\n",
      "    load_time_ms: 1.328\n",
      "    num_steps_sampled: 1840000\n",
      "    num_steps_trained: 1840000\n",
      "    sample_time_ms: 15842.207\n",
      "    update_time_ms: 4.404\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3441.057033061981\n",
      "  time_this_iter_s: 17.39423155784607\n",
      "  time_total_s: 3441.057033061981\n",
      "  timestamp: 1550619865\n",
      "  timesteps_since_restore: 1840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1840000\n",
      "  training_iteration: 184\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3441 s, 184 iter, 1840000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-44-43\n",
      "  done: false\n",
      "  episode_len_mean: 124.41\n",
      "  episode_reward_max: 197.3169073103974\n",
      "  episode_reward_mean: 150.6794582207172\n",
      "  episode_reward_min: -50.523111736567905\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 13451\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.358839511871338\n",
      "      kl: 0.01402207650244236\n",
      "      policy_loss: -0.0012889089994132519\n",
      "      total_loss: 208.16844177246094\n",
      "      vf_explained_var: 0.9223721027374268\n",
      "      vf_loss: 208.1697235107422\n",
      "    grad_time_ms: 1564.334\n",
      "    load_time_ms: 1.321\n",
      "    num_steps_sampled: 1850000\n",
      "    num_steps_trained: 1850000\n",
      "    sample_time_ms: 15898.447\n",
      "    update_time_ms: 4.293\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3458.746830224991\n",
      "  time_this_iter_s: 17.689797163009644\n",
      "  time_total_s: 3458.746830224991\n",
      "  timestamp: 1550619883\n",
      "  timesteps_since_restore: 1850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1850000\n",
      "  training_iteration: 185\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3458 s, 185 iter, 1850000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-45-01\n",
      "  done: false\n",
      "  episode_len_mean: 126.82\n",
      "  episode_reward_max: 213.39534085693933\n",
      "  episode_reward_mean: 153.24364395651364\n",
      "  episode_reward_min: -50.523111736567905\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 13529\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5895442962646484\n",
      "      kl: 0.011973696760833263\n",
      "      policy_loss: -0.0012622115900740027\n",
      "      total_loss: 122.49773406982422\n",
      "      vf_explained_var: 0.9517332911491394\n",
      "      vf_loss: 122.49897003173828\n",
      "    grad_time_ms: 1565.219\n",
      "    load_time_ms: 1.329\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "    sample_time_ms: 15881.525\n",
      "    update_time_ms: 4.329\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3476.096097946167\n",
      "  time_this_iter_s: 17.349267721176147\n",
      "  time_total_s: 3476.096097946167\n",
      "  timestamp: 1550619901\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 186\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3476 s, 186 iter, 1860000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-45-18\n",
      "  done: false\n",
      "  episode_len_mean: 128.1\n",
      "  episode_reward_max: 213.39534085693933\n",
      "  episode_reward_mean: 159.13302731512323\n",
      "  episode_reward_min: -48.7091500649948\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 13607\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4440879821777344\n",
      "      kl: 0.024414515122771263\n",
      "      policy_loss: 0.0012705893022939563\n",
      "      total_loss: 59.63877868652344\n",
      "      vf_explained_var: 0.9760571718215942\n",
      "      vf_loss: 59.63751220703125\n",
      "    grad_time_ms: 1539.662\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 1870000\n",
      "    num_steps_trained: 1870000\n",
      "    sample_time_ms: 15877.705\n",
      "    update_time_ms: 4.453\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3493.4238057136536\n",
      "  time_this_iter_s: 17.327707767486572\n",
      "  time_total_s: 3493.4238057136536\n",
      "  timestamp: 1550619918\n",
      "  timesteps_since_restore: 1870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1870000\n",
      "  training_iteration: 187\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3493 s, 187 iter, 1870000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-45-36\n",
      "  done: false\n",
      "  episode_len_mean: 125.61\n",
      "  episode_reward_max: 198.28865715330193\n",
      "  episode_reward_mean: 155.5159967499175\n",
      "  episode_reward_min: -48.583436173967776\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 13687\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.324929714202881\n",
      "      kl: 0.027577470988035202\n",
      "      policy_loss: 0.002474758541211486\n",
      "      total_loss: 163.964599609375\n",
      "      vf_explained_var: 0.9359162449836731\n",
      "      vf_loss: 163.9621124267578\n",
      "    grad_time_ms: 1546.241\n",
      "    load_time_ms: 1.373\n",
      "    num_steps_sampled: 1880000\n",
      "    num_steps_trained: 1880000\n",
      "    sample_time_ms: 15913.986\n",
      "    update_time_ms: 4.633\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3511.085756778717\n",
      "  time_this_iter_s: 17.661951065063477\n",
      "  time_total_s: 3511.085756778717\n",
      "  timestamp: 1550619936\n",
      "  timesteps_since_restore: 1880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1880000\n",
      "  training_iteration: 188\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3511 s, 188 iter, 1880000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-45-52\n",
      "  done: false\n",
      "  episode_len_mean: 127.46\n",
      "  episode_reward_max: 196.3995646409468\n",
      "  episode_reward_mean: 151.41351691984883\n",
      "  episode_reward_min: -42.892598713978686\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 13766\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5067696571350098\n",
      "      kl: 0.017851410433650017\n",
      "      policy_loss: -0.00874171033501625\n",
      "      total_loss: 146.58590698242188\n",
      "      vf_explained_var: 0.9447387456893921\n",
      "      vf_loss: 146.5946502685547\n",
      "    grad_time_ms: 1544.762\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "    sample_time_ms: 15843.267\n",
      "    update_time_ms: 4.685\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3527.832659959793\n",
      "  time_this_iter_s: 16.74690318107605\n",
      "  time_total_s: 3527.832659959793\n",
      "  timestamp: 1550619952\n",
      "  timesteps_since_restore: 1890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 189\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3527 s, 189 iter, 1890000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-46-10\n",
      "  done: false\n",
      "  episode_len_mean: 128.6\n",
      "  episode_reward_max: 197.66798734889932\n",
      "  episode_reward_mean: 151.33517626343865\n",
      "  episode_reward_min: -42.892598713978686\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 13844\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6396965980529785\n",
      "      kl: 0.026062577962875366\n",
      "      policy_loss: -0.006069618742913008\n",
      "      total_loss: 151.2091522216797\n",
      "      vf_explained_var: 0.943372368812561\n",
      "      vf_loss: 151.21522521972656\n",
      "    grad_time_ms: 1545.576\n",
      "    load_time_ms: 1.416\n",
      "    num_steps_sampled: 1900000\n",
      "    num_steps_trained: 1900000\n",
      "    sample_time_ms: 15791.659\n",
      "    update_time_ms: 4.656\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3544.966475009918\n",
      "  time_this_iter_s: 17.133815050125122\n",
      "  time_total_s: 3544.966475009918\n",
      "  timestamp: 1550619970\n",
      "  timesteps_since_restore: 1900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1900000\n",
      "  training_iteration: 190\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3544 s, 190 iter, 1900000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-46-27\n",
      "  done: false\n",
      "  episode_len_mean: 129.55\n",
      "  episode_reward_max: 208.19410934808246\n",
      "  episode_reward_mean: 154.90601865405768\n",
      "  episode_reward_min: -50.298052068467776\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 13921\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.521815776824951\n",
      "      kl: 0.010570443235337734\n",
      "      policy_loss: 0.00027989051886834204\n",
      "      total_loss: 110.51093292236328\n",
      "      vf_explained_var: 0.9601788520812988\n",
      "      vf_loss: 110.51062774658203\n",
      "    grad_time_ms: 1543.847\n",
      "    load_time_ms: 1.384\n",
      "    num_steps_sampled: 1910000\n",
      "    num_steps_trained: 1910000\n",
      "    sample_time_ms: 15757.744\n",
      "    update_time_ms: 4.774\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3562.134182691574\n",
      "  time_this_iter_s: 17.167707681655884\n",
      "  time_total_s: 3562.134182691574\n",
      "  timestamp: 1550619987\n",
      "  timesteps_since_restore: 1910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1910000\n",
      "  training_iteration: 191\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3562 s, 191 iter, 1910000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-46-44\n",
      "  done: false\n",
      "  episode_len_mean: 129.5\n",
      "  episode_reward_max: 211.8390546175513\n",
      "  episode_reward_mean: 162.22599877753294\n",
      "  episode_reward_min: -43.574645985766175\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 13997\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.588012933731079\n",
      "      kl: 0.015328442677855492\n",
      "      policy_loss: -0.0018486984772607684\n",
      "      total_loss: 44.13789749145508\n",
      "      vf_explained_var: 0.9826281666755676\n",
      "      vf_loss: 44.13974380493164\n",
      "    grad_time_ms: 1543.751\n",
      "    load_time_ms: 1.392\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "    sample_time_ms: 15755.656\n",
      "    update_time_ms: 4.842\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3579.015048980713\n",
      "  time_this_iter_s: 16.880866289138794\n",
      "  time_total_s: 3579.015048980713\n",
      "  timestamp: 1550620004\n",
      "  timesteps_since_restore: 1920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 192\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3579 s, 192 iter, 1920000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-47-01\n",
      "  done: false\n",
      "  episode_len_mean: 127.61\n",
      "  episode_reward_max: 203.52673775857633\n",
      "  episode_reward_mean: 157.559442291683\n",
      "  episode_reward_min: -47.807768310945804\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 14076\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.512833833694458\n",
      "      kl: 0.014628107659518719\n",
      "      policy_loss: -0.005969873629510403\n",
      "      total_loss: 75.0965805053711\n",
      "      vf_explained_var: 0.9705401659011841\n",
      "      vf_loss: 75.10254669189453\n",
      "    grad_time_ms: 1547.136\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 1930000\n",
      "    num_steps_trained: 1930000\n",
      "    sample_time_ms: 15724.917\n",
      "    update_time_ms: 4.736\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3596.575805425644\n",
      "  time_this_iter_s: 17.56075644493103\n",
      "  time_total_s: 3596.575805425644\n",
      "  timestamp: 1550620021\n",
      "  timesteps_since_restore: 1930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1930000\n",
      "  training_iteration: 193\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3596 s, 193 iter, 1930000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-47-18\n",
      "  done: false\n",
      "  episode_len_mean: 127.75\n",
      "  episode_reward_max: 197.37587450990588\n",
      "  episode_reward_mean: 158.30240893007152\n",
      "  episode_reward_min: -45.95775679934141\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 14155\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.512594699859619\n",
      "      kl: 0.026305733248591423\n",
      "      policy_loss: 0.003633173881098628\n",
      "      total_loss: 82.280029296875\n",
      "      vf_explained_var: 0.9670429825782776\n",
      "      vf_loss: 82.27639770507812\n",
      "    grad_time_ms: 1545.334\n",
      "    load_time_ms: 1.312\n",
      "    num_steps_sampled: 1940000\n",
      "    num_steps_trained: 1940000\n",
      "    sample_time_ms: 15699.938\n",
      "    update_time_ms: 4.767\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3613.7013165950775\n",
      "  time_this_iter_s: 17.125511169433594\n",
      "  time_total_s: 3613.7013165950775\n",
      "  timestamp: 1550620038\n",
      "  timesteps_since_restore: 1940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1940000\n",
      "  training_iteration: 194\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3613 s, 194 iter, 1940000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-47-36\n",
      "  done: false\n",
      "  episode_len_mean: 129.24\n",
      "  episode_reward_max: 197.37587450990588\n",
      "  episode_reward_mean: 159.16335917815755\n",
      "  episode_reward_min: 91.48409859821359\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 14232\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.682042121887207\n",
      "      kl: 0.01807977631688118\n",
      "      policy_loss: -0.00014252438268158585\n",
      "      total_loss: 31.224740982055664\n",
      "      vf_explained_var: 0.9871601462364197\n",
      "      vf_loss: 31.22488784790039\n",
      "    grad_time_ms: 1548.719\n",
      "    load_time_ms: 1.307\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "    sample_time_ms: 15661.772\n",
      "    update_time_ms: 4.933\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3631.044112443924\n",
      "  time_this_iter_s: 17.342795848846436\n",
      "  time_total_s: 3631.044112443924\n",
      "  timestamp: 1550620056\n",
      "  timesteps_since_restore: 1950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 195\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3631 s, 195 iter, 1950000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-47-53\n",
      "  done: false\n",
      "  episode_len_mean: 126.86\n",
      "  episode_reward_max: 194.6407137942491\n",
      "  episode_reward_mean: 152.53815057711302\n",
      "  episode_reward_min: -48.713329380396566\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 14311\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.465329885482788\n",
      "      kl: 0.013706617057323456\n",
      "      policy_loss: -0.0006012952653691173\n",
      "      total_loss: 93.61795043945312\n",
      "      vf_explained_var: 0.9637790322303772\n",
      "      vf_loss: 93.61854553222656\n",
      "    grad_time_ms: 1562.135\n",
      "    load_time_ms: 1.31\n",
      "    num_steps_sampled: 1960000\n",
      "    num_steps_trained: 1960000\n",
      "    sample_time_ms: 15631.283\n",
      "    update_time_ms: 4.837\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3648.2239079475403\n",
      "  time_this_iter_s: 17.179795503616333\n",
      "  time_total_s: 3648.2239079475403\n",
      "  timestamp: 1550620073\n",
      "  timesteps_since_restore: 1960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1960000\n",
      "  training_iteration: 196\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3648 s, 196 iter, 1960000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-48-10\n",
      "  done: false\n",
      "  episode_len_mean: 123.25\n",
      "  episode_reward_max: 196.69877970100632\n",
      "  episode_reward_mean: 143.38497937804775\n",
      "  episode_reward_min: -50.70082848083854\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 14393\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.977850717950488e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3445041179656982\n",
      "      kl: 22.360200881958008\n",
      "      policy_loss: 0.05103136971592903\n",
      "      total_loss: 300.0820617675781\n",
      "      vf_explained_var: 0.8916538953781128\n",
      "      vf_loss: 300.0310363769531\n",
      "    grad_time_ms: 1563.937\n",
      "    load_time_ms: 1.287\n",
      "    num_steps_sampled: 1970000\n",
      "    num_steps_trained: 1970000\n",
      "    sample_time_ms: 15589.971\n",
      "    update_time_ms: 4.973\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3665.156750679016\n",
      "  time_this_iter_s: 16.93284273147583\n",
      "  time_total_s: 3665.156750679016\n",
      "  timestamp: 1550620090\n",
      "  timesteps_since_restore: 1970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1970000\n",
      "  training_iteration: 197\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3665 s, 197 iter, 1970000 ts, 143 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-48-28\n",
      "  done: false\n",
      "  episode_len_mean: 123.31\n",
      "  episode_reward_max: 187.04392143346303\n",
      "  episode_reward_mean: 148.56547951461508\n",
      "  episode_reward_min: -50.70082848083854\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 14474\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.46677538667244e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4234936237335205\n",
      "      kl: 0.011166457086801529\n",
      "      policy_loss: 0.00017062459664884955\n",
      "      total_loss: 125.73511505126953\n",
      "      vf_explained_var: 0.9511812925338745\n",
      "      vf_loss: 125.73497772216797\n",
      "    grad_time_ms: 1559.054\n",
      "    load_time_ms: 1.328\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "    sample_time_ms: 15570.219\n",
      "    update_time_ms: 4.934\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3682.570262670517\n",
      "  time_this_iter_s: 17.413511991500854\n",
      "  time_total_s: 3682.570262670517\n",
      "  timestamp: 1550620108\n",
      "  timesteps_since_restore: 1980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 198\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3682 s, 198 iter, 1980000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-48-45\n",
      "  done: false\n",
      "  episode_len_mean: 127.93\n",
      "  episode_reward_max: 207.0199805963601\n",
      "  episode_reward_mean: 160.00188821828564\n",
      "  episode_reward_min: -42.38923096479757\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 14552\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.46677538667244e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.596921682357788\n",
      "      kl: 0.017116248607635498\n",
      "      policy_loss: 0.004227609373629093\n",
      "      total_loss: 14.542490005493164\n",
      "      vf_explained_var: 0.9941462278366089\n",
      "      vf_loss: 14.538259506225586\n",
      "    grad_time_ms: 1560.745\n",
      "    load_time_ms: 1.279\n",
      "    num_steps_sampled: 1990000\n",
      "    num_steps_trained: 1990000\n",
      "    sample_time_ms: 15620.801\n",
      "    update_time_ms: 5.146\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3699.842580795288\n",
      "  time_this_iter_s: 17.272318124771118\n",
      "  time_total_s: 3699.842580795288\n",
      "  timestamp: 1550620125\n",
      "  timesteps_since_restore: 1990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1990000\n",
      "  training_iteration: 199\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3699 s, 199 iter, 1990000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-49-02\n",
      "  done: false\n",
      "  episode_len_mean: 125.97\n",
      "  episode_reward_max: 198.93378815349965\n",
      "  episode_reward_mean: 156.1625012418964\n",
      "  episode_reward_min: -51.21030069223723\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 14631\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.46677538667244e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.468432903289795\n",
      "      kl: 0.03198884800076485\n",
      "      policy_loss: 0.0006731020985171199\n",
      "      total_loss: 101.51626586914062\n",
      "      vf_explained_var: 0.9577919244766235\n",
      "      vf_loss: 101.51558685302734\n",
      "    grad_time_ms: 1559.676\n",
      "    load_time_ms: 1.278\n",
      "    num_steps_sampled: 2000000\n",
      "    num_steps_trained: 2000000\n",
      "    sample_time_ms: 15616.396\n",
      "    update_time_ms: 5.141\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3716.922862768173\n",
      "  time_this_iter_s: 17.080281972885132\n",
      "  time_total_s: 3716.922862768173\n",
      "  timestamp: 1550620142\n",
      "  timesteps_since_restore: 2000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2000000\n",
      "  training_iteration: 200\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3716 s, 200 iter, 2000000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-49-19\n",
      "  done: false\n",
      "  episode_len_mean: 127.58\n",
      "  episode_reward_max: 198.93378815349965\n",
      "  episode_reward_mean: 157.29515063502237\n",
      "  episode_reward_min: -43.69623200742915\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 14710\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.46677538667244e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.533381462097168\n",
      "      kl: 4.417206764221191\n",
      "      policy_loss: 0.04308706149458885\n",
      "      total_loss: 129.03619384765625\n",
      "      vf_explained_var: 0.9511869549751282\n",
      "      vf_loss: 128.99313354492188\n",
      "    grad_time_ms: 1562.544\n",
      "    load_time_ms: 1.272\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "    sample_time_ms: 15560.06\n",
      "    update_time_ms: 5.014\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3733.555008172989\n",
      "  time_this_iter_s: 16.632145404815674\n",
      "  time_total_s: 3733.555008172989\n",
      "  timestamp: 1550620159\n",
      "  timesteps_since_restore: 2010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 201\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3733 s, 201 iter, 2010000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-49-36\n",
      "  done: false\n",
      "  episode_len_mean: 123.28\n",
      "  episode_reward_max: 193.62965012688466\n",
      "  episode_reward_mean: 144.75940565921735\n",
      "  episode_reward_min: -47.85668476043952\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 14790\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.70016091064117e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4140446186065674\n",
      "      kl: 0.027754703536629677\n",
      "      policy_loss: 0.003970778547227383\n",
      "      total_loss: 179.53810119628906\n",
      "      vf_explained_var: 0.9329132437705994\n",
      "      vf_loss: 179.53414916992188\n",
      "    grad_time_ms: 1566.669\n",
      "    load_time_ms: 1.266\n",
      "    num_steps_sampled: 2020000\n",
      "    num_steps_trained: 2020000\n",
      "    sample_time_ms: 15559.025\n",
      "    update_time_ms: 4.952\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3750.4667978286743\n",
      "  time_this_iter_s: 16.911789655685425\n",
      "  time_total_s: 3750.4667978286743\n",
      "  timestamp: 1550620176\n",
      "  timesteps_since_restore: 2020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2020000\n",
      "  training_iteration: 202\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3750 s, 202 iter, 2020000 ts, 145 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 124.67\n",
      "  episode_reward_max: 204.13327799014533\n",
      "  episode_reward_mean: 153.90780475599598\n",
      "  episode_reward_min: -44.63422098873868\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 14871\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.70016091064117e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3831727504730225\n",
      "      kl: 0.013092291541397572\n",
      "      policy_loss: 0.0006837905966676772\n",
      "      total_loss: 65.55641174316406\n",
      "      vf_explained_var: 0.9738597273826599\n",
      "      vf_loss: 65.55571746826172\n",
      "    grad_time_ms: 1563.127\n",
      "    load_time_ms: 1.3\n",
      "    num_steps_sampled: 2030000\n",
      "    num_steps_trained: 2030000\n",
      "    sample_time_ms: 15454.605\n",
      "    update_time_ms: 5.007\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3766.9505319595337\n",
      "  time_this_iter_s: 16.483734130859375\n",
      "  time_total_s: 3766.9505319595337\n",
      "  timestamp: 1550620192\n",
      "  timesteps_since_restore: 2030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2030000\n",
      "  training_iteration: 203\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3766 s, 203 iter, 2030000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-50-09\n",
      "  done: false\n",
      "  episode_len_mean: 123.52\n",
      "  episode_reward_max: 199.0409201704482\n",
      "  episode_reward_mean: 153.27887674584792\n",
      "  episode_reward_min: -46.50455716812965\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 14951\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.70016091064117e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4332542419433594\n",
      "      kl: 0.027224158868193626\n",
      "      policy_loss: 0.004484784323722124\n",
      "      total_loss: 87.93538665771484\n",
      "      vf_explained_var: 0.9636034965515137\n",
      "      vf_loss: 87.93089294433594\n",
      "    grad_time_ms: 1564.337\n",
      "    load_time_ms: 1.255\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "    sample_time_ms: 15470.63\n",
      "    update_time_ms: 5.112\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3784.2476925849915\n",
      "  time_this_iter_s: 17.297160625457764\n",
      "  time_total_s: 3784.2476925849915\n",
      "  timestamp: 1550620209\n",
      "  timesteps_since_restore: 2040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 204\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3784 s, 204 iter, 2040000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-50-27\n",
      "  done: false\n",
      "  episode_len_mean: 122.92\n",
      "  episode_reward_max: 196.18556935406565\n",
      "  episode_reward_mean: 154.61450233225165\n",
      "  episode_reward_min: -44.541521784987786\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 15033\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.70016091064117e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.273216962814331\n",
      "      kl: 0.011760530062019825\n",
      "      policy_loss: -0.0014949905453249812\n",
      "      total_loss: 62.954559326171875\n",
      "      vf_explained_var: 0.9751545786857605\n",
      "      vf_loss: 62.95604705810547\n",
      "    grad_time_ms: 1561.313\n",
      "    load_time_ms: 1.294\n",
      "    num_steps_sampled: 2050000\n",
      "    num_steps_trained: 2050000\n",
      "    sample_time_ms: 15502.618\n",
      "    update_time_ms: 5.094\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3801.8813972473145\n",
      "  time_this_iter_s: 17.633704662322998\n",
      "  time_total_s: 3801.8813972473145\n",
      "  timestamp: 1550620227\n",
      "  timesteps_since_restore: 2050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2050000\n",
      "  training_iteration: 205\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3801 s, 205 iter, 2050000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-50-44\n",
      "  done: false\n",
      "  episode_len_mean: 124.55\n",
      "  episode_reward_max: 200.47231477026872\n",
      "  episode_reward_mean: 157.73469474201522\n",
      "  episode_reward_min: -40.592896357031144\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 15113\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.70016091064117e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.437568187713623\n",
      "      kl: 0.015492811799049377\n",
      "      policy_loss: 0.0018738865619525313\n",
      "      total_loss: 15.95864486694336\n",
      "      vf_explained_var: 0.9936204552650452\n",
      "      vf_loss: 15.956772804260254\n",
      "    grad_time_ms: 1547.728\n",
      "    load_time_ms: 1.331\n",
      "    num_steps_sampled: 2060000\n",
      "    num_steps_trained: 2060000\n",
      "    sample_time_ms: 15510.491\n",
      "    update_time_ms: 5.118\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3819.0021891593933\n",
      "  time_this_iter_s: 17.120791912078857\n",
      "  time_total_s: 3819.0021891593933\n",
      "  timestamp: 1550620244\n",
      "  timesteps_since_restore: 2060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2060000\n",
      "  training_iteration: 206\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3819 s, 206 iter, 2060000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-51-01\n",
      "  done: false\n",
      "  episode_len_mean: 125.84\n",
      "  episode_reward_max: 200.47231477026872\n",
      "  episode_reward_mean: 159.7551947463407\n",
      "  episode_reward_min: -41.45452121637836\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 15193\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.70016091064117e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5513057708740234\n",
      "      kl: 2.066901922225952\n",
      "      policy_loss: 0.03491431474685669\n",
      "      total_loss: 55.45896530151367\n",
      "      vf_explained_var: 0.9772332310676575\n",
      "      vf_loss: 55.42405319213867\n",
      "    grad_time_ms: 1550.817\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "    sample_time_ms: 15526.241\n",
      "    update_time_ms: 4.931\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3836.1253368854523\n",
      "  time_this_iter_s: 17.12314772605896\n",
      "  time_total_s: 3836.1253368854523\n",
      "  timestamp: 1550620261\n",
      "  timesteps_since_restore: 2070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 207\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3836 s, 207 iter, 2070000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-51-18\n",
      "  done: false\n",
      "  episode_len_mean: 124.39\n",
      "  episode_reward_max: 197.32658938429137\n",
      "  episode_reward_mean: 153.9392409010668\n",
      "  episode_reward_min: -47.598210974495025\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 15273\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.005024649355764e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.393679141998291\n",
      "      kl: 0.014112346805632114\n",
      "      policy_loss: -0.0023127596359699965\n",
      "      total_loss: 78.00282287597656\n",
      "      vf_explained_var: 0.9699801206588745\n",
      "      vf_loss: 78.00514221191406\n",
      "    grad_time_ms: 1550.869\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 2080000\n",
      "    num_steps_trained: 2080000\n",
      "    sample_time_ms: 15482.772\n",
      "    update_time_ms: 4.837\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3853.103748559952\n",
      "  time_this_iter_s: 16.97841167449951\n",
      "  time_total_s: 3853.103748559952\n",
      "  timestamp: 1550620278\n",
      "  timesteps_since_restore: 2080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2080000\n",
      "  training_iteration: 208\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3853 s, 208 iter, 2080000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-51-36\n",
      "  done: false\n",
      "  episode_len_mean: 125.07\n",
      "  episode_reward_max: 205.39437878308894\n",
      "  episode_reward_mean: 148.78454300716137\n",
      "  episode_reward_min: -47.702643717869655\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 15352\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.005024649355764e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5858089923858643\n",
      "      kl: 0.009271339513361454\n",
      "      policy_loss: -0.0010091406293213367\n",
      "      total_loss: 127.67759704589844\n",
      "      vf_explained_var: 0.9510369896888733\n",
      "      vf_loss: 127.6785888671875\n",
      "    grad_time_ms: 1554.721\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 2090000\n",
      "    num_steps_trained: 2090000\n",
      "    sample_time_ms: 15488.141\n",
      "    update_time_ms: 4.645\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3870.4654631614685\n",
      "  time_this_iter_s: 17.361714601516724\n",
      "  time_total_s: 3870.4654631614685\n",
      "  timestamp: 1550620296\n",
      "  timesteps_since_restore: 2090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2090000\n",
      "  training_iteration: 209\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3870 s, 209 iter, 2090000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-51-53\n",
      "  done: false\n",
      "  episode_len_mean: 125.03\n",
      "  episode_reward_max: 197.7505166484135\n",
      "  episode_reward_mean: 154.93137170622\n",
      "  episode_reward_min: -48.50283934367765\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 15433\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.40248966217041\n",
      "      kl: 0.02803599275648594\n",
      "      policy_loss: -0.003937557339668274\n",
      "      total_loss: 140.802978515625\n",
      "      vf_explained_var: 0.9465807676315308\n",
      "      vf_loss: 140.80691528320312\n",
      "    grad_time_ms: 1568.048\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "    sample_time_ms: 15486.763\n",
      "    update_time_ms: 4.576\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3887.666750192642\n",
      "  time_this_iter_s: 17.201287031173706\n",
      "  time_total_s: 3887.666750192642\n",
      "  timestamp: 1550620313\n",
      "  timesteps_since_restore: 2100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 210\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3887 s, 210 iter, 2100000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-52-10\n",
      "  done: false\n",
      "  episode_len_mean: 123.4\n",
      "  episode_reward_max: 199.30121466355152\n",
      "  episode_reward_mean: 154.65177279682902\n",
      "  episode_reward_min: -48.50283934367765\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 15515\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.365478038787842\n",
      "      kl: 0.015119442716240883\n",
      "      policy_loss: -0.0011450762394815683\n",
      "      total_loss: 73.69857025146484\n",
      "      vf_explained_var: 0.9734674096107483\n",
      "      vf_loss: 73.69972229003906\n",
      "    grad_time_ms: 1566.025\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 2110000\n",
      "    num_steps_trained: 2110000\n",
      "    sample_time_ms: 15566.582\n",
      "    update_time_ms: 4.631\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3905.0780823230743\n",
      "  time_this_iter_s: 17.41133213043213\n",
      "  time_total_s: 3905.0780823230743\n",
      "  timestamp: 1550620330\n",
      "  timesteps_since_restore: 2110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2110000\n",
      "  training_iteration: 211\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3905 s, 211 iter, 2110000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-52-28\n",
      "  done: false\n",
      "  episode_len_mean: 124.73\n",
      "  episode_reward_max: 195.07942872560852\n",
      "  episode_reward_mean: 156.1876317851615\n",
      "  episode_reward_min: -46.41706934497499\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 15594\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4040305614471436\n",
      "      kl: 0.012331339530646801\n",
      "      policy_loss: -0.0005124472663737833\n",
      "      total_loss: 44.156837463378906\n",
      "      vf_explained_var: 0.9821473360061646\n",
      "      vf_loss: 44.15735626220703\n",
      "    grad_time_ms: 1562.872\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 2120000\n",
      "    num_steps_trained: 2120000\n",
      "    sample_time_ms: 15608.664\n",
      "    update_time_ms: 4.647\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3922.382527112961\n",
      "  time_this_iter_s: 17.304444789886475\n",
      "  time_total_s: 3922.382527112961\n",
      "  timestamp: 1550620348\n",
      "  timesteps_since_restore: 2120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2120000\n",
      "  training_iteration: 212\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3922 s, 212 iter, 2120000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-52-45\n",
      "  done: false\n",
      "  episode_len_mean: 125.25\n",
      "  episode_reward_max: 206.26118295824162\n",
      "  episode_reward_mean: 156.37804258888218\n",
      "  episode_reward_min: -44.615501307614956\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 15674\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.558497905731201\n",
      "      kl: 0.013695809990167618\n",
      "      policy_loss: 0.000492886349093169\n",
      "      total_loss: 67.04326629638672\n",
      "      vf_explained_var: 0.9726806282997131\n",
      "      vf_loss: 67.04278564453125\n",
      "    grad_time_ms: 1564.424\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "    sample_time_ms: 15696.137\n",
      "    update_time_ms: 4.611\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3939.7547402381897\n",
      "  time_this_iter_s: 17.372213125228882\n",
      "  time_total_s: 3939.7547402381897\n",
      "  timestamp: 1550620365\n",
      "  timesteps_since_restore: 2130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 213\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3939 s, 213 iter, 2130000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-53-02\n",
      "  done: false\n",
      "  episode_len_mean: 125.28\n",
      "  episode_reward_max: 206.26118295824162\n",
      "  episode_reward_mean: 156.42520818164843\n",
      "  episode_reward_min: -48.61628398077914\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 15754\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.383852958679199\n",
      "      kl: 0.012935352511703968\n",
      "      policy_loss: 0.0019573275931179523\n",
      "      total_loss: 75.22288513183594\n",
      "      vf_explained_var: 0.9696154594421387\n",
      "      vf_loss: 75.22093200683594\n",
      "    grad_time_ms: 1561.77\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 2140000\n",
      "    num_steps_trained: 2140000\n",
      "    sample_time_ms: 15667.192\n",
      "    update_time_ms: 4.496\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3956.7375581264496\n",
      "  time_this_iter_s: 16.982817888259888\n",
      "  time_total_s: 3956.7375581264496\n",
      "  timestamp: 1550620382\n",
      "  timesteps_since_restore: 2140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2140000\n",
      "  training_iteration: 214\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3956 s, 214 iter, 2140000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-53-19\n",
      "  done: false\n",
      "  episode_len_mean: 126.18\n",
      "  episode_reward_max: 206.17272324719931\n",
      "  episode_reward_mean: 157.15580095829444\n",
      "  episode_reward_min: -39.045027662031686\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 15834\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4126336574554443\n",
      "      kl: 0.017667286098003387\n",
      "      policy_loss: -0.001714065670967102\n",
      "      total_loss: 33.18594741821289\n",
      "      vf_explained_var: 0.9872013926506042\n",
      "      vf_loss: 33.18765640258789\n",
      "    grad_time_ms: 1561.109\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 2150000\n",
      "    num_steps_trained: 2150000\n",
      "    sample_time_ms: 15611.181\n",
      "    update_time_ms: 4.382\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3973.8009748458862\n",
      "  time_this_iter_s: 17.063416719436646\n",
      "  time_total_s: 3973.8009748458862\n",
      "  timestamp: 1550620399\n",
      "  timesteps_since_restore: 2150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2150000\n",
      "  training_iteration: 215\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3973 s, 215 iter, 2150000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-53-37\n",
      "  done: false\n",
      "  episode_len_mean: 125.61\n",
      "  episode_reward_max: 206.17272324719931\n",
      "  episode_reward_mean: 154.8128496119539\n",
      "  episode_reward_min: -43.16406880363377\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 15913\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4711899757385254\n",
      "      kl: 0.03341618552803993\n",
      "      policy_loss: -0.0026219033170491457\n",
      "      total_loss: 89.306640625\n",
      "      vf_explained_var: 0.9654806852340698\n",
      "      vf_loss: 89.30926513671875\n",
      "    grad_time_ms: 1564.809\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "    sample_time_ms: 15618.017\n",
      "    update_time_ms: 4.424\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 3991.027134656906\n",
      "  time_this_iter_s: 17.226159811019897\n",
      "  time_total_s: 3991.027134656906\n",
      "  timestamp: 1550620417\n",
      "  timesteps_since_restore: 2160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 216\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 3991 s, 216 iter, 2160000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-53-54\n",
      "  done: false\n",
      "  episode_len_mean: 123.53\n",
      "  episode_reward_max: 194.78614537609678\n",
      "  episode_reward_mean: 155.64411490837648\n",
      "  episode_reward_min: -48.218285958365634\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 15994\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3127288818359375\n",
      "      kl: 0.015304474160075188\n",
      "      policy_loss: -0.0010504676029086113\n",
      "      total_loss: 65.9847412109375\n",
      "      vf_explained_var: 0.974026620388031\n",
      "      vf_loss: 65.98578643798828\n",
      "    grad_time_ms: 1585.699\n",
      "    load_time_ms: 1.38\n",
      "    num_steps_sampled: 2170000\n",
      "    num_steps_trained: 2170000\n",
      "    sample_time_ms: 15600.849\n",
      "    update_time_ms: 4.498\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4008.184761285782\n",
      "  time_this_iter_s: 17.157626628875732\n",
      "  time_total_s: 4008.184761285782\n",
      "  timestamp: 1550620434\n",
      "  timesteps_since_restore: 2170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2170000\n",
      "  training_iteration: 217\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4008 s, 217 iter, 2170000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-54-11\n",
      "  done: false\n",
      "  episode_len_mean: 124.42\n",
      "  episode_reward_max: 188.28482128790407\n",
      "  episode_reward_mean: 154.08415188978316\n",
      "  episode_reward_min: -45.52996206490119\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 16074\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.334394931793213\n",
      "      kl: 0.03485070914030075\n",
      "      policy_loss: -0.0010281478753313422\n",
      "      total_loss: 81.06189727783203\n",
      "      vf_explained_var: 0.9681742787361145\n",
      "      vf_loss: 81.06293487548828\n",
      "    grad_time_ms: 1584.8\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 2180000\n",
      "    num_steps_trained: 2180000\n",
      "    sample_time_ms: 15604.348\n",
      "    update_time_ms: 4.511\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4025.1906309127808\n",
      "  time_this_iter_s: 17.0058696269989\n",
      "  time_total_s: 4025.1906309127808\n",
      "  timestamp: 1550620451\n",
      "  timesteps_since_restore: 2180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2180000\n",
      "  training_iteration: 218\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4025 s, 218 iter, 2180000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-54-29\n",
      "  done: false\n",
      "  episode_len_mean: 123.17\n",
      "  episode_reward_max: 188.04751508867392\n",
      "  episode_reward_mean: 150.29130815707546\n",
      "  episode_reward_min: -47.17712017244633\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 16155\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3186542987823486\n",
      "      kl: 0.012523303739726543\n",
      "      policy_loss: -0.0007505107787437737\n",
      "      total_loss: 77.63841247558594\n",
      "      vf_explained_var: 0.9687126278877258\n",
      "      vf_loss: 77.63917541503906\n",
      "    grad_time_ms: 1579.423\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "    sample_time_ms: 15680.792\n",
      "    update_time_ms: 4.433\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4043.263252258301\n",
      "  time_this_iter_s: 18.07262134552002\n",
      "  time_total_s: 4043.263252258301\n",
      "  timestamp: 1550620469\n",
      "  timesteps_since_restore: 2190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 219\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4043 s, 219 iter, 2190000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 121.41\n",
      "  episode_reward_max: 194.98060919355484\n",
      "  episode_reward_mean: 150.65264903732992\n",
      "  episode_reward_min: -47.17712017244633\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 16238\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.266930103302002\n",
      "      kl: 0.014734086580574512\n",
      "      policy_loss: -0.0012071134988218546\n",
      "      total_loss: 94.18485260009766\n",
      "      vf_explained_var: 0.9628939628601074\n",
      "      vf_loss: 94.1860580444336\n",
      "    grad_time_ms: 1564.939\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 2200000\n",
      "    num_steps_trained: 2200000\n",
      "    sample_time_ms: 15645.441\n",
      "    update_time_ms: 4.566\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4059.9631745815277\n",
      "  time_this_iter_s: 16.69992232322693\n",
      "  time_total_s: 4059.9631745815277\n",
      "  timestamp: 1550620486\n",
      "  timesteps_since_restore: 2200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2200000\n",
      "  training_iteration: 220\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4059 s, 220 iter, 2200000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-55-03\n",
      "  done: false\n",
      "  episode_len_mean: 128.27\n",
      "  episode_reward_max: 201.09476342236624\n",
      "  episode_reward_mean: 157.5714725802872\n",
      "  episode_reward_min: 40.77235609529052\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 16315\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5925071239471436\n",
      "      kl: 0.02111721970140934\n",
      "      policy_loss: 0.0014124977169558406\n",
      "      total_loss: 35.4244270324707\n",
      "      vf_explained_var: 0.9856340289115906\n",
      "      vf_loss: 35.423011779785156\n",
      "    grad_time_ms: 1564.507\n",
      "    load_time_ms: 1.434\n",
      "    num_steps_sampled: 2210000\n",
      "    num_steps_trained: 2210000\n",
      "    sample_time_ms: 15662.109\n",
      "    update_time_ms: 4.615\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4077.536442756653\n",
      "  time_this_iter_s: 17.573268175125122\n",
      "  time_total_s: 4077.536442756653\n",
      "  timestamp: 1550620503\n",
      "  timesteps_since_restore: 2210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2210000\n",
      "  training_iteration: 221\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4077 s, 221 iter, 2210000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 124.86\n",
      "  episode_reward_max: 197.5761040673396\n",
      "  episode_reward_mean: 149.0244283384096\n",
      "  episode_reward_min: -48.13662486943868\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 16396\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.02512324677882e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5227105617523193\n",
      "      kl: 0.009162085130810738\n",
      "      policy_loss: -0.0012016699183732271\n",
      "      total_loss: 139.33775329589844\n",
      "      vf_explained_var: 0.9459614753723145\n",
      "      vf_loss: 139.33892822265625\n",
      "    grad_time_ms: 1562.091\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "    sample_time_ms: 15644.107\n",
      "    update_time_ms: 4.534\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4094.632745742798\n",
      "  time_this_iter_s: 17.09630298614502\n",
      "  time_total_s: 4094.632745742798\n",
      "  timestamp: 1550620520\n",
      "  timesteps_since_restore: 2220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 222\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4094 s, 222 iter, 2220000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-55-38\n",
      "  done: false\n",
      "  episode_len_mean: 124.73\n",
      "  episode_reward_max: 194.29982124313278\n",
      "  episode_reward_mean: 152.4636768855054\n",
      "  episode_reward_min: -49.88463029737518\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 16475\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.51256162338941e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3651583194732666\n",
      "      kl: 0.011194756254553795\n",
      "      policy_loss: -0.000747950398363173\n",
      "      total_loss: 60.481258392333984\n",
      "      vf_explained_var: 0.9756209254264832\n",
      "      vf_loss: 60.48199462890625\n",
      "    grad_time_ms: 1563.792\n",
      "    load_time_ms: 1.412\n",
      "    num_steps_sampled: 2230000\n",
      "    num_steps_trained: 2230000\n",
      "    sample_time_ms: 15676.86\n",
      "    update_time_ms: 4.613\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4112.350789785385\n",
      "  time_this_iter_s: 17.71804404258728\n",
      "  time_total_s: 4112.350789785385\n",
      "  timestamp: 1550620538\n",
      "  timesteps_since_restore: 2230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2230000\n",
      "  training_iteration: 223\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4112 s, 223 iter, 2230000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-55-56\n",
      "  done: false\n",
      "  episode_len_mean: 124.03\n",
      "  episode_reward_max: 197.31054501869903\n",
      "  episode_reward_mean: 156.68330200227965\n",
      "  episode_reward_min: -44.738284404177456\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 16555\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.51256162338941e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.258683443069458\n",
      "      kl: 0.015281806699931622\n",
      "      policy_loss: -0.0031711836345493793\n",
      "      total_loss: 38.58115005493164\n",
      "      vf_explained_var: 0.984847366809845\n",
      "      vf_loss: 38.58431625366211\n",
      "    grad_time_ms: 1565.524\n",
      "    load_time_ms: 1.389\n",
      "    num_steps_sampled: 2240000\n",
      "    num_steps_trained: 2240000\n",
      "    sample_time_ms: 15706.609\n",
      "    update_time_ms: 4.663\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4129.646737337112\n",
      "  time_this_iter_s: 17.295947551727295\n",
      "  time_total_s: 4129.646737337112\n",
      "  timestamp: 1550620556\n",
      "  timesteps_since_restore: 2240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2240000\n",
      "  training_iteration: 224\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4129 s, 224 iter, 2240000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-56-13\n",
      "  done: false\n",
      "  episode_len_mean: 126.06\n",
      "  episode_reward_max: 197.31054501869903\n",
      "  episode_reward_mean: 160.5029973860709\n",
      "  episode_reward_min: 125.48392870865997\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 16635\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.51256162338941e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3179149627685547\n",
      "      kl: 0.013826422393321991\n",
      "      policy_loss: -0.0007204531575553119\n",
      "      total_loss: 10.959120750427246\n",
      "      vf_explained_var: 0.9953553676605225\n",
      "      vf_loss: 10.959840774536133\n",
      "    grad_time_ms: 1566.832\n",
      "    load_time_ms: 1.376\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "    sample_time_ms: 15713.662\n",
      "    update_time_ms: 4.685\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4146.79372048378\n",
      "  time_this_iter_s: 17.14698314666748\n",
      "  time_total_s: 4146.79372048378\n",
      "  timestamp: 1550620573\n",
      "  timesteps_since_restore: 2250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 225\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4146 s, 225 iter, 2250000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-56-30\n",
      "  done: false\n",
      "  episode_len_mean: 124.63\n",
      "  episode_reward_max: 188.84199819072057\n",
      "  episode_reward_mean: 160.91370899617039\n",
      "  episode_reward_min: -42.23860143611927\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 16716\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.51256162338941e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2335052490234375\n",
      "      kl: 12.032065391540527\n",
      "      policy_loss: 0.03513789549469948\n",
      "      total_loss: 67.74324798583984\n",
      "      vf_explained_var: 0.9735655188560486\n",
      "      vf_loss: 67.7081069946289\n",
      "    grad_time_ms: 1561.993\n",
      "    load_time_ms: 1.417\n",
      "    num_steps_sampled: 2260000\n",
      "    num_steps_trained: 2260000\n",
      "    sample_time_ms: 15729.352\n",
      "    update_time_ms: 4.6\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4164.129080057144\n",
      "  time_this_iter_s: 17.335359573364258\n",
      "  time_total_s: 4164.129080057144\n",
      "  timestamp: 1550620590\n",
      "  timesteps_since_restore: 2260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2260000\n",
      "  training_iteration: 226\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4164 s, 226 iter, 2260000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-56-47\n",
      "  done: false\n",
      "  episode_len_mean: 123.59\n",
      "  episode_reward_max: 195.66775342172923\n",
      "  episode_reward_mean: 156.3027099436422\n",
      "  episode_reward_min: -51.73002515231617\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 16797\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.76884135040037e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.295262336730957\n",
      "      kl: 0.01413847878575325\n",
      "      policy_loss: -0.0025604579132050276\n",
      "      total_loss: 101.22183227539062\n",
      "      vf_explained_var: 0.9627543687820435\n",
      "      vf_loss: 101.22438049316406\n",
      "    grad_time_ms: 1539.512\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 2270000\n",
      "    num_steps_trained: 2270000\n",
      "    sample_time_ms: 15720.703\n",
      "    update_time_ms: 4.516\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4180.974135398865\n",
      "  time_this_iter_s: 16.84505534172058\n",
      "  time_total_s: 4180.974135398865\n",
      "  timestamp: 1550620607\n",
      "  timesteps_since_restore: 2270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2270000\n",
      "  training_iteration: 227\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4180 s, 227 iter, 2270000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-57-05\n",
      "  done: false\n",
      "  episode_len_mean: 127.34\n",
      "  episode_reward_max: 204.29000810703428\n",
      "  episode_reward_mean: 163.07021474980147\n",
      "  episode_reward_min: -38.051197535330715\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 16875\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.76884135040037e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4375059604644775\n",
      "      kl: 0.02367394044995308\n",
      "      policy_loss: 0.0015336365904659033\n",
      "      total_loss: 35.79606628417969\n",
      "      vf_explained_var: 0.9861289858818054\n",
      "      vf_loss: 35.79452896118164\n",
      "    grad_time_ms: 1539.119\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "    sample_time_ms: 15776.193\n",
      "    update_time_ms: 4.608\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4198.531771183014\n",
      "  time_this_iter_s: 17.55763578414917\n",
      "  time_total_s: 4198.531771183014\n",
      "  timestamp: 1550620625\n",
      "  timesteps_since_restore: 2280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 228\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4198 s, 228 iter, 2280000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-57-21\n",
      "  done: false\n",
      "  episode_len_mean: 127.02\n",
      "  episode_reward_max: 203.32868226211843\n",
      "  episode_reward_mean: 158.35500825519523\n",
      "  episode_reward_min: -38.051197535330715\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 16954\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.76884135040037e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4669206142425537\n",
      "      kl: 0.019472967833280563\n",
      "      policy_loss: 0.0010325771290808916\n",
      "      total_loss: 41.64223861694336\n",
      "      vf_explained_var: 0.9833142161369324\n",
      "      vf_loss: 41.64120101928711\n",
      "    grad_time_ms: 1541.077\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 2290000\n",
      "    num_steps_trained: 2290000\n",
      "    sample_time_ms: 15656.951\n",
      "    update_time_ms: 4.61\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4215.429880857468\n",
      "  time_this_iter_s: 16.898109674453735\n",
      "  time_total_s: 4215.429880857468\n",
      "  timestamp: 1550620641\n",
      "  timesteps_since_restore: 2290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2290000\n",
      "  training_iteration: 229\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4215 s, 229 iter, 2290000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-57-39\n",
      "  done: false\n",
      "  episode_len_mean: 125.66\n",
      "  episode_reward_max: 201.26538479844527\n",
      "  episode_reward_mean: 162.43187561147784\n",
      "  episode_reward_min: -34.62717147510834\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 17034\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.76884135040037e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.319387912750244\n",
      "      kl: 0.01950147934257984\n",
      "      policy_loss: -0.0012439193669706583\n",
      "      total_loss: 72.8960189819336\n",
      "      vf_explained_var: 0.9735284447669983\n",
      "      vf_loss: 72.89727020263672\n",
      "    grad_time_ms: 1543.433\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 2300000\n",
      "    num_steps_trained: 2300000\n",
      "    sample_time_ms: 15704.531\n",
      "    update_time_ms: 4.521\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4232.628067970276\n",
      "  time_this_iter_s: 17.198187112808228\n",
      "  time_total_s: 4232.628067970276\n",
      "  timestamp: 1550620659\n",
      "  timesteps_since_restore: 2300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2300000\n",
      "  training_iteration: 230\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4232 s, 230 iter, 2300000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-57-56\n",
      "  done: false\n",
      "  episode_len_mean: 124.92\n",
      "  episode_reward_max: 195.03917358033718\n",
      "  episode_reward_mean: 154.77692430568908\n",
      "  episode_reward_min: -46.092043183670185\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 17114\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.76884135040037e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2772514820098877\n",
      "      kl: 0.0322074331343174\n",
      "      policy_loss: -0.0006219833740033209\n",
      "      total_loss: 141.05247497558594\n",
      "      vf_explained_var: 0.9454208612442017\n",
      "      vf_loss: 141.05307006835938\n",
      "    grad_time_ms: 1543.619\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "    sample_time_ms: 15715.291\n",
      "    update_time_ms: 4.405\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4250.308922767639\n",
      "  time_this_iter_s: 17.68085479736328\n",
      "  time_total_s: 4250.308922767639\n",
      "  timestamp: 1550620676\n",
      "  timesteps_since_restore: 2310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 231\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4250 s, 231 iter, 2310000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-58-14\n",
      "  done: false\n",
      "  episode_len_mean: 126.52\n",
      "  episode_reward_max: 203.91040682187776\n",
      "  episode_reward_mean: 160.7037694584385\n",
      "  episode_reward_min: -35.66840162932283\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 17193\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.76884135040037e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.425896644592285\n",
      "      kl: 0.014993730001151562\n",
      "      policy_loss: 0.0025536625180393457\n",
      "      total_loss: 16.778968811035156\n",
      "      vf_explained_var: 0.9934180974960327\n",
      "      vf_loss: 16.77641487121582\n",
      "    grad_time_ms: 1547.685\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 2320000\n",
      "    num_steps_trained: 2320000\n",
      "    sample_time_ms: 15750.738\n",
      "    update_time_ms: 4.489\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4267.798818349838\n",
      "  time_this_iter_s: 17.489895582199097\n",
      "  time_total_s: 4267.798818349838\n",
      "  timestamp: 1550620694\n",
      "  timesteps_since_restore: 2320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2320000\n",
      "  training_iteration: 232\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4267 s, 232 iter, 2320000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 124.61\n",
      "  episode_reward_max: 198.1116632892945\n",
      "  episode_reward_mean: 152.6175863191189\n",
      "  episode_reward_min: -43.37249207127803\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 17272\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.76884135040037e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.356642484664917\n",
      "      kl: 0.07872096449136734\n",
      "      policy_loss: 0.013616185635328293\n",
      "      total_loss: 187.8354949951172\n",
      "      vf_explained_var: 0.9321272373199463\n",
      "      vf_loss: 187.82188415527344\n",
      "    grad_time_ms: 1543.828\n",
      "    load_time_ms: 1.342\n",
      "    num_steps_sampled: 2330000\n",
      "    num_steps_trained: 2330000\n",
      "    sample_time_ms: 15707.93\n",
      "    update_time_ms: 4.406\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4285.048143625259\n",
      "  time_this_iter_s: 17.249325275421143\n",
      "  time_total_s: 4285.048143625259\n",
      "  timestamp: 1550620711\n",
      "  timesteps_since_restore: 2330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2330000\n",
      "  training_iteration: 233\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4285 s, 233 iter, 2330000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-58-49\n",
      "  done: false\n",
      "  episode_len_mean: 126.28\n",
      "  episode_reward_max: 209.25507637327243\n",
      "  episode_reward_mean: 159.78246702949787\n",
      "  episode_reward_min: -43.37249207127803\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 17352\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3861327171325684\n",
      "      kl: 0.02914847992360592\n",
      "      policy_loss: 0.0029957895167171955\n",
      "      total_loss: 57.45320510864258\n",
      "      vf_explained_var: 0.9774755835533142\n",
      "      vf_loss: 57.4502067565918\n",
      "    grad_time_ms: 1543.33\n",
      "    load_time_ms: 1.327\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "    sample_time_ms: 15711.514\n",
      "    update_time_ms: 4.379\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4302.375294685364\n",
      "  time_this_iter_s: 17.32715106010437\n",
      "  time_total_s: 4302.375294685364\n",
      "  timestamp: 1550620729\n",
      "  timesteps_since_restore: 2340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 234\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4302 s, 234 iter, 2340000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-59-06\n",
      "  done: false\n",
      "  episode_len_mean: 126.18\n",
      "  episode_reward_max: 193.78391397818183\n",
      "  episode_reward_mean: 161.97297531986075\n",
      "  episode_reward_min: -41.969346668460574\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 17430\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4160306453704834\n",
      "      kl: 0.017220987007021904\n",
      "      policy_loss: -0.005118322093039751\n",
      "      total_loss: 78.97136688232422\n",
      "      vf_explained_var: 0.9711458086967468\n",
      "      vf_loss: 78.97647857666016\n",
      "    grad_time_ms: 1542.286\n",
      "    load_time_ms: 1.348\n",
      "    num_steps_sampled: 2350000\n",
      "    num_steps_trained: 2350000\n",
      "    sample_time_ms: 15714.068\n",
      "    update_time_ms: 4.355\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4319.539043188095\n",
      "  time_this_iter_s: 17.163748502731323\n",
      "  time_total_s: 4319.539043188095\n",
      "  timestamp: 1550620746\n",
      "  timesteps_since_restore: 2350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2350000\n",
      "  training_iteration: 235\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4319 s, 235 iter, 2350000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-59-23\n",
      "  done: false\n",
      "  episode_len_mean: 123.49\n",
      "  episode_reward_max: 193.78391397818183\n",
      "  episode_reward_mean: 155.73467854381124\n",
      "  episode_reward_min: -43.63915627929243\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 17512\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.410355567932129\n",
      "      kl: 0.031781669706106186\n",
      "      policy_loss: 0.0013903164071962237\n",
      "      total_loss: 84.10467529296875\n",
      "      vf_explained_var: 0.9675832986831665\n",
      "      vf_loss: 84.10328674316406\n",
      "    grad_time_ms: 1544.595\n",
      "    load_time_ms: 1.305\n",
      "    num_steps_sampled: 2360000\n",
      "    num_steps_trained: 2360000\n",
      "    sample_time_ms: 15644.467\n",
      "    update_time_ms: 4.407\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4336.200914144516\n",
      "  time_this_iter_s: 16.6618709564209\n",
      "  time_total_s: 4336.200914144516\n",
      "  timestamp: 1550620763\n",
      "  timesteps_since_restore: 2360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2360000\n",
      "  training_iteration: 236\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4336 s, 236 iter, 2360000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-59-40\n",
      "  done: false\n",
      "  episode_len_mean: 124.33\n",
      "  episode_reward_max: 207.831939879768\n",
      "  episode_reward_mean: 154.49931568284183\n",
      "  episode_reward_min: -46.47583635992341\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 17593\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2990353107452393\n",
      "      kl: 0.023647908121347427\n",
      "      policy_loss: -0.005197370890527964\n",
      "      total_loss: 176.52178955078125\n",
      "      vf_explained_var: 0.9354131817817688\n",
      "      vf_loss: 176.5269775390625\n",
      "    grad_time_ms: 1543.124\n",
      "    load_time_ms: 1.347\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "    sample_time_ms: 15708.43\n",
      "    update_time_ms: 4.41\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4353.673231601715\n",
      "  time_this_iter_s: 17.472317457199097\n",
      "  time_total_s: 4353.673231601715\n",
      "  timestamp: 1550620780\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 237\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4353 s, 237 iter, 2370000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_00-59-57\n",
      "  done: false\n",
      "  episode_len_mean: 126.3\n",
      "  episode_reward_max: 199.11954015124545\n",
      "  episode_reward_mean: 155.48200380573064\n",
      "  episode_reward_min: -44.82440176473398\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 17672\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5289249420166016\n",
      "      kl: 0.014812414534389973\n",
      "      policy_loss: -0.002072899369522929\n",
      "      total_loss: 140.5372314453125\n",
      "      vf_explained_var: 0.9481362700462341\n",
      "      vf_loss: 140.53932189941406\n",
      "    grad_time_ms: 1544.132\n",
      "    load_time_ms: 1.279\n",
      "    num_steps_sampled: 2380000\n",
      "    num_steps_trained: 2380000\n",
      "    sample_time_ms: 15663.734\n",
      "    update_time_ms: 4.406\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4370.79380941391\n",
      "  time_this_iter_s: 17.120577812194824\n",
      "  time_total_s: 4370.79380941391\n",
      "  timestamp: 1550620797\n",
      "  timesteps_since_restore: 2380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2380000\n",
      "  training_iteration: 238\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4370 s, 238 iter, 2380000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-00-14\n",
      "  done: false\n",
      "  episode_len_mean: 127.34\n",
      "  episode_reward_max: 221.43815202701202\n",
      "  episode_reward_mean: 161.4755810008506\n",
      "  episode_reward_min: -44.82440176473398\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 17750\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4572300910949707\n",
      "      kl: 0.010531092062592506\n",
      "      policy_loss: 0.00039352820022031665\n",
      "      total_loss: 12.441136360168457\n",
      "      vf_explained_var: 0.9949312210083008\n",
      "      vf_loss: 12.440741539001465\n",
      "    grad_time_ms: 1542.737\n",
      "    load_time_ms: 1.272\n",
      "    num_steps_sampled: 2390000\n",
      "    num_steps_trained: 2390000\n",
      "    sample_time_ms: 15701.316\n",
      "    update_time_ms: 4.512\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4388.055683374405\n",
      "  time_this_iter_s: 17.261873960494995\n",
      "  time_total_s: 4388.055683374405\n",
      "  timestamp: 1550620814\n",
      "  timesteps_since_restore: 2390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2390000\n",
      "  training_iteration: 239\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4388 s, 239 iter, 2390000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-00-32\n",
      "  done: false\n",
      "  episode_len_mean: 124.63\n",
      "  episode_reward_max: 201.96934696028737\n",
      "  episode_reward_mean: 161.81218192127403\n",
      "  episode_reward_min: -32.386775781907645\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 17831\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2854831218719482\n",
      "      kl: 0.015144551172852516\n",
      "      policy_loss: -0.0008413856849074364\n",
      "      total_loss: 43.565704345703125\n",
      "      vf_explained_var: 0.9828653335571289\n",
      "      vf_loss: 43.566551208496094\n",
      "    grad_time_ms: 1540.833\n",
      "    load_time_ms: 1.273\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "    sample_time_ms: 15735.74\n",
      "    update_time_ms: 4.461\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4405.580785751343\n",
      "  time_this_iter_s: 17.525102376937866\n",
      "  time_total_s: 4405.580785751343\n",
      "  timestamp: 1550620832\n",
      "  timesteps_since_restore: 2400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 240\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4405 s, 240 iter, 2400000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-00-49\n",
      "  done: false\n",
      "  episode_len_mean: 129.51\n",
      "  episode_reward_max: 197.79812925286814\n",
      "  episode_reward_mean: 156.1140321203045\n",
      "  episode_reward_min: -43.29874315769364\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 17907\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.508007049560547\n",
      "      kl: 0.016632303595542908\n",
      "      policy_loss: -0.0036748808342963457\n",
      "      total_loss: 84.17455291748047\n",
      "      vf_explained_var: 0.9722654819488525\n",
      "      vf_loss: 84.17823791503906\n",
      "    grad_time_ms: 1541.601\n",
      "    load_time_ms: 1.283\n",
      "    num_steps_sampled: 2410000\n",
      "    num_steps_trained: 2410000\n",
      "    sample_time_ms: 15701.428\n",
      "    update_time_ms: 4.489\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4422.926930427551\n",
      "  time_this_iter_s: 17.346144676208496\n",
      "  time_total_s: 4422.926930427551\n",
      "  timestamp: 1550620849\n",
      "  timesteps_since_restore: 2410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2410000\n",
      "  training_iteration: 241\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4422 s, 241 iter, 2410000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-01-07\n",
      "  done: false\n",
      "  episode_len_mean: 125.47\n",
      "  episode_reward_max: 195.38179830808477\n",
      "  episode_reward_mean: 160.5180265909675\n",
      "  episode_reward_min: -48.77723802847437\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 17987\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.65326123673965e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3849833011627197\n",
      "      kl: 0.09200867265462875\n",
      "      policy_loss: 0.009639181196689606\n",
      "      total_loss: 79.35569763183594\n",
      "      vf_explained_var: 0.9703692197799683\n",
      "      vf_loss: 79.3460693359375\n",
      "    grad_time_ms: 1539.947\n",
      "    load_time_ms: 1.341\n",
      "    num_steps_sampled: 2420000\n",
      "    num_steps_trained: 2420000\n",
      "    sample_time_ms: 15719.744\n",
      "    update_time_ms: 4.388\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4440.586244106293\n",
      "  time_this_iter_s: 17.659313678741455\n",
      "  time_total_s: 4440.586244106293\n",
      "  timestamp: 1550620867\n",
      "  timesteps_since_restore: 2420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2420000\n",
      "  training_iteration: 242\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4440 s, 242 iter, 2420000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-01-25\n",
      "  done: false\n",
      "  episode_len_mean: 125.13\n",
      "  episode_reward_max: 197.22114047290083\n",
      "  episode_reward_mean: 151.53295215715866\n",
      "  episode_reward_min: -44.02049396843602\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 18067\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.448519468307495\n",
      "      kl: 0.013429074548184872\n",
      "      policy_loss: -0.0007708329358138144\n",
      "      total_loss: 111.23383331298828\n",
      "      vf_explained_var: 0.9609173536300659\n",
      "      vf_loss: 111.23463439941406\n",
      "    grad_time_ms: 1542.688\n",
      "    load_time_ms: 1.309\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "    sample_time_ms: 15746.805\n",
      "    update_time_ms: 4.376\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4458.133295297623\n",
      "  time_this_iter_s: 17.547051191329956\n",
      "  time_total_s: 4458.133295297623\n",
      "  timestamp: 1550620885\n",
      "  timesteps_since_restore: 2430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 243\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4458 s, 243 iter, 2430000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-01-42\n",
      "  done: false\n",
      "  episode_len_mean: 125.57\n",
      "  episode_reward_max: 207.82060927573093\n",
      "  episode_reward_mean: 143.35818688988584\n",
      "  episode_reward_min: -46.462158333842105\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 18145\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5682730674743652\n",
      "      kl: 0.018201347440481186\n",
      "      policy_loss: -0.00029003029339946806\n",
      "      total_loss: 183.6507110595703\n",
      "      vf_explained_var: 0.9363827705383301\n",
      "      vf_loss: 183.6510009765625\n",
      "    grad_time_ms: 1541.964\n",
      "    load_time_ms: 1.346\n",
      "    num_steps_sampled: 2440000\n",
      "    num_steps_trained: 2440000\n",
      "    sample_time_ms: 15736.777\n",
      "    update_time_ms: 4.365\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4475.354128837585\n",
      "  time_this_iter_s: 17.22083353996277\n",
      "  time_total_s: 4475.354128837585\n",
      "  timestamp: 1550620902\n",
      "  timesteps_since_restore: 2440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2440000\n",
      "  training_iteration: 244\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4475 s, 244 iter, 2440000 ts, 143 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-01-59\n",
      "  done: false\n",
      "  episode_len_mean: 122.41\n",
      "  episode_reward_max: 207.82060927573093\n",
      "  episode_reward_mean: 154.07859188808257\n",
      "  episode_reward_min: -48.406546427176735\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 18226\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.258810043334961\n",
      "      kl: 0.017498714849352837\n",
      "      policy_loss: -0.0006054158438928425\n",
      "      total_loss: 98.99114227294922\n",
      "      vf_explained_var: 0.9638267159461975\n",
      "      vf_loss: 98.99175262451172\n",
      "    grad_time_ms: 1541.162\n",
      "    load_time_ms: 1.381\n",
      "    num_steps_sampled: 2450000\n",
      "    num_steps_trained: 2450000\n",
      "    sample_time_ms: 15748.696\n",
      "    update_time_ms: 4.372\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4492.6300501823425\n",
      "  time_this_iter_s: 17.27592134475708\n",
      "  time_total_s: 4492.6300501823425\n",
      "  timestamp: 1550620919\n",
      "  timesteps_since_restore: 2450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2450000\n",
      "  training_iteration: 245\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4492 s, 245 iter, 2450000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-02-16\n",
      "  done: false\n",
      "  episode_len_mean: 124.03\n",
      "  episode_reward_max: 203.81854707356726\n",
      "  episode_reward_mean: 156.1982135327214\n",
      "  episode_reward_min: -47.24165629093892\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 18308\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2955198287963867\n",
      "      kl: 0.012332281097769737\n",
      "      policy_loss: -0.0006061558960936964\n",
      "      total_loss: 87.63030242919922\n",
      "      vf_explained_var: 0.9693143963813782\n",
      "      vf_loss: 87.63091278076172\n",
      "    grad_time_ms: 1539.779\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "    sample_time_ms: 15781.077\n",
      "    update_time_ms: 4.348\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4509.603654384613\n",
      "  time_this_iter_s: 16.973604202270508\n",
      "  time_total_s: 4509.603654384613\n",
      "  timestamp: 1550620936\n",
      "  timesteps_since_restore: 2460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 246\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4509 s, 246 iter, 2460000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-02-34\n",
      "  done: false\n",
      "  episode_len_mean: 123.8\n",
      "  episode_reward_max: 211.03390633853365\n",
      "  episode_reward_mean: 152.0638726604273\n",
      "  episode_reward_min: -48.049470609957616\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 18387\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4195759296417236\n",
      "      kl: 0.031853415071964264\n",
      "      policy_loss: 0.0002749643463175744\n",
      "      total_loss: 112.91169738769531\n",
      "      vf_explained_var: 0.9565379023551941\n",
      "      vf_loss: 112.91142272949219\n",
      "    grad_time_ms: 1537.288\n",
      "    load_time_ms: 1.398\n",
      "    num_steps_sampled: 2470000\n",
      "    num_steps_trained: 2470000\n",
      "    sample_time_ms: 15801.902\n",
      "    update_time_ms: 4.406\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4527.259144067764\n",
      "  time_this_iter_s: 17.655489683151245\n",
      "  time_total_s: 4527.259144067764\n",
      "  timestamp: 1550620954\n",
      "  timesteps_since_restore: 2470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2470000\n",
      "  training_iteration: 247\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4527 s, 247 iter, 2470000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-02-51\n",
      "  done: false\n",
      "  episode_len_mean: 124.38\n",
      "  episode_reward_max: 193.53468126058578\n",
      "  episode_reward_mean: 150.26210194540198\n",
      "  episode_reward_min: -48.049470609957616\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 18468\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3504438400268555\n",
      "      kl: 0.023823264986276627\n",
      "      policy_loss: 0.0007734318496659398\n",
      "      total_loss: 134.05662536621094\n",
      "      vf_explained_var: 0.9527027606964111\n",
      "      vf_loss: 134.0558319091797\n",
      "    grad_time_ms: 1536.396\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 2480000\n",
      "    num_steps_trained: 2480000\n",
      "    sample_time_ms: 15839.237\n",
      "    update_time_ms: 4.361\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4544.744125127792\n",
      "  time_this_iter_s: 17.484981060028076\n",
      "  time_total_s: 4544.744125127792\n",
      "  timestamp: 1550620971\n",
      "  timesteps_since_restore: 2480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2480000\n",
      "  training_iteration: 248\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4544 s, 248 iter, 2480000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-03-09\n",
      "  done: false\n",
      "  episode_len_mean: 125.33\n",
      "  episode_reward_max: 209.68980894938548\n",
      "  episode_reward_mean: 154.53207872300374\n",
      "  episode_reward_min: -45.88852459752912\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 18548\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.423018455505371\n",
      "      kl: 0.012784814462065697\n",
      "      policy_loss: -0.0022390454541891813\n",
      "      total_loss: 100.00022888183594\n",
      "      vf_explained_var: 0.9615170359611511\n",
      "      vf_loss: 100.00245666503906\n",
      "    grad_time_ms: 1535.537\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "    sample_time_ms: 15892.327\n",
      "    update_time_ms: 4.32\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4562.526931762695\n",
      "  time_this_iter_s: 17.782806634902954\n",
      "  time_total_s: 4562.526931762695\n",
      "  timestamp: 1550620989\n",
      "  timesteps_since_restore: 2490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 249\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4562 s, 249 iter, 2490000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-03-27\n",
      "  done: false\n",
      "  episode_len_mean: 123.19\n",
      "  episode_reward_max: 197.73242427010334\n",
      "  episode_reward_mean: 155.6227662996118\n",
      "  episode_reward_min: -43.55632500778329\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 18628\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.264256477355957\n",
      "      kl: 0.01906461827456951\n",
      "      policy_loss: 0.0017485445132479072\n",
      "      total_loss: 63.07161331176758\n",
      "      vf_explained_var: 0.9775511622428894\n",
      "      vf_loss: 63.069862365722656\n",
      "    grad_time_ms: 1536.358\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 2500000\n",
      "    num_steps_trained: 2500000\n",
      "    sample_time_ms: 15868.648\n",
      "    update_time_ms: 4.286\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4579.820884227753\n",
      "  time_this_iter_s: 17.293952465057373\n",
      "  time_total_s: 4579.820884227753\n",
      "  timestamp: 1550621007\n",
      "  timesteps_since_restore: 2500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2500000\n",
      "  training_iteration: 250\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4579 s, 250 iter, 2500000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-03-44\n",
      "  done: false\n",
      "  episode_len_mean: 123.84\n",
      "  episode_reward_max: 189.61262185797833\n",
      "  episode_reward_mean: 155.10611788685813\n",
      "  episode_reward_min: -43.55632500778329\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 18709\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2595393657684326\n",
      "      kl: 0.023592432960867882\n",
      "      policy_loss: -0.0013213084312155843\n",
      "      total_loss: 120.48451232910156\n",
      "      vf_explained_var: 0.9551042318344116\n",
      "      vf_loss: 120.48580169677734\n",
      "    grad_time_ms: 1535.46\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 2510000\n",
      "    num_steps_trained: 2510000\n",
      "    sample_time_ms: 15891.82\n",
      "    update_time_ms: 4.389\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4597.391407251358\n",
      "  time_this_iter_s: 17.570523023605347\n",
      "  time_total_s: 4597.391407251358\n",
      "  timestamp: 1550621024\n",
      "  timesteps_since_restore: 2510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2510000\n",
      "  training_iteration: 251\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4597 s, 251 iter, 2510000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-04-02\n",
      "  done: false\n",
      "  episode_len_mean: 127.52\n",
      "  episode_reward_max: 206.59076358363183\n",
      "  episode_reward_mean: 156.23052885294618\n",
      "  episode_reward_min: -44.424661271642904\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 18787\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.479895799414001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5003843307495117\n",
      "      kl: 0.009791362099349499\n",
      "      policy_loss: -0.0027740481309592724\n",
      "      total_loss: 62.02174758911133\n",
      "      vf_explained_var: 0.9762913584709167\n",
      "      vf_loss: 62.02452087402344\n",
      "    grad_time_ms: 1535.347\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "    sample_time_ms: 15867.507\n",
      "    update_time_ms: 4.391\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4614.804629564285\n",
      "  time_this_iter_s: 17.413222312927246\n",
      "  time_total_s: 4614.804629564285\n",
      "  timestamp: 1550621042\n",
      "  timesteps_since_restore: 2520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 252\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4614 s, 252 iter, 2520000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 128.0\n",
      "  episode_reward_max: 204.75050682862204\n",
      "  episode_reward_mean: 156.58364636571153\n",
      "  episode_reward_min: -44.424661271642904\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 18865\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4842023849487305\n",
      "      kl: 0.0315023697912693\n",
      "      policy_loss: -0.0008860217058099806\n",
      "      total_loss: 80.41795349121094\n",
      "      vf_explained_var: 0.9702267050743103\n",
      "      vf_loss: 80.4188461303711\n",
      "    grad_time_ms: 1534.571\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 2530000\n",
      "    num_steps_trained: 2530000\n",
      "    sample_time_ms: 15816.889\n",
      "    update_time_ms: 4.458\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4631.839462280273\n",
      "  time_this_iter_s: 17.03483271598816\n",
      "  time_total_s: 4631.839462280273\n",
      "  timestamp: 1550621059\n",
      "  timesteps_since_restore: 2530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2530000\n",
      "  training_iteration: 253\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4631 s, 253 iter, 2530000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-04-36\n",
      "  done: false\n",
      "  episode_len_mean: 127.35\n",
      "  episode_reward_max: 204.75050682862204\n",
      "  episode_reward_mean: 160.85729804185118\n",
      "  episode_reward_min: -50.00174751081089\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 18944\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.378382444381714\n",
      "      kl: 0.023312117904424667\n",
      "      policy_loss: -0.0012005724711343646\n",
      "      total_loss: 93.93941497802734\n",
      "      vf_explained_var: 0.9647547602653503\n",
      "      vf_loss: 93.94059753417969\n",
      "    grad_time_ms: 1535.748\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 2540000\n",
      "    num_steps_trained: 2540000\n",
      "    sample_time_ms: 15851.734\n",
      "    update_time_ms: 4.445\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4649.4179537296295\n",
      "  time_this_iter_s: 17.57849144935608\n",
      "  time_total_s: 4649.4179537296295\n",
      "  timestamp: 1550621076\n",
      "  timesteps_since_restore: 2540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2540000\n",
      "  training_iteration: 254\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4649 s, 254 iter, 2540000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-04-54\n",
      "  done: false\n",
      "  episode_len_mean: 127.91\n",
      "  episode_reward_max: 194.91323991931316\n",
      "  episode_reward_mean: 158.40517420214877\n",
      "  episode_reward_min: -42.87431819722204\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 19022\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.497117280960083\n",
      "      kl: 0.014299163594841957\n",
      "      policy_loss: -0.00022351655934471637\n",
      "      total_loss: 80.91007995605469\n",
      "      vf_explained_var: 0.9706081748008728\n",
      "      vf_loss: 80.91030883789062\n",
      "    grad_time_ms: 1555.79\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "    sample_time_ms: 15856.955\n",
      "    update_time_ms: 4.391\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4666.946152925491\n",
      "  time_this_iter_s: 17.528199195861816\n",
      "  time_total_s: 4666.946152925491\n",
      "  timestamp: 1550621094\n",
      "  timesteps_since_restore: 2550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 255\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4666 s, 255 iter, 2550000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-05-11\n",
      "  done: false\n",
      "  episode_len_mean: 124.45\n",
      "  episode_reward_max: 208.2971412713575\n",
      "  episode_reward_mean: 150.7362428146974\n",
      "  episode_reward_min: -45.14456618451835\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 19103\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3991153240203857\n",
      "      kl: 0.021242134273052216\n",
      "      policy_loss: -0.0019101593643426895\n",
      "      total_loss: 146.62545776367188\n",
      "      vf_explained_var: 0.9483051896095276\n",
      "      vf_loss: 146.6273956298828\n",
      "    grad_time_ms: 1556.152\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 2560000\n",
      "    num_steps_trained: 2560000\n",
      "    sample_time_ms: 15870.92\n",
      "    update_time_ms: 4.395\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4684.059191226959\n",
      "  time_this_iter_s: 17.113038301467896\n",
      "  time_total_s: 4684.059191226959\n",
      "  timestamp: 1550621111\n",
      "  timesteps_since_restore: 2560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2560000\n",
      "  training_iteration: 256\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4684 s, 256 iter, 2560000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-05-28\n",
      "  done: false\n",
      "  episode_len_mean: 127.53\n",
      "  episode_reward_max: 205.41983737361315\n",
      "  episode_reward_mean: 150.1941711217794\n",
      "  episode_reward_min: -48.98172483202254\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 19180\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.548619270324707\n",
      "      kl: 0.02491540089249611\n",
      "      policy_loss: 0.002192398998886347\n",
      "      total_loss: 136.44325256347656\n",
      "      vf_explained_var: 0.9507840275764465\n",
      "      vf_loss: 136.44105529785156\n",
      "    grad_time_ms: 1558.491\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 2570000\n",
      "    num_steps_trained: 2570000\n",
      "    sample_time_ms: 15824.028\n",
      "    update_time_ms: 4.414\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4701.269691228867\n",
      "  time_this_iter_s: 17.21050000190735\n",
      "  time_total_s: 4701.269691228867\n",
      "  timestamp: 1550621128\n",
      "  timesteps_since_restore: 2570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2570000\n",
      "  training_iteration: 257\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4701 s, 257 iter, 2570000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-05-46\n",
      "  done: false\n",
      "  episode_len_mean: 121.46\n",
      "  episode_reward_max: 201.5376569534293\n",
      "  episode_reward_mean: 146.52851094236343\n",
      "  episode_reward_min: -48.98172483202254\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 19262\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2884163856506348\n",
      "      kl: 0.029402371495962143\n",
      "      policy_loss: 0.0033503465820103884\n",
      "      total_loss: 112.19195556640625\n",
      "      vf_explained_var: 0.9602392911911011\n",
      "      vf_loss: 112.1885986328125\n",
      "    grad_time_ms: 1559.353\n",
      "    load_time_ms: 1.399\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "    sample_time_ms: 15834.565\n",
      "    update_time_ms: 4.308\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4718.8669991493225\n",
      "  time_this_iter_s: 17.597307920455933\n",
      "  time_total_s: 4718.8669991493225\n",
      "  timestamp: 1550621146\n",
      "  timesteps_since_restore: 2580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 258\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4718 s, 258 iter, 2580000 ts, 147 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-06-03\n",
      "  done: false\n",
      "  episode_len_mean: 124.63\n",
      "  episode_reward_max: 198.51830994227146\n",
      "  episode_reward_mean: 158.87980095139335\n",
      "  episode_reward_min: -45.94318096177411\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 19341\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3808839321136475\n",
      "      kl: 0.02236214652657509\n",
      "      policy_loss: -0.0012110763927921653\n",
      "      total_loss: 84.13175201416016\n",
      "      vf_explained_var: 0.9668876528739929\n",
      "      vf_loss: 84.13297271728516\n",
      "    grad_time_ms: 1560.244\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 2590000\n",
      "    num_steps_trained: 2590000\n",
      "    sample_time_ms: 15740.357\n",
      "    update_time_ms: 4.303\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4735.717473268509\n",
      "  time_this_iter_s: 16.8504741191864\n",
      "  time_total_s: 4735.717473268509\n",
      "  timestamp: 1550621163\n",
      "  timesteps_since_restore: 2590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2590000\n",
      "  training_iteration: 259\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4735 s, 259 iter, 2590000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-06-20\n",
      "  done: false\n",
      "  episode_len_mean: 129.3\n",
      "  episode_reward_max: 196.87446437407255\n",
      "  episode_reward_mean: 158.5326179548614\n",
      "  episode_reward_min: -48.69549466477764\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 19418\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5622501373291016\n",
      "      kl: 0.014722339808940887\n",
      "      policy_loss: -0.0019951288122683764\n",
      "      total_loss: 81.11511993408203\n",
      "      vf_explained_var: 0.9710588455200195\n",
      "      vf_loss: 81.11711883544922\n",
      "    grad_time_ms: 1559.004\n",
      "    load_time_ms: 1.451\n",
      "    num_steps_sampled: 2600000\n",
      "    num_steps_trained: 2600000\n",
      "    sample_time_ms: 15745.714\n",
      "    update_time_ms: 4.381\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4753.055157899857\n",
      "  time_this_iter_s: 17.337684631347656\n",
      "  time_total_s: 4753.055157899857\n",
      "  timestamp: 1550621180\n",
      "  timesteps_since_restore: 2600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2600000\n",
      "  training_iteration: 260\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4753 s, 260 iter, 2600000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-06-38\n",
      "  done: false\n",
      "  episode_len_mean: 125.74\n",
      "  episode_reward_max: 204.50831269067098\n",
      "  episode_reward_mean: 157.7642160137994\n",
      "  episode_reward_min: -50.134739895563314\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 19498\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.399479389190674\n",
      "      kl: 0.019651714712381363\n",
      "      policy_loss: 0.0011186862830072641\n",
      "      total_loss: 48.02425765991211\n",
      "      vf_explained_var: 0.980947732925415\n",
      "      vf_loss: 48.023136138916016\n",
      "    grad_time_ms: 1558.765\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "    sample_time_ms: 15761.554\n",
      "    update_time_ms: 4.457\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4770.783839941025\n",
      "  time_this_iter_s: 17.728682041168213\n",
      "  time_total_s: 4770.783839941025\n",
      "  timestamp: 1550621198\n",
      "  timesteps_since_restore: 2610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 261\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4770 s, 261 iter, 2610000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-06-56\n",
      "  done: false\n",
      "  episode_len_mean: 124.9\n",
      "  episode_reward_max: 215.59686375844603\n",
      "  episode_reward_mean: 154.14620573477734\n",
      "  episode_reward_min: -50.17556673789967\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 19577\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3585543632507324\n",
      "      kl: 0.011144534684717655\n",
      "      policy_loss: -0.004758980590850115\n",
      "      total_loss: 87.35655975341797\n",
      "      vf_explained_var: 0.9688107371330261\n",
      "      vf_loss: 87.36131286621094\n",
      "    grad_time_ms: 1556.984\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 2620000\n",
      "    num_steps_trained: 2620000\n",
      "    sample_time_ms: 15796.969\n",
      "    update_time_ms: 4.552\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4788.534219503403\n",
      "  time_this_iter_s: 17.75037956237793\n",
      "  time_total_s: 4788.534219503403\n",
      "  timestamp: 1550621216\n",
      "  timesteps_since_restore: 2620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2620000\n",
      "  training_iteration: 262\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4788 s, 262 iter, 2620000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-07-13\n",
      "  done: false\n",
      "  episode_len_mean: 125.98\n",
      "  episode_reward_max: 198.80650141245056\n",
      "  episode_reward_mean: 160.06312971635805\n",
      "  episode_reward_min: -42.593092533031324\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 19657\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.239947899707001e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2790634632110596\n",
      "      kl: 6.618176460266113\n",
      "      policy_loss: 0.047426652163267136\n",
      "      total_loss: 80.00576782226562\n",
      "      vf_explained_var: 0.9710855484008789\n",
      "      vf_loss: 79.95834350585938\n",
      "    grad_time_ms: 1557.855\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 2630000\n",
      "    num_steps_trained: 2630000\n",
      "    sample_time_ms: 15840.368\n",
      "    update_time_ms: 4.437\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4806.012293815613\n",
      "  time_this_iter_s: 17.478074312210083\n",
      "  time_total_s: 4806.012293815613\n",
      "  timestamp: 1550621233\n",
      "  timesteps_since_restore: 2630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2630000\n",
      "  training_iteration: 263\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4806 s, 263 iter, 2630000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-07-31\n",
      "  done: false\n",
      "  episode_len_mean: 122.81\n",
      "  episode_reward_max: 198.05608884444325\n",
      "  episode_reward_mean: 147.75265396306224\n",
      "  episode_reward_min: -45.60355857929381\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 19739\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2925782203674316\n",
      "      kl: 0.010539961978793144\n",
      "      policy_loss: -0.001193698262795806\n",
      "      total_loss: 242.22604370117188\n",
      "      vf_explained_var: 0.9259480237960815\n",
      "      vf_loss: 242.2272186279297\n",
      "    grad_time_ms: 1561.199\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "    sample_time_ms: 15884.705\n",
      "    update_time_ms: 4.486\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4824.070571184158\n",
      "  time_this_iter_s: 18.058277368545532\n",
      "  time_total_s: 4824.070571184158\n",
      "  timestamp: 1550621251\n",
      "  timesteps_since_restore: 2640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 264\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4824 s, 264 iter, 2640000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-07-49\n",
      "  done: false\n",
      "  episode_len_mean: 122.07\n",
      "  episode_reward_max: 199.71618599938859\n",
      "  episode_reward_mean: 146.40418979376076\n",
      "  episode_reward_min: -52.75370570545151\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 19822\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2715184688568115\n",
      "      kl: 0.02226182632148266\n",
      "      policy_loss: -0.0024156798608601093\n",
      "      total_loss: 203.49656677246094\n",
      "      vf_explained_var: 0.9270428419113159\n",
      "      vf_loss: 203.49899291992188\n",
      "    grad_time_ms: 1541.246\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 2650000\n",
      "    num_steps_trained: 2650000\n",
      "    sample_time_ms: 15904.35\n",
      "    update_time_ms: 4.538\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4841.595520496368\n",
      "  time_this_iter_s: 17.524949312210083\n",
      "  time_total_s: 4841.595520496368\n",
      "  timestamp: 1550621269\n",
      "  timesteps_since_restore: 2650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2650000\n",
      "  training_iteration: 265\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4841 s, 265 iter, 2650000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-08-06\n",
      "  done: false\n",
      "  episode_len_mean: 124.56\n",
      "  episode_reward_max: 198.04245096976226\n",
      "  episode_reward_mean: 157.64543503227617\n",
      "  episode_reward_min: -53.67033060972053\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 19902\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3063299655914307\n",
      "      kl: 0.02364737167954445\n",
      "      policy_loss: 0.0009674347820691764\n",
      "      total_loss: 139.20530700683594\n",
      "      vf_explained_var: 0.952774703502655\n",
      "      vf_loss: 139.204345703125\n",
      "    grad_time_ms: 1539.849\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 2660000\n",
      "    num_steps_trained: 2660000\n",
      "    sample_time_ms: 15934.213\n",
      "    update_time_ms: 4.562\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4858.995000362396\n",
      "  time_this_iter_s: 17.399479866027832\n",
      "  time_total_s: 4858.995000362396\n",
      "  timestamp: 1550621286\n",
      "  timesteps_since_restore: 2660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2660000\n",
      "  training_iteration: 266\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4858 s, 266 iter, 2660000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-08-24\n",
      "  done: false\n",
      "  episode_len_mean: 124.18\n",
      "  episode_reward_max: 197.94366482667417\n",
      "  episode_reward_mean: 157.13589800907593\n",
      "  episode_reward_min: -52.23310316199122\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 19982\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.380192279815674\n",
      "      kl: 0.014798601157963276\n",
      "      policy_loss: -0.0009865541942417622\n",
      "      total_loss: 49.43438720703125\n",
      "      vf_explained_var: 0.9817465543746948\n",
      "      vf_loss: 49.43537139892578\n",
      "    grad_time_ms: 1558.819\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "    sample_time_ms: 15927.987\n",
      "    update_time_ms: 4.502\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4876.33195567131\n",
      "  time_this_iter_s: 17.336955308914185\n",
      "  time_total_s: 4876.33195567131\n",
      "  timestamp: 1550621304\n",
      "  timesteps_since_restore: 2670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 267\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4876 s, 267 iter, 2670000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 123.49\n",
      "  episode_reward_max: 200.1471018614156\n",
      "  episode_reward_mean: 155.02110766624747\n",
      "  episode_reward_min: -51.93691788805594\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 20063\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1995811462402344\n",
      "      kl: 0.012394232675433159\n",
      "      policy_loss: -0.0009831946808844805\n",
      "      total_loss: 124.89093780517578\n",
      "      vf_explained_var: 0.9574739336967468\n",
      "      vf_loss: 124.89189910888672\n",
      "    grad_time_ms: 1556.461\n",
      "    load_time_ms: 1.445\n",
      "    num_steps_sampled: 2680000\n",
      "    num_steps_trained: 2680000\n",
      "    sample_time_ms: 15906.193\n",
      "    update_time_ms: 4.601\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4893.688804864883\n",
      "  time_this_iter_s: 17.356849193572998\n",
      "  time_total_s: 4893.688804864883\n",
      "  timestamp: 1550621321\n",
      "  timesteps_since_restore: 2680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2680000\n",
      "  training_iteration: 268\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4893 s, 268 iter, 2680000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-08-58\n",
      "  done: false\n",
      "  episode_len_mean: 123.51\n",
      "  episode_reward_max: 197.84537685824776\n",
      "  episode_reward_mean: 153.3349351250871\n",
      "  episode_reward_min: -51.93691788805594\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 20144\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.308711528778076\n",
      "      kl: 0.031010599806904793\n",
      "      policy_loss: 0.0040812683291733265\n",
      "      total_loss: 117.08756256103516\n",
      "      vf_explained_var: 0.959102213382721\n",
      "      vf_loss: 117.0834732055664\n",
      "    grad_time_ms: 1558.656\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 2690000\n",
      "    num_steps_trained: 2690000\n",
      "    sample_time_ms: 15931.916\n",
      "    update_time_ms: 4.571\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4910.820424795151\n",
      "  time_this_iter_s: 17.131619930267334\n",
      "  time_total_s: 4910.820424795151\n",
      "  timestamp: 1550621338\n",
      "  timesteps_since_restore: 2690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2690000\n",
      "  training_iteration: 269\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4910 s, 269 iter, 2690000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-09-15\n",
      "  done: false\n",
      "  episode_len_mean: 126.12\n",
      "  episode_reward_max: 206.61596905890082\n",
      "  episode_reward_mean: 158.2050648680284\n",
      "  episode_reward_min: -42.125301270791816\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 20222\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3718769550323486\n",
      "      kl: 0.014752580784261227\n",
      "      policy_loss: -3.186258254572749e-05\n",
      "      total_loss: 87.47775268554688\n",
      "      vf_explained_var: 0.9684137105941772\n",
      "      vf_loss: 87.477783203125\n",
      "    grad_time_ms: 1557.652\n",
      "    load_time_ms: 1.421\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "    sample_time_ms: 15880.56\n",
      "    update_time_ms: 4.549\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4927.631914138794\n",
      "  time_this_iter_s: 16.81148934364319\n",
      "  time_total_s: 4927.631914138794\n",
      "  timestamp: 1550621355\n",
      "  timesteps_since_restore: 2700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 270\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4927 s, 270 iter, 2700000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-09-32\n",
      "  done: false\n",
      "  episode_len_mean: 125.46\n",
      "  episode_reward_max: 206.61596905890082\n",
      "  episode_reward_mean: 158.02828526483313\n",
      "  episode_reward_min: -44.009887439632195\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 20303\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.381474733352661\n",
      "      kl: 0.01713995262980461\n",
      "      policy_loss: -0.002338926075026393\n",
      "      total_loss: 87.3355712890625\n",
      "      vf_explained_var: 0.9683926701545715\n",
      "      vf_loss: 87.33790588378906\n",
      "    grad_time_ms: 1557.418\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 2710000\n",
      "    num_steps_trained: 2710000\n",
      "    sample_time_ms: 15823.347\n",
      "    update_time_ms: 4.493\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4944.786438703537\n",
      "  time_this_iter_s: 17.154524564743042\n",
      "  time_total_s: 4944.786438703537\n",
      "  timestamp: 1550621372\n",
      "  timesteps_since_restore: 2710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2710000\n",
      "  training_iteration: 271\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4944 s, 271 iter, 2710000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-09-50\n",
      "  done: false\n",
      "  episode_len_mean: 126.26\n",
      "  episode_reward_max: 199.53557932819498\n",
      "  episode_reward_mean: 155.79616804365133\n",
      "  episode_reward_min: -52.27602881045623\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 20382\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3477299213409424\n",
      "      kl: 0.02264551632106304\n",
      "      policy_loss: 0.00033993771648965776\n",
      "      total_loss: 112.89822387695312\n",
      "      vf_explained_var: 0.9616877436637878\n",
      "      vf_loss: 112.89789581298828\n",
      "    grad_time_ms: 1556.978\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 2720000\n",
      "    num_steps_trained: 2720000\n",
      "    sample_time_ms: 15785.668\n",
      "    update_time_ms: 4.435\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4962.155571460724\n",
      "  time_this_iter_s: 17.36913275718689\n",
      "  time_total_s: 4962.155571460724\n",
      "  timestamp: 1550621390\n",
      "  timesteps_since_restore: 2720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2720000\n",
      "  training_iteration: 272\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4962 s, 272 iter, 2720000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-10-07\n",
      "  done: false\n",
      "  episode_len_mean: 126.33\n",
      "  episode_reward_max: 208.4410848132161\n",
      "  episode_reward_mean: 153.51328758878395\n",
      "  episode_reward_min: -48.322082373470394\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 20461\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.496047019958496\n",
      "      kl: 0.019488414749503136\n",
      "      policy_loss: -0.00015394370711874217\n",
      "      total_loss: 142.12879943847656\n",
      "      vf_explained_var: 0.9483124017715454\n",
      "      vf_loss: 142.12896728515625\n",
      "    grad_time_ms: 1557.272\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "    sample_time_ms: 15762.835\n",
      "    update_time_ms: 4.505\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4979.404844284058\n",
      "  time_this_iter_s: 17.24927282333374\n",
      "  time_total_s: 4979.404844284058\n",
      "  timestamp: 1550621407\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 273\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4979 s, 273 iter, 2730000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-10-24\n",
      "  done: false\n",
      "  episode_len_mean: 128.68\n",
      "  episode_reward_max: 209.16373358002988\n",
      "  episode_reward_mean: 160.3452268502946\n",
      "  episode_reward_min: -52.70292045353072\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 20538\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.359919285762559e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4994654655456543\n",
      "      kl: 0.00974976271390915\n",
      "      policy_loss: 1.0680502782633994e-05\n",
      "      total_loss: 69.2088623046875\n",
      "      vf_explained_var: 0.9749847650527954\n",
      "      vf_loss: 69.2088394165039\n",
      "    grad_time_ms: 1578.099\n",
      "    load_time_ms: 1.391\n",
      "    num_steps_sampled: 2740000\n",
      "    num_steps_trained: 2740000\n",
      "    sample_time_ms: 15658.226\n",
      "    update_time_ms: 4.415\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 4996.621470928192\n",
      "  time_this_iter_s: 17.21662664413452\n",
      "  time_total_s: 4996.621470928192\n",
      "  timestamp: 1550621424\n",
      "  timesteps_since_restore: 2740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2740000\n",
      "  training_iteration: 274\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 4996 s, 274 iter, 2740000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-10-41\n",
      "  done: false\n",
      "  episode_len_mean: 129.8\n",
      "  episode_reward_max: 209.16373358002988\n",
      "  episode_reward_mean: 158.1630345460619\n",
      "  episode_reward_min: -49.94275278679216\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 20616\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5764732360839844\n",
      "      kl: 0.019591400399804115\n",
      "      policy_loss: -0.001491830567829311\n",
      "      total_loss: 138.1904754638672\n",
      "      vf_explained_var: 0.9512867331504822\n",
      "      vf_loss: 138.19198608398438\n",
      "    grad_time_ms: 1577.409\n",
      "    load_time_ms: 1.392\n",
      "    num_steps_sampled: 2750000\n",
      "    num_steps_trained: 2750000\n",
      "    sample_time_ms: 15615.799\n",
      "    update_time_ms: 4.366\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5013.714798688889\n",
      "  time_this_iter_s: 17.09332776069641\n",
      "  time_total_s: 5013.714798688889\n",
      "  timestamp: 1550621441\n",
      "  timesteps_since_restore: 2750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2750000\n",
      "  training_iteration: 275\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5013 s, 275 iter, 2750000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-10-59\n",
      "  done: false\n",
      "  episode_len_mean: 128.67\n",
      "  episode_reward_max: 205.06621062578537\n",
      "  episode_reward_mean: 155.86519748077345\n",
      "  episode_reward_min: -48.60480139043072\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 20695\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.390990734100342\n",
      "      kl: 0.014438505284488201\n",
      "      policy_loss: -0.0010039223125204444\n",
      "      total_loss: 67.70945739746094\n",
      "      vf_explained_var: 0.9766424894332886\n",
      "      vf_loss: 67.7104721069336\n",
      "    grad_time_ms: 1579.339\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "    sample_time_ms: 15624.332\n",
      "    update_time_ms: 4.311\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5031.220384836197\n",
      "  time_this_iter_s: 17.50558614730835\n",
      "  time_total_s: 5031.220384836197\n",
      "  timestamp: 1550621459\n",
      "  timesteps_since_restore: 2760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 276\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5031 s, 276 iter, 2760000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-11-16\n",
      "  done: false\n",
      "  episode_len_mean: 123.84\n",
      "  episode_reward_max: 206.96505487555328\n",
      "  episode_reward_mean: 146.14214869443683\n",
      "  episode_reward_min: -49.87507871088416\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 20775\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4236600399017334\n",
      "      kl: 0.020085040479898453\n",
      "      policy_loss: -0.0017357569886371493\n",
      "      total_loss: 222.0770721435547\n",
      "      vf_explained_var: 0.9203617572784424\n",
      "      vf_loss: 222.07879638671875\n",
      "    grad_time_ms: 1561.333\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 2770000\n",
      "    num_steps_trained: 2770000\n",
      "    sample_time_ms: 15629.699\n",
      "    update_time_ms: 4.291\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5048.428780794144\n",
      "  time_this_iter_s: 17.208395957946777\n",
      "  time_total_s: 5048.428780794144\n",
      "  timestamp: 1550621476\n",
      "  timesteps_since_restore: 2770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2770000\n",
      "  training_iteration: 277\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5048 s, 277 iter, 2770000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-11-34\n",
      "  done: false\n",
      "  episode_len_mean: 124.37\n",
      "  episode_reward_max: 196.14329735008934\n",
      "  episode_reward_mean: 150.82669639622907\n",
      "  episode_reward_min: -49.640558635539335\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 20854\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.380765199661255\n",
      "      kl: 0.01997370459139347\n",
      "      policy_loss: -0.0004526165721472353\n",
      "      total_loss: 107.11585998535156\n",
      "      vf_explained_var: 0.9603842496871948\n",
      "      vf_loss: 107.11629486083984\n",
      "    grad_time_ms: 1563.09\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 2780000\n",
      "    num_steps_trained: 2780000\n",
      "    sample_time_ms: 15639.576\n",
      "    update_time_ms: 4.245\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5065.901833772659\n",
      "  time_this_iter_s: 17.473052978515625\n",
      "  time_total_s: 5065.901833772659\n",
      "  timestamp: 1550621494\n",
      "  timesteps_since_restore: 2780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2780000\n",
      "  training_iteration: 278\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5065 s, 278 iter, 2780000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-11-51\n",
      "  done: false\n",
      "  episode_len_mean: 124.41\n",
      "  episode_reward_max: 213.9740700839767\n",
      "  episode_reward_mean: 152.85062366969657\n",
      "  episode_reward_min: -47.74781155748532\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 20934\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3652846813201904\n",
      "      kl: 0.015089409425854683\n",
      "      policy_loss: -0.00024416096857748926\n",
      "      total_loss: 120.72931671142578\n",
      "      vf_explained_var: 0.9585636854171753\n",
      "      vf_loss: 120.72956848144531\n",
      "    grad_time_ms: 1561.181\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "    sample_time_ms: 15674.622\n",
      "    update_time_ms: 4.149\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5083.363441705704\n",
      "  time_this_iter_s: 17.461607933044434\n",
      "  time_total_s: 5083.363441705704\n",
      "  timestamp: 1550621511\n",
      "  timesteps_since_restore: 2790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 279\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5083 s, 279 iter, 2790000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-12-09\n",
      "  done: false\n",
      "  episode_len_mean: 127.93\n",
      "  episode_reward_max: 213.9740700839767\n",
      "  episode_reward_mean: 155.47566597796754\n",
      "  episode_reward_min: -45.856758853586584\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 21013\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5432748794555664\n",
      "      kl: 0.027653560042381287\n",
      "      policy_loss: 0.0013588600559160113\n",
      "      total_loss: 124.7514877319336\n",
      "      vf_explained_var: 0.9525366425514221\n",
      "      vf_loss: 124.75015258789062\n",
      "    grad_time_ms: 1562.713\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 2800000\n",
      "    num_steps_trained: 2800000\n",
      "    sample_time_ms: 15725.603\n",
      "    update_time_ms: 4.209\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5100.701001882553\n",
      "  time_this_iter_s: 17.337560176849365\n",
      "  time_total_s: 5100.701001882553\n",
      "  timestamp: 1550621529\n",
      "  timesteps_since_restore: 2800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2800000\n",
      "  training_iteration: 280\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5100 s, 280 iter, 2800000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-12-26\n",
      "  done: false\n",
      "  episode_len_mean: 126.06\n",
      "  episode_reward_max: 198.71523801052922\n",
      "  episode_reward_mean: 152.14084945589357\n",
      "  episode_reward_min: -45.856758853586584\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 21092\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.418938159942627\n",
      "      kl: 0.02420535869896412\n",
      "      policy_loss: 0.001385446754284203\n",
      "      total_loss: 123.86656188964844\n",
      "      vf_explained_var: 0.9544445872306824\n",
      "      vf_loss: 123.86517333984375\n",
      "    grad_time_ms: 1561.606\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 2810000\n",
      "    num_steps_trained: 2810000\n",
      "    sample_time_ms: 15735.526\n",
      "    update_time_ms: 4.156\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5117.940952777863\n",
      "  time_this_iter_s: 17.23995089530945\n",
      "  time_total_s: 5117.940952777863\n",
      "  timestamp: 1550621546\n",
      "  timesteps_since_restore: 2810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2810000\n",
      "  training_iteration: 281\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5117 s, 281 iter, 2810000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-12-43\n",
      "  done: false\n",
      "  episode_len_mean: 125.99\n",
      "  episode_reward_max: 198.71523801052922\n",
      "  episode_reward_mean: 162.9800075241772\n",
      "  episode_reward_min: -36.42854155821376\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 21171\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3306729793548584\n",
      "      kl: 0.027008093893527985\n",
      "      policy_loss: 0.0029922197572886944\n",
      "      total_loss: 53.74576187133789\n",
      "      vf_explained_var: 0.979108452796936\n",
      "      vf_loss: 53.74277114868164\n",
      "    grad_time_ms: 1562.229\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "    sample_time_ms: 15686.494\n",
      "    update_time_ms: 4.093\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5134.823968172073\n",
      "  time_this_iter_s: 16.883015394210815\n",
      "  time_total_s: 5134.823968172073\n",
      "  timestamp: 1550621563\n",
      "  timesteps_since_restore: 2820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 282\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5134 s, 282 iter, 2820000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-13-00\n",
      "  done: false\n",
      "  episode_len_mean: 130.16\n",
      "  episode_reward_max: 204.4071566037613\n",
      "  episode_reward_mean: 160.12750195181695\n",
      "  episode_reward_min: -50.57268079466159\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 21247\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.6023693084716797\n",
      "      kl: 0.019032593816518784\n",
      "      policy_loss: 0.0013465730007737875\n",
      "      total_loss: 64.89921569824219\n",
      "      vf_explained_var: 0.9772385954856873\n",
      "      vf_loss: 64.89786529541016\n",
      "    grad_time_ms: 1561.159\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 2830000\n",
      "    num_steps_trained: 2830000\n",
      "    sample_time_ms: 15686.223\n",
      "    update_time_ms: 4.099\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5152.0627727508545\n",
      "  time_this_iter_s: 17.238804578781128\n",
      "  time_total_s: 5152.0627727508545\n",
      "  timestamp: 1550621580\n",
      "  timesteps_since_restore: 2830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2830000\n",
      "  training_iteration: 283\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5152 s, 283 iter, 2830000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-13-18\n",
      "  done: false\n",
      "  episode_len_mean: 123.73\n",
      "  episode_reward_max: 207.57848407092075\n",
      "  episode_reward_mean: 151.40373051663067\n",
      "  episode_reward_min: -50.57268079466159\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 21329\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.273275136947632\n",
      "      kl: 0.02679205872118473\n",
      "      policy_loss: -0.0033320034854114056\n",
      "      total_loss: 209.01248168945312\n",
      "      vf_explained_var: 0.92771315574646\n",
      "      vf_loss: 209.0158233642578\n",
      "    grad_time_ms: 1536.928\n",
      "    load_time_ms: 1.545\n",
      "    num_steps_sampled: 2840000\n",
      "    num_steps_trained: 2840000\n",
      "    sample_time_ms: 15728.625\n",
      "    update_time_ms: 4.205\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5169.462576627731\n",
      "  time_this_iter_s: 17.39980387687683\n",
      "  time_total_s: 5169.462576627731\n",
      "  timestamp: 1550621598\n",
      "  timesteps_since_restore: 2840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2840000\n",
      "  training_iteration: 284\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5169 s, 284 iter, 2840000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-13-35\n",
      "  done: false\n",
      "  episode_len_mean: 125.7\n",
      "  episode_reward_max: 194.9210828124443\n",
      "  episode_reward_mean: 155.39605861464557\n",
      "  episode_reward_min: -45.2419880230238\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 21408\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3769688606262207\n",
      "      kl: 0.01578483171761036\n",
      "      policy_loss: -0.00394147215411067\n",
      "      total_loss: 85.05863952636719\n",
      "      vf_explained_var: 0.9679877161979675\n",
      "      vf_loss: 85.06256866455078\n",
      "    grad_time_ms: 1538.376\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "    sample_time_ms: 15739.06\n",
      "    update_time_ms: 4.177\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5186.674697399139\n",
      "  time_this_iter_s: 17.21212077140808\n",
      "  time_total_s: 5186.674697399139\n",
      "  timestamp: 1550621615\n",
      "  timesteps_since_restore: 2850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 285\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5186 s, 285 iter, 2850000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-13-53\n",
      "  done: false\n",
      "  episode_len_mean: 125.2\n",
      "  episode_reward_max: 198.45686548682727\n",
      "  episode_reward_mean: 155.09444924869575\n",
      "  episode_reward_min: -53.60211958418979\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 21489\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.30625319480896\n",
      "      kl: 0.018752695992588997\n",
      "      policy_loss: -0.0006447177147492766\n",
      "      total_loss: 159.97549438476562\n",
      "      vf_explained_var: 0.9443458318710327\n",
      "      vf_loss: 159.97613525390625\n",
      "    grad_time_ms: 1537.699\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 2860000\n",
      "    num_steps_trained: 2860000\n",
      "    sample_time_ms: 15765.024\n",
      "    update_time_ms: 4.24\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5204.43092918396\n",
      "  time_this_iter_s: 17.756231784820557\n",
      "  time_total_s: 5204.43092918396\n",
      "  timestamp: 1550621633\n",
      "  timesteps_since_restore: 2860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2860000\n",
      "  training_iteration: 286\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5204 s, 286 iter, 2860000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-14-10\n",
      "  done: false\n",
      "  episode_len_mean: 124.7\n",
      "  episode_reward_max: 196.94513135233746\n",
      "  episode_reward_mean: 154.62296093757493\n",
      "  episode_reward_min: -51.79134092457813\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 21570\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.222090482711792\n",
      "      kl: 0.015936018899083138\n",
      "      policy_loss: -0.0014722950290888548\n",
      "      total_loss: 87.2126235961914\n",
      "      vf_explained_var: 0.9696518182754517\n",
      "      vf_loss: 87.21409606933594\n",
      "    grad_time_ms: 1536.767\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 2870000\n",
      "    num_steps_trained: 2870000\n",
      "    sample_time_ms: 15794.318\n",
      "    update_time_ms: 4.222\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5221.923063278198\n",
      "  time_this_iter_s: 17.49213409423828\n",
      "  time_total_s: 5221.923063278198\n",
      "  timestamp: 1550621650\n",
      "  timesteps_since_restore: 2870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2870000\n",
      "  training_iteration: 287\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5221 s, 287 iter, 2870000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-14-28\n",
      "  done: false\n",
      "  episode_len_mean: 122.06\n",
      "  episode_reward_max: 200.20458357286915\n",
      "  episode_reward_mean: 147.71881146351672\n",
      "  episode_reward_min: -52.47888139096817\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 21652\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.212475299835205\n",
      "      kl: 0.017492180690169334\n",
      "      policy_loss: -0.0004170368774794042\n",
      "      total_loss: 192.47592163085938\n",
      "      vf_explained_var: 0.9368779063224792\n",
      "      vf_loss: 192.47633361816406\n",
      "    grad_time_ms: 1535.877\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "    sample_time_ms: 15844.289\n",
      "    update_time_ms: 4.195\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5239.886294126511\n",
      "  time_this_iter_s: 17.963230848312378\n",
      "  time_total_s: 5239.886294126511\n",
      "  timestamp: 1550621668\n",
      "  timesteps_since_restore: 2880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 288\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5239 s, 288 iter, 2880000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-14-45\n",
      "  done: false\n",
      "  episode_len_mean: 126.47\n",
      "  episode_reward_max: 215.6811459151531\n",
      "  episode_reward_mean: 156.35988227470324\n",
      "  episode_reward_min: -46.01202453008971\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 21731\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1799596428812795e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4135658740997314\n",
      "      kl: 0.00945344753563404\n",
      "      policy_loss: -0.0008647161885164678\n",
      "      total_loss: 111.52226257324219\n",
      "      vf_explained_var: 0.961284339427948\n",
      "      vf_loss: 111.52312469482422\n",
      "    grad_time_ms: 1535.649\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 2890000\n",
      "    num_steps_trained: 2890000\n",
      "    sample_time_ms: 15820.408\n",
      "    update_time_ms: 4.267\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5257.106491327286\n",
      "  time_this_iter_s: 17.220197200775146\n",
      "  time_total_s: 5257.106491327286\n",
      "  timestamp: 1550621685\n",
      "  timesteps_since_restore: 2890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2890000\n",
      "  training_iteration: 289\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5257 s, 289 iter, 2890000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-15-02\n",
      "  done: false\n",
      "  episode_len_mean: 124.41\n",
      "  episode_reward_max: 208.75297702893144\n",
      "  episode_reward_mean: 152.4321183936582\n",
      "  episode_reward_min: -51.83410037360569\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 21811\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5899798214406398e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3934667110443115\n",
      "      kl: 0.01548940222710371\n",
      "      policy_loss: 0.0017813900485634804\n",
      "      total_loss: 78.09459686279297\n",
      "      vf_explained_var: 0.9719619750976562\n",
      "      vf_loss: 78.09281158447266\n",
      "    grad_time_ms: 1535.075\n",
      "    load_time_ms: 1.383\n",
      "    num_steps_sampled: 2900000\n",
      "    num_steps_trained: 2900000\n",
      "    sample_time_ms: 15778.108\n",
      "    update_time_ms: 4.409\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5274.017580509186\n",
      "  time_this_iter_s: 16.911089181900024\n",
      "  time_total_s: 5274.017580509186\n",
      "  timestamp: 1550621702\n",
      "  timesteps_since_restore: 2900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2900000\n",
      "  training_iteration: 290\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5274 s, 290 iter, 2900000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-15-19\n",
      "  done: false\n",
      "  episode_len_mean: 124.35\n",
      "  episode_reward_max: 197.86181511220954\n",
      "  episode_reward_mean: 153.0117386042516\n",
      "  episode_reward_min: -51.83410037360569\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 21891\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5899798214406398e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3144755363464355\n",
      "      kl: 0.02477131225168705\n",
      "      policy_loss: -0.00036158948205411434\n",
      "      total_loss: 98.57475280761719\n",
      "      vf_explained_var: 0.9645636081695557\n",
      "      vf_loss: 98.57511901855469\n",
      "    grad_time_ms: 1537.74\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "    sample_time_ms: 15767.702\n",
      "    update_time_ms: 4.403\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5291.179237127304\n",
      "  time_this_iter_s: 17.161656618118286\n",
      "  time_total_s: 5291.179237127304\n",
      "  timestamp: 1550621719\n",
      "  timesteps_since_restore: 2910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 291\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5291 s, 291 iter, 2910000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 122.71\n",
      "  episode_reward_max: 209.94169522984183\n",
      "  episode_reward_mean: 152.4066939560147\n",
      "  episode_reward_min: -51.76626457170686\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 21974\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5899798214406398e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.126641035079956\n",
      "      kl: 0.05179716274142265\n",
      "      policy_loss: 0.0049442569725215435\n",
      "      total_loss: 174.09092712402344\n",
      "      vf_explained_var: 0.9396252632141113\n",
      "      vf_loss: 174.0859832763672\n",
      "    grad_time_ms: 1542.009\n",
      "    load_time_ms: 1.379\n",
      "    num_steps_sampled: 2920000\n",
      "    num_steps_trained: 2920000\n",
      "    sample_time_ms: 15835.044\n",
      "    update_time_ms: 4.525\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5308.779434204102\n",
      "  time_this_iter_s: 17.600197076797485\n",
      "  time_total_s: 5308.779434204102\n",
      "  timestamp: 1550621737\n",
      "  timesteps_since_restore: 2920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2920000\n",
      "  training_iteration: 292\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5308 s, 292 iter, 2920000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-15-55\n",
      "  done: false\n",
      "  episode_len_mean: 124.28\n",
      "  episode_reward_max: 205.73038924950188\n",
      "  episode_reward_mean: 158.93844373912953\n",
      "  episode_reward_min: -46.0329567022843\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 22054\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.292144775390625\n",
      "      kl: 0.010158898308873177\n",
      "      policy_loss: 0.00034901424078270793\n",
      "      total_loss: 59.16951370239258\n",
      "      vf_explained_var: 0.978594183921814\n",
      "      vf_loss: 59.16917037963867\n",
      "    grad_time_ms: 1548.126\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 2930000\n",
      "    num_steps_trained: 2930000\n",
      "    sample_time_ms: 15841.864\n",
      "    update_time_ms: 4.509\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5326.147352933884\n",
      "  time_this_iter_s: 17.367918729782104\n",
      "  time_total_s: 5326.147352933884\n",
      "  timestamp: 1550621755\n",
      "  timesteps_since_restore: 2930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2930000\n",
      "  training_iteration: 293\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5326 s, 293 iter, 2930000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-16-12\n",
      "  done: false\n",
      "  episode_len_mean: 123.44\n",
      "  episode_reward_max: 193.37892636959222\n",
      "  episode_reward_mean: 154.0842350797782\n",
      "  episode_reward_min: -53.55900677610744\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 22135\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2955214977264404\n",
      "      kl: 0.013346618972718716\n",
      "      policy_loss: -0.0016793685499578714\n",
      "      total_loss: 91.76123809814453\n",
      "      vf_explained_var: 0.9680958986282349\n",
      "      vf_loss: 91.76292419433594\n",
      "    grad_time_ms: 1549.533\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "    sample_time_ms: 15849.9\n",
      "    update_time_ms: 4.361\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5343.641820907593\n",
      "  time_this_iter_s: 17.494467973709106\n",
      "  time_total_s: 5343.641820907593\n",
      "  timestamp: 1550621772\n",
      "  timesteps_since_restore: 2940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 294\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5343 s, 294 iter, 2940000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 125.87\n",
      "  episode_reward_max: 196.06570762025976\n",
      "  episode_reward_mean: 153.06557546392247\n",
      "  episode_reward_min: -53.55900677610744\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 22212\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5597434043884277\n",
      "      kl: 0.017530057579278946\n",
      "      policy_loss: -0.0006845727912150323\n",
      "      total_loss: 77.66793823242188\n",
      "      vf_explained_var: 0.9706405997276306\n",
      "      vf_loss: 77.66861724853516\n",
      "    grad_time_ms: 1551.404\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 2950000\n",
      "    num_steps_trained: 2950000\n",
      "    sample_time_ms: 15883.073\n",
      "    update_time_ms: 4.381\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5361.205801486969\n",
      "  time_this_iter_s: 17.56398057937622\n",
      "  time_total_s: 5361.205801486969\n",
      "  timestamp: 1550621790\n",
      "  timesteps_since_restore: 2950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2950000\n",
      "  training_iteration: 295\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5361 s, 295 iter, 2950000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-16-47\n",
      "  done: false\n",
      "  episode_len_mean: 126.38\n",
      "  episode_reward_max: 210.34717601390173\n",
      "  episode_reward_mean: 160.8833797611533\n",
      "  episode_reward_min: -53.46571488707961\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 22291\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.252856731414795\n",
      "      kl: 0.01554497517645359\n",
      "      policy_loss: -0.0009563411585986614\n",
      "      total_loss: 95.27277374267578\n",
      "      vf_explained_var: 0.9659463763237\n",
      "      vf_loss: 95.27373504638672\n",
      "    grad_time_ms: 1551.1\n",
      "    load_time_ms: 1.363\n",
      "    num_steps_sampled: 2960000\n",
      "    num_steps_trained: 2960000\n",
      "    sample_time_ms: 15833.939\n",
      "    update_time_ms: 4.307\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5378.46784901619\n",
      "  time_this_iter_s: 17.26204752922058\n",
      "  time_total_s: 5378.46784901619\n",
      "  timestamp: 1550621807\n",
      "  timesteps_since_restore: 2960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2960000\n",
      "  training_iteration: 296\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5378 s, 296 iter, 2960000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-17-05\n",
      "  done: false\n",
      "  episode_len_mean: 124.15\n",
      "  episode_reward_max: 210.36100566770762\n",
      "  episode_reward_mean: 154.8920057588038\n",
      "  episode_reward_min: -44.00777545482806\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 22372\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2995877265930176\n",
      "      kl: 0.02838379517197609\n",
      "      policy_loss: -0.0002650327223818749\n",
      "      total_loss: 129.91656494140625\n",
      "      vf_explained_var: 0.9552499055862427\n",
      "      vf_loss: 129.9168243408203\n",
      "    grad_time_ms: 1551.839\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "    sample_time_ms: 15846.777\n",
      "    update_time_ms: 4.476\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5396.099085569382\n",
      "  time_this_iter_s: 17.63123655319214\n",
      "  time_total_s: 5396.099085569382\n",
      "  timestamp: 1550621825\n",
      "  timesteps_since_restore: 2970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 297\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5396 s, 297 iter, 2970000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-17-22\n",
      "  done: false\n",
      "  episode_len_mean: 128.87\n",
      "  episode_reward_max: 196.6230137920616\n",
      "  episode_reward_mean: 166.90927354452896\n",
      "  episode_reward_min: -44.00777545482806\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 22450\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4546220302581787\n",
      "      kl: 0.014546050690114498\n",
      "      policy_loss: -0.001975882798433304\n",
      "      total_loss: 16.764780044555664\n",
      "      vf_explained_var: 0.9939683079719543\n",
      "      vf_loss: 16.766754150390625\n",
      "    grad_time_ms: 1554.129\n",
      "    load_time_ms: 1.346\n",
      "    num_steps_sampled: 2980000\n",
      "    num_steps_trained: 2980000\n",
      "    sample_time_ms: 15762.204\n",
      "    update_time_ms: 4.538\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5413.238364696503\n",
      "  time_this_iter_s: 17.13927912712097\n",
      "  time_total_s: 5413.238364696503\n",
      "  timestamp: 1550621842\n",
      "  timesteps_since_restore: 2980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2980000\n",
      "  training_iteration: 298\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5413 s, 298 iter, 2980000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-17-39\n",
      "  done: false\n",
      "  episode_len_mean: 123.77\n",
      "  episode_reward_max: 207.37111712829903\n",
      "  episode_reward_mean: 155.45614343062746\n",
      "  episode_reward_min: -51.00926078723209\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 22531\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.175518035888672\n",
      "      kl: 0.017000550404191017\n",
      "      policy_loss: -0.0006454120157286525\n",
      "      total_loss: 102.90008544921875\n",
      "      vf_explained_var: 0.9661769270896912\n",
      "      vf_loss: 102.90071868896484\n",
      "    grad_time_ms: 1554.725\n",
      "    load_time_ms: 1.403\n",
      "    num_steps_sampled: 2990000\n",
      "    num_steps_trained: 2990000\n",
      "    sample_time_ms: 15793.938\n",
      "    update_time_ms: 4.62\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5430.785815238953\n",
      "  time_this_iter_s: 17.54745054244995\n",
      "  time_total_s: 5430.785815238953\n",
      "  timestamp: 1550621859\n",
      "  timesteps_since_restore: 2990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2990000\n",
      "  training_iteration: 299\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5430 s, 299 iter, 2990000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-17-57\n",
      "  done: false\n",
      "  episode_len_mean: 129.29\n",
      "  episode_reward_max: 208.0142964676464\n",
      "  episode_reward_mean: 166.91140996610974\n",
      "  episode_reward_min: -45.278441823650105\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 22608\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2617955207824707\n",
      "      kl: 0.016323590651154518\n",
      "      policy_loss: 0.0005180916050449014\n",
      "      total_loss: 24.638256072998047\n",
      "      vf_explained_var: 0.9911229014396667\n",
      "      vf_loss: 24.637739181518555\n",
      "    grad_time_ms: 1557.433\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "    sample_time_ms: 15842.251\n",
      "    update_time_ms: 4.541\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5448.206645011902\n",
      "  time_this_iter_s: 17.42082977294922\n",
      "  time_total_s: 5448.206645011902\n",
      "  timestamp: 1550621877\n",
      "  timesteps_since_restore: 3000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 300\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5448 s, 300 iter, 3000000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-18-14\n",
      "  done: false\n",
      "  episode_len_mean: 124.87\n",
      "  episode_reward_max: 215.9383143434429\n",
      "  episode_reward_mean: 155.95754243021648\n",
      "  episode_reward_min: -48.409897507417334\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 22688\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3945858478546143\n",
      "      kl: 0.018654849380254745\n",
      "      policy_loss: 0.0011485927971079946\n",
      "      total_loss: 69.76813507080078\n",
      "      vf_explained_var: 0.9767594933509827\n",
      "      vf_loss: 69.76700592041016\n",
      "    grad_time_ms: 1557.654\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 3010000\n",
      "    num_steps_trained: 3010000\n",
      "    sample_time_ms: 15856.676\n",
      "    update_time_ms: 4.496\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5465.519713640213\n",
      "  time_this_iter_s: 17.313068628311157\n",
      "  time_total_s: 5465.519713640213\n",
      "  timestamp: 1550621894\n",
      "  timesteps_since_restore: 3010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3010000\n",
      "  training_iteration: 301\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5465 s, 301 iter, 3010000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 126.98\n",
      "  episode_reward_max: 207.03727613360005\n",
      "  episode_reward_mean: 163.17547177848138\n",
      "  episode_reward_min: -48.397553160639106\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 22765\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4067442417144775\n",
      "      kl: 0.013398616574704647\n",
      "      policy_loss: 0.00033758580684661865\n",
      "      total_loss: 30.692325592041016\n",
      "      vf_explained_var: 0.988847017288208\n",
      "      vf_loss: 30.691991806030273\n",
      "    grad_time_ms: 1552.177\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 3020000\n",
      "    num_steps_trained: 3020000\n",
      "    sample_time_ms: 15873.762\n",
      "    update_time_ms: 4.417\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5483.237315654755\n",
      "  time_this_iter_s: 17.717602014541626\n",
      "  time_total_s: 5483.237315654755\n",
      "  timestamp: 1550621912\n",
      "  timesteps_since_restore: 3020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3020000\n",
      "  training_iteration: 302\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5483 s, 302 iter, 3020000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-18-49\n",
      "  done: false\n",
      "  episode_len_mean: 127.9\n",
      "  episode_reward_max: 211.0317906814047\n",
      "  episode_reward_mean: 158.31382953627684\n",
      "  episode_reward_min: -52.017956313225305\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 22844\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.510864496231079\n",
      "      kl: 0.010970095172524452\n",
      "      policy_loss: -0.0014617997221648693\n",
      "      total_loss: 88.34815979003906\n",
      "      vf_explained_var: 0.9689190983772278\n",
      "      vf_loss: 88.34962463378906\n",
      "    grad_time_ms: 1545.676\n",
      "    load_time_ms: 1.412\n",
      "    num_steps_sampled: 3030000\n",
      "    num_steps_trained: 3030000\n",
      "    sample_time_ms: 15856.743\n",
      "    update_time_ms: 4.52\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5500.370176315308\n",
      "  time_this_iter_s: 17.13286066055298\n",
      "  time_total_s: 5500.370176315308\n",
      "  timestamp: 1550621929\n",
      "  timesteps_since_restore: 3030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3030000\n",
      "  training_iteration: 303\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5500 s, 303 iter, 3030000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-19-06\n",
      "  done: false\n",
      "  episode_len_mean: 126.53\n",
      "  episode_reward_max: 211.0317906814047\n",
      "  episode_reward_mean: 153.84458135137066\n",
      "  episode_reward_min: -48.70182659100778\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 22924\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.5209579467773438\n",
      "      kl: 0.020151885226368904\n",
      "      policy_loss: 0.0009672594023868442\n",
      "      total_loss: 85.31571960449219\n",
      "      vf_explained_var: 0.9713424444198608\n",
      "      vf_loss: 85.31475067138672\n",
      "    grad_time_ms: 1543.105\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 3040000\n",
      "    num_steps_trained: 3040000\n",
      "    sample_time_ms: 15834.468\n",
      "    update_time_ms: 4.622\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5517.617876529694\n",
      "  time_this_iter_s: 17.247700214385986\n",
      "  time_total_s: 5517.617876529694\n",
      "  timestamp: 1550621946\n",
      "  timesteps_since_restore: 3040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3040000\n",
      "  training_iteration: 304\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5517 s, 304 iter, 3040000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-19-23\n",
      "  done: false\n",
      "  episode_len_mean: 125.97\n",
      "  episode_reward_max: 204.84711502433427\n",
      "  episode_reward_mean: 158.86163679837222\n",
      "  episode_reward_min: -53.94766585337053\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 23003\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.305786609649658\n",
      "      kl: 0.026647930964827538\n",
      "      policy_loss: -0.0003297573421150446\n",
      "      total_loss: 85.917236328125\n",
      "      vf_explained_var: 0.9696516394615173\n",
      "      vf_loss: 85.91756439208984\n",
      "    grad_time_ms: 1561.161\n",
      "    load_time_ms: 1.357\n",
      "    num_steps_sampled: 3050000\n",
      "    num_steps_trained: 3050000\n",
      "    sample_time_ms: 15757.39\n",
      "    update_time_ms: 4.753\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5534.588813304901\n",
      "  time_this_iter_s: 16.97093677520752\n",
      "  time_total_s: 5534.588813304901\n",
      "  timestamp: 1550621963\n",
      "  timesteps_since_restore: 3050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3050000\n",
      "  training_iteration: 305\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5534 s, 305 iter, 3050000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-19-40\n",
      "  done: false\n",
      "  episode_len_mean: 126.36\n",
      "  episode_reward_max: 204.84711502433427\n",
      "  episode_reward_mean: 154.2692287101814\n",
      "  episode_reward_min: -47.117746712252654\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 23083\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.441500425338745\n",
      "      kl: 0.015761643648147583\n",
      "      policy_loss: 0.0008910813485272229\n",
      "      total_loss: 153.2834014892578\n",
      "      vf_explained_var: 0.9482168555259705\n",
      "      vf_loss: 153.28248596191406\n",
      "    grad_time_ms: 1561.717\n",
      "    load_time_ms: 1.398\n",
      "    num_steps_sampled: 3060000\n",
      "    num_steps_trained: 3060000\n",
      "    sample_time_ms: 15726.195\n",
      "    update_time_ms: 4.722\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5551.544275045395\n",
      "  time_this_iter_s: 16.955461740493774\n",
      "  time_total_s: 5551.544275045395\n",
      "  timestamp: 1550621980\n",
      "  timesteps_since_restore: 3060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3060000\n",
      "  training_iteration: 306\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5551 s, 306 iter, 3060000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-19-58\n",
      "  done: false\n",
      "  episode_len_mean: 124.3\n",
      "  episode_reward_max: 211.73599029015207\n",
      "  episode_reward_mean: 150.28276389626254\n",
      "  episode_reward_min: -46.473499194525246\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 23162\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3341023921966553\n",
      "      kl: 0.03259166330099106\n",
      "      policy_loss: -0.0004322189779486507\n",
      "      total_loss: 100.62018585205078\n",
      "      vf_explained_var: 0.964397132396698\n",
      "      vf_loss: 100.62061309814453\n",
      "    grad_time_ms: 1559.974\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 3070000\n",
      "    num_steps_trained: 3070000\n",
      "    sample_time_ms: 15691.525\n",
      "    update_time_ms: 4.647\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5568.809288024902\n",
      "  time_this_iter_s: 17.265012979507446\n",
      "  time_total_s: 5568.809288024902\n",
      "  timestamp: 1550621998\n",
      "  timesteps_since_restore: 3070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3070000\n",
      "  training_iteration: 307\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5568 s, 307 iter, 3070000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-20-15\n",
      "  done: false\n",
      "  episode_len_mean: 126.32\n",
      "  episode_reward_max: 216.37216649226627\n",
      "  episode_reward_mean: 162.56881118468849\n",
      "  episode_reward_min: -43.861284091331015\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 23241\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.286606788635254\n",
      "      kl: 0.014616127125918865\n",
      "      policy_loss: -0.0007026857347227633\n",
      "      total_loss: 37.93375778198242\n",
      "      vf_explained_var: 0.9857116341590881\n",
      "      vf_loss: 37.93446731567383\n",
      "    grad_time_ms: 1558.007\n",
      "    load_time_ms: 1.414\n",
      "    num_steps_sampled: 3080000\n",
      "    num_steps_trained: 3080000\n",
      "    sample_time_ms: 15698.773\n",
      "    update_time_ms: 4.679\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5586.003078460693\n",
      "  time_this_iter_s: 17.193790435791016\n",
      "  time_total_s: 5586.003078460693\n",
      "  timestamp: 1550622015\n",
      "  timesteps_since_restore: 3080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3080000\n",
      "  training_iteration: 308\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5586 s, 308 iter, 3080000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-20-32\n",
      "  done: false\n",
      "  episode_len_mean: 126.53\n",
      "  episode_reward_max: 214.4202393523536\n",
      "  episode_reward_mean: 160.86611760080433\n",
      "  episode_reward_min: -51.53190668473148\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 23321\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.371464252471924\n",
      "      kl: 0.017097771167755127\n",
      "      policy_loss: -0.0005714452126994729\n",
      "      total_loss: 98.01163482666016\n",
      "      vf_explained_var: 0.9636124968528748\n",
      "      vf_loss: 98.01219940185547\n",
      "    grad_time_ms: 1559.334\n",
      "    load_time_ms: 1.387\n",
      "    num_steps_sampled: 3090000\n",
      "    num_steps_trained: 3090000\n",
      "    sample_time_ms: 15646.414\n",
      "    update_time_ms: 4.598\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5603.0382244586945\n",
      "  time_this_iter_s: 17.0351459980011\n",
      "  time_total_s: 5603.0382244586945\n",
      "  timestamp: 1550622032\n",
      "  timesteps_since_restore: 3090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3090000\n",
      "  training_iteration: 309\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5603 s, 309 iter, 3090000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-20-49\n",
      "  done: false\n",
      "  episode_len_mean: 128.75\n",
      "  episode_reward_max: 201.1475738993671\n",
      "  episode_reward_mean: 159.5252399757692\n",
      "  episode_reward_min: -51.53190668473148\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 23397\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4831466674804688\n",
      "      kl: 0.012620851397514343\n",
      "      policy_loss: -0.0013404153287410736\n",
      "      total_loss: 46.304603576660156\n",
      "      vf_explained_var: 0.9823533296585083\n",
      "      vf_loss: 46.305938720703125\n",
      "    grad_time_ms: 1555.681\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 3100000\n",
      "    num_steps_trained: 3100000\n",
      "    sample_time_ms: 15612.565\n",
      "    update_time_ms: 4.486\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5620.083530902863\n",
      "  time_this_iter_s: 17.04530644416809\n",
      "  time_total_s: 5620.083530902863\n",
      "  timestamp: 1550622049\n",
      "  timesteps_since_restore: 3100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3100000\n",
      "  training_iteration: 310\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5620 s, 310 iter, 3100000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-21-06\n",
      "  done: false\n",
      "  episode_len_mean: 124.83\n",
      "  episode_reward_max: 219.91941380353248\n",
      "  episode_reward_mean: 152.7960140580449\n",
      "  episode_reward_min: -50.591062680624496\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 23478\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2562973499298096\n",
      "      kl: 0.013233216479420662\n",
      "      policy_loss: -0.0014694281853735447\n",
      "      total_loss: 123.8413314819336\n",
      "      vf_explained_var: 0.9591040015220642\n",
      "      vf_loss: 123.84281158447266\n",
      "    grad_time_ms: 1555.229\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 3110000\n",
      "    num_steps_trained: 3110000\n",
      "    sample_time_ms: 15598.634\n",
      "    update_time_ms: 4.508\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5637.248732805252\n",
      "  time_this_iter_s: 17.165201902389526\n",
      "  time_total_s: 5637.248732805252\n",
      "  timestamp: 1550622066\n",
      "  timesteps_since_restore: 3110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3110000\n",
      "  training_iteration: 311\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5637 s, 311 iter, 3110000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-21-24\n",
      "  done: false\n",
      "  episode_len_mean: 126.53\n",
      "  episode_reward_max: 198.53880812862124\n",
      "  episode_reward_mean: 153.61882849757055\n",
      "  episode_reward_min: -50.591062680624496\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 23556\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.3849700772876057e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.48954176902771\n",
      "      kl: 0.05697072297334671\n",
      "      policy_loss: 0.006777812261134386\n",
      "      total_loss: 87.61677551269531\n",
      "      vf_explained_var: 0.9680193662643433\n",
      "      vf_loss: 87.61000061035156\n",
      "    grad_time_ms: 1574.698\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 3120000\n",
      "    num_steps_trained: 3120000\n",
      "    sample_time_ms: 15566.17\n",
      "    update_time_ms: 4.588\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5654.835419178009\n",
      "  time_this_iter_s: 17.586686372756958\n",
      "  time_total_s: 5654.835419178009\n",
      "  timestamp: 1550622084\n",
      "  timesteps_since_restore: 3120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3120000\n",
      "  training_iteration: 312\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5654 s, 312 iter, 3120000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-21-41\n",
      "  done: false\n",
      "  episode_len_mean: 126.73\n",
      "  episode_reward_max: 197.58660328974665\n",
      "  episode_reward_mean: 159.83714256150162\n",
      "  episode_reward_min: -52.263666818932705\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 23635\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.427800178527832\n",
      "      kl: 0.027021002024412155\n",
      "      policy_loss: -0.0010498369811102748\n",
      "      total_loss: 80.568115234375\n",
      "      vf_explained_var: 0.9713547825813293\n",
      "      vf_loss: 80.56917572021484\n",
      "    grad_time_ms: 1575.042\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 3130000\n",
      "    num_steps_trained: 3130000\n",
      "    sample_time_ms: 15568.966\n",
      "    update_time_ms: 4.534\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5671.999143600464\n",
      "  time_this_iter_s: 17.163724422454834\n",
      "  time_total_s: 5671.999143600464\n",
      "  timestamp: 1550622101\n",
      "  timesteps_since_restore: 3130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3130000\n",
      "  training_iteration: 313\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5671 s, 313 iter, 3130000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-21-59\n",
      "  done: false\n",
      "  episode_len_mean: 122.68\n",
      "  episode_reward_max: 206.001330965964\n",
      "  episode_reward_mean: 148.29443190815184\n",
      "  episode_reward_min: -52.263666818932705\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 23716\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2393314838409424\n",
      "      kl: 0.015089757740497589\n",
      "      policy_loss: -0.00037543600774370134\n",
      "      total_loss: 162.9333038330078\n",
      "      vf_explained_var: 0.9478326439857483\n",
      "      vf_loss: 162.9336395263672\n",
      "    grad_time_ms: 1575.302\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 3140000\n",
      "    num_steps_trained: 3140000\n",
      "    sample_time_ms: 15593.999\n",
      "    update_time_ms: 4.601\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5689.501770019531\n",
      "  time_this_iter_s: 17.502626419067383\n",
      "  time_total_s: 5689.501770019531\n",
      "  timestamp: 1550622119\n",
      "  timesteps_since_restore: 3140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3140000\n",
      "  training_iteration: 314\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5689 s, 314 iter, 3140000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-22-16\n",
      "  done: false\n",
      "  episode_len_mean: 123.89\n",
      "  episode_reward_max: 195.94861166223436\n",
      "  episode_reward_mean: 148.49460163788603\n",
      "  episode_reward_min: -46.26667767659862\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 23797\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3392832279205322\n",
      "      kl: 0.014773656614124775\n",
      "      policy_loss: -0.0004419067408889532\n",
      "      total_loss: 181.54959106445312\n",
      "      vf_explained_var: 0.9389227628707886\n",
      "      vf_loss: 181.550048828125\n",
      "    grad_time_ms: 1555.286\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 3150000\n",
      "    num_steps_trained: 3150000\n",
      "    sample_time_ms: 15632.756\n",
      "    update_time_ms: 4.503\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5706.659677028656\n",
      "  time_this_iter_s: 17.157907009124756\n",
      "  time_total_s: 5706.659677028656\n",
      "  timestamp: 1550622136\n",
      "  timesteps_since_restore: 3150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3150000\n",
      "  training_iteration: 315\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5706 s, 315 iter, 3150000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-22-33\n",
      "  done: false\n",
      "  episode_len_mean: 125.91\n",
      "  episode_reward_max: 210.0478314094906\n",
      "  episode_reward_mean: 157.92462693173624\n",
      "  episode_reward_min: -46.11078060853597\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 23875\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.32845139503479\n",
      "      kl: 0.02240527607500553\n",
      "      policy_loss: 0.0007531627779826522\n",
      "      total_loss: 86.32825469970703\n",
      "      vf_explained_var: 0.9684120416641235\n",
      "      vf_loss: 86.3275146484375\n",
      "    grad_time_ms: 1554.087\n",
      "    load_time_ms: 1.422\n",
      "    num_steps_sampled: 3160000\n",
      "    num_steps_trained: 3160000\n",
      "    sample_time_ms: 15659.229\n",
      "    update_time_ms: 4.593\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5723.869410991669\n",
      "  time_this_iter_s: 17.209733963012695\n",
      "  time_total_s: 5723.869410991669\n",
      "  timestamp: 1550622153\n",
      "  timesteps_since_restore: 3160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3160000\n",
      "  training_iteration: 316\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5723 s, 316 iter, 3160000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-22-50\n",
      "  done: false\n",
      "  episode_len_mean: 126.2\n",
      "  episode_reward_max: 210.0478314094906\n",
      "  episode_reward_mean: 158.7001494199271\n",
      "  episode_reward_min: -53.57721062757002\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 23954\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2362184524536133\n",
      "      kl: 0.013015546835958958\n",
      "      policy_loss: -0.0023845559917390347\n",
      "      total_loss: 109.21958923339844\n",
      "      vf_explained_var: 0.9633196592330933\n",
      "      vf_loss: 109.22196960449219\n",
      "    grad_time_ms: 1553.524\n",
      "    load_time_ms: 1.384\n",
      "    num_steps_sampled: 3170000\n",
      "    num_steps_trained: 3170000\n",
      "    sample_time_ms: 15662.998\n",
      "    update_time_ms: 4.495\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5741.165096998215\n",
      "  time_this_iter_s: 17.29568600654602\n",
      "  time_total_s: 5741.165096998215\n",
      "  timestamp: 1550622170\n",
      "  timesteps_since_restore: 3170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3170000\n",
      "  training_iteration: 317\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5741 s, 317 iter, 3170000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-23-08\n",
      "  done: false\n",
      "  episode_len_mean: 127.34\n",
      "  episode_reward_max: 209.8201042286831\n",
      "  episode_reward_mean: 159.99821907864396\n",
      "  episode_reward_min: -53.695638588454464\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 24032\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3818719387054443\n",
      "      kl: 0.023441290482878685\n",
      "      policy_loss: 0.003856794210150838\n",
      "      total_loss: 125.70060729980469\n",
      "      vf_explained_var: 0.9530391097068787\n",
      "      vf_loss: 125.69677734375\n",
      "    grad_time_ms: 1555.213\n",
      "    load_time_ms: 1.377\n",
      "    num_steps_sampled: 3180000\n",
      "    num_steps_trained: 3180000\n",
      "    sample_time_ms: 15657.508\n",
      "    update_time_ms: 4.47\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5758.3199026584625\n",
      "  time_this_iter_s: 17.154805660247803\n",
      "  time_total_s: 5758.3199026584625\n",
      "  timestamp: 1550622188\n",
      "  timesteps_since_restore: 3180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3180000\n",
      "  training_iteration: 318\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5758 s, 318 iter, 3180000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-23-25\n",
      "  done: false\n",
      "  episode_len_mean: 127.92\n",
      "  episode_reward_max: 204.0922541914895\n",
      "  episode_reward_mean: 159.39421138211168\n",
      "  episode_reward_min: -48.08647883454763\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 24111\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3588528633117676\n",
      "      kl: 0.013386976905167103\n",
      "      policy_loss: -0.0011822909582406282\n",
      "      total_loss: 60.009063720703125\n",
      "      vf_explained_var: 0.9795008897781372\n",
      "      vf_loss: 60.01025390625\n",
      "    grad_time_ms: 1556.086\n",
      "    load_time_ms: 1.307\n",
      "    num_steps_sampled: 3190000\n",
      "    num_steps_trained: 3190000\n",
      "    sample_time_ms: 15716.149\n",
      "    update_time_ms: 4.465\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5775.948075532913\n",
      "  time_this_iter_s: 17.628172874450684\n",
      "  time_total_s: 5775.948075532913\n",
      "  timestamp: 1550622205\n",
      "  timesteps_since_restore: 3190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3190000\n",
      "  training_iteration: 319\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5775 s, 319 iter, 3190000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-23-43\n",
      "  done: false\n",
      "  episode_len_mean: 124.8\n",
      "  episode_reward_max: 199.06139854098316\n",
      "  episode_reward_mean: 153.67002508285893\n",
      "  episode_reward_min: -45.85017651614576\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 24191\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2249650955200195\n",
      "      kl: 0.01331298891454935\n",
      "      policy_loss: -0.001509385067038238\n",
      "      total_loss: 81.85298919677734\n",
      "      vf_explained_var: 0.971379816532135\n",
      "      vf_loss: 81.8544921875\n",
      "    grad_time_ms: 1558.037\n",
      "    load_time_ms: 1.328\n",
      "    num_steps_sampled: 3200000\n",
      "    num_steps_trained: 3200000\n",
      "    sample_time_ms: 15732.142\n",
      "    update_time_ms: 4.466\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5793.172869920731\n",
      "  time_this_iter_s: 17.224794387817383\n",
      "  time_total_s: 5793.172869920731\n",
      "  timestamp: 1550622223\n",
      "  timesteps_since_restore: 3200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3200000\n",
      "  training_iteration: 320\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5793 s, 320 iter, 3200000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-24-00\n",
      "  done: false\n",
      "  episode_len_mean: 128.48\n",
      "  episode_reward_max: 209.0887137548166\n",
      "  episode_reward_mean: 161.180722222629\n",
      "  episode_reward_min: -49.983929778089625\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 24268\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.436803102493286\n",
      "      kl: 0.02076301909983158\n",
      "      policy_loss: 0.0016282384749501944\n",
      "      total_loss: 72.44578552246094\n",
      "      vf_explained_var: 0.974157452583313\n",
      "      vf_loss: 72.44416046142578\n",
      "    grad_time_ms: 1559.053\n",
      "    load_time_ms: 1.329\n",
      "    num_steps_sampled: 3210000\n",
      "    num_steps_trained: 3210000\n",
      "    sample_time_ms: 15724.326\n",
      "    update_time_ms: 4.561\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5810.273119926453\n",
      "  time_this_iter_s: 17.100250005722046\n",
      "  time_total_s: 5810.273119926453\n",
      "  timestamp: 1550622240\n",
      "  timesteps_since_restore: 3210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3210000\n",
      "  training_iteration: 321\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5810 s, 321 iter, 3210000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-24-17\n",
      "  done: false\n",
      "  episode_len_mean: 128.31\n",
      "  episode_reward_max: 209.0887137548166\n",
      "  episode_reward_mean: 157.28357615450014\n",
      "  episode_reward_min: -44.16348577726003\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 24348\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.577456200615153e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3200483322143555\n",
      "      kl: 7.7628173828125\n",
      "      policy_loss: 0.03301967307925224\n",
      "      total_loss: 117.20775604248047\n",
      "      vf_explained_var: 0.9570770263671875\n",
      "      vf_loss: 117.17472839355469\n",
      "    grad_time_ms: 1540.616\n",
      "    load_time_ms: 1.329\n",
      "    num_steps_sampled: 3220000\n",
      "    num_steps_trained: 3220000\n",
      "    sample_time_ms: 15700.987\n",
      "    update_time_ms: 4.502\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5827.441427946091\n",
      "  time_this_iter_s: 17.16830801963806\n",
      "  time_total_s: 5827.441427946091\n",
      "  timestamp: 1550622257\n",
      "  timesteps_since_restore: 3220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3220000\n",
      "  training_iteration: 322\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5827 s, 322 iter, 3220000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-24-34\n",
      "  done: false\n",
      "  episode_len_mean: 127.01\n",
      "  episode_reward_max: 202.38455109017914\n",
      "  episode_reward_mean: 162.17473651298752\n",
      "  episode_reward_min: -34.757875390572096\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 24426\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1688449382781982\n",
      "      kl: 0.01554027572274208\n",
      "      policy_loss: -0.0017301123589277267\n",
      "      total_loss: 69.06340789794922\n",
      "      vf_explained_var: 0.9738948345184326\n",
      "      vf_loss: 69.06515502929688\n",
      "    grad_time_ms: 1539.675\n",
      "    load_time_ms: 1.333\n",
      "    num_steps_sampled: 3230000\n",
      "    num_steps_trained: 3230000\n",
      "    sample_time_ms: 15729.39\n",
      "    update_time_ms: 4.499\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5844.879068851471\n",
      "  time_this_iter_s: 17.43764090538025\n",
      "  time_total_s: 5844.879068851471\n",
      "  timestamp: 1550622274\n",
      "  timesteps_since_restore: 3230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3230000\n",
      "  training_iteration: 323\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5844 s, 323 iter, 3230000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-24-52\n",
      "  done: false\n",
      "  episode_len_mean: 126.95\n",
      "  episode_reward_max: 206.98853769337762\n",
      "  episode_reward_mean: 156.5543059962012\n",
      "  episode_reward_min: -36.689009108755855\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 24505\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2833402156829834\n",
      "      kl: 0.012140740640461445\n",
      "      policy_loss: -0.002365604741498828\n",
      "      total_loss: 97.83016204833984\n",
      "      vf_explained_var: 0.9645033478736877\n",
      "      vf_loss: 97.83253479003906\n",
      "    grad_time_ms: 1540.369\n",
      "    load_time_ms: 1.395\n",
      "    num_steps_sampled: 3240000\n",
      "    num_steps_trained: 3240000\n",
      "    sample_time_ms: 15740.624\n",
      "    update_time_ms: 4.485\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5862.49858379364\n",
      "  time_this_iter_s: 17.61951494216919\n",
      "  time_total_s: 5862.49858379364\n",
      "  timestamp: 1550622292\n",
      "  timesteps_since_restore: 3240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3240000\n",
      "  training_iteration: 324\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5862 s, 324 iter, 3240000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-25-10\n",
      "  done: false\n",
      "  episode_len_mean: 124.05\n",
      "  episode_reward_max: 201.01064734736303\n",
      "  episode_reward_mean: 155.0126467540646\n",
      "  episode_reward_min: -51.73230830366068\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 24585\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1150758266448975\n",
      "      kl: 0.016434069722890854\n",
      "      policy_loss: -0.0005175143596716225\n",
      "      total_loss: 96.74616241455078\n",
      "      vf_explained_var: 0.9645960927009583\n",
      "      vf_loss: 96.74667358398438\n",
      "    grad_time_ms: 1539.513\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 3250000\n",
      "    num_steps_trained: 3250000\n",
      "    sample_time_ms: 15793.913\n",
      "    update_time_ms: 4.656\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5880.186052322388\n",
      "  time_this_iter_s: 17.68746852874756\n",
      "  time_total_s: 5880.186052322388\n",
      "  timestamp: 1550622310\n",
      "  timesteps_since_restore: 3250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3250000\n",
      "  training_iteration: 325\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5880 s, 325 iter, 3250000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-25-27\n",
      "  done: false\n",
      "  episode_len_mean: 126.81\n",
      "  episode_reward_max: 203.84947549131266\n",
      "  episode_reward_mean: 157.90561397793152\n",
      "  episode_reward_min: -51.73230830366068\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 24663\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.280355930328369\n",
      "      kl: 0.015116361901164055\n",
      "      policy_loss: -0.0005359367933124304\n",
      "      total_loss: 97.55558776855469\n",
      "      vf_explained_var: 0.9651839137077332\n",
      "      vf_loss: 97.55611419677734\n",
      "    grad_time_ms: 1540.875\n",
      "    load_time_ms: 1.395\n",
      "    num_steps_sampled: 3260000\n",
      "    num_steps_trained: 3260000\n",
      "    sample_time_ms: 15840.142\n",
      "    update_time_ms: 4.704\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5897.870313882828\n",
      "  time_this_iter_s: 17.684261560440063\n",
      "  time_total_s: 5897.870313882828\n",
      "  timestamp: 1550622327\n",
      "  timesteps_since_restore: 3260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3260000\n",
      "  training_iteration: 326\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5897 s, 326 iter, 3260000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-25-45\n",
      "  done: false\n",
      "  episode_len_mean: 126.29\n",
      "  episode_reward_max: 204.8280154859075\n",
      "  episode_reward_mean: 156.26186254286904\n",
      "  episode_reward_min: -43.475730282245294\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 24743\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1874051094055176\n",
      "      kl: 0.024623962119221687\n",
      "      policy_loss: 0.00020964242867194116\n",
      "      total_loss: 113.79467010498047\n",
      "      vf_explained_var: 0.9575505256652832\n",
      "      vf_loss: 113.79444885253906\n",
      "    grad_time_ms: 1542.623\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 3270000\n",
      "    num_steps_trained: 3270000\n",
      "    sample_time_ms: 15843.331\n",
      "    update_time_ms: 4.731\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5915.217039108276\n",
      "  time_this_iter_s: 17.34672522544861\n",
      "  time_total_s: 5915.217039108276\n",
      "  timestamp: 1550622345\n",
      "  timesteps_since_restore: 3270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3270000\n",
      "  training_iteration: 327\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5915 s, 327 iter, 3270000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-26-03\n",
      "  done: false\n",
      "  episode_len_mean: 125.95\n",
      "  episode_reward_max: 202.16644270172208\n",
      "  episode_reward_mean: 150.45499904372392\n",
      "  episode_reward_min: -51.76401260259128\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 24823\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.091590404510498\n",
      "      kl: 0.01694733463227749\n",
      "      policy_loss: -0.00011726889351848513\n",
      "      total_loss: 124.8831787109375\n",
      "      vf_explained_var: 0.9612497091293335\n",
      "      vf_loss: 124.88331604003906\n",
      "    grad_time_ms: 1541.816\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 3280000\n",
      "    num_steps_trained: 3280000\n",
      "    sample_time_ms: 15896.366\n",
      "    update_time_ms: 4.77\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5932.89489531517\n",
      "  time_this_iter_s: 17.67785620689392\n",
      "  time_total_s: 5932.89489531517\n",
      "  timestamp: 1550622363\n",
      "  timesteps_since_restore: 3280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3280000\n",
      "  training_iteration: 328\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5932 s, 328 iter, 3280000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-26-20\n",
      "  done: false\n",
      "  episode_len_mean: 130.23\n",
      "  episode_reward_max: 202.9413022080269\n",
      "  episode_reward_mean: 156.27995807369993\n",
      "  episode_reward_min: -51.89015805691775\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 24899\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4291412830352783\n",
      "      kl: 0.01062984298914671\n",
      "      policy_loss: -0.00020821708312723786\n",
      "      total_loss: 75.51327514648438\n",
      "      vf_explained_var: 0.9715628027915955\n",
      "      vf_loss: 75.51348114013672\n",
      "    grad_time_ms: 1539.365\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 3290000\n",
      "    num_steps_trained: 3290000\n",
      "    sample_time_ms: 15851.364\n",
      "    update_time_ms: 4.896\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5950.051109790802\n",
      "  time_this_iter_s: 17.156214475631714\n",
      "  time_total_s: 5950.051109790802\n",
      "  timestamp: 1550622380\n",
      "  timesteps_since_restore: 3290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3290000\n",
      "  training_iteration: 329\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5950 s, 329 iter, 3290000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-26-37\n",
      "  done: false\n",
      "  episode_len_mean: 129.37\n",
      "  episode_reward_max: 205.32519069638587\n",
      "  episode_reward_mean: 158.3268123195376\n",
      "  episode_reward_min: -43.17058888933446\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 24977\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.4505393505096436\n",
      "      kl: 0.019213158637285233\n",
      "      policy_loss: 0.0004252791404724121\n",
      "      total_loss: 58.67265701293945\n",
      "      vf_explained_var: 0.9781818985939026\n",
      "      vf_loss: 58.67223358154297\n",
      "    grad_time_ms: 1540.717\n",
      "    load_time_ms: 1.401\n",
      "    num_steps_sampled: 3300000\n",
      "    num_steps_trained: 3300000\n",
      "    sample_time_ms: 15863.992\n",
      "    update_time_ms: 4.947\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5967.414089202881\n",
      "  time_this_iter_s: 17.362979412078857\n",
      "  time_total_s: 5967.414089202881\n",
      "  timestamp: 1550622397\n",
      "  timesteps_since_restore: 3300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3300000\n",
      "  training_iteration: 330\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5967 s, 330 iter, 3300000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-26-54\n",
      "  done: false\n",
      "  episode_len_mean: 125.6\n",
      "  episode_reward_max: 204.47327828289264\n",
      "  episode_reward_mean: 151.78342783668478\n",
      "  episode_reward_min: -45.294436186256995\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 25056\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.172961711883545\n",
      "      kl: 0.037105876952409744\n",
      "      policy_loss: -0.0002013303601415828\n",
      "      total_loss: 151.48684692382812\n",
      "      vf_explained_var: 0.9487046599388123\n",
      "      vf_loss: 151.48704528808594\n",
      "    grad_time_ms: 1551.895\n",
      "    load_time_ms: 1.344\n",
      "    num_steps_sampled: 3310000\n",
      "    num_steps_trained: 3310000\n",
      "    sample_time_ms: 15859.236\n",
      "    update_time_ms: 4.852\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 5984.5745849609375\n",
      "  time_this_iter_s: 17.16049575805664\n",
      "  time_total_s: 5984.5745849609375\n",
      "  timestamp: 1550622414\n",
      "  timesteps_since_restore: 3310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3310000\n",
      "  training_iteration: 331\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 5984 s, 331 iter, 3310000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-27-11\n",
      "  done: false\n",
      "  episode_len_mean: 126.41\n",
      "  episode_reward_max: 202.17745792231358\n",
      "  episode_reward_mean: 162.22148785276102\n",
      "  episode_reward_min: -46.155204095462764\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 25135\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1200790405273438\n",
      "      kl: 0.030820947140455246\n",
      "      policy_loss: 0.0013399343006312847\n",
      "      total_loss: 64.8661880493164\n",
      "      vf_explained_var: 0.9757528901100159\n",
      "      vf_loss: 64.86485290527344\n",
      "    grad_time_ms: 1552.157\n",
      "    load_time_ms: 1.343\n",
      "    num_steps_sampled: 3320000\n",
      "    num_steps_trained: 3320000\n",
      "    sample_time_ms: 15846.126\n",
      "    update_time_ms: 4.872\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6001.615047216415\n",
      "  time_this_iter_s: 17.040462255477905\n",
      "  time_total_s: 6001.615047216415\n",
      "  timestamp: 1550622431\n",
      "  timesteps_since_restore: 3320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3320000\n",
      "  training_iteration: 332\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6001 s, 332 iter, 3320000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-27-28\n",
      "  done: false\n",
      "  episode_len_mean: 126.84\n",
      "  episode_reward_max: 205.4173249105121\n",
      "  episode_reward_mean: 159.8314091880367\n",
      "  episode_reward_min: -51.73209792021478\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 25214\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1904287338256836\n",
      "      kl: 0.017012475058436394\n",
      "      policy_loss: -0.001889134873636067\n",
      "      total_loss: 77.68800354003906\n",
      "      vf_explained_var: 0.9705663919448853\n",
      "      vf_loss: 77.68988800048828\n",
      "    grad_time_ms: 1552.892\n",
      "    load_time_ms: 1.334\n",
      "    num_steps_sampled: 3330000\n",
      "    num_steps_trained: 3330000\n",
      "    sample_time_ms: 15805.98\n",
      "    update_time_ms: 5.022\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6018.659903287888\n",
      "  time_this_iter_s: 17.044856071472168\n",
      "  time_total_s: 6018.659903287888\n",
      "  timestamp: 1550622448\n",
      "  timesteps_since_restore: 3330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3330000\n",
      "  training_iteration: 333\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6018 s, 333 iter, 3330000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-27-46\n",
      "  done: false\n",
      "  episode_len_mean: 126.64\n",
      "  episode_reward_max: 196.0633168393139\n",
      "  episode_reward_mean: 151.24998611889487\n",
      "  episode_reward_min: -51.73209792021478\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 25293\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.197077989578247\n",
      "      kl: 0.020034166052937508\n",
      "      policy_loss: 0.003542792284861207\n",
      "      total_loss: 129.4385528564453\n",
      "      vf_explained_var: 0.9570658802986145\n",
      "      vf_loss: 129.43499755859375\n",
      "    grad_time_ms: 1553.78\n",
      "    load_time_ms: 1.265\n",
      "    num_steps_sampled: 3340000\n",
      "    num_steps_trained: 3340000\n",
      "    sample_time_ms: 15750.095\n",
      "    update_time_ms: 4.991\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6035.7272436618805\n",
      "  time_this_iter_s: 17.06734037399292\n",
      "  time_total_s: 6035.7272436618805\n",
      "  timestamp: 1550622466\n",
      "  timesteps_since_restore: 3340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3340000\n",
      "  training_iteration: 334\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6035 s, 334 iter, 3340000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-28-03\n",
      "  done: false\n",
      "  episode_len_mean: 127.2\n",
      "  episode_reward_max: 201.48785811544636\n",
      "  episode_reward_mean: 158.66901812633307\n",
      "  episode_reward_min: -46.80929704172776\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 25373\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0649659633636475\n",
      "      kl: 0.021655485033988953\n",
      "      policy_loss: 0.0022127048578113317\n",
      "      total_loss: 65.52345275878906\n",
      "      vf_explained_var: 0.9771720767021179\n",
      "      vf_loss: 65.52123260498047\n",
      "    grad_time_ms: 1553.378\n",
      "    load_time_ms: 1.228\n",
      "    num_steps_sampled: 3350000\n",
      "    num_steps_trained: 3350000\n",
      "    sample_time_ms: 15719.273\n",
      "    update_time_ms: 4.832\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6053.098615407944\n",
      "  time_this_iter_s: 17.371371746063232\n",
      "  time_total_s: 6053.098615407944\n",
      "  timestamp: 1550622483\n",
      "  timesteps_since_restore: 3350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3350000\n",
      "  training_iteration: 335\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6053 s, 335 iter, 3350000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-28-20\n",
      "  done: false\n",
      "  episode_len_mean: 124.44\n",
      "  episode_reward_max: 200.46122228287825\n",
      "  episode_reward_mean: 147.65862906132799\n",
      "  episode_reward_min: -50.625642072151194\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 25454\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.147132158279419\n",
      "      kl: 0.019726542755961418\n",
      "      policy_loss: -0.0006839135312475264\n",
      "      total_loss: 141.70350646972656\n",
      "      vf_explained_var: 0.9543469548225403\n",
      "      vf_loss: 141.70419311523438\n",
      "    grad_time_ms: 1552.02\n",
      "    load_time_ms: 1.232\n",
      "    num_steps_sampled: 3360000\n",
      "    num_steps_trained: 3360000\n",
      "    sample_time_ms: 15655.689\n",
      "    update_time_ms: 4.828\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6070.1341071128845\n",
      "  time_this_iter_s: 17.035491704940796\n",
      "  time_total_s: 6070.1341071128845\n",
      "  timestamp: 1550622500\n",
      "  timesteps_since_restore: 3360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3360000\n",
      "  training_iteration: 336\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6070 s, 336 iter, 3360000 ts, 148 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-28-38\n",
      "  done: false\n",
      "  episode_len_mean: 125.2\n",
      "  episode_reward_max: 205.03223423940128\n",
      "  episode_reward_mean: 156.03160818262154\n",
      "  episode_reward_min: -51.91640550193221\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 25533\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0594112873077393\n",
      "      kl: 0.020531710237264633\n",
      "      policy_loss: 0.002500060247257352\n",
      "      total_loss: 65.45762634277344\n",
      "      vf_explained_var: 0.9761923551559448\n",
      "      vf_loss: 65.45512390136719\n",
      "    grad_time_ms: 1552.677\n",
      "    load_time_ms: 1.201\n",
      "    num_steps_sampled: 3370000\n",
      "    num_steps_trained: 3370000\n",
      "    sample_time_ms: 15668.056\n",
      "    update_time_ms: 4.922\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6087.6110582351685\n",
      "  time_this_iter_s: 17.476951122283936\n",
      "  time_total_s: 6087.6110582351685\n",
      "  timestamp: 1550622518\n",
      "  timesteps_since_restore: 3370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3370000\n",
      "  training_iteration: 337\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6087 s, 337 iter, 3370000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-28-55\n",
      "  done: false\n",
      "  episode_len_mean: 125.31\n",
      "  episode_reward_max: 205.03223423940128\n",
      "  episode_reward_mean: 156.4960456472639\n",
      "  episode_reward_min: -42.92146915020328\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 25612\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0616683959960938\n",
      "      kl: 0.01757434383034706\n",
      "      policy_loss: -0.0007979801157489419\n",
      "      total_loss: 117.71701049804688\n",
      "      vf_explained_var: 0.9583098292350769\n",
      "      vf_loss: 117.71781158447266\n",
      "    grad_time_ms: 1551.502\n",
      "    load_time_ms: 1.187\n",
      "    num_steps_sampled: 3380000\n",
      "    num_steps_trained: 3380000\n",
      "    sample_time_ms: 15644.284\n",
      "    update_time_ms: 4.925\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6105.0411241054535\n",
      "  time_this_iter_s: 17.430065870285034\n",
      "  time_total_s: 6105.0411241054535\n",
      "  timestamp: 1550622535\n",
      "  timesteps_since_restore: 3380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3380000\n",
      "  training_iteration: 338\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6105 s, 338 iter, 3380000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-29-12\n",
      "  done: false\n",
      "  episode_len_mean: 124.49\n",
      "  episode_reward_max: 197.56987743035384\n",
      "  episode_reward_mean: 154.25154903050216\n",
      "  episode_reward_min: -53.937828931330465\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 25693\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2476561069488525\n",
      "      kl: 0.014790541492402554\n",
      "      policy_loss: -0.0001263502927031368\n",
      "      total_loss: 87.0014419555664\n",
      "      vf_explained_var: 0.9691700339317322\n",
      "      vf_loss: 87.00154876708984\n",
      "    grad_time_ms: 1551.229\n",
      "    load_time_ms: 1.281\n",
      "    num_steps_sampled: 3390000\n",
      "    num_steps_trained: 3390000\n",
      "    sample_time_ms: 15663.649\n",
      "    update_time_ms: 4.802\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6122.387820482254\n",
      "  time_this_iter_s: 17.346696376800537\n",
      "  time_total_s: 6122.387820482254\n",
      "  timestamp: 1550622552\n",
      "  timesteps_since_restore: 3390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3390000\n",
      "  training_iteration: 339\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6122 s, 339 iter, 3390000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-29-30\n",
      "  done: false\n",
      "  episode_len_mean: 127.57\n",
      "  episode_reward_max: 206.13371160183814\n",
      "  episode_reward_mean: 162.13274782412873\n",
      "  episode_reward_min: -41.29686877278996\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 25771\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.237330198287964\n",
      "      kl: 0.018243402242660522\n",
      "      policy_loss: -0.0032141555566340685\n",
      "      total_loss: 54.56855392456055\n",
      "      vf_explained_var: 0.9791827201843262\n",
      "      vf_loss: 54.5717658996582\n",
      "    grad_time_ms: 1549.377\n",
      "    load_time_ms: 1.275\n",
      "    num_steps_sampled: 3400000\n",
      "    num_steps_trained: 3400000\n",
      "    sample_time_ms: 15716.59\n",
      "    update_time_ms: 4.707\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6140.260469675064\n",
      "  time_this_iter_s: 17.87264919281006\n",
      "  time_total_s: 6140.260469675064\n",
      "  timestamp: 1550622570\n",
      "  timesteps_since_restore: 3400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3400000\n",
      "  training_iteration: 340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6140 s, 340 iter, 3400000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-29-48\n",
      "  done: false\n",
      "  episode_len_mean: 127.01\n",
      "  episode_reward_max: 214.59431096911442\n",
      "  episode_reward_mean: 163.26155465311788\n",
      "  episode_reward_min: -49.23399158368018\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 25850\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.046470880508423\n",
      "      kl: 0.022145092487335205\n",
      "      policy_loss: -0.002107195556163788\n",
      "      total_loss: 80.99526977539062\n",
      "      vf_explained_var: 0.9739115834236145\n",
      "      vf_loss: 80.99737548828125\n",
      "    grad_time_ms: 1536.34\n",
      "    load_time_ms: 1.354\n",
      "    num_steps_sampled: 3410000\n",
      "    num_steps_trained: 3410000\n",
      "    sample_time_ms: 15787.046\n",
      "    update_time_ms: 4.749\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6157.99754858017\n",
      "  time_this_iter_s: 17.73707890510559\n",
      "  time_total_s: 6157.99754858017\n",
      "  timestamp: 1550622588\n",
      "  timesteps_since_restore: 3410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3410000\n",
      "  training_iteration: 341\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6157 s, 341 iter, 3410000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-30-06\n",
      "  done: false\n",
      "  episode_len_mean: 124.79\n",
      "  episode_reward_max: 199.27172352609648\n",
      "  episode_reward_mean: 152.15775316461622\n",
      "  episode_reward_min: -49.23399158368018\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 25930\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2029643058776855\n",
      "      kl: 0.011959531344473362\n",
      "      policy_loss: 0.00031393920653499663\n",
      "      total_loss: 74.53321838378906\n",
      "      vf_explained_var: 0.9737766981124878\n",
      "      vf_loss: 74.53289794921875\n",
      "    grad_time_ms: 1537.397\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 3420000\n",
      "    num_steps_trained: 3420000\n",
      "    sample_time_ms: 15835.495\n",
      "    update_time_ms: 4.761\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6175.53395485878\n",
      "  time_this_iter_s: 17.53640627861023\n",
      "  time_total_s: 6175.53395485878\n",
      "  timestamp: 1550622606\n",
      "  timesteps_since_restore: 3420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3420000\n",
      "  training_iteration: 342\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6175 s, 342 iter, 3420000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-30-23\n",
      "  done: false\n",
      "  episode_len_mean: 125.49\n",
      "  episode_reward_max: 197.45926493900546\n",
      "  episode_reward_mean: 156.49022766738915\n",
      "  episode_reward_min: -45.55431059224179\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 26008\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1393723487854004\n",
      "      kl: 0.014605477452278137\n",
      "      policy_loss: -1.3009382200834807e-05\n",
      "      total_loss: 41.090576171875\n",
      "      vf_explained_var: 0.9850683808326721\n",
      "      vf_loss: 41.09059143066406\n",
      "    grad_time_ms: 1558.586\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 3430000\n",
      "    num_steps_trained: 3430000\n",
      "    sample_time_ms: 15858.59\n",
      "    update_time_ms: 4.576\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6193.019497156143\n",
      "  time_this_iter_s: 17.48554229736328\n",
      "  time_total_s: 6193.019497156143\n",
      "  timestamp: 1550622623\n",
      "  timesteps_since_restore: 3430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3430000\n",
      "  training_iteration: 343\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6193 s, 343 iter, 3430000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-30-41\n",
      "  done: false\n",
      "  episode_len_mean: 127.78\n",
      "  episode_reward_max: 197.3310329346078\n",
      "  episode_reward_mean: 164.84641298001392\n",
      "  episode_reward_min: 127.62134297147838\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 26087\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2122533321380615\n",
      "      kl: 0.019579099491238594\n",
      "      policy_loss: -6.644563836744055e-05\n",
      "      total_loss: 13.059995651245117\n",
      "      vf_explained_var: 0.9950156807899475\n",
      "      vf_loss: 13.06006145477295\n",
      "    grad_time_ms: 1558.694\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 3440000\n",
      "    num_steps_trained: 3440000\n",
      "    sample_time_ms: 15889.915\n",
      "    update_time_ms: 4.539\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6210.403541326523\n",
      "  time_this_iter_s: 17.38404417037964\n",
      "  time_total_s: 6210.403541326523\n",
      "  timestamp: 1550622641\n",
      "  timesteps_since_restore: 3440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3440000\n",
      "  training_iteration: 344\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6210 s, 344 iter, 3440000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-30-58\n",
      "  done: false\n",
      "  episode_len_mean: 126.35\n",
      "  episode_reward_max: 198.26271431448657\n",
      "  episode_reward_mean: 159.26057748152664\n",
      "  episode_reward_min: -47.205098698929966\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 26166\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0730655193328857\n",
      "      kl: 0.026964407414197922\n",
      "      policy_loss: -0.0005561084835790098\n",
      "      total_loss: 90.5252685546875\n",
      "      vf_explained_var: 0.9692140221595764\n",
      "      vf_loss: 90.52581787109375\n",
      "    grad_time_ms: 1559.999\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 3450000\n",
      "    num_steps_trained: 3450000\n",
      "    sample_time_ms: 15882.886\n",
      "    update_time_ms: 4.536\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6227.7188510894775\n",
      "  time_this_iter_s: 17.315309762954712\n",
      "  time_total_s: 6227.7188510894775\n",
      "  timestamp: 1550622658\n",
      "  timesteps_since_restore: 3450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3450000\n",
      "  training_iteration: 345\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6227 s, 345 iter, 3450000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-31-15\n",
      "  done: false\n",
      "  episode_len_mean: 130.6\n",
      "  episode_reward_max: 202.38746105721387\n",
      "  episode_reward_mean: 160.1783150952643\n",
      "  episode_reward_min: -37.92105662881739\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 26242\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3940296173095703\n",
      "      kl: 0.024769090116024017\n",
      "      policy_loss: -0.0008580298745073378\n",
      "      total_loss: 83.90559387207031\n",
      "      vf_explained_var: 0.9703201651573181\n",
      "      vf_loss: 83.90644836425781\n",
      "    grad_time_ms: 1560.628\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 3460000\n",
      "    num_steps_trained: 3460000\n",
      "    sample_time_ms: 15918.076\n",
      "    update_time_ms: 4.523\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6245.113960027695\n",
      "  time_this_iter_s: 17.395108938217163\n",
      "  time_total_s: 6245.113960027695\n",
      "  timestamp: 1550622675\n",
      "  timesteps_since_restore: 3460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3460000\n",
      "  training_iteration: 346\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6245 s, 346 iter, 3460000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-31-33\n",
      "  done: false\n",
      "  episode_len_mean: 123.04\n",
      "  episode_reward_max: 214.13836304946693\n",
      "  episode_reward_mean: 149.27694213711715\n",
      "  episode_reward_min: -48.55021642281277\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 26323\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9473230838775635\n",
      "      kl: 0.020583903416991234\n",
      "      policy_loss: 0.0004660133854486048\n",
      "      total_loss: 108.9980697631836\n",
      "      vf_explained_var: 0.9641973972320557\n",
      "      vf_loss: 108.99759674072266\n",
      "    grad_time_ms: 1560.687\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 3470000\n",
      "    num_steps_trained: 3470000\n",
      "    sample_time_ms: 15918.866\n",
      "    update_time_ms: 4.528\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6262.600969552994\n",
      "  time_this_iter_s: 17.487009525299072\n",
      "  time_total_s: 6262.600969552994\n",
      "  timestamp: 1550622693\n",
      "  timesteps_since_restore: 3470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3470000\n",
      "  training_iteration: 347\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6262 s, 347 iter, 3470000 ts, 149 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-31-50\n",
      "  done: false\n",
      "  episode_len_mean: 128.12\n",
      "  episode_reward_max: 202.4612274639087\n",
      "  episode_reward_mean: 162.65131971207467\n",
      "  episode_reward_min: -48.55021642281277\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 26401\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.366181737124788e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0876762866973877\n",
      "      kl: 0.008426225744187832\n",
      "      policy_loss: -0.0016379893058910966\n",
      "      total_loss: 48.291500091552734\n",
      "      vf_explained_var: 0.9836442470550537\n",
      "      vf_loss: 48.29313659667969\n",
      "    grad_time_ms: 1561.441\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 3480000\n",
      "    num_steps_trained: 3480000\n",
      "    sample_time_ms: 15914.702\n",
      "    update_time_ms: 4.468\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6279.9939506053925\n",
      "  time_this_iter_s: 17.39298105239868\n",
      "  time_total_s: 6279.9939506053925\n",
      "  timestamp: 1550622710\n",
      "  timesteps_since_restore: 3480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3480000\n",
      "  training_iteration: 348\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6279 s, 348 iter, 3480000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-32-08\n",
      "  done: false\n",
      "  episode_len_mean: 128.23\n",
      "  episode_reward_max: 195.46549456618197\n",
      "  episode_reward_mean: 164.2122295506138\n",
      "  episode_reward_min: -41.06570058315994\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 26480\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.683090868562394e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.987064242362976\n",
      "      kl: 0.014863510616123676\n",
      "      policy_loss: -5.762914224760607e-05\n",
      "      total_loss: 27.948881149291992\n",
      "      vf_explained_var: 0.9901432394981384\n",
      "      vf_loss: 27.94894027709961\n",
      "    grad_time_ms: 1561.079\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 3490000\n",
      "    num_steps_trained: 3490000\n",
      "    sample_time_ms: 15916.535\n",
      "    update_time_ms: 4.514\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6297.35218167305\n",
      "  time_this_iter_s: 17.35823106765747\n",
      "  time_total_s: 6297.35218167305\n",
      "  timestamp: 1550622728\n",
      "  timesteps_since_restore: 3490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3490000\n",
      "  training_iteration: 349\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6297 s, 349 iter, 3490000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-32-25\n",
      "  done: false\n",
      "  episode_len_mean: 127.54\n",
      "  episode_reward_max: 197.10675729294812\n",
      "  episode_reward_mean: 163.043345937327\n",
      "  episode_reward_min: -41.59075136202398\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 26558\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.683090868562394e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.279958724975586\n",
      "      kl: 0.01216212473809719\n",
      "      policy_loss: 0.001585503458045423\n",
      "      total_loss: 38.416664123535156\n",
      "      vf_explained_var: 0.9848983883857727\n",
      "      vf_loss: 38.415077209472656\n",
      "    grad_time_ms: 1562.848\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 3500000\n",
      "    num_steps_trained: 3500000\n",
      "    sample_time_ms: 15848.826\n",
      "    update_time_ms: 4.727\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6314.569533586502\n",
      "  time_this_iter_s: 17.21735191345215\n",
      "  time_total_s: 6314.569533586502\n",
      "  timestamp: 1550622745\n",
      "  timesteps_since_restore: 3500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3500000\n",
      "  training_iteration: 350\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6314 s, 350 iter, 3500000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-32-42\n",
      "  done: false\n",
      "  episode_len_mean: 126.44\n",
      "  episode_reward_max: 197.10675729294812\n",
      "  episode_reward_mean: 153.11589469508286\n",
      "  episode_reward_min: -51.43604185277282\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 26638\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.683090868562394e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.076122522354126\n",
      "      kl: 0.02313743531703949\n",
      "      policy_loss: -0.006853698752820492\n",
      "      total_loss: 112.4063720703125\n",
      "      vf_explained_var: 0.9603995084762573\n",
      "      vf_loss: 112.41322326660156\n",
      "    grad_time_ms: 1562.331\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 3510000\n",
      "    num_steps_trained: 3510000\n",
      "    sample_time_ms: 15777.858\n",
      "    update_time_ms: 4.669\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6331.590455293655\n",
      "  time_this_iter_s: 17.02092170715332\n",
      "  time_total_s: 6331.590455293655\n",
      "  timestamp: 1550622762\n",
      "  timesteps_since_restore: 3510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3510000\n",
      "  training_iteration: 351\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6331 s, 351 iter, 3510000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-33-00\n",
      "  done: false\n",
      "  episode_len_mean: 125.69\n",
      "  episode_reward_max: 214.25270772983538\n",
      "  episode_reward_mean: 150.78312837583226\n",
      "  episode_reward_min: -51.43604185277282\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 26718\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.683090868562394e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0206000804901123\n",
      "      kl: 3.4770045280456543\n",
      "      policy_loss: 0.05347197502851486\n",
      "      total_loss: 172.00038146972656\n",
      "      vf_explained_var: 0.9448431134223938\n",
      "      vf_loss: 171.94688415527344\n",
      "    grad_time_ms: 1561.75\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 3520000\n",
      "    num_steps_trained: 3520000\n",
      "    sample_time_ms: 15770.157\n",
      "    update_time_ms: 4.682\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6349.048270702362\n",
      "  time_this_iter_s: 17.457815408706665\n",
      "  time_total_s: 6349.048270702362\n",
      "  timestamp: 1550622780\n",
      "  timesteps_since_restore: 3520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3520000\n",
      "  training_iteration: 352\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6349 s, 352 iter, 3520000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-33-16\n",
      "  done: false\n",
      "  episode_len_mean: 123.43\n",
      "  episode_reward_max: 206.77760882277312\n",
      "  episode_reward_mean: 152.75634558995887\n",
      "  episode_reward_min: -47.402476955500276\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 26798\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8956983089447021\n",
      "      kl: 0.012938863597810268\n",
      "      policy_loss: -0.00019129518477711827\n",
      "      total_loss: 40.18342590332031\n",
      "      vf_explained_var: 0.9853382706642151\n",
      "      vf_loss: 40.18362045288086\n",
      "    grad_time_ms: 1541.167\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 3530000\n",
      "    num_steps_trained: 3530000\n",
      "    sample_time_ms: 15694.347\n",
      "    update_time_ms: 5.007\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6365.575695991516\n",
      "  time_this_iter_s: 16.527425289154053\n",
      "  time_total_s: 6365.575695991516\n",
      "  timestamp: 1550622796\n",
      "  timesteps_since_restore: 3530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3530000\n",
      "  training_iteration: 353\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6365 s, 353 iter, 3530000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-33-34\n",
      "  done: false\n",
      "  episode_len_mean: 126.5\n",
      "  episode_reward_max: 206.77760882277312\n",
      "  episode_reward_mean: 159.71807706042014\n",
      "  episode_reward_min: -49.560603733995165\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 26877\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0982933044433594\n",
      "      kl: 0.011797493323683739\n",
      "      policy_loss: 0.000600947008933872\n",
      "      total_loss: 66.47357940673828\n",
      "      vf_explained_var: 0.974753737449646\n",
      "      vf_loss: 66.47298431396484\n",
      "    grad_time_ms: 1539.456\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 3540000\n",
      "    num_steps_trained: 3540000\n",
      "    sample_time_ms: 15719.713\n",
      "    update_time_ms: 5.089\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6383.197843790054\n",
      "  time_this_iter_s: 17.622147798538208\n",
      "  time_total_s: 6383.197843790054\n",
      "  timestamp: 1550622814\n",
      "  timesteps_since_restore: 3540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3540000\n",
      "  training_iteration: 354\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6383 s, 354 iter, 3540000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-33-51\n",
      "  done: false\n",
      "  episode_len_mean: 124.07\n",
      "  episode_reward_max: 196.3140526189663\n",
      "  episode_reward_mean: 152.01176651473057\n",
      "  episode_reward_min: -49.560603733995165\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 26957\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0373775959014893\n",
      "      kl: 0.013566093519330025\n",
      "      policy_loss: -0.0035530775785446167\n",
      "      total_loss: 69.65105438232422\n",
      "      vf_explained_var: 0.9744316339492798\n",
      "      vf_loss: 69.65460205078125\n",
      "    grad_time_ms: 1538.927\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 3550000\n",
      "    num_steps_trained: 3550000\n",
      "    sample_time_ms: 15730.62\n",
      "    update_time_ms: 5.112\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6400.61550617218\n",
      "  time_this_iter_s: 17.417662382125854\n",
      "  time_total_s: 6400.61550617218\n",
      "  timestamp: 1550622831\n",
      "  timesteps_since_restore: 3550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3550000\n",
      "  training_iteration: 355\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6400 s, 355 iter, 3550000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-34-09\n",
      "  done: false\n",
      "  episode_len_mean: 128.84\n",
      "  episode_reward_max: 195.7039955750771\n",
      "  episode_reward_mean: 164.8720985548816\n",
      "  episode_reward_min: -42.09879785776138\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 27034\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0089173316955566\n",
      "      kl: 0.012736991047859192\n",
      "      policy_loss: -0.00034140973002649844\n",
      "      total_loss: 29.440244674682617\n",
      "      vf_explained_var: 0.9895155429840088\n",
      "      vf_loss: 29.440589904785156\n",
      "    grad_time_ms: 1538.609\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 3560000\n",
      "    num_steps_trained: 3560000\n",
      "    sample_time_ms: 15748.174\n",
      "    update_time_ms: 5.05\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6418.180294275284\n",
      "  time_this_iter_s: 17.564788103103638\n",
      "  time_total_s: 6418.180294275284\n",
      "  timestamp: 1550622849\n",
      "  timesteps_since_restore: 3560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3560000\n",
      "  training_iteration: 356\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6418 s, 356 iter, 3560000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-34-25\n",
      "  done: false\n",
      "  episode_len_mean: 127.12\n",
      "  episode_reward_max: 195.2491393912547\n",
      "  episode_reward_mean: 162.84239528077632\n",
      "  episode_reward_min: -41.850183410367144\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 27112\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0470805168151855\n",
      "      kl: 0.016499897465109825\n",
      "      policy_loss: -0.001616814755834639\n",
      "      total_loss: 34.98699188232422\n",
      "      vf_explained_var: 0.9875489473342896\n",
      "      vf_loss: 34.98860168457031\n",
      "    grad_time_ms: 1539.083\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 3570000\n",
      "    num_steps_trained: 3570000\n",
      "    sample_time_ms: 15651.353\n",
      "    update_time_ms: 4.911\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6434.702030181885\n",
      "  time_this_iter_s: 16.521735906600952\n",
      "  time_total_s: 6434.702030181885\n",
      "  timestamp: 1550622865\n",
      "  timesteps_since_restore: 3570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3570000\n",
      "  training_iteration: 357\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6434 s, 357 iter, 3570000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-34-42\n",
      "  done: false\n",
      "  episode_len_mean: 129.36\n",
      "  episode_reward_max: 203.45195474726438\n",
      "  episode_reward_mean: 161.9450721173968\n",
      "  episode_reward_min: -41.389968788859875\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 27189\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2106945514678955\n",
      "      kl: 0.014648344367742538\n",
      "      policy_loss: -0.0012203489895910025\n",
      "      total_loss: 12.959477424621582\n",
      "      vf_explained_var: 0.9947304129600525\n",
      "      vf_loss: 12.960699081420898\n",
      "    grad_time_ms: 1538.72\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 3580000\n",
      "    num_steps_trained: 3580000\n",
      "    sample_time_ms: 15586.86\n",
      "    update_time_ms: 4.871\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6451.44678735733\n",
      "  time_this_iter_s: 16.744757175445557\n",
      "  time_total_s: 6451.44678735733\n",
      "  timestamp: 1550622882\n",
      "  timesteps_since_restore: 3580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3580000\n",
      "  training_iteration: 358\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6451 s, 358 iter, 3580000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-34-59\n",
      "  done: false\n",
      "  episode_len_mean: 126.97\n",
      "  episode_reward_max: 198.32590960814522\n",
      "  episode_reward_mean: 157.69139162991326\n",
      "  episode_reward_min: -48.38466823307593\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 27269\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.027522563934326\n",
      "      kl: 0.018601788207888603\n",
      "      policy_loss: -0.0033931140787899494\n",
      "      total_loss: 105.16001892089844\n",
      "      vf_explained_var: 0.9634578227996826\n",
      "      vf_loss: 105.16342163085938\n",
      "    grad_time_ms: 1540.572\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 3590000\n",
      "    num_steps_trained: 3590000\n",
      "    sample_time_ms: 15565.057\n",
      "    update_time_ms: 4.803\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6468.606830120087\n",
      "  time_this_iter_s: 17.160042762756348\n",
      "  time_total_s: 6468.606830120087\n",
      "  timestamp: 1550622899\n",
      "  timesteps_since_restore: 3590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3590000\n",
      "  training_iteration: 359\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6468 s, 359 iter, 3590000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-35-17\n",
      "  done: false\n",
      "  episode_len_mean: 125.79\n",
      "  episode_reward_max: 195.1989504154957\n",
      "  episode_reward_mean: 158.85139779274658\n",
      "  episode_reward_min: -45.93690488273554\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 27348\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9538190364837646\n",
      "      kl: 0.01257731020450592\n",
      "      policy_loss: -0.00414641946554184\n",
      "      total_loss: 52.04947280883789\n",
      "      vf_explained_var: 0.980987548828125\n",
      "      vf_loss: 52.05362319946289\n",
      "    grad_time_ms: 1537.136\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 3600000\n",
      "    num_steps_trained: 3600000\n",
      "    sample_time_ms: 15570.428\n",
      "    update_time_ms: 4.673\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6485.842734575272\n",
      "  time_this_iter_s: 17.235904455184937\n",
      "  time_total_s: 6485.842734575272\n",
      "  timestamp: 1550622917\n",
      "  timesteps_since_restore: 3600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3600000\n",
      "  training_iteration: 360\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6485 s, 360 iter, 3600000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-35-34\n",
      "  done: false\n",
      "  episode_len_mean: 128.18\n",
      "  episode_reward_max: 208.22288929383353\n",
      "  episode_reward_mean: 165.61042307459823\n",
      "  episode_reward_min: -46.03238308916588\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 27426\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.039289712905884\n",
      "      kl: 0.015488323755562305\n",
      "      policy_loss: -0.00026025265106000006\n",
      "      total_loss: 33.282649993896484\n",
      "      vf_explained_var: 0.9877120852470398\n",
      "      vf_loss: 33.28291320800781\n",
      "    grad_time_ms: 1539.454\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 3610000\n",
      "    num_steps_trained: 3610000\n",
      "    sample_time_ms: 15616.986\n",
      "    update_time_ms: 4.748\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6503.351572275162\n",
      "  time_this_iter_s: 17.508837699890137\n",
      "  time_total_s: 6503.351572275162\n",
      "  timestamp: 1550622934\n",
      "  timesteps_since_restore: 3610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3610000\n",
      "  training_iteration: 361\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6503 s, 361 iter, 3610000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-35-51\n",
      "  done: false\n",
      "  episode_len_mean: 129.34\n",
      "  episode_reward_max: 199.14568635142678\n",
      "  episode_reward_mean: 160.92339863879823\n",
      "  episode_reward_min: -46.03238308916588\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 27502\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.024636204235978e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.126988649368286\n",
      "      kl: 0.009252534247934818\n",
      "      policy_loss: -0.0009118900052271783\n",
      "      total_loss: 46.02437210083008\n",
      "      vf_explained_var: 0.985043466091156\n",
      "      vf_loss: 46.02527618408203\n",
      "    grad_time_ms: 1540.442\n",
      "    load_time_ms: 1.449\n",
      "    num_steps_sampled: 3620000\n",
      "    num_steps_trained: 3620000\n",
      "    sample_time_ms: 15585.28\n",
      "    update_time_ms: 4.733\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6520.496970415115\n",
      "  time_this_iter_s: 17.145398139953613\n",
      "  time_total_s: 6520.496970415115\n",
      "  timestamp: 1550622951\n",
      "  timesteps_since_restore: 3620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3620000\n",
      "  training_iteration: 362\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6520 s, 362 iter, 3620000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-36-09\n",
      "  done: false\n",
      "  episode_len_mean: 127.7\n",
      "  episode_reward_max: 206.59077715091792\n",
      "  episode_reward_mean: 161.51379423136532\n",
      "  episode_reward_min: -43.956978895286504\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 27581\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.012318102117989e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0949831008911133\n",
      "      kl: 0.01367450412362814\n",
      "      policy_loss: -0.0019394594710320234\n",
      "      total_loss: 47.10392379760742\n",
      "      vf_explained_var: 0.9828870892524719\n",
      "      vf_loss: 47.10586166381836\n",
      "    grad_time_ms: 1540.7\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 3630000\n",
      "    num_steps_trained: 3630000\n",
      "    sample_time_ms: 15734.228\n",
      "    update_time_ms: 4.461\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6538.514415979385\n",
      "  time_this_iter_s: 18.01744556427002\n",
      "  time_total_s: 6538.514415979385\n",
      "  timestamp: 1550622969\n",
      "  timesteps_since_restore: 3630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3630000\n",
      "  training_iteration: 363\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6538 s, 363 iter, 3630000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-36-27\n",
      "  done: false\n",
      "  episode_len_mean: 131.6\n",
      "  episode_reward_max: 193.03407835960385\n",
      "  episode_reward_mean: 162.47549687818798\n",
      "  episode_reward_min: -46.03965467509655\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 27656\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.012318102117989e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.122785806655884\n",
      "      kl: 0.015281464904546738\n",
      "      policy_loss: 0.0007311381632462144\n",
      "      total_loss: 22.676267623901367\n",
      "      vf_explained_var: 0.9923248291015625\n",
      "      vf_loss: 22.675537109375\n",
      "    grad_time_ms: 1540.735\n",
      "    load_time_ms: 1.343\n",
      "    num_steps_sampled: 3640000\n",
      "    num_steps_trained: 3640000\n",
      "    sample_time_ms: 15734.438\n",
      "    update_time_ms: 4.36\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6556.137515544891\n",
      "  time_this_iter_s: 17.62309956550598\n",
      "  time_total_s: 6556.137515544891\n",
      "  timestamp: 1550622987\n",
      "  timesteps_since_restore: 3640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3640000\n",
      "  training_iteration: 364\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6556 s, 364 iter, 3640000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-36-44\n",
      "  done: false\n",
      "  episode_len_mean: 131.21\n",
      "  episode_reward_max: 197.02378393901446\n",
      "  episode_reward_mean: 157.22557037425295\n",
      "  episode_reward_min: -46.55653155779485\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 27735\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.012318102117989e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0939292907714844\n",
      "      kl: 0.016412004828453064\n",
      "      policy_loss: -0.0013059211196377873\n",
      "      total_loss: 41.49032974243164\n",
      "      vf_explained_var: 0.9851284623146057\n",
      "      vf_loss: 41.49163818359375\n",
      "    grad_time_ms: 1540.676\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 3650000\n",
      "    num_steps_trained: 3650000\n",
      "    sample_time_ms: 15698.56\n",
      "    update_time_ms: 4.393\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6573.196613073349\n",
      "  time_this_iter_s: 17.05909752845764\n",
      "  time_total_s: 6573.196613073349\n",
      "  timestamp: 1550623004\n",
      "  timesteps_since_restore: 3650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3650000\n",
      "  training_iteration: 365\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6573 s, 365 iter, 3650000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-37-01\n",
      "  done: false\n",
      "  episode_len_mean: 126.79\n",
      "  episode_reward_max: 204.60129360028432\n",
      "  episode_reward_mean: 163.53012243445127\n",
      "  episode_reward_min: -38.68063617785376\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 27814\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.012318102117989e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9092845916748047\n",
      "      kl: 7.172131061553955\n",
      "      policy_loss: 0.025679420679807663\n",
      "      total_loss: 62.776973724365234\n",
      "      vf_explained_var: 0.9782446622848511\n",
      "      vf_loss: 62.75128936767578\n",
      "    grad_time_ms: 1542.081\n",
      "    load_time_ms: 1.417\n",
      "    num_steps_sampled: 3660000\n",
      "    num_steps_trained: 3660000\n",
      "    sample_time_ms: 15666.368\n",
      "    update_time_ms: 4.474\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6590.45720410347\n",
      "  time_this_iter_s: 17.26059103012085\n",
      "  time_total_s: 6590.45720410347\n",
      "  timestamp: 1550623021\n",
      "  timesteps_since_restore: 3660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3660000\n",
      "  training_iteration: 366\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6590 s, 366 iter, 3660000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-37-19\n",
      "  done: false\n",
      "  episode_len_mean: 131.73\n",
      "  episode_reward_max: 204.60129360028432\n",
      "  episode_reward_mean: 158.90517020052238\n",
      "  episode_reward_min: -41.4351730364384\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 27889\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.018477646215049e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.229452133178711\n",
      "      kl: 0.026022495701909065\n",
      "      policy_loss: -0.002234324114397168\n",
      "      total_loss: 102.51725769042969\n",
      "      vf_explained_var: 0.967778742313385\n",
      "      vf_loss: 102.51949310302734\n",
      "    grad_time_ms: 1542.004\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 3670000\n",
      "    num_steps_trained: 3670000\n",
      "    sample_time_ms: 15759.171\n",
      "    update_time_ms: 4.483\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6607.9068858623505\n",
      "  time_this_iter_s: 17.449681758880615\n",
      "  time_total_s: 6607.9068858623505\n",
      "  timestamp: 1550623039\n",
      "  timesteps_since_restore: 3670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3670000\n",
      "  training_iteration: 367\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6607 s, 367 iter, 3670000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-37-36\n",
      "  done: false\n",
      "  episode_len_mean: 125.11\n",
      "  episode_reward_max: 193.41855561969297\n",
      "  episode_reward_mean: 155.59187782549196\n",
      "  episode_reward_min: -47.79515295394575\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 27969\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.018477646215049e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9744937419891357\n",
      "      kl: 0.017210625112056732\n",
      "      policy_loss: 0.0008340707281604409\n",
      "      total_loss: 110.62165832519531\n",
      "      vf_explained_var: 0.9627302885055542\n",
      "      vf_loss: 110.62083435058594\n",
      "    grad_time_ms: 1546.88\n",
      "    load_time_ms: 1.414\n",
      "    num_steps_sampled: 3680000\n",
      "    num_steps_trained: 3680000\n",
      "    sample_time_ms: 15825.88\n",
      "    update_time_ms: 4.574\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6625.368475675583\n",
      "  time_this_iter_s: 17.461589813232422\n",
      "  time_total_s: 6625.368475675583\n",
      "  timestamp: 1550623056\n",
      "  timesteps_since_restore: 3680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3680000\n",
      "  training_iteration: 368\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6625 s, 368 iter, 3680000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-37-54\n",
      "  done: false\n",
      "  episode_len_mean: 124.51\n",
      "  episode_reward_max: 205.15937908392127\n",
      "  episode_reward_mean: 152.78022073765757\n",
      "  episode_reward_min: -45.94423753554278\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 28050\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.018477646215049e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8625425100326538\n",
      "      kl: 0.03666931390762329\n",
      "      policy_loss: 0.002977784024551511\n",
      "      total_loss: 175.4797821044922\n",
      "      vf_explained_var: 0.9440016150474548\n",
      "      vf_loss: 175.476806640625\n",
      "    grad_time_ms: 1561.894\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 3690000\n",
      "    num_steps_trained: 3690000\n",
      "    sample_time_ms: 15870.356\n",
      "    update_time_ms: 4.586\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6643.124614238739\n",
      "  time_this_iter_s: 17.756138563156128\n",
      "  time_total_s: 6643.124614238739\n",
      "  timestamp: 1550623074\n",
      "  timesteps_since_restore: 3690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3690000\n",
      "  training_iteration: 369\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6643 s, 369 iter, 3690000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-38-11\n",
      "  done: false\n",
      "  episode_len_mean: 127.01\n",
      "  episode_reward_max: 214.6002461365103\n",
      "  episode_reward_mean: 155.29877768211975\n",
      "  episode_reward_min: -50.78043908175856\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 28126\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.018477646215049e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1322004795074463\n",
      "      kl: 0.02330600470304489\n",
      "      policy_loss: -0.003999981563538313\n",
      "      total_loss: 71.94615173339844\n",
      "      vf_explained_var: 0.9774590730667114\n",
      "      vf_loss: 71.95014190673828\n",
      "    grad_time_ms: 1564.716\n",
      "    load_time_ms: 1.451\n",
      "    num_steps_sampled: 3700000\n",
      "    num_steps_trained: 3700000\n",
      "    sample_time_ms: 15861.838\n",
      "    update_time_ms: 4.543\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6660.302406072617\n",
      "  time_this_iter_s: 17.177791833877563\n",
      "  time_total_s: 6660.302406072617\n",
      "  timestamp: 1550623091\n",
      "  timesteps_since_restore: 3700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3700000\n",
      "  training_iteration: 370\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6660 s, 370 iter, 3700000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-38-29\n",
      "  done: false\n",
      "  episode_len_mean: 128.75\n",
      "  episode_reward_max: 209.87745863317267\n",
      "  episode_reward_mean: 161.3501068232083\n",
      "  episode_reward_min: -50.78043908175856\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 28204\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.018477646215049e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1954808235168457\n",
      "      kl: 0.013178265653550625\n",
      "      policy_loss: -0.003193990793079138\n",
      "      total_loss: 72.42241668701172\n",
      "      vf_explained_var: 0.9756004214286804\n",
      "      vf_loss: 72.42559814453125\n",
      "    grad_time_ms: 1563.983\n",
      "    load_time_ms: 1.454\n",
      "    num_steps_sampled: 3710000\n",
      "    num_steps_trained: 3710000\n",
      "    sample_time_ms: 15826.99\n",
      "    update_time_ms: 4.547\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6677.455286741257\n",
      "  time_this_iter_s: 17.152880668640137\n",
      "  time_total_s: 6677.455286741257\n",
      "  timestamp: 1550623109\n",
      "  timesteps_since_restore: 3710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3710000\n",
      "  training_iteration: 371\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6677 s, 371 iter, 3710000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-38-46\n",
      "  done: false\n",
      "  episode_len_mean: 128.7\n",
      "  episode_reward_max: 213.61536787715866\n",
      "  episode_reward_mean: 162.60188975862184\n",
      "  episode_reward_min: -47.486765670894414\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 28282\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.018477646215049e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0522868633270264\n",
      "      kl: 0.010711751878261566\n",
      "      policy_loss: -0.0001485516841057688\n",
      "      total_loss: 52.96084976196289\n",
      "      vf_explained_var: 0.9805684089660645\n",
      "      vf_loss: 52.96099853515625\n",
      "    grad_time_ms: 1562.004\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 3720000\n",
      "    num_steps_trained: 3720000\n",
      "    sample_time_ms: 15865.379\n",
      "    update_time_ms: 4.443\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6694.965304851532\n",
      "  time_this_iter_s: 17.51001811027527\n",
      "  time_total_s: 6694.965304851532\n",
      "  timestamp: 1550623126\n",
      "  timesteps_since_restore: 3720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3720000\n",
      "  training_iteration: 372\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6694 s, 372 iter, 3720000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-39-04\n",
      "  done: false\n",
      "  episode_len_mean: 125.62\n",
      "  episode_reward_max: 200.6658295010133\n",
      "  episode_reward_mean: 157.208142495677\n",
      "  episode_reward_min: -45.53622217284571\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 28362\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.018477646215049e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9342461824417114\n",
      "      kl: 0.06235041469335556\n",
      "      policy_loss: 0.0061243269592523575\n",
      "      total_loss: 120.15250396728516\n",
      "      vf_explained_var: 0.9606282114982605\n",
      "      vf_loss: 120.1463851928711\n",
      "    grad_time_ms: 1562.845\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 3730000\n",
      "    num_steps_trained: 3730000\n",
      "    sample_time_ms: 15825.876\n",
      "    update_time_ms: 4.446\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6712.593284368515\n",
      "  time_this_iter_s: 17.627979516983032\n",
      "  time_total_s: 6712.593284368515\n",
      "  timestamp: 1550623144\n",
      "  timesteps_since_restore: 3730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3730000\n",
      "  training_iteration: 373\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6712 s, 373 iter, 3730000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-39-21\n",
      "  done: false\n",
      "  episode_len_mean: 123.51\n",
      "  episode_reward_max: 202.98958362742223\n",
      "  episode_reward_mean: 152.65910847873363\n",
      "  episode_reward_min: -49.97144091099795\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 28443\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.5277164693225736e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9339282512664795\n",
      "      kl: 0.019670646637678146\n",
      "      policy_loss: -0.00018817574891727418\n",
      "      total_loss: 111.66443634033203\n",
      "      vf_explained_var: 0.9644717574119568\n",
      "      vf_loss: 111.66462707519531\n",
      "    grad_time_ms: 1565.428\n",
      "    load_time_ms: 1.379\n",
      "    num_steps_sampled: 3740000\n",
      "    num_steps_trained: 3740000\n",
      "    sample_time_ms: 15789.81\n",
      "    update_time_ms: 4.467\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6729.879214763641\n",
      "  time_this_iter_s: 17.285930395126343\n",
      "  time_total_s: 6729.879214763641\n",
      "  timestamp: 1550623161\n",
      "  timesteps_since_restore: 3740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3740000\n",
      "  training_iteration: 374\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6729 s, 374 iter, 3740000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-39-38\n",
      "  done: false\n",
      "  episode_len_mean: 123.23\n",
      "  episode_reward_max: 204.8680660557924\n",
      "  episode_reward_mean: 150.0024548680306\n",
      "  episode_reward_min: -43.25462672379938\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 28524\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.5277164693225736e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0380563735961914\n",
      "      kl: 0.018390247598290443\n",
      "      policy_loss: 0.0013126824051141739\n",
      "      total_loss: 106.26486206054688\n",
      "      vf_explained_var: 0.9646319150924683\n",
      "      vf_loss: 106.2635498046875\n",
      "    grad_time_ms: 1565.939\n",
      "    load_time_ms: 1.412\n",
      "    num_steps_sampled: 3750000\n",
      "    num_steps_trained: 3750000\n",
      "    sample_time_ms: 15786.171\n",
      "    update_time_ms: 4.453\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6746.907917737961\n",
      "  time_this_iter_s: 17.028702974319458\n",
      "  time_total_s: 6746.907917737961\n",
      "  timestamp: 1550623178\n",
      "  timesteps_since_restore: 3750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3750000\n",
      "  training_iteration: 375\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6746 s, 375 iter, 3750000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-39-55\n",
      "  done: false\n",
      "  episode_len_mean: 124.44\n",
      "  episode_reward_max: 201.46169156072173\n",
      "  episode_reward_mean: 157.48055098237342\n",
      "  episode_reward_min: -42.7756841781706\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 28603\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.5277164693225736e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9702380895614624\n",
      "      kl: 0.021387644112110138\n",
      "      policy_loss: 0.0017861590022221208\n",
      "      total_loss: 14.123513221740723\n",
      "      vf_explained_var: 0.9945696592330933\n",
      "      vf_loss: 14.121728897094727\n",
      "    grad_time_ms: 1566.314\n",
      "    load_time_ms: 1.364\n",
      "    num_steps_sampled: 3760000\n",
      "    num_steps_trained: 3760000\n",
      "    sample_time_ms: 15765.191\n",
      "    update_time_ms: 4.391\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6763.9593732357025\n",
      "  time_this_iter_s: 17.0514554977417\n",
      "  time_total_s: 6763.9593732357025\n",
      "  timestamp: 1550623195\n",
      "  timesteps_since_restore: 3760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3760000\n",
      "  training_iteration: 376\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6763 s, 376 iter, 3760000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-40-13\n",
      "  done: false\n",
      "  episode_len_mean: 126.52\n",
      "  episode_reward_max: 202.93660613175211\n",
      "  episode_reward_mean: 161.49744356967912\n",
      "  episode_reward_min: -52.80939969036839\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 28681\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.5277164693225736e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.091681957244873\n",
      "      kl: 0.018133562058210373\n",
      "      policy_loss: -0.00038810327532701194\n",
      "      total_loss: 64.01446533203125\n",
      "      vf_explained_var: 0.9755964279174805\n",
      "      vf_loss: 64.01486206054688\n",
      "    grad_time_ms: 1566.491\n",
      "    load_time_ms: 1.332\n",
      "    num_steps_sampled: 3770000\n",
      "    num_steps_trained: 3770000\n",
      "    sample_time_ms: 15739.515\n",
      "    update_time_ms: 4.542\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6781.152769327164\n",
      "  time_this_iter_s: 17.19339609146118\n",
      "  time_total_s: 6781.152769327164\n",
      "  timestamp: 1550623213\n",
      "  timesteps_since_restore: 3770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3770000\n",
      "  training_iteration: 377\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6781 s, 377 iter, 3770000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-40-29\n",
      "  done: false\n",
      "  episode_len_mean: 126.92\n",
      "  episode_reward_max: 199.93383935211907\n",
      "  episode_reward_mean: 156.05258821115928\n",
      "  episode_reward_min: -47.204343783383315\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 28760\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.5277164693225736e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.07832932472229\n",
      "      kl: 0.0837412029504776\n",
      "      policy_loss: 0.0055049629881978035\n",
      "      total_loss: 165.54051208496094\n",
      "      vf_explained_var: 0.94451904296875\n",
      "      vf_loss: 165.5349884033203\n",
      "    grad_time_ms: 1561.386\n",
      "    load_time_ms: 1.416\n",
      "    num_steps_sampled: 3780000\n",
      "    num_steps_trained: 3780000\n",
      "    sample_time_ms: 15669.937\n",
      "    update_time_ms: 4.444\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6797.868012666702\n",
      "  time_this_iter_s: 16.715243339538574\n",
      "  time_total_s: 6797.868012666702\n",
      "  timestamp: 1550623229\n",
      "  timesteps_since_restore: 3780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3780000\n",
      "  training_iteration: 378\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6797 s, 378 iter, 3780000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-40-47\n",
      "  done: false\n",
      "  episode_len_mean: 132.51\n",
      "  episode_reward_max: 202.02877484129195\n",
      "  episode_reward_mean: 161.82684563653157\n",
      "  episode_reward_min: -45.63702728370629\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 28834\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.23813533782959\n",
      "      kl: 0.013194079510867596\n",
      "      policy_loss: -0.0007495160098187625\n",
      "      total_loss: 24.78982162475586\n",
      "      vf_explained_var: 0.9917538166046143\n",
      "      vf_loss: 24.790573120117188\n",
      "    grad_time_ms: 1544.565\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 3790000\n",
      "    num_steps_trained: 3790000\n",
      "    sample_time_ms: 15644.456\n",
      "    update_time_ms: 4.586\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6815.201671361923\n",
      "  time_this_iter_s: 17.333658695220947\n",
      "  time_total_s: 6815.201671361923\n",
      "  timestamp: 1550623247\n",
      "  timesteps_since_restore: 3790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3790000\n",
      "  training_iteration: 379\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6815 s, 379 iter, 3790000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-41-04\n",
      "  done: false\n",
      "  episode_len_mean: 130.6\n",
      "  episode_reward_max: 202.02877484129195\n",
      "  episode_reward_mean: 159.97605804313906\n",
      "  episode_reward_min: -46.72700900724621\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 28914\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8949729204177856\n",
      "      kl: 0.0192301906645298\n",
      "      policy_loss: -0.0018142767949029803\n",
      "      total_loss: 82.67952728271484\n",
      "      vf_explained_var: 0.9710494875907898\n",
      "      vf_loss: 82.68134307861328\n",
      "    grad_time_ms: 1543.766\n",
      "    load_time_ms: 1.338\n",
      "    num_steps_sampled: 3800000\n",
      "    num_steps_trained: 3800000\n",
      "    sample_time_ms: 15704.018\n",
      "    update_time_ms: 4.601\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6832.965336561203\n",
      "  time_this_iter_s: 17.763665199279785\n",
      "  time_total_s: 6832.965336561203\n",
      "  timestamp: 1550623264\n",
      "  timesteps_since_restore: 3800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3800000\n",
      "  training_iteration: 380\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6832 s, 380 iter, 3800000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-41-22\n",
      "  done: false\n",
      "  episode_len_mean: 125.56\n",
      "  episode_reward_max: 202.3556591647097\n",
      "  episode_reward_mean: 154.9028191138454\n",
      "  episode_reward_min: -47.901468392350885\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 28993\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9835410118103027\n",
      "      kl: 0.012239147908985615\n",
      "      policy_loss: -0.0010212988127022982\n",
      "      total_loss: 114.29312896728516\n",
      "      vf_explained_var: 0.9604043364524841\n",
      "      vf_loss: 114.29414367675781\n",
      "    grad_time_ms: 1546.049\n",
      "    load_time_ms: 1.334\n",
      "    num_steps_sampled: 3810000\n",
      "    num_steps_trained: 3810000\n",
      "    sample_time_ms: 15695.941\n",
      "    update_time_ms: 4.606\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6850.059454202652\n",
      "  time_this_iter_s: 17.094117641448975\n",
      "  time_total_s: 6850.059454202652\n",
      "  timestamp: 1550623282\n",
      "  timesteps_since_restore: 3810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3810000\n",
      "  training_iteration: 381\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6850 s, 381 iter, 3810000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-41-39\n",
      "  done: false\n",
      "  episode_len_mean: 127.62\n",
      "  episode_reward_max: 201.0725021471482\n",
      "  episode_reward_mean: 150.28893014865096\n",
      "  episode_reward_min: -47.901468392350885\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 29072\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.166532516479492\n",
      "      kl: 0.022412307560443878\n",
      "      policy_loss: -0.000979532254859805\n",
      "      total_loss: 111.14200592041016\n",
      "      vf_explained_var: 0.9653335213661194\n",
      "      vf_loss: 111.14299011230469\n",
      "    grad_time_ms: 1547.472\n",
      "    load_time_ms: 1.313\n",
      "    num_steps_sampled: 3820000\n",
      "    num_steps_trained: 3820000\n",
      "    sample_time_ms: 15696.028\n",
      "    update_time_ms: 4.633\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6867.58379983902\n",
      "  time_this_iter_s: 17.524345636367798\n",
      "  time_total_s: 6867.58379983902\n",
      "  timestamp: 1550623299\n",
      "  timesteps_since_restore: 3820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3820000\n",
      "  training_iteration: 382\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6867 s, 382 iter, 3820000 ts, 150 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-41-57\n",
      "  done: false\n",
      "  episode_len_mean: 130.01\n",
      "  episode_reward_max: 201.0725021471482\n",
      "  episode_reward_mean: 154.651405483895\n",
      "  episode_reward_min: -49.480915654118704\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 29150\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.205010175704956\n",
      "      kl: 0.026134977117180824\n",
      "      policy_loss: 0.0022963332012295723\n",
      "      total_loss: 107.5341567993164\n",
      "      vf_explained_var: 0.9634312391281128\n",
      "      vf_loss: 107.5318603515625\n",
      "    grad_time_ms: 1546.711\n",
      "    load_time_ms: 1.319\n",
      "    num_steps_sampled: 3830000\n",
      "    num_steps_trained: 3830000\n",
      "    sample_time_ms: 15674.522\n",
      "    update_time_ms: 4.771\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6884.991998910904\n",
      "  time_this_iter_s: 17.408199071884155\n",
      "  time_total_s: 6884.991998910904\n",
      "  timestamp: 1550623317\n",
      "  timesteps_since_restore: 3830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3830000\n",
      "  training_iteration: 383\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6884 s, 383 iter, 3830000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-42-14\n",
      "  done: false\n",
      "  episode_len_mean: 131.82\n",
      "  episode_reward_max: 207.02409071585922\n",
      "  episode_reward_mean: 166.3761207474754\n",
      "  episode_reward_min: 105.8343718005438\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 29226\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1084272861480713\n",
      "      kl: 0.022115346044301987\n",
      "      policy_loss: 0.004288874566555023\n",
      "      total_loss: 12.39199161529541\n",
      "      vf_explained_var: 0.9952787756919861\n",
      "      vf_loss: 12.387701988220215\n",
      "    grad_time_ms: 1544.902\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 3840000\n",
      "    num_steps_trained: 3840000\n",
      "    sample_time_ms: 15639.517\n",
      "    update_time_ms: 4.841\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6901.912797689438\n",
      "  time_this_iter_s: 16.920798778533936\n",
      "  time_total_s: 6901.912797689438\n",
      "  timestamp: 1550623334\n",
      "  timesteps_since_restore: 3840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3840000\n",
      "  training_iteration: 384\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6901 s, 384 iter, 3840000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-42-31\n",
      "  done: false\n",
      "  episode_len_mean: 123.9\n",
      "  episode_reward_max: 203.1816453817162\n",
      "  episode_reward_mean: 156.61995642167068\n",
      "  episode_reward_min: -48.40425499683559\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 29307\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.862052083015442\n",
      "      kl: 0.013838442042469978\n",
      "      policy_loss: -0.0005919700488448143\n",
      "      total_loss: 114.00824737548828\n",
      "      vf_explained_var: 0.9622330069541931\n",
      "      vf_loss: 114.00882720947266\n",
      "    grad_time_ms: 1543.825\n",
      "    load_time_ms: 1.294\n",
      "    num_steps_sampled: 3850000\n",
      "    num_steps_trained: 3850000\n",
      "    sample_time_ms: 15669.018\n",
      "    update_time_ms: 4.878\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6919.224049806595\n",
      "  time_this_iter_s: 17.311252117156982\n",
      "  time_total_s: 6919.224049806595\n",
      "  timestamp: 1550623351\n",
      "  timesteps_since_restore: 3850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3850000\n",
      "  training_iteration: 385\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6919 s, 385 iter, 3850000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-42-49\n",
      "  done: false\n",
      "  episode_len_mean: 127.61\n",
      "  episode_reward_max: 198.2049375921488\n",
      "  episode_reward_mean: 160.99801597682188\n",
      "  episode_reward_min: -42.94396683662244\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 29386\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.073591470718384\n",
      "      kl: 0.015389022417366505\n",
      "      policy_loss: -0.0005542664439417422\n",
      "      total_loss: 50.08263397216797\n",
      "      vf_explained_var: 0.983003556728363\n",
      "      vf_loss: 50.08319091796875\n",
      "    grad_time_ms: 1541.337\n",
      "    load_time_ms: 1.285\n",
      "    num_steps_sampled: 3860000\n",
      "    num_steps_trained: 3860000\n",
      "    sample_time_ms: 15737.961\n",
      "    update_time_ms: 4.826\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6936.938526391983\n",
      "  time_this_iter_s: 17.714476585388184\n",
      "  time_total_s: 6936.938526391983\n",
      "  timestamp: 1550623369\n",
      "  timesteps_since_restore: 3860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3860000\n",
      "  training_iteration: 386\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6936 s, 386 iter, 3860000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-43-07\n",
      "  done: false\n",
      "  episode_len_mean: 127.14\n",
      "  episode_reward_max: 197.48595133187732\n",
      "  episode_reward_mean: 164.7882612030101\n",
      "  episode_reward_min: -41.41683207644094\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 29464\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9559824466705322\n",
      "      kl: 0.015650128945708275\n",
      "      policy_loss: -0.002382845850661397\n",
      "      total_loss: 36.49464416503906\n",
      "      vf_explained_var: 0.9864860773086548\n",
      "      vf_loss: 36.49702835083008\n",
      "    grad_time_ms: 1540.181\n",
      "    load_time_ms: 1.352\n",
      "    num_steps_sampled: 3870000\n",
      "    num_steps_trained: 3870000\n",
      "    sample_time_ms: 15805.127\n",
      "    update_time_ms: 4.671\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6954.7930908203125\n",
      "  time_this_iter_s: 17.854564428329468\n",
      "  time_total_s: 6954.7930908203125\n",
      "  timestamp: 1550623387\n",
      "  timesteps_since_restore: 3870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3870000\n",
      "  training_iteration: 387\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6954 s, 387 iter, 3870000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-43-24\n",
      "  done: false\n",
      "  episode_len_mean: 127.24\n",
      "  episode_reward_max: 208.80684456480034\n",
      "  episode_reward_mean: 162.19116708677873\n",
      "  episode_reward_min: -45.32947560997291\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 29542\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.140342950820923\n",
      "      kl: 0.01887883059680462\n",
      "      policy_loss: -0.003980452194809914\n",
      "      total_loss: 52.138282775878906\n",
      "      vf_explained_var: 0.9804584980010986\n",
      "      vf_loss: 52.142269134521484\n",
      "    grad_time_ms: 1555.509\n",
      "    load_time_ms: 1.339\n",
      "    num_steps_sampled: 3880000\n",
      "    num_steps_trained: 3880000\n",
      "    sample_time_ms: 15845.348\n",
      "    update_time_ms: 4.827\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6972.064821481705\n",
      "  time_this_iter_s: 17.271730661392212\n",
      "  time_total_s: 6972.064821481705\n",
      "  timestamp: 1550623404\n",
      "  timesteps_since_restore: 3880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3880000\n",
      "  training_iteration: 388\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6972 s, 388 iter, 3880000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-43-42\n",
      "  done: false\n",
      "  episode_len_mean: 127.7\n",
      "  episode_reward_max: 206.95135481522811\n",
      "  episode_reward_mean: 163.77193183246308\n",
      "  episode_reward_min: -45.625587960871144\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 29621\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.089301824569702\n",
      "      kl: 0.014982214197516441\n",
      "      policy_loss: 0.000606744724791497\n",
      "      total_loss: 23.939556121826172\n",
      "      vf_explained_var: 0.9907986521720886\n",
      "      vf_loss: 23.938953399658203\n",
      "    grad_time_ms: 1557.238\n",
      "    load_time_ms: 1.339\n",
      "    num_steps_sampled: 3890000\n",
      "    num_steps_trained: 3890000\n",
      "    sample_time_ms: 15872.883\n",
      "    update_time_ms: 4.718\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 6989.689322710037\n",
      "  time_this_iter_s: 17.62450122833252\n",
      "  time_total_s: 6989.689322710037\n",
      "  timestamp: 1550623422\n",
      "  timesteps_since_restore: 3890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3890000\n",
      "  training_iteration: 389\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 6989 s, 389 iter, 3890000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-43-59\n",
      "  done: false\n",
      "  episode_len_mean: 126.59\n",
      "  episode_reward_max: 201.06428642320165\n",
      "  episode_reward_mean: 155.79307800170014\n",
      "  episode_reward_min: -45.6070601420827\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 29701\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1542375087738037\n",
      "      kl: 0.014040229842066765\n",
      "      policy_loss: 0.0010832615662366152\n",
      "      total_loss: 112.84437561035156\n",
      "      vf_explained_var: 0.9637713432312012\n",
      "      vf_loss: 112.84331512451172\n",
      "    grad_time_ms: 1557.72\n",
      "    load_time_ms: 1.337\n",
      "    num_steps_sampled: 3900000\n",
      "    num_steps_trained: 3900000\n",
      "    sample_time_ms: 15825.064\n",
      "    update_time_ms: 4.718\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7006.9807097911835\n",
      "  time_this_iter_s: 17.29138708114624\n",
      "  time_total_s: 7006.9807097911835\n",
      "  timestamp: 1550623439\n",
      "  timesteps_since_restore: 3900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3900000\n",
      "  training_iteration: 390\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7006 s, 390 iter, 3900000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-44-16\n",
      "  done: false\n",
      "  episode_len_mean: 122.6\n",
      "  episode_reward_max: 205.8108257790752\n",
      "  episode_reward_mean: 145.66957535385274\n",
      "  episode_reward_min: -48.69803917348973\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 29782\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9552620649337769\n",
      "      kl: 0.015859097242355347\n",
      "      policy_loss: -0.0037052761763334274\n",
      "      total_loss: 117.1297836303711\n",
      "      vf_explained_var: 0.9630101323127747\n",
      "      vf_loss: 117.13349914550781\n",
      "    grad_time_ms: 1555.857\n",
      "    load_time_ms: 1.362\n",
      "    num_steps_sampled: 3910000\n",
      "    num_steps_trained: 3910000\n",
      "    sample_time_ms: 15820.615\n",
      "    update_time_ms: 4.621\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7024.012064218521\n",
      "  time_this_iter_s: 17.031354427337646\n",
      "  time_total_s: 7024.012064218521\n",
      "  timestamp: 1550623456\n",
      "  timesteps_since_restore: 3910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3910000\n",
      "  training_iteration: 391\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7024 s, 391 iter, 3910000 ts, 146 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-44-34\n",
      "  done: false\n",
      "  episode_len_mean: 127.45\n",
      "  episode_reward_max: 202.56843006138763\n",
      "  episode_reward_mean: 159.1578968623233\n",
      "  episode_reward_min: -41.944092163355045\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 29860\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.149492025375366\n",
      "      kl: 0.014447638764977455\n",
      "      policy_loss: -0.0022275238297879696\n",
      "      total_loss: 79.7731704711914\n",
      "      vf_explained_var: 0.9712263345718384\n",
      "      vf_loss: 79.77539825439453\n",
      "    grad_time_ms: 1557.162\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 3920000\n",
      "    num_steps_trained: 3920000\n",
      "    sample_time_ms: 15872.906\n",
      "    update_time_ms: 4.714\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7042.072650194168\n",
      "  time_this_iter_s: 18.060585975646973\n",
      "  time_total_s: 7042.072650194168\n",
      "  timestamp: 1550623474\n",
      "  timesteps_since_restore: 3920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3920000\n",
      "  training_iteration: 392\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7042 s, 392 iter, 3920000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-44-51\n",
      "  done: false\n",
      "  episode_len_mean: 132.19\n",
      "  episode_reward_max: 197.65302966077752\n",
      "  episode_reward_mean: 163.6020906239569\n",
      "  episode_reward_min: -48.039625179649576\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 29935\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2535409927368164\n",
      "      kl: 0.010812008753418922\n",
      "      policy_loss: -0.0016606327844783664\n",
      "      total_loss: 55.54356384277344\n",
      "      vf_explained_var: 0.9818419218063354\n",
      "      vf_loss: 55.545223236083984\n",
      "    grad_time_ms: 1556.471\n",
      "    load_time_ms: 1.357\n",
      "    num_steps_sampled: 3930000\n",
      "    num_steps_trained: 3930000\n",
      "    sample_time_ms: 15822.053\n",
      "    update_time_ms: 4.556\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7058.962380409241\n",
      "  time_this_iter_s: 16.889730215072632\n",
      "  time_total_s: 7058.962380409241\n",
      "  timestamp: 1550623491\n",
      "  timesteps_since_restore: 3930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3930000\n",
      "  training_iteration: 393\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7058 s, 393 iter, 3930000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-45-08\n",
      "  done: false\n",
      "  episode_len_mean: 128.0\n",
      "  episode_reward_max: 199.52690178952602\n",
      "  episode_reward_mean: 162.20848432481714\n",
      "  episode_reward_min: -50.963861049401885\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 30014\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.058892011642456\n",
      "      kl: 0.014614910818636417\n",
      "      policy_loss: -0.001892165862955153\n",
      "      total_loss: 55.14424514770508\n",
      "      vf_explained_var: 0.9800326824188232\n",
      "      vf_loss: 55.14614486694336\n",
      "    grad_time_ms: 1557.897\n",
      "    load_time_ms: 1.325\n",
      "    num_steps_sampled: 3940000\n",
      "    num_steps_trained: 3940000\n",
      "    sample_time_ms: 15861.235\n",
      "    update_time_ms: 4.603\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7076.289409637451\n",
      "  time_this_iter_s: 17.32702922821045\n",
      "  time_total_s: 7076.289409637451\n",
      "  timestamp: 1550623508\n",
      "  timesteps_since_restore: 3940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3940000\n",
      "  training_iteration: 394\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7076 s, 394 iter, 3940000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-45-26\n",
      "  done: false\n",
      "  episode_len_mean: 125.54\n",
      "  episode_reward_max: 201.0464108754504\n",
      "  episode_reward_mean: 153.43662528777634\n",
      "  episode_reward_min: -50.963861049401885\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 30093\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1215693950653076\n",
      "      kl: 0.02010379731655121\n",
      "      policy_loss: -0.0004762434109579772\n",
      "      total_loss: 97.17243957519531\n",
      "      vf_explained_var: 0.9674018621444702\n",
      "      vf_loss: 97.17292022705078\n",
      "    grad_time_ms: 1558.233\n",
      "    load_time_ms: 1.319\n",
      "    num_steps_sampled: 3950000\n",
      "    num_steps_trained: 3950000\n",
      "    sample_time_ms: 15881.134\n",
      "    update_time_ms: 4.469\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7093.801978588104\n",
      "  time_this_iter_s: 17.512568950653076\n",
      "  time_total_s: 7093.801978588104\n",
      "  timestamp: 1550623526\n",
      "  timesteps_since_restore: 3950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3950000\n",
      "  training_iteration: 395\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7093 s, 395 iter, 3950000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-45-43\n",
      "  done: false\n",
      "  episode_len_mean: 126.07\n",
      "  episode_reward_max: 209.84016292756144\n",
      "  episode_reward_mean: 157.98292448543708\n",
      "  episode_reward_min: -47.94747428640281\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 30172\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.019695997238159\n",
      "      kl: 0.0132835004478693\n",
      "      policy_loss: -0.00014853276661597192\n",
      "      total_loss: 57.47543716430664\n",
      "      vf_explained_var: 0.9789940118789673\n",
      "      vf_loss: 57.4755744934082\n",
      "    grad_time_ms: 1561.203\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 3960000\n",
      "    num_steps_trained: 3960000\n",
      "    sample_time_ms: 15842.035\n",
      "    update_time_ms: 4.607\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7111.158219575882\n",
      "  time_this_iter_s: 17.35624098777771\n",
      "  time_total_s: 7111.158219575882\n",
      "  timestamp: 1550623543\n",
      "  timesteps_since_restore: 3960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3960000\n",
      "  training_iteration: 396\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7111 s, 396 iter, 3960000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-46-01\n",
      "  done: false\n",
      "  episode_len_mean: 127.0\n",
      "  episode_reward_max: 202.05304917693138\n",
      "  episode_reward_mean: 160.8554859601278\n",
      "  episode_reward_min: -49.36154406554628\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 30251\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.025904893875122\n",
      "      kl: 0.022262679412961006\n",
      "      policy_loss: -0.001726984977722168\n",
      "      total_loss: 50.79647445678711\n",
      "      vf_explained_var: 0.9818546772003174\n",
      "      vf_loss: 50.79820251464844\n",
      "    grad_time_ms: 1563.757\n",
      "    load_time_ms: 1.288\n",
      "    num_steps_sampled: 3970000\n",
      "    num_steps_trained: 3970000\n",
      "    sample_time_ms: 15781.85\n",
      "    update_time_ms: 4.589\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7128.434284925461\n",
      "  time_this_iter_s: 17.276065349578857\n",
      "  time_total_s: 7128.434284925461\n",
      "  timestamp: 1550623561\n",
      "  timesteps_since_restore: 3970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3970000\n",
      "  training_iteration: 397\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7128 s, 397 iter, 3970000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-46-18\n",
      "  done: false\n",
      "  episode_len_mean: 127.0\n",
      "  episode_reward_max: 201.54877990056394\n",
      "  episode_reward_mean: 161.07865987563304\n",
      "  episode_reward_min: -49.36154406554628\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 30329\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.170775890350342\n",
      "      kl: 0.02172882668673992\n",
      "      policy_loss: -0.0010556373745203018\n",
      "      total_loss: 20.489526748657227\n",
      "      vf_explained_var: 0.9925854802131653\n",
      "      vf_loss: 20.490583419799805\n",
      "    grad_time_ms: 1549.59\n",
      "    load_time_ms: 1.218\n",
      "    num_steps_sampled: 3980000\n",
      "    num_steps_trained: 3980000\n",
      "    sample_time_ms: 15805.849\n",
      "    update_time_ms: 4.506\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7145.803904771805\n",
      "  time_this_iter_s: 17.369619846343994\n",
      "  time_total_s: 7145.803904771805\n",
      "  timestamp: 1550623578\n",
      "  timesteps_since_restore: 3980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3980000\n",
      "  training_iteration: 398\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7145 s, 398 iter, 3980000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 126.09\n",
      "  episode_reward_max: 196.57985804960282\n",
      "  episode_reward_mean: 155.09006952271974\n",
      "  episode_reward_min: -46.66230958287078\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 30409\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0432417392730713\n",
      "      kl: 0.019030913710594177\n",
      "      policy_loss: -0.005340782459825277\n",
      "      total_loss: 130.63536071777344\n",
      "      vf_explained_var: 0.9588710069656372\n",
      "      vf_loss: 130.64071655273438\n",
      "    grad_time_ms: 1548.063\n",
      "    load_time_ms: 1.218\n",
      "    num_steps_sampled: 3990000\n",
      "    num_steps_trained: 3990000\n",
      "    sample_time_ms: 15778.115\n",
      "    update_time_ms: 4.625\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7163.135994911194\n",
      "  time_this_iter_s: 17.332090139389038\n",
      "  time_total_s: 7163.135994911194\n",
      "  timestamp: 1550623595\n",
      "  timesteps_since_restore: 3990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3990000\n",
      "  training_iteration: 399\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7163 s, 399 iter, 3990000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-46-54\n",
      "  done: false\n",
      "  episode_len_mean: 129.34\n",
      "  episode_reward_max: 193.81796245763775\n",
      "  episode_reward_mean: 163.19337216222922\n",
      "  episode_reward_min: -39.74135166450891\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 30485\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1453819274902344\n",
      "      kl: 0.020002445206046104\n",
      "      policy_loss: -0.002562261652201414\n",
      "      total_loss: 34.713863372802734\n",
      "      vf_explained_var: 0.9878794550895691\n",
      "      vf_loss: 34.716426849365234\n",
      "    grad_time_ms: 1571.983\n",
      "    load_time_ms: 1.214\n",
      "    num_steps_sampled: 4000000\n",
      "    num_steps_trained: 4000000\n",
      "    sample_time_ms: 15838.818\n",
      "    update_time_ms: 4.779\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7181.278085231781\n",
      "  time_this_iter_s: 18.142090320587158\n",
      "  time_total_s: 7181.278085231781\n",
      "  timestamp: 1550623614\n",
      "  timesteps_since_restore: 4000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4000000\n",
      "  training_iteration: 400\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7181 s, 400 iter, 4000000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-47-11\n",
      "  done: false\n",
      "  episode_len_mean: 133.39\n",
      "  episode_reward_max: 211.8740640351973\n",
      "  episode_reward_mean: 162.19736696827434\n",
      "  episode_reward_min: -47.87421735265467\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 30559\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3772690296173096\n",
      "      kl: 0.014166081324219704\n",
      "      policy_loss: 0.0008009107550606132\n",
      "      total_loss: 32.49944305419922\n",
      "      vf_explained_var: 0.9884417653083801\n",
      "      vf_loss: 32.49863815307617\n",
      "    grad_time_ms: 1570.791\n",
      "    load_time_ms: 1.194\n",
      "    num_steps_sampled: 4010000\n",
      "    num_steps_trained: 4010000\n",
      "    sample_time_ms: 15920.878\n",
      "    update_time_ms: 4.887\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7199.119281053543\n",
      "  time_this_iter_s: 17.841195821762085\n",
      "  time_total_s: 7199.119281053543\n",
      "  timestamp: 1550623631\n",
      "  timesteps_since_restore: 4010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4010000\n",
      "  training_iteration: 401\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7199 s, 401 iter, 4010000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-47-29\n",
      "  done: false\n",
      "  episode_len_mean: 131.33\n",
      "  episode_reward_max: 211.8740640351973\n",
      "  episode_reward_mean: 160.7782683088626\n",
      "  episode_reward_min: -47.87421735265467\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 30638\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0567195415496826\n",
      "      kl: 0.028736015781760216\n",
      "      policy_loss: 0.003190267365425825\n",
      "      total_loss: 25.84464454650879\n",
      "      vf_explained_var: 0.9906083345413208\n",
      "      vf_loss: 25.841453552246094\n",
      "    grad_time_ms: 1569.664\n",
      "    load_time_ms: 1.184\n",
      "    num_steps_sampled: 4020000\n",
      "    num_steps_trained: 4020000\n",
      "    sample_time_ms: 15852.1\n",
      "    update_time_ms: 4.88\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7216.481188774109\n",
      "  time_this_iter_s: 17.361907720565796\n",
      "  time_total_s: 7216.481188774109\n",
      "  timestamp: 1550623649\n",
      "  timesteps_since_restore: 4020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4020000\n",
      "  training_iteration: 402\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7216 s, 402 iter, 4020000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-47-47\n",
      "  done: false\n",
      "  episode_len_mean: 127.54\n",
      "  episode_reward_max: 209.4434750926968\n",
      "  episode_reward_mean: 159.86614216019942\n",
      "  episode_reward_min: -45.32230117799032\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 30716\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1099183559417725\n",
      "      kl: 0.01527462713420391\n",
      "      policy_loss: -0.001451812102459371\n",
      "      total_loss: 48.149444580078125\n",
      "      vf_explained_var: 0.9828180074691772\n",
      "      vf_loss: 48.150901794433594\n",
      "    grad_time_ms: 1568.301\n",
      "    load_time_ms: 1.214\n",
      "    num_steps_sampled: 4030000\n",
      "    num_steps_trained: 4030000\n",
      "    sample_time_ms: 15932.838\n",
      "    update_time_ms: 4.836\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7234.164779424667\n",
      "  time_this_iter_s: 17.68359065055847\n",
      "  time_total_s: 7234.164779424667\n",
      "  timestamp: 1550623667\n",
      "  timesteps_since_restore: 4030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4030000\n",
      "  training_iteration: 403\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7234 s, 403 iter, 4030000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-48-04\n",
      "  done: false\n",
      "  episode_len_mean: 127.31\n",
      "  episode_reward_max: 210.61974306566873\n",
      "  episode_reward_mean: 155.66844077153777\n",
      "  episode_reward_min: -46.06521712287815\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 30794\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.095057964324951\n",
      "      kl: 0.027391882613301277\n",
      "      policy_loss: -0.0010711620561778545\n",
      "      total_loss: 110.55755615234375\n",
      "      vf_explained_var: 0.9620537161827087\n",
      "      vf_loss: 110.55863189697266\n",
      "    grad_time_ms: 1566.695\n",
      "    load_time_ms: 1.25\n",
      "    num_steps_sampled: 4040000\n",
      "    num_steps_trained: 4040000\n",
      "    sample_time_ms: 15963.261\n",
      "    update_time_ms: 4.72\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7251.778654098511\n",
      "  time_this_iter_s: 17.613874673843384\n",
      "  time_total_s: 7251.778654098511\n",
      "  timestamp: 1550623684\n",
      "  timesteps_since_restore: 4040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4040000\n",
      "  training_iteration: 404\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7251 s, 404 iter, 4040000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-48-21\n",
      "  done: false\n",
      "  episode_len_mean: 132.73\n",
      "  episode_reward_max: 209.14077220399776\n",
      "  episode_reward_mean: 164.48346767770957\n",
      "  episode_reward_min: -44.266289050331196\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 30868\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.3107380867004395\n",
      "      kl: 0.01437859795987606\n",
      "      policy_loss: -0.0005127246840856969\n",
      "      total_loss: 18.941055297851562\n",
      "      vf_explained_var: 0.9936966300010681\n",
      "      vf_loss: 18.94156837463379\n",
      "    grad_time_ms: 1566.487\n",
      "    load_time_ms: 1.288\n",
      "    num_steps_sampled: 4050000\n",
      "    num_steps_trained: 4050000\n",
      "    sample_time_ms: 15941.49\n",
      "    update_time_ms: 4.747\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7269.072862148285\n",
      "  time_this_iter_s: 17.29420804977417\n",
      "  time_total_s: 7269.072862148285\n",
      "  timestamp: 1550623701\n",
      "  timesteps_since_restore: 4050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4050000\n",
      "  training_iteration: 405\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7269 s, 405 iter, 4050000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-48-39\n",
      "  done: false\n",
      "  episode_len_mean: 129.5\n",
      "  episode_reward_max: 205.5712190904829\n",
      "  episode_reward_mean: 165.40471809837948\n",
      "  episode_reward_min: -48.26182283962717\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 30945\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0967769622802734\n",
      "      kl: 0.020912038162350655\n",
      "      policy_loss: 0.000169553910382092\n",
      "      total_loss: 50.06142807006836\n",
      "      vf_explained_var: 0.9816389083862305\n",
      "      vf_loss: 50.061256408691406\n",
      "    grad_time_ms: 1565.213\n",
      "    load_time_ms: 1.261\n",
      "    num_steps_sampled: 4060000\n",
      "    num_steps_trained: 4060000\n",
      "    sample_time_ms: 15987.606\n",
      "    update_time_ms: 4.549\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7286.87567615509\n",
      "  time_this_iter_s: 17.80281400680542\n",
      "  time_total_s: 7286.87567615509\n",
      "  timestamp: 1550623719\n",
      "  timesteps_since_restore: 4060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4060000\n",
      "  training_iteration: 406\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7286 s, 406 iter, 4060000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-48-57\n",
      "  done: false\n",
      "  episode_len_mean: 128.94\n",
      "  episode_reward_max: 207.24017550892145\n",
      "  episode_reward_mean: 165.01528707186185\n",
      "  episode_reward_min: -41.93606569536841\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 31023\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.064305543899536\n",
      "      kl: 0.0209780503064394\n",
      "      policy_loss: -0.0025748086627572775\n",
      "      total_loss: 55.93972396850586\n",
      "      vf_explained_var: 0.97965008020401\n",
      "      vf_loss: 55.94228744506836\n",
      "    grad_time_ms: 1562.315\n",
      "    load_time_ms: 1.3\n",
      "    num_steps_sampled: 4070000\n",
      "    num_steps_trained: 4070000\n",
      "    sample_time_ms: 15990.6\n",
      "    update_time_ms: 4.715\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7304.156809329987\n",
      "  time_this_iter_s: 17.28113317489624\n",
      "  time_total_s: 7304.156809329987\n",
      "  timestamp: 1550623737\n",
      "  timesteps_since_restore: 4070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4070000\n",
      "  training_iteration: 407\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7304 s, 407 iter, 4070000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-49-14\n",
      "  done: false\n",
      "  episode_len_mean: 125.65\n",
      "  episode_reward_max: 212.4779897591853\n",
      "  episode_reward_mean: 156.08293339430182\n",
      "  episode_reward_min: -46.113357554420375\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 31103\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.038170576095581\n",
      "      kl: 0.02226574532687664\n",
      "      policy_loss: 0.0005891277105547488\n",
      "      total_loss: 69.02793884277344\n",
      "      vf_explained_var: 0.9766107201576233\n",
      "      vf_loss: 69.02735900878906\n",
      "    grad_time_ms: 1563.37\n",
      "    load_time_ms: 1.32\n",
      "    num_steps_sampled: 4080000\n",
      "    num_steps_trained: 4080000\n",
      "    sample_time_ms: 16017.393\n",
      "    update_time_ms: 4.679\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7321.805296421051\n",
      "  time_this_iter_s: 17.648487091064453\n",
      "  time_total_s: 7321.805296421051\n",
      "  timestamp: 1550623754\n",
      "  timesteps_since_restore: 4080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4080000\n",
      "  training_iteration: 408\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7321 s, 408 iter, 4080000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-49-32\n",
      "  done: false\n",
      "  episode_len_mean: 126.84\n",
      "  episode_reward_max: 205.4569468675273\n",
      "  episode_reward_mean: 154.9293793727273\n",
      "  episode_reward_min: -47.44924731419815\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 31181\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.125791549682617\n",
      "      kl: 0.01358964666724205\n",
      "      policy_loss: -0.0007620147080160677\n",
      "      total_loss: 45.45014572143555\n",
      "      vf_explained_var: 0.9846511483192444\n",
      "      vf_loss: 45.45090103149414\n",
      "    grad_time_ms: 1566.084\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 4090000\n",
      "    num_steps_trained: 4090000\n",
      "    sample_time_ms: 16061.417\n",
      "    update_time_ms: 4.686\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7339.607985019684\n",
      "  time_this_iter_s: 17.802688598632812\n",
      "  time_total_s: 7339.607985019684\n",
      "  timestamp: 1550623772\n",
      "  timesteps_since_restore: 4090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4090000\n",
      "  training_iteration: 409\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7339 s, 409 iter, 4090000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-49-50\n",
      "  done: false\n",
      "  episode_len_mean: 126.85\n",
      "  episode_reward_max: 199.8975439500986\n",
      "  episode_reward_mean: 161.42316831659636\n",
      "  episode_reward_min: -47.44924731419815\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 31260\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.074453592300415\n",
      "      kl: 0.025527771562337875\n",
      "      policy_loss: 0.0031742495484650135\n",
      "      total_loss: 58.93829345703125\n",
      "      vf_explained_var: 0.9781994819641113\n",
      "      vf_loss: 58.93512725830078\n",
      "    grad_time_ms: 1543.193\n",
      "    load_time_ms: 1.396\n",
      "    num_steps_sampled: 4100000\n",
      "    num_steps_trained: 4100000\n",
      "    sample_time_ms: 16011.755\n",
      "    update_time_ms: 4.528\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7357.0203404426575\n",
      "  time_this_iter_s: 17.412355422973633\n",
      "  time_total_s: 7357.0203404426575\n",
      "  timestamp: 1550623790\n",
      "  timesteps_since_restore: 4100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4100000\n",
      "  training_iteration: 410\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7357 s, 410 iter, 4100000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-50-07\n",
      "  done: false\n",
      "  episode_len_mean: 126.47\n",
      "  episode_reward_max: 206.94885509232486\n",
      "  episode_reward_mean: 163.38142065226054\n",
      "  episode_reward_min: -41.87474365812719\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 31339\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0509674549102783\n",
      "      kl: 0.034088246524333954\n",
      "      policy_loss: 0.00679442286491394\n",
      "      total_loss: 64.83415985107422\n",
      "      vf_explained_var: 0.9758326411247253\n",
      "      vf_loss: 64.82736206054688\n",
      "    grad_time_ms: 1544.163\n",
      "    load_time_ms: 1.398\n",
      "    num_steps_sampled: 4110000\n",
      "    num_steps_trained: 4110000\n",
      "    sample_time_ms: 15986.932\n",
      "    update_time_ms: 4.551\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7374.622937917709\n",
      "  time_this_iter_s: 17.60259747505188\n",
      "  time_total_s: 7374.622937917709\n",
      "  timestamp: 1550623807\n",
      "  timesteps_since_restore: 4110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4110000\n",
      "  training_iteration: 411\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7374 s, 411 iter, 4110000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-50-24\n",
      "  done: false\n",
      "  episode_len_mean: 128.32\n",
      "  episode_reward_max: 206.56167254146965\n",
      "  episode_reward_mean: 161.23378672120612\n",
      "  episode_reward_min: -45.637967085484206\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 31417\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.791574901199087e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2042219638824463\n",
      "      kl: 1.6439831256866455\n",
      "      policy_loss: 0.023892344906926155\n",
      "      total_loss: 124.59074401855469\n",
      "      vf_explained_var: 0.958812415599823\n",
      "      vf_loss: 124.56684112548828\n",
      "    grad_time_ms: 1551.193\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 4120000\n",
      "    num_steps_trained: 4120000\n",
      "    sample_time_ms: 15956.665\n",
      "    update_time_ms: 4.525\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7391.755380392075\n",
      "  time_this_iter_s: 17.132442474365234\n",
      "  time_total_s: 7391.755380392075\n",
      "  timestamp: 1550623824\n",
      "  timesteps_since_restore: 4120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4120000\n",
      "  training_iteration: 412\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7391 s, 412 iter, 4120000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-50-42\n",
      "  done: false\n",
      "  episode_len_mean: 127.78\n",
      "  episode_reward_max: 202.59526423372256\n",
      "  episode_reward_mean: 159.40073387930153\n",
      "  episode_reward_min: -45.92654253026048\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 31497\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.018736392952044e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.056401014328003\n",
      "      kl: 0.016394158825278282\n",
      "      policy_loss: -0.0004422301717568189\n",
      "      total_loss: 61.41844940185547\n",
      "      vf_explained_var: 0.9788446426391602\n",
      "      vf_loss: 61.41888427734375\n",
      "    grad_time_ms: 1553.363\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 4130000\n",
      "    num_steps_trained: 4130000\n",
      "    sample_time_ms: 15896.174\n",
      "    update_time_ms: 4.51\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7408.8594563007355\n",
      "  time_this_iter_s: 17.10407590866089\n",
      "  time_total_s: 7408.8594563007355\n",
      "  timestamp: 1550623842\n",
      "  timesteps_since_restore: 4130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4130000\n",
      "  training_iteration: 413\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7408 s, 413 iter, 4130000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-50-59\n",
      "  done: false\n",
      "  episode_len_mean: 130.05\n",
      "  episode_reward_max: 202.68241870403287\n",
      "  episode_reward_mean: 162.80676380155774\n",
      "  episode_reward_min: -43.45083974419843\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 31574\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.018736392952044e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1063528060913086\n",
      "      kl: 0.020557302981615067\n",
      "      policy_loss: -0.001581792370416224\n",
      "      total_loss: 52.060150146484375\n",
      "      vf_explained_var: 0.9816676378250122\n",
      "      vf_loss: 52.061729431152344\n",
      "    grad_time_ms: 1554.404\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 4140000\n",
      "    num_steps_trained: 4140000\n",
      "    sample_time_ms: 15843.269\n",
      "    update_time_ms: 4.552\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7425.955803155899\n",
      "  time_this_iter_s: 17.096346855163574\n",
      "  time_total_s: 7425.955803155899\n",
      "  timestamp: 1550623859\n",
      "  timesteps_since_restore: 4140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4140000\n",
      "  training_iteration: 414\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7425 s, 414 iter, 4140000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-51-16\n",
      "  done: false\n",
      "  episode_len_mean: 126.9\n",
      "  episode_reward_max: 207.77308241919707\n",
      "  episode_reward_mean: 159.54735054274093\n",
      "  episode_reward_min: -43.45083974419843\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 31653\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.018736392952044e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9984052181243896\n",
      "      kl: 0.016247374936938286\n",
      "      policy_loss: -0.0001316949346801266\n",
      "      total_loss: 47.47523498535156\n",
      "      vf_explained_var: 0.9830937385559082\n",
      "      vf_loss: 47.47536849975586\n",
      "    grad_time_ms: 1554.546\n",
      "    load_time_ms: 1.442\n",
      "    num_steps_sampled: 4150000\n",
      "    num_steps_trained: 4150000\n",
      "    sample_time_ms: 15854.299\n",
      "    update_time_ms: 4.616\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7443.361660242081\n",
      "  time_this_iter_s: 17.40585708618164\n",
      "  time_total_s: 7443.361660242081\n",
      "  timestamp: 1550623876\n",
      "  timesteps_since_restore: 4150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4150000\n",
      "  training_iteration: 415\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7443 s, 415 iter, 4150000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-51-33\n",
      "  done: false\n",
      "  episode_len_mean: 128.06\n",
      "  episode_reward_max: 206.67525888079473\n",
      "  episode_reward_mean: 167.2423743621058\n",
      "  episode_reward_min: -40.30672297368542\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 31731\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.018736392952044e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0025224685668945\n",
      "      kl: 0.011115183122456074\n",
      "      policy_loss: -0.0011836079647764564\n",
      "      total_loss: 29.11732292175293\n",
      "      vf_explained_var: 0.9890816807746887\n",
      "      vf_loss: 29.118505477905273\n",
      "    grad_time_ms: 1555.206\n",
      "    load_time_ms: 1.5\n",
      "    num_steps_sampled: 4160000\n",
      "    num_steps_trained: 4160000\n",
      "    sample_time_ms: 15803.283\n",
      "    update_time_ms: 4.755\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7460.664809703827\n",
      "  time_this_iter_s: 17.303149461746216\n",
      "  time_total_s: 7460.664809703827\n",
      "  timestamp: 1550623893\n",
      "  timesteps_since_restore: 4160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4160000\n",
      "  training_iteration: 416\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7460 s, 416 iter, 4160000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-51-51\n",
      "  done: false\n",
      "  episode_len_mean: 127.84\n",
      "  episode_reward_max: 204.1611050641771\n",
      "  episode_reward_mean: 165.26570590643487\n",
      "  episode_reward_min: -42.27726500872341\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 31809\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.018736392952044e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0168490409851074\n",
      "      kl: 0.0652482882142067\n",
      "      policy_loss: 0.016884809359908104\n",
      "      total_loss: 92.00303649902344\n",
      "      vf_explained_var: 0.9689578413963318\n",
      "      vf_loss: 91.98613739013672\n",
      "    grad_time_ms: 1555.957\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 4170000\n",
      "    num_steps_trained: 4170000\n",
      "    sample_time_ms: 15828.799\n",
      "    update_time_ms: 4.679\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7478.207672595978\n",
      "  time_this_iter_s: 17.54286289215088\n",
      "  time_total_s: 7478.207672595978\n",
      "  timestamp: 1550623911\n",
      "  timesteps_since_restore: 4170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4170000\n",
      "  training_iteration: 417\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7478 s, 417 iter, 4170000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-52-08\n",
      "  done: false\n",
      "  episode_len_mean: 126.09\n",
      "  episode_reward_max: 209.5421677113759\n",
      "  episode_reward_mean: 161.59692955782668\n",
      "  episode_reward_min: -43.03068125365986\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 31889\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5281041949976135e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.946362853050232\n",
      "      kl: 0.013929657638072968\n",
      "      policy_loss: -0.002142725046724081\n",
      "      total_loss: 56.0666389465332\n",
      "      vf_explained_var: 0.9824708104133606\n",
      "      vf_loss: 56.06877899169922\n",
      "    grad_time_ms: 1555.727\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 4180000\n",
      "    num_steps_trained: 4180000\n",
      "    sample_time_ms: 15785.021\n",
      "    update_time_ms: 4.569\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7495.4141964912415\n",
      "  time_this_iter_s: 17.206523895263672\n",
      "  time_total_s: 7495.4141964912415\n",
      "  timestamp: 1550623928\n",
      "  timesteps_since_restore: 4180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4180000\n",
      "  training_iteration: 418\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7495 s, 418 iter, 4180000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-52-26\n",
      "  done: false\n",
      "  episode_len_mean: 130.87\n",
      "  episode_reward_max: 200.041067845603\n",
      "  episode_reward_mean: 165.72117023074458\n",
      "  episode_reward_min: 126.58858450037425\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 31965\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5281041949976135e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2596657276153564\n",
      "      kl: 0.01906818524003029\n",
      "      policy_loss: 0.00228968751616776\n",
      "      total_loss: 24.14910316467285\n",
      "      vf_explained_var: 0.9910944700241089\n",
      "      vf_loss: 24.146814346313477\n",
      "    grad_time_ms: 1553.451\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 4190000\n",
      "    num_steps_trained: 4190000\n",
      "    sample_time_ms: 15759.374\n",
      "    update_time_ms: 4.457\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7512.935980319977\n",
      "  time_this_iter_s: 17.52178382873535\n",
      "  time_total_s: 7512.935980319977\n",
      "  timestamp: 1550623946\n",
      "  timesteps_since_restore: 4190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4190000\n",
      "  training_iteration: 419\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7512 s, 419 iter, 4190000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-52-43\n",
      "  done: false\n",
      "  episode_len_mean: 128.22\n",
      "  episode_reward_max: 200.041067845603\n",
      "  episode_reward_mean: 162.0697931044929\n",
      "  episode_reward_min: -39.399171235242676\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 32043\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5281041949976135e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0002005100250244\n",
      "      kl: 0.01927882805466652\n",
      "      policy_loss: 0.00042219823808409274\n",
      "      total_loss: 24.690101623535156\n",
      "      vf_explained_var: 0.9906678795814514\n",
      "      vf_loss: 24.689682006835938\n",
      "    grad_time_ms: 1552.495\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 4200000\n",
      "    num_steps_trained: 4200000\n",
      "    sample_time_ms: 15735.24\n",
      "    update_time_ms: 4.502\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7530.09695315361\n",
      "  time_this_iter_s: 17.160972833633423\n",
      "  time_total_s: 7530.09695315361\n",
      "  timestamp: 1550623963\n",
      "  timesteps_since_restore: 4200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4200000\n",
      "  training_iteration: 420\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7530 s, 420 iter, 4200000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-53-00\n",
      "  done: false\n",
      "  episode_len_mean: 126.19\n",
      "  episode_reward_max: 208.24055114595018\n",
      "  episode_reward_mean: 160.3326004524101\n",
      "  episode_reward_min: -48.09544757377391\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 32122\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5281041949976135e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9354333877563477\n",
      "      kl: 0.021245483309030533\n",
      "      policy_loss: -0.0038790064863860607\n",
      "      total_loss: 65.60319519042969\n",
      "      vf_explained_var: 0.9772969484329224\n",
      "      vf_loss: 65.6070785522461\n",
      "    grad_time_ms: 1554.047\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 4210000\n",
      "    num_steps_trained: 4210000\n",
      "    sample_time_ms: 15713.169\n",
      "    update_time_ms: 4.339\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7547.492862701416\n",
      "  time_this_iter_s: 17.395909547805786\n",
      "  time_total_s: 7547.492862701416\n",
      "  timestamp: 1550623980\n",
      "  timesteps_since_restore: 4210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4210000\n",
      "  training_iteration: 421\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7547 s, 421 iter, 4210000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-53-18\n",
      "  done: false\n",
      "  episode_len_mean: 130.76\n",
      "  episode_reward_max: 198.35365707508416\n",
      "  episode_reward_mean: 168.7943053087214\n",
      "  episode_reward_min: 126.16863515530487\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 32198\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5281041949976135e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1123671531677246\n",
      "      kl: 0.03183545544743538\n",
      "      policy_loss: 0.007472582161426544\n",
      "      total_loss: 11.669594764709473\n",
      "      vf_explained_var: 0.9955886602401733\n",
      "      vf_loss: 11.66212272644043\n",
      "    grad_time_ms: 1547.796\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 4220000\n",
      "    num_steps_trained: 4220000\n",
      "    sample_time_ms: 15758.615\n",
      "    update_time_ms: 4.308\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7565.014163970947\n",
      "  time_this_iter_s: 17.52130126953125\n",
      "  time_total_s: 7565.014163970947\n",
      "  timestamp: 1550623998\n",
      "  timesteps_since_restore: 4220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4220000\n",
      "  training_iteration: 422\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7565 s, 422 iter, 4220000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-53-36\n",
      "  done: false\n",
      "  episode_len_mean: 127.76\n",
      "  episode_reward_max: 202.43974682098568\n",
      "  episode_reward_mean: 162.0859776732329\n",
      "  episode_reward_min: -45.0737109346555\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 32277\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5281041949976135e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7958914041519165\n",
      "      kl: 0.01763584278523922\n",
      "      policy_loss: -0.0004342550819274038\n",
      "      total_loss: 81.21427917480469\n",
      "      vf_explained_var: 0.9753870964050293\n",
      "      vf_loss: 81.2147216796875\n",
      "    grad_time_ms: 1549.061\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 4230000\n",
      "    num_steps_trained: 4230000\n",
      "    sample_time_ms: 15818.727\n",
      "    update_time_ms: 4.412\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7582.7303149700165\n",
      "  time_this_iter_s: 17.716150999069214\n",
      "  time_total_s: 7582.7303149700165\n",
      "  timestamp: 1550624016\n",
      "  timesteps_since_restore: 4230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4230000\n",
      "  training_iteration: 423\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7582 s, 423 iter, 4230000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-53-53\n",
      "  done: false\n",
      "  episode_len_mean: 126.25\n",
      "  episode_reward_max: 203.97283096050862\n",
      "  episode_reward_mean: 156.5558355148323\n",
      "  episode_reward_min: -45.77858026207673\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 32356\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5281041949976135e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.053292989730835\n",
      "      kl: 0.020458294078707695\n",
      "      policy_loss: 0.0011388156563043594\n",
      "      total_loss: 79.55485534667969\n",
      "      vf_explained_var: 0.9741934537887573\n",
      "      vf_loss: 79.55371856689453\n",
      "    grad_time_ms: 1568.375\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 4240000\n",
      "    num_steps_trained: 4240000\n",
      "    sample_time_ms: 15846.843\n",
      "    update_time_ms: 4.386\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7600.3005027771\n",
      "  time_this_iter_s: 17.57018780708313\n",
      "  time_total_s: 7600.3005027771\n",
      "  timestamp: 1550624033\n",
      "  timesteps_since_restore: 4240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4240000\n",
      "  training_iteration: 424\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7600 s, 424 iter, 4240000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-54-10\n",
      "  done: false\n",
      "  episode_len_mean: 131.07\n",
      "  episode_reward_max: 212.19339312229414\n",
      "  episode_reward_mean: 161.28827554025577\n",
      "  episode_reward_min: -45.77858026207673\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 32432\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5281041949976135e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.2553460597991943\n",
      "      kl: 0.009735740721225739\n",
      "      policy_loss: 0.00047604204155504704\n",
      "      total_loss: 21.451824188232422\n",
      "      vf_explained_var: 0.9918745756149292\n",
      "      vf_loss: 21.45134925842285\n",
      "    grad_time_ms: 1567.997\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 4250000\n",
      "    num_steps_trained: 4250000\n",
      "    sample_time_ms: 15805.201\n",
      "    update_time_ms: 4.298\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7617.285758972168\n",
      "  time_this_iter_s: 16.98525619506836\n",
      "  time_total_s: 7617.285758972168\n",
      "  timestamp: 1550624050\n",
      "  timesteps_since_restore: 4250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4250000\n",
      "  training_iteration: 425\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7617 s, 425 iter, 4250000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-54-28\n",
      "  done: false\n",
      "  episode_len_mean: 127.11\n",
      "  episode_reward_max: 198.41468357656268\n",
      "  episode_reward_mean: 160.3815853117886\n",
      "  episode_reward_min: -47.00208597136017\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 32512\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.640520974988067e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.842678189277649\n",
      "      kl: 0.01287191454321146\n",
      "      policy_loss: -0.0017565599409863353\n",
      "      total_loss: 87.30662536621094\n",
      "      vf_explained_var: 0.9734501838684082\n",
      "      vf_loss: 87.30838012695312\n",
      "    grad_time_ms: 1567.101\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 4260000\n",
      "    num_steps_trained: 4260000\n",
      "    sample_time_ms: 15798.063\n",
      "    update_time_ms: 4.317\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7634.506366491318\n",
      "  time_this_iter_s: 17.22060751914978\n",
      "  time_total_s: 7634.506366491318\n",
      "  timestamp: 1550624068\n",
      "  timesteps_since_restore: 4260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4260000\n",
      "  training_iteration: 426\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7634 s, 426 iter, 4260000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-54-45\n",
      "  done: false\n",
      "  episode_len_mean: 125.42\n",
      "  episode_reward_max: 209.92050215092928\n",
      "  episode_reward_mean: 152.54139491389623\n",
      "  episode_reward_min: -49.32430899674348\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 32592\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.640520974988067e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.93547785282135\n",
      "      kl: 0.03550414741039276\n",
      "      policy_loss: 0.0013383495388552547\n",
      "      total_loss: 93.68511199951172\n",
      "      vf_explained_var: 0.969539225101471\n",
      "      vf_loss: 93.68377685546875\n",
      "    grad_time_ms: 1566.949\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 4270000\n",
      "    num_steps_trained: 4270000\n",
      "    sample_time_ms: 15772.796\n",
      "    update_time_ms: 4.33\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7651.792948722839\n",
      "  time_this_iter_s: 17.286582231521606\n",
      "  time_total_s: 7651.792948722839\n",
      "  timestamp: 1550624085\n",
      "  timesteps_since_restore: 4270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4270000\n",
      "  training_iteration: 427\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7651 s, 427 iter, 4270000 ts, 153 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-55-02\n",
      "  done: false\n",
      "  episode_len_mean: 127.11\n",
      "  episode_reward_max: 209.92050215092928\n",
      "  episode_reward_mean: 163.7519024404937\n",
      "  episode_reward_min: -49.32430899674348\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 32670\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.640520974988067e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.885066270828247\n",
      "      kl: 0.012493479996919632\n",
      "      policy_loss: -0.002388323424383998\n",
      "      total_loss: 16.21894645690918\n",
      "      vf_explained_var: 0.9940664768218994\n",
      "      vf_loss: 16.22133445739746\n",
      "    grad_time_ms: 1566.92\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 4280000\n",
      "    num_steps_trained: 4280000\n",
      "    sample_time_ms: 15793.395\n",
      "    update_time_ms: 4.534\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7669.208953619003\n",
      "  time_this_iter_s: 17.41600489616394\n",
      "  time_total_s: 7669.208953619003\n",
      "  timestamp: 1550624102\n",
      "  timesteps_since_restore: 4280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4280000\n",
      "  training_iteration: 428\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7669 s, 428 iter, 4280000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-55-19\n",
      "  done: false\n",
      "  episode_len_mean: 128.39\n",
      "  episode_reward_max: 206.10281627647356\n",
      "  episode_reward_mean: 161.26361058413397\n",
      "  episode_reward_min: -43.82460420586094\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 32747\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.640520974988067e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9749376773834229\n",
      "      kl: 0.020269164815545082\n",
      "      policy_loss: -0.001682856003753841\n",
      "      total_loss: 67.55623626708984\n",
      "      vf_explained_var: 0.9776157736778259\n",
      "      vf_loss: 67.55791473388672\n",
      "    grad_time_ms: 1568.317\n",
      "    load_time_ms: 1.367\n",
      "    num_steps_sampled: 4290000\n",
      "    num_steps_trained: 4290000\n",
      "    sample_time_ms: 15725.917\n",
      "    update_time_ms: 4.571\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7686.068251371384\n",
      "  time_this_iter_s: 16.85929775238037\n",
      "  time_total_s: 7686.068251371384\n",
      "  timestamp: 1550624119\n",
      "  timesteps_since_restore: 4290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4290000\n",
      "  training_iteration: 429\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7686 s, 429 iter, 4290000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-55-36\n",
      "  done: false\n",
      "  episode_len_mean: 127.96\n",
      "  episode_reward_max: 198.72569632943305\n",
      "  episode_reward_mean: 163.64903519353228\n",
      "  episode_reward_min: -42.70044364964608\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 32825\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.640520974988067e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.05366587638855\n",
      "      kl: 0.009476241655647755\n",
      "      policy_loss: 0.00013627522275783122\n",
      "      total_loss: 14.051834106445312\n",
      "      vf_explained_var: 0.9947123527526855\n",
      "      vf_loss: 14.051698684692383\n",
      "    grad_time_ms: 1566.493\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 4300000\n",
      "    num_steps_trained: 4300000\n",
      "    sample_time_ms: 15719.747\n",
      "    update_time_ms: 4.543\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7703.148920297623\n",
      "  time_this_iter_s: 17.080668926239014\n",
      "  time_total_s: 7703.148920297623\n",
      "  timestamp: 1550624136\n",
      "  timesteps_since_restore: 4300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4300000\n",
      "  training_iteration: 430\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7703 s, 430 iter, 4300000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-55-54\n",
      "  done: false\n",
      "  episode_len_mean: 128.43\n",
      "  episode_reward_max: 206.30649309863554\n",
      "  episode_reward_mean: 154.8170327800748\n",
      "  episode_reward_min: -48.49367114754003\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 32904\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.16745924949646\n",
      "      kl: 0.01601566933095455\n",
      "      policy_loss: -0.002752890344709158\n",
      "      total_loss: 57.46440505981445\n",
      "      vf_explained_var: 0.9810051321983337\n",
      "      vf_loss: 57.467159271240234\n",
      "    grad_time_ms: 1581.045\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 4310000\n",
      "    num_steps_trained: 4310000\n",
      "    sample_time_ms: 15754.012\n",
      "    update_time_ms: 4.607\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7721.034943342209\n",
      "  time_this_iter_s: 17.88602304458618\n",
      "  time_total_s: 7721.034943342209\n",
      "  timestamp: 1550624154\n",
      "  timesteps_since_restore: 4310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4310000\n",
      "  training_iteration: 431\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7721 s, 431 iter, 4310000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-56-12\n",
      "  done: false\n",
      "  episode_len_mean: 126.71\n",
      "  episode_reward_max: 203.77833785382228\n",
      "  episode_reward_mean: 163.09537588396248\n",
      "  episode_reward_min: -48.73278261322785\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 32983\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8499832153320312\n",
      "      kl: 0.013251657597720623\n",
      "      policy_loss: -0.0016232621856033802\n",
      "      total_loss: 63.16666030883789\n",
      "      vf_explained_var: 0.9780439734458923\n",
      "      vf_loss: 63.168270111083984\n",
      "    grad_time_ms: 1578.668\n",
      "    load_time_ms: 1.417\n",
      "    num_steps_sampled: 4320000\n",
      "    num_steps_trained: 4320000\n",
      "    sample_time_ms: 15745.414\n",
      "    update_time_ms: 4.595\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7738.446410179138\n",
      "  time_this_iter_s: 17.41146683692932\n",
      "  time_total_s: 7738.446410179138\n",
      "  timestamp: 1550624172\n",
      "  timesteps_since_restore: 4320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4320000\n",
      "  training_iteration: 432\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7738 s, 432 iter, 4320000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 126.71\n",
      "  episode_reward_max: 201.19509556402676\n",
      "  episode_reward_mean: 159.66662720637117\n",
      "  episode_reward_min: -49.732695043972214\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 33061\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9128555059432983\n",
      "      kl: 0.01538717932999134\n",
      "      policy_loss: 0.0020875963382422924\n",
      "      total_loss: 42.89795684814453\n",
      "      vf_explained_var: 0.9862135648727417\n",
      "      vf_loss: 42.89586639404297\n",
      "    grad_time_ms: 1576.839\n",
      "    load_time_ms: 1.357\n",
      "    num_steps_sampled: 4330000\n",
      "    num_steps_trained: 4330000\n",
      "    sample_time_ms: 15702.973\n",
      "    update_time_ms: 4.483\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7755.71826338768\n",
      "  time_this_iter_s: 17.27185320854187\n",
      "  time_total_s: 7755.71826338768\n",
      "  timestamp: 1550624189\n",
      "  timesteps_since_restore: 4330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4330000\n",
      "  training_iteration: 433\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7755 s, 433 iter, 4330000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-56-46\n",
      "  done: false\n",
      "  episode_len_mean: 126.46\n",
      "  episode_reward_max: 198.18100516166143\n",
      "  episode_reward_mean: 159.4024029050997\n",
      "  episode_reward_min: -47.993611016338406\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 33141\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8649951219558716\n",
      "      kl: 0.015831131488084793\n",
      "      policy_loss: -0.001030515180900693\n",
      "      total_loss: 56.18157958984375\n",
      "      vf_explained_var: 0.9813460111618042\n",
      "      vf_loss: 56.18260955810547\n",
      "    grad_time_ms: 1556.318\n",
      "    load_time_ms: 1.301\n",
      "    num_steps_sampled: 4340000\n",
      "    num_steps_trained: 4340000\n",
      "    sample_time_ms: 15685.993\n",
      "    update_time_ms: 4.532\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7772.9125893116\n",
      "  time_this_iter_s: 17.194325923919678\n",
      "  time_total_s: 7772.9125893116\n",
      "  timestamp: 1550624206\n",
      "  timesteps_since_restore: 4340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4340000\n",
      "  training_iteration: 434\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7772 s, 434 iter, 4340000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-57-04\n",
      "  done: false\n",
      "  episode_len_mean: 128.74\n",
      "  episode_reward_max: 213.63159081590643\n",
      "  episode_reward_mean: 167.20159395008045\n",
      "  episode_reward_min: -47.993611016338406\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 33218\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9405337572097778\n",
      "      kl: 0.016519909724593163\n",
      "      policy_loss: -0.0021618292666971684\n",
      "      total_loss: 12.90101146697998\n",
      "      vf_explained_var: 0.9953637719154358\n",
      "      vf_loss: 12.903172492980957\n",
      "    grad_time_ms: 1558.414\n",
      "    load_time_ms: 1.23\n",
      "    num_steps_sampled: 4350000\n",
      "    num_steps_trained: 4350000\n",
      "    sample_time_ms: 15733.762\n",
      "    update_time_ms: 4.524\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7790.394986867905\n",
      "  time_this_iter_s: 17.48239755630493\n",
      "  time_total_s: 7790.394986867905\n",
      "  timestamp: 1550624224\n",
      "  timesteps_since_restore: 4350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4350000\n",
      "  training_iteration: 435\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7790 s, 435 iter, 4350000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-57-21\n",
      "  done: false\n",
      "  episode_len_mean: 128.41\n",
      "  episode_reward_max: 210.01409762153534\n",
      "  episode_reward_mean: 167.3474064112248\n",
      "  episode_reward_min: -48.91232043180134\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 33296\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8593618869781494\n",
      "      kl: 0.015692412853240967\n",
      "      policy_loss: -0.0014883781550452113\n",
      "      total_loss: 21.0821475982666\n",
      "      vf_explained_var: 0.9922091960906982\n",
      "      vf_loss: 21.083635330200195\n",
      "    grad_time_ms: 1557.594\n",
      "    load_time_ms: 1.299\n",
      "    num_steps_sampled: 4360000\n",
      "    num_steps_trained: 4360000\n",
      "    sample_time_ms: 15766.513\n",
      "    update_time_ms: 4.561\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7807.936898946762\n",
      "  time_this_iter_s: 17.541912078857422\n",
      "  time_total_s: 7807.936898946762\n",
      "  timestamp: 1550624241\n",
      "  timesteps_since_restore: 4360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4360000\n",
      "  training_iteration: 436\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7807 s, 436 iter, 4360000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-57-39\n",
      "  done: false\n",
      "  episode_len_mean: 127.8\n",
      "  episode_reward_max: 215.85329343732644\n",
      "  episode_reward_mean: 158.3773817013318\n",
      "  episode_reward_min: -48.91232043180134\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 33373\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9468331336975098\n",
      "      kl: 0.025993509218096733\n",
      "      policy_loss: -0.0003347566816955805\n",
      "      total_loss: 107.6513671875\n",
      "      vf_explained_var: 0.9658845663070679\n",
      "      vf_loss: 107.65170288085938\n",
      "    grad_time_ms: 1562.047\n",
      "    load_time_ms: 1.297\n",
      "    num_steps_sampled: 4370000\n",
      "    num_steps_trained: 4370000\n",
      "    sample_time_ms: 15772.872\n",
      "    update_time_ms: 4.68\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7825.33252954483\n",
      "  time_this_iter_s: 17.395630598068237\n",
      "  time_total_s: 7825.33252954483\n",
      "  timestamp: 1550624259\n",
      "  timesteps_since_restore: 4370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4370000\n",
      "  training_iteration: 437\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7825 s, 437 iter, 4370000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 129.09\n",
      "  episode_reward_max: 204.1029350427117\n",
      "  episode_reward_mean: 161.91171960825525\n",
      "  episode_reward_min: -41.813902645122866\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 33452\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.975122094154358\n",
      "      kl: 0.028520479798316956\n",
      "      policy_loss: 0.003290114924311638\n",
      "      total_loss: 72.9857177734375\n",
      "      vf_explained_var: 0.9764267206192017\n",
      "      vf_loss: 72.98242950439453\n",
      "    grad_time_ms: 1561.363\n",
      "    load_time_ms: 1.298\n",
      "    num_steps_sampled: 4380000\n",
      "    num_steps_trained: 4380000\n",
      "    sample_time_ms: 15830.976\n",
      "    update_time_ms: 4.859\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7843.319750547409\n",
      "  time_this_iter_s: 17.987221002578735\n",
      "  time_total_s: 7843.319750547409\n",
      "  timestamp: 1550624277\n",
      "  timesteps_since_restore: 4380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4380000\n",
      "  training_iteration: 438\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7843 s, 438 iter, 4380000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-58-14\n",
      "  done: false\n",
      "  episode_len_mean: 129.69\n",
      "  episode_reward_max: 203.26485942584458\n",
      "  episode_reward_mean: 156.36174991340403\n",
      "  episode_reward_min: -45.855767174817544\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 33529\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.820260487494034e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0024023056030273\n",
      "      kl: 0.49500253796577454\n",
      "      policy_loss: 0.0074489363469183445\n",
      "      total_loss: 129.0860595703125\n",
      "      vf_explained_var: 0.9583596587181091\n",
      "      vf_loss: 129.07861328125\n",
      "    grad_time_ms: 1560.939\n",
      "    load_time_ms: 1.301\n",
      "    num_steps_sampled: 4390000\n",
      "    num_steps_trained: 4390000\n",
      "    sample_time_ms: 15877.317\n",
      "    update_time_ms: 4.744\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7860.635656118393\n",
      "  time_this_iter_s: 17.315905570983887\n",
      "  time_total_s: 7860.635656118393\n",
      "  timestamp: 1550624294\n",
      "  timesteps_since_restore: 4390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4390000\n",
      "  training_iteration: 439\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7860 s, 439 iter, 4390000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 125.76\n",
      "  episode_reward_max: 200.1197914616159\n",
      "  episode_reward_mean: 155.63604359054696\n",
      "  episode_reward_min: -45.98697737242916\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 33609\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7492282390594482\n",
      "      kl: 0.017584148794412613\n",
      "      policy_loss: -0.001491229748353362\n",
      "      total_loss: 99.38731384277344\n",
      "      vf_explained_var: 0.9689757227897644\n",
      "      vf_loss: 99.38880920410156\n",
      "    grad_time_ms: 1562.301\n",
      "    load_time_ms: 1.302\n",
      "    num_steps_sampled: 4400000\n",
      "    num_steps_trained: 4400000\n",
      "    sample_time_ms: 15879.785\n",
      "    update_time_ms: 4.733\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7877.755246162415\n",
      "  time_this_iter_s: 17.119590044021606\n",
      "  time_total_s: 7877.755246162415\n",
      "  timestamp: 1550624311\n",
      "  timesteps_since_restore: 4400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4400000\n",
      "  training_iteration: 440\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7877 s, 440 iter, 4400000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-58-48\n",
      "  done: false\n",
      "  episode_len_mean: 127.83\n",
      "  episode_reward_max: 205.02081334590912\n",
      "  episode_reward_mean: 160.77139472141823\n",
      "  episode_reward_min: -39.617601939357165\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 33686\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.799599289894104\n",
      "      kl: 0.014142774976789951\n",
      "      policy_loss: -0.001788676017895341\n",
      "      total_loss: 57.10459899902344\n",
      "      vf_explained_var: 0.9807101488113403\n",
      "      vf_loss: 57.10639572143555\n",
      "    grad_time_ms: 1545.542\n",
      "    load_time_ms: 1.24\n",
      "    num_steps_sampled: 4410000\n",
      "    num_steps_trained: 4410000\n",
      "    sample_time_ms: 15778.921\n",
      "    update_time_ms: 4.804\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7894.463869810104\n",
      "  time_this_iter_s: 16.70862364768982\n",
      "  time_total_s: 7894.463869810104\n",
      "  timestamp: 1550624328\n",
      "  timesteps_since_restore: 4410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4410000\n",
      "  training_iteration: 441\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7894 s, 441 iter, 4410000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-59-06\n",
      "  done: false\n",
      "  episode_len_mean: 127.7\n",
      "  episode_reward_max: 202.6824313382259\n",
      "  episode_reward_mean: 163.267068163643\n",
      "  episode_reward_min: -39.617601939357165\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 33764\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7649898529052734\n",
      "      kl: 0.015140799805521965\n",
      "      policy_loss: 0.0007544878171756864\n",
      "      total_loss: 15.508950233459473\n",
      "      vf_explained_var: 0.9945423603057861\n",
      "      vf_loss: 15.508195877075195\n",
      "    grad_time_ms: 1546.56\n",
      "    load_time_ms: 1.241\n",
      "    num_steps_sampled: 4420000\n",
      "    num_steps_trained: 4420000\n",
      "    sample_time_ms: 15775.159\n",
      "    update_time_ms: 4.883\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7911.84884595871\n",
      "  time_this_iter_s: 17.384976148605347\n",
      "  time_total_s: 7911.84884595871\n",
      "  timestamp: 1550624346\n",
      "  timesteps_since_restore: 4420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4420000\n",
      "  training_iteration: 442\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7911 s, 442 iter, 4420000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-59-23\n",
      "  done: false\n",
      "  episode_len_mean: 126.31\n",
      "  episode_reward_max: 208.95851597750547\n",
      "  episode_reward_mean: 159.41234778461774\n",
      "  episode_reward_min: -49.83628118141452\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 33844\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.765124797821045\n",
      "      kl: 0.023253751918673515\n",
      "      policy_loss: -0.001695556566119194\n",
      "      total_loss: 95.96630096435547\n",
      "      vf_explained_var: 0.9702915549278259\n",
      "      vf_loss: 95.96800231933594\n",
      "    grad_time_ms: 1554.608\n",
      "    load_time_ms: 1.24\n",
      "    num_steps_sampled: 4430000\n",
      "    num_steps_trained: 4430000\n",
      "    sample_time_ms: 15758.847\n",
      "    update_time_ms: 4.819\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7929.038831472397\n",
      "  time_this_iter_s: 17.189985513687134\n",
      "  time_total_s: 7929.038831472397\n",
      "  timestamp: 1550624363\n",
      "  timesteps_since_restore: 4430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4430000\n",
      "  training_iteration: 443\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7929 s, 443 iter, 4430000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-59-40\n",
      "  done: false\n",
      "  episode_len_mean: 127.45\n",
      "  episode_reward_max: 197.59912966265534\n",
      "  episode_reward_mean: 158.78855274851426\n",
      "  episode_reward_min: -49.83628118141452\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 33922\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9788024425506592\n",
      "      kl: 0.022865520790219307\n",
      "      policy_loss: -0.003573812311515212\n",
      "      total_loss: 55.305946350097656\n",
      "      vf_explained_var: 0.9817274808883667\n",
      "      vf_loss: 55.309513092041016\n",
      "    grad_time_ms: 1556.019\n",
      "    load_time_ms: 1.221\n",
      "    num_steps_sampled: 4440000\n",
      "    num_steps_trained: 4440000\n",
      "    sample_time_ms: 15802.191\n",
      "    update_time_ms: 4.721\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7946.680372476578\n",
      "  time_this_iter_s: 17.641541004180908\n",
      "  time_total_s: 7946.680372476578\n",
      "  timestamp: 1550624380\n",
      "  timesteps_since_restore: 4440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4440000\n",
      "  training_iteration: 444\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7946 s, 444 iter, 4440000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_01-59-58\n",
      "  done: false\n",
      "  episode_len_mean: 128.01\n",
      "  episode_reward_max: 197.16350318956205\n",
      "  episode_reward_mean: 161.24670615961227\n",
      "  episode_reward_min: -41.04809558288295\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 34000\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9086039066314697\n",
      "      kl: 0.025052256882190704\n",
      "      policy_loss: 0.005829993169754744\n",
      "      total_loss: 29.080678939819336\n",
      "      vf_explained_var: 0.9894163608551025\n",
      "      vf_loss: 29.07485008239746\n",
      "    grad_time_ms: 1553.118\n",
      "    load_time_ms: 1.271\n",
      "    num_steps_sampled: 4450000\n",
      "    num_steps_trained: 4450000\n",
      "    sample_time_ms: 15764.714\n",
      "    update_time_ms: 4.805\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7963.762222290039\n",
      "  time_this_iter_s: 17.081849813461304\n",
      "  time_total_s: 7963.762222290039\n",
      "  timestamp: 1550624398\n",
      "  timesteps_since_restore: 4450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4450000\n",
      "  training_iteration: 445\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7963 s, 445 iter, 4450000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-00-15\n",
      "  done: false\n",
      "  episode_len_mean: 125.84\n",
      "  episode_reward_max: 197.64174175255076\n",
      "  episode_reward_mean: 163.07108736554125\n",
      "  episode_reward_min: -50.142902829859516\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 34080\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7007824182510376\n",
      "      kl: 0.01386849582195282\n",
      "      policy_loss: -0.002167010447010398\n",
      "      total_loss: 23.817712783813477\n",
      "      vf_explained_var: 0.9917705059051514\n",
      "      vf_loss: 23.819881439208984\n",
      "    grad_time_ms: 1552.297\n",
      "    load_time_ms: 1.246\n",
      "    num_steps_sampled: 4460000\n",
      "    num_steps_trained: 4460000\n",
      "    sample_time_ms: 15753.524\n",
      "    update_time_ms: 4.668\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7981.1827483177185\n",
      "  time_this_iter_s: 17.420526027679443\n",
      "  time_total_s: 7981.1827483177185\n",
      "  timestamp: 1550624415\n",
      "  timesteps_since_restore: 4460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4460000\n",
      "  training_iteration: 446\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7981 s, 446 iter, 4460000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-00-32\n",
      "  done: false\n",
      "  episode_len_mean: 126.26\n",
      "  episode_reward_max: 214.91392639412135\n",
      "  episode_reward_mean: 162.06791066233012\n",
      "  episode_reward_min: -39.18201892682822\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 34159\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8057531118392944\n",
      "      kl: 0.021622419357299805\n",
      "      policy_loss: -0.001262227538973093\n",
      "      total_loss: 86.22229766845703\n",
      "      vf_explained_var: 0.9699453711509705\n",
      "      vf_loss: 86.22356414794922\n",
      "    grad_time_ms: 1547.305\n",
      "    load_time_ms: 1.255\n",
      "    num_steps_sampled: 4470000\n",
      "    num_steps_trained: 4470000\n",
      "    sample_time_ms: 15751.808\n",
      "    update_time_ms: 4.636\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 7998.512644529343\n",
      "  time_this_iter_s: 17.329896211624146\n",
      "  time_total_s: 7998.512644529343\n",
      "  timestamp: 1550624432\n",
      "  timesteps_since_restore: 4470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4470000\n",
      "  training_iteration: 447\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 7998 s, 447 iter, 4470000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-00-50\n",
      "  done: false\n",
      "  episode_len_mean: 125.65\n",
      "  episode_reward_max: 203.53631486987115\n",
      "  episode_reward_mean: 157.61124099452263\n",
      "  episode_reward_min: -48.985637772496375\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 34238\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9116055965423584\n",
      "      kl: 0.024953966960310936\n",
      "      policy_loss: -0.0006993685383349657\n",
      "      total_loss: 51.57090759277344\n",
      "      vf_explained_var: 0.9831714034080505\n",
      "      vf_loss: 51.57161331176758\n",
      "    grad_time_ms: 1545.816\n",
      "    load_time_ms: 1.311\n",
      "    num_steps_sampled: 4480000\n",
      "    num_steps_trained: 4480000\n",
      "    sample_time_ms: 15686.674\n",
      "    update_time_ms: 4.374\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8015.834027528763\n",
      "  time_this_iter_s: 17.321382999420166\n",
      "  time_total_s: 8015.834027528763\n",
      "  timestamp: 1550624450\n",
      "  timesteps_since_restore: 4480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4480000\n",
      "  training_iteration: 448\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8015 s, 448 iter, 4480000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-01-07\n",
      "  done: false\n",
      "  episode_len_mean: 124.33\n",
      "  episode_reward_max: 211.10280388534665\n",
      "  episode_reward_mean: 155.22775607940665\n",
      "  episode_reward_min: -48.985637772496375\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 34319\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.768564224243164\n",
      "      kl: 0.030551543459296227\n",
      "      policy_loss: 0.0007785879424773157\n",
      "      total_loss: 58.122833251953125\n",
      "      vf_explained_var: 0.9799151420593262\n",
      "      vf_loss: 58.1220588684082\n",
      "    grad_time_ms: 1544.266\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 4490000\n",
      "    num_steps_trained: 4490000\n",
      "    sample_time_ms: 15713.006\n",
      "    update_time_ms: 4.369\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8033.401723384857\n",
      "  time_this_iter_s: 17.56769585609436\n",
      "  time_total_s: 8033.401723384857\n",
      "  timestamp: 1550624467\n",
      "  timesteps_since_restore: 4490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4490000\n",
      "  training_iteration: 449\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8033 s, 449 iter, 4490000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-01-24\n",
      "  done: false\n",
      "  episode_len_mean: 125.18\n",
      "  episode_reward_max: 204.62099584737922\n",
      "  episode_reward_mean: 159.1067764742026\n",
      "  episode_reward_min: -46.479734418120685\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 34399\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.764013409614563\n",
      "      kl: 0.016312643885612488\n",
      "      policy_loss: -0.003770156530663371\n",
      "      total_loss: 49.253849029541016\n",
      "      vf_explained_var: 0.9834538102149963\n",
      "      vf_loss: 49.25761413574219\n",
      "    grad_time_ms: 1553.705\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 4500000\n",
      "    num_steps_trained: 4500000\n",
      "    sample_time_ms: 15700.081\n",
      "    update_time_ms: 4.312\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8050.485050916672\n",
      "  time_this_iter_s: 17.083327531814575\n",
      "  time_total_s: 8050.485050916672\n",
      "  timestamp: 1550624484\n",
      "  timesteps_since_restore: 4500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4500000\n",
      "  training_iteration: 450\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8050 s, 450 iter, 4500000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-01-42\n",
      "  done: false\n",
      "  episode_len_mean: 126.07\n",
      "  episode_reward_max: 198.61888486755518\n",
      "  episode_reward_mean: 161.22741173354544\n",
      "  episode_reward_min: -50.47644394791071\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 34477\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8135675191879272\n",
      "      kl: 0.023120684549212456\n",
      "      policy_loss: -0.00411108136177063\n",
      "      total_loss: 50.45313262939453\n",
      "      vf_explained_var: 0.9827983379364014\n",
      "      vf_loss: 50.457237243652344\n",
      "    grad_time_ms: 1556.542\n",
      "    load_time_ms: 1.442\n",
      "    num_steps_sampled: 4510000\n",
      "    num_steps_trained: 4510000\n",
      "    sample_time_ms: 15781.074\n",
      "    update_time_ms: 4.204\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8068.034408569336\n",
      "  time_this_iter_s: 17.549357652664185\n",
      "  time_total_s: 8068.034408569336\n",
      "  timestamp: 1550624502\n",
      "  timesteps_since_restore: 4510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4510000\n",
      "  training_iteration: 451\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8068 s, 451 iter, 4510000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-01-59\n",
      "  done: false\n",
      "  episode_len_mean: 126.27\n",
      "  episode_reward_max: 201.9039051743721\n",
      "  episode_reward_mean: 159.3668792346076\n",
      "  episode_reward_min: -49.25284263196558\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 34556\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.883652925491333\n",
      "      kl: 0.012912781909108162\n",
      "      policy_loss: -0.003604516852647066\n",
      "      total_loss: 39.68297576904297\n",
      "      vf_explained_var: 0.9854626655578613\n",
      "      vf_loss: 39.68658447265625\n",
      "    grad_time_ms: 1556.947\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 4520000\n",
      "    num_steps_trained: 4520000\n",
      "    sample_time_ms: 15731.953\n",
      "    update_time_ms: 4.111\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8084.930328130722\n",
      "  time_this_iter_s: 16.89591956138611\n",
      "  time_total_s: 8084.930328130722\n",
      "  timestamp: 1550624519\n",
      "  timesteps_since_restore: 4520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4520000\n",
      "  training_iteration: 452\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8084 s, 452 iter, 4520000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-02-16\n",
      "  done: false\n",
      "  episode_len_mean: 126.74\n",
      "  episode_reward_max: 207.3386318887224\n",
      "  episode_reward_mean: 159.69034014963253\n",
      "  episode_reward_min: -49.25284263196558\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 34635\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.730391717317182e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8226513862609863\n",
      "      kl: 0.0429130420088768\n",
      "      policy_loss: 0.0035598850809037685\n",
      "      total_loss: 64.03199768066406\n",
      "      vf_explained_var: 0.9780060052871704\n",
      "      vf_loss: 64.0284423828125\n",
      "    grad_time_ms: 1547.747\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 4530000\n",
      "    num_steps_trained: 4530000\n",
      "    sample_time_ms: 15758.048\n",
      "    update_time_ms: 4.251\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8102.288114309311\n",
      "  time_this_iter_s: 17.357786178588867\n",
      "  time_total_s: 8102.288114309311\n",
      "  timestamp: 1550624536\n",
      "  timesteps_since_restore: 4530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4530000\n",
      "  training_iteration: 453\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8102 s, 453 iter, 4530000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-02-34\n",
      "  done: false\n",
      "  episode_len_mean: 128.62\n",
      "  episode_reward_max: 207.3386318887224\n",
      "  episode_reward_mean: 164.10298442495696\n",
      "  episode_reward_min: -47.15299753328362\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 34712\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9075250625610352\n",
      "      kl: 0.019306417554616928\n",
      "      policy_loss: -0.0031707866583019495\n",
      "      total_loss: 63.260196685791016\n",
      "      vf_explained_var: 0.9784501791000366\n",
      "      vf_loss: 63.263370513916016\n",
      "    grad_time_ms: 1547.981\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 4540000\n",
      "    num_steps_trained: 4540000\n",
      "    sample_time_ms: 15715.155\n",
      "    update_time_ms: 4.235\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8119.502615213394\n",
      "  time_this_iter_s: 17.214500904083252\n",
      "  time_total_s: 8119.502615213394\n",
      "  timestamp: 1550624554\n",
      "  timesteps_since_restore: 4540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4540000\n",
      "  training_iteration: 454\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8119 s, 454 iter, 4540000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-02-51\n",
      "  done: false\n",
      "  episode_len_mean: 127.19\n",
      "  episode_reward_max: 202.45877910884883\n",
      "  episode_reward_mean: 159.38133031302988\n",
      "  episode_reward_min: -48.933104883399906\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 34791\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8387850522994995\n",
      "      kl: 0.017640968784689903\n",
      "      policy_loss: -0.0014273431152105331\n",
      "      total_loss: 82.98310089111328\n",
      "      vf_explained_var: 0.9715507626533508\n",
      "      vf_loss: 82.98452758789062\n",
      "    grad_time_ms: 1548.849\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 4550000\n",
      "    num_steps_trained: 4550000\n",
      "    sample_time_ms: 15758.752\n",
      "    update_time_ms: 4.152\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8137.026723384857\n",
      "  time_this_iter_s: 17.524108171463013\n",
      "  time_total_s: 8137.026723384857\n",
      "  timestamp: 1550624571\n",
      "  timesteps_since_restore: 4550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4550000\n",
      "  training_iteration: 455\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8137 s, 455 iter, 4550000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-03-09\n",
      "  done: false\n",
      "  episode_len_mean: 127.82\n",
      "  episode_reward_max: 212.69129344319364\n",
      "  episode_reward_mean: 163.469664595457\n",
      "  episode_reward_min: -48.933104883399906\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 34868\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.979852557182312\n",
      "      kl: 0.015004429966211319\n",
      "      policy_loss: 0.0009094250272028148\n",
      "      total_loss: 21.859155654907227\n",
      "      vf_explained_var: 0.9921296238899231\n",
      "      vf_loss: 21.858243942260742\n",
      "    grad_time_ms: 1551.6\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 4560000\n",
      "    num_steps_trained: 4560000\n",
      "    sample_time_ms: 15781.719\n",
      "    update_time_ms: 4.159\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8154.7021725177765\n",
      "  time_this_iter_s: 17.67544913291931\n",
      "  time_total_s: 8154.7021725177765\n",
      "  timestamp: 1550624589\n",
      "  timesteps_since_restore: 4560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4560000\n",
      "  training_iteration: 456\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8154 s, 456 iter, 4560000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-03-26\n",
      "  done: false\n",
      "  episode_len_mean: 130.65\n",
      "  episode_reward_max: 212.69129344319364\n",
      "  episode_reward_mean: 165.16765505403808\n",
      "  episode_reward_min: -40.74607092466684\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 34945\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8746750354766846\n",
      "      kl: 0.018623940646648407\n",
      "      policy_loss: -0.0013861162588000298\n",
      "      total_loss: 45.50390625\n",
      "      vf_explained_var: 0.9850791692733765\n",
      "      vf_loss: 45.50529098510742\n",
      "    grad_time_ms: 1553.575\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 4570000\n",
      "    num_steps_trained: 4570000\n",
      "    sample_time_ms: 15751.706\n",
      "    update_time_ms: 4.009\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8171.751526594162\n",
      "  time_this_iter_s: 17.049354076385498\n",
      "  time_total_s: 8171.751526594162\n",
      "  timestamp: 1550624606\n",
      "  timesteps_since_restore: 4570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4570000\n",
      "  training_iteration: 457\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8171 s, 457 iter, 4570000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-03-43\n",
      "  done: false\n",
      "  episode_len_mean: 126.78\n",
      "  episode_reward_max: 206.75500093422616\n",
      "  episode_reward_mean: 154.53624817804584\n",
      "  episode_reward_min: -41.09217390093471\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 35024\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9368857145309448\n",
      "      kl: 0.022801678627729416\n",
      "      policy_loss: -2.7138452423969284e-05\n",
      "      total_loss: 100.55742645263672\n",
      "      vf_explained_var: 0.9685385227203369\n",
      "      vf_loss: 100.55745697021484\n",
      "    grad_time_ms: 1556.334\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 4580000\n",
      "    num_steps_trained: 4580000\n",
      "    sample_time_ms: 15740.334\n",
      "    update_time_ms: 3.973\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8188.985146284103\n",
      "  time_this_iter_s: 17.233619689941406\n",
      "  time_total_s: 8188.985146284103\n",
      "  timestamp: 1550624623\n",
      "  timesteps_since_restore: 4580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4580000\n",
      "  training_iteration: 458\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8188 s, 458 iter, 4580000 ts, 155 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-04-00\n",
      "  done: false\n",
      "  episode_len_mean: 128.3\n",
      "  episode_reward_max: 202.87892067609462\n",
      "  episode_reward_mean: 155.7187570526056\n",
      "  episode_reward_min: -42.26548199488386\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 35100\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0074474811553955\n",
      "      kl: 0.015736764296889305\n",
      "      policy_loss: -0.002054576063528657\n",
      "      total_loss: 42.79245376586914\n",
      "      vf_explained_var: 0.985579788684845\n",
      "      vf_loss: 42.79450607299805\n",
      "    grad_time_ms: 1558.39\n",
      "    load_time_ms: 1.37\n",
      "    num_steps_sampled: 4590000\n",
      "    num_steps_trained: 4590000\n",
      "    sample_time_ms: 15695.559\n",
      "    update_time_ms: 3.929\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8206.121945858002\n",
      "  time_this_iter_s: 17.136799573898315\n",
      "  time_total_s: 8206.121945858002\n",
      "  timestamp: 1550624640\n",
      "  timesteps_since_restore: 4590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4590000\n",
      "  training_iteration: 459\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8206 s, 459 iter, 4590000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 128.69\n",
      "  episode_reward_max: 211.41102851233856\n",
      "  episode_reward_mean: 166.58180942482738\n",
      "  episode_reward_min: -38.99569619583464\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 35179\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9207216501235962\n",
      "      kl: 0.013027637265622616\n",
      "      policy_loss: 0.0009626193786971271\n",
      "      total_loss: 17.227853775024414\n",
      "      vf_explained_var: 0.993585467338562\n",
      "      vf_loss: 17.22688865661621\n",
      "    grad_time_ms: 1549.275\n",
      "    load_time_ms: 1.407\n",
      "    num_steps_sampled: 4600000\n",
      "    num_steps_trained: 4600000\n",
      "    sample_time_ms: 15739.297\n",
      "    update_time_ms: 3.887\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8223.552148342133\n",
      "  time_this_iter_s: 17.43020248413086\n",
      "  time_total_s: 8223.552148342133\n",
      "  timestamp: 1550624658\n",
      "  timesteps_since_restore: 4600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4600000\n",
      "  training_iteration: 460\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8223 s, 460 iter, 4600000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-04-35\n",
      "  done: false\n",
      "  episode_len_mean: 126.25\n",
      "  episode_reward_max: 207.8458747447717\n",
      "  episode_reward_mean: 162.44621399829225\n",
      "  episode_reward_min: -42.67816356421993\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 35258\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7574505805969238\n",
      "      kl: 0.018104592338204384\n",
      "      policy_loss: 0.0009502897737547755\n",
      "      total_loss: 53.34029006958008\n",
      "      vf_explained_var: 0.9856430292129517\n",
      "      vf_loss: 53.33933639526367\n",
      "    grad_time_ms: 1546.683\n",
      "    load_time_ms: 1.412\n",
      "    num_steps_sampled: 4610000\n",
      "    num_steps_trained: 4610000\n",
      "    sample_time_ms: 15699.224\n",
      "    update_time_ms: 3.948\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8240.674912691116\n",
      "  time_this_iter_s: 17.122764348983765\n",
      "  time_total_s: 8240.674912691116\n",
      "  timestamp: 1550624675\n",
      "  timesteps_since_restore: 4610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4610000\n",
      "  training_iteration: 461\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8240 s, 461 iter, 4610000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-04-52\n",
      "  done: false\n",
      "  episode_len_mean: 131.1\n",
      "  episode_reward_max: 211.82933081066835\n",
      "  episode_reward_mean: 162.52114105057453\n",
      "  episode_reward_min: -37.378154636019545\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 35333\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0965919494628906\n",
      "      kl: 0.017955666407942772\n",
      "      policy_loss: -0.004359046462923288\n",
      "      total_loss: 118.68881225585938\n",
      "      vf_explained_var: 0.9586443901062012\n",
      "      vf_loss: 118.69316101074219\n",
      "    grad_time_ms: 1546.319\n",
      "    load_time_ms: 1.391\n",
      "    num_steps_sampled: 4620000\n",
      "    num_steps_trained: 4620000\n",
      "    sample_time_ms: 15700.566\n",
      "    update_time_ms: 3.912\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8257.579624652863\n",
      "  time_this_iter_s: 16.904711961746216\n",
      "  time_total_s: 8257.579624652863\n",
      "  timestamp: 1550624692\n",
      "  timesteps_since_restore: 4620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4620000\n",
      "  training_iteration: 462\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8257 s, 462 iter, 4620000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-05-10\n",
      "  done: false\n",
      "  episode_len_mean: 131.4\n",
      "  episode_reward_max: 201.93900719653863\n",
      "  episode_reward_mean: 162.84935785361222\n",
      "  episode_reward_min: -48.88083435580282\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 35410\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.595586195469189e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9439902305603027\n",
      "      kl: 0.040684349834918976\n",
      "      policy_loss: 0.006122022867202759\n",
      "      total_loss: 63.3002815246582\n",
      "      vf_explained_var: 0.9781089425086975\n",
      "      vf_loss: 63.294158935546875\n",
      "    grad_time_ms: 1548.952\n",
      "    load_time_ms: 1.391\n",
      "    num_steps_sampled: 4630000\n",
      "    num_steps_trained: 4630000\n",
      "    sample_time_ms: 15729.248\n",
      "    update_time_ms: 3.821\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8275.251807928085\n",
      "  time_this_iter_s: 17.67218327522278\n",
      "  time_total_s: 8275.251807928085\n",
      "  timestamp: 1550624710\n",
      "  timesteps_since_restore: 4630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4630000\n",
      "  training_iteration: 463\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8275 s, 463 iter, 4630000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-05-27\n",
      "  done: false\n",
      "  episode_len_mean: 128.84\n",
      "  episode_reward_max: 201.7745622192869\n",
      "  episode_reward_mean: 164.71123105745747\n",
      "  episode_reward_min: -51.40671892124827\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 35488\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2893382448647404e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.819547176361084\n",
      "      kl: 0.02714933454990387\n",
      "      policy_loss: 0.004144772421568632\n",
      "      total_loss: 39.58561325073242\n",
      "      vf_explained_var: 0.986603856086731\n",
      "      vf_loss: 39.58146667480469\n",
      "    grad_time_ms: 1548.662\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 4640000\n",
      "    num_steps_trained: 4640000\n",
      "    sample_time_ms: 15761.615\n",
      "    update_time_ms: 3.832\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8292.786422252655\n",
      "  time_this_iter_s: 17.534614324569702\n",
      "  time_total_s: 8292.786422252655\n",
      "  timestamp: 1550624727\n",
      "  timesteps_since_restore: 4640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4640000\n",
      "  training_iteration: 464\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8292 s, 464 iter, 4640000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-05-45\n",
      "  done: false\n",
      "  episode_len_mean: 128.03\n",
      "  episode_reward_max: 206.2388844005395\n",
      "  episode_reward_mean: 159.53406874662377\n",
      "  episode_reward_min: -51.40671892124827\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 35566\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2893382448647404e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.001002073287964\n",
      "      kl: 0.023833017796278\n",
      "      policy_loss: 0.0007677527028135955\n",
      "      total_loss: 47.32074737548828\n",
      "      vf_explained_var: 0.9839922785758972\n",
      "      vf_loss: 47.319984436035156\n",
      "    grad_time_ms: 1549.758\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 4650000\n",
      "    num_steps_trained: 4650000\n",
      "    sample_time_ms: 15775.888\n",
      "    update_time_ms: 3.866\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8310.464669466019\n",
      "  time_this_iter_s: 17.678247213363647\n",
      "  time_total_s: 8310.464669466019\n",
      "  timestamp: 1550624745\n",
      "  timesteps_since_restore: 4650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4650000\n",
      "  training_iteration: 465\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8310 s, 465 iter, 4650000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-06-03\n",
      "  done: false\n",
      "  episode_len_mean: 129.1\n",
      "  episode_reward_max: 206.2388844005395\n",
      "  episode_reward_mean: 160.68306186499504\n",
      "  episode_reward_min: -45.345051411354866\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 35643\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2893382448647404e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.925009846687317\n",
      "      kl: 0.023150863125920296\n",
      "      policy_loss: 0.0018391225021332502\n",
      "      total_loss: 52.81686782836914\n",
      "      vf_explained_var: 0.9818458557128906\n",
      "      vf_loss: 52.81503677368164\n",
      "    grad_time_ms: 1548.819\n",
      "    load_time_ms: 1.449\n",
      "    num_steps_sampled: 4660000\n",
      "    num_steps_trained: 4660000\n",
      "    sample_time_ms: 15798.416\n",
      "    update_time_ms: 3.862\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8328.360924005508\n",
      "  time_this_iter_s: 17.896254539489746\n",
      "  time_total_s: 8328.360924005508\n",
      "  timestamp: 1550624763\n",
      "  timesteps_since_restore: 4660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4660000\n",
      "  training_iteration: 466\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8328 s, 466 iter, 4660000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-06-21\n",
      "  done: false\n",
      "  episode_len_mean: 128.38\n",
      "  episode_reward_max: 204.5425763830247\n",
      "  episode_reward_mean: 157.2140596241673\n",
      "  episode_reward_min: -39.38610651299799\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 35722\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2893382448647404e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9884459972381592\n",
      "      kl: 0.049163974821567535\n",
      "      policy_loss: 0.00475719990208745\n",
      "      total_loss: 95.97120666503906\n",
      "      vf_explained_var: 0.9698100686073303\n",
      "      vf_loss: 95.9664306640625\n",
      "    grad_time_ms: 1548.614\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 4670000\n",
      "    num_steps_trained: 4670000\n",
      "    sample_time_ms: 15856.789\n",
      "    update_time_ms: 3.931\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8345.990337848663\n",
      "  time_this_iter_s: 17.629413843154907\n",
      "  time_total_s: 8345.990337848663\n",
      "  timestamp: 1550624781\n",
      "  timesteps_since_restore: 4670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4670000\n",
      "  training_iteration: 467\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8345 s, 467 iter, 4670000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-06-38\n",
      "  done: false\n",
      "  episode_len_mean: 128.67\n",
      "  episode_reward_max: 217.3160318168673\n",
      "  episode_reward_mean: 160.2170096900876\n",
      "  episode_reward_min: -44.09584677780027\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 35800\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9340070517527485e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8543474674224854\n",
      "      kl: 0.021855410188436508\n",
      "      policy_loss: -0.0005437684012576938\n",
      "      total_loss: 77.6129150390625\n",
      "      vf_explained_var: 0.9747589230537415\n",
      "      vf_loss: 77.61344146728516\n",
      "    grad_time_ms: 1545.734\n",
      "    load_time_ms: 1.396\n",
      "    num_steps_sampled: 4680000\n",
      "    num_steps_trained: 4680000\n",
      "    sample_time_ms: 15824.9\n",
      "    update_time_ms: 3.974\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8362.875539302826\n",
      "  time_this_iter_s: 16.885201454162598\n",
      "  time_total_s: 8362.875539302826\n",
      "  timestamp: 1550624798\n",
      "  timesteps_since_restore: 4680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4680000\n",
      "  training_iteration: 468\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8362 s, 468 iter, 4680000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-06-55\n",
      "  done: false\n",
      "  episode_len_mean: 128.61\n",
      "  episode_reward_max: 217.3160318168673\n",
      "  episode_reward_mean: 158.2545877197154\n",
      "  episode_reward_min: -47.84086227409615\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 35877\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9340070517527485e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.039616107940674\n",
      "      kl: 0.029149578884243965\n",
      "      policy_loss: 0.0025051271077245474\n",
      "      total_loss: 70.1055908203125\n",
      "      vf_explained_var: 0.9766192436218262\n",
      "      vf_loss: 70.10308837890625\n",
      "    grad_time_ms: 1545.477\n",
      "    load_time_ms: 1.396\n",
      "    num_steps_sampled: 4690000\n",
      "    num_steps_trained: 4690000\n",
      "    sample_time_ms: 15856.621\n",
      "    update_time_ms: 4.127\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8380.328664541245\n",
      "  time_this_iter_s: 17.45312523841858\n",
      "  time_total_s: 8380.328664541245\n",
      "  timestamp: 1550624815\n",
      "  timesteps_since_restore: 4690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4690000\n",
      "  training_iteration: 469\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8380 s, 469 iter, 4690000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-07-12\n",
      "  done: false\n",
      "  episode_len_mean: 129.01\n",
      "  episode_reward_max: 217.29600759337438\n",
      "  episode_reward_mean: 165.84758537628753\n",
      "  episode_reward_min: -37.28987684639373\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 35955\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9340070517527485e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7620632648468018\n",
      "      kl: 0.022022996097803116\n",
      "      policy_loss: 9.367099119117483e-05\n",
      "      total_loss: 55.77449035644531\n",
      "      vf_explained_var: 0.9811975359916687\n",
      "      vf_loss: 55.77438735961914\n",
      "    grad_time_ms: 1545.012\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 4700000\n",
      "    num_steps_trained: 4700000\n",
      "    sample_time_ms: 15822.983\n",
      "    update_time_ms: 4.303\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8397.42072057724\n",
      "  time_this_iter_s: 17.092056035995483\n",
      "  time_total_s: 8397.42072057724\n",
      "  timestamp: 1550624832\n",
      "  timesteps_since_restore: 4700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4700000\n",
      "  training_iteration: 470\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8397 s, 470 iter, 4700000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-07-29\n",
      "  done: false\n",
      "  episode_len_mean: 128.61\n",
      "  episode_reward_max: 211.16521586344967\n",
      "  episode_reward_mean: 157.46024707258627\n",
      "  episode_reward_min: -43.09222712862019\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 36033\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9340070517527485e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.960007905960083\n",
      "      kl: 0.015356641262769699\n",
      "      policy_loss: -0.0005787656991742551\n",
      "      total_loss: 65.57637786865234\n",
      "      vf_explained_var: 0.9795914888381958\n",
      "      vf_loss: 65.57695770263672\n",
      "    grad_time_ms: 1544.31\n",
      "    load_time_ms: 1.354\n",
      "    num_steps_sampled: 4710000\n",
      "    num_steps_trained: 4710000\n",
      "    sample_time_ms: 15817.772\n",
      "    update_time_ms: 4.263\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8414.481040000916\n",
      "  time_this_iter_s: 17.060319423675537\n",
      "  time_total_s: 8414.481040000916\n",
      "  timestamp: 1550624849\n",
      "  timesteps_since_restore: 4710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4710000\n",
      "  training_iteration: 471\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8414 s, 471 iter, 4710000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-07-47\n",
      "  done: false\n",
      "  episode_len_mean: 128.53\n",
      "  episode_reward_max: 216.38808905960312\n",
      "  episode_reward_mean: 157.6349927275468\n",
      "  episode_reward_min: -49.33914647819384\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 36112\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9340070517527485e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.854193091392517\n",
      "      kl: 0.026799913495779037\n",
      "      policy_loss: 0.0005997740081511438\n",
      "      total_loss: 102.5859146118164\n",
      "      vf_explained_var: 0.9659702777862549\n",
      "      vf_loss: 102.58531951904297\n",
      "    grad_time_ms: 1542.906\n",
      "    load_time_ms: 1.383\n",
      "    num_steps_sampled: 4720000\n",
      "    num_steps_trained: 4720000\n",
      "    sample_time_ms: 15869.397\n",
      "    update_time_ms: 4.223\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8431.888898611069\n",
      "  time_this_iter_s: 17.4078586101532\n",
      "  time_total_s: 8431.888898611069\n",
      "  timestamp: 1550624867\n",
      "  timesteps_since_restore: 4720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4720000\n",
      "  training_iteration: 472\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8431 s, 472 iter, 4720000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-08-04\n",
      "  done: false\n",
      "  episode_len_mean: 128.45\n",
      "  episode_reward_max: 216.38808905960312\n",
      "  episode_reward_mean: 166.23980417435604\n",
      "  episode_reward_min: -41.259748742426964\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 36190\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9340070517527485e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8517550230026245\n",
      "      kl: 0.036286234855651855\n",
      "      policy_loss: 0.0023459617514163256\n",
      "      total_loss: 49.96291732788086\n",
      "      vf_explained_var: 0.9820683598518372\n",
      "      vf_loss: 49.96056365966797\n",
      "    grad_time_ms: 1542.116\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 4730000\n",
      "    num_steps_trained: 4730000\n",
      "    sample_time_ms: 15809.745\n",
      "    update_time_ms: 4.327\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8448.957843065262\n",
      "  time_this_iter_s: 17.068944454193115\n",
      "  time_total_s: 8448.957843065262\n",
      "  timestamp: 1550624884\n",
      "  timesteps_since_restore: 4730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4730000\n",
      "  training_iteration: 473\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8448 s, 473 iter, 4730000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-08-21\n",
      "  done: false\n",
      "  episode_len_mean: 127.0\n",
      "  episode_reward_max: 203.37416554028445\n",
      "  episode_reward_mean: 161.1807727110154\n",
      "  episode_reward_min: -51.501090869897666\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 36269\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9340070517527485e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8476247787475586\n",
      "      kl: 0.02163793332874775\n",
      "      policy_loss: 0.002676441101357341\n",
      "      total_loss: 38.38002395629883\n",
      "      vf_explained_var: 0.9868161082267761\n",
      "      vf_loss: 38.37734603881836\n",
      "    grad_time_ms: 1541.11\n",
      "    load_time_ms: 1.421\n",
      "    num_steps_sampled: 4740000\n",
      "    num_steps_trained: 4740000\n",
      "    sample_time_ms: 15730.451\n",
      "    update_time_ms: 4.406\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8465.691587209702\n",
      "  time_this_iter_s: 16.733744144439697\n",
      "  time_total_s: 8465.691587209702\n",
      "  timestamp: 1550624901\n",
      "  timesteps_since_restore: 4740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4740000\n",
      "  training_iteration: 474\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8465 s, 474 iter, 4740000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-08-38\n",
      "  done: false\n",
      "  episode_len_mean: 127.04\n",
      "  episode_reward_max: 208.2990543227089\n",
      "  episode_reward_mean: 164.16777743177653\n",
      "  episode_reward_min: -40.94506536438914\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 36348\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.9340070517527485e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7796120643615723\n",
      "      kl: 0.040799330919981\n",
      "      policy_loss: 0.006467806175351143\n",
      "      total_loss: 56.57529067993164\n",
      "      vf_explained_var: 0.9809901118278503\n",
      "      vf_loss: 56.56882095336914\n",
      "    grad_time_ms: 1541.109\n",
      "    load_time_ms: 1.393\n",
      "    num_steps_sampled: 4750000\n",
      "    num_steps_trained: 4750000\n",
      "    sample_time_ms: 15674.152\n",
      "    update_time_ms: 4.472\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8482.806787967682\n",
      "  time_this_iter_s: 17.115200757980347\n",
      "  time_total_s: 8482.806787967682\n",
      "  timestamp: 1550624918\n",
      "  timesteps_since_restore: 4750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4750000\n",
      "  training_iteration: 475\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8482 s, 475 iter, 4750000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-08-55\n",
      "  done: false\n",
      "  episode_len_mean: 127.69\n",
      "  episode_reward_max: 211.75420880052116\n",
      "  episode_reward_mean: 159.3409467071046\n",
      "  episode_reward_min: -46.12141185939902\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 36425\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.901011050945666e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8773359060287476\n",
      "      kl: 0.017420342192053795\n",
      "      policy_loss: -0.001592622371390462\n",
      "      total_loss: 72.59889221191406\n",
      "      vf_explained_var: 0.9764498472213745\n",
      "      vf_loss: 72.6004867553711\n",
      "    grad_time_ms: 1539.261\n",
      "    load_time_ms: 1.321\n",
      "    num_steps_sampled: 4760000\n",
      "    num_steps_trained: 4760000\n",
      "    sample_time_ms: 15601.486\n",
      "    update_time_ms: 4.424\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8499.95240187645\n",
      "  time_this_iter_s: 17.1456139087677\n",
      "  time_total_s: 8499.95240187645\n",
      "  timestamp: 1550624935\n",
      "  timesteps_since_restore: 4760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4760000\n",
      "  training_iteration: 476\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8499 s, 476 iter, 4760000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-09-12\n",
      "  done: false\n",
      "  episode_len_mean: 127.27\n",
      "  episode_reward_max: 204.95409053755867\n",
      "  episode_reward_mean: 158.03495649416388\n",
      "  episode_reward_min: -45.39192148984068\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 36504\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.901011050945666e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8667776584625244\n",
      "      kl: 0.019153336063027382\n",
      "      policy_loss: -0.002159810159355402\n",
      "      total_loss: 63.76513671875\n",
      "      vf_explained_var: 0.9800078272819519\n",
      "      vf_loss: 63.767303466796875\n",
      "    grad_time_ms: 1536.678\n",
      "    load_time_ms: 1.347\n",
      "    num_steps_sampled: 4770000\n",
      "    num_steps_trained: 4770000\n",
      "    sample_time_ms: 15540.646\n",
      "    update_time_ms: 4.352\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8516.947110652924\n",
      "  time_this_iter_s: 16.994708776474\n",
      "  time_total_s: 8516.947110652924\n",
      "  timestamp: 1550624952\n",
      "  timesteps_since_restore: 4770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4770000\n",
      "  training_iteration: 477\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8516 s, 477 iter, 4770000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-09-29\n",
      "  done: false\n",
      "  episode_len_mean: 128.83\n",
      "  episode_reward_max: 207.937852072834\n",
      "  episode_reward_mean: 163.65767072569182\n",
      "  episode_reward_min: -51.21038644856744\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 36582\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.901011050945666e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.865163803100586\n",
      "      kl: 0.027331572026014328\n",
      "      policy_loss: 0.0021707694977521896\n",
      "      total_loss: 42.18117141723633\n",
      "      vf_explained_var: 0.9857109189033508\n",
      "      vf_loss: 42.17900848388672\n",
      "    grad_time_ms: 1537.402\n",
      "    load_time_ms: 1.367\n",
      "    num_steps_sampled: 4780000\n",
      "    num_steps_trained: 4780000\n",
      "    sample_time_ms: 15556.173\n",
      "    update_time_ms: 4.345\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8533.994039297104\n",
      "  time_this_iter_s: 17.046928644180298\n",
      "  time_total_s: 8533.994039297104\n",
      "  timestamp: 1550624969\n",
      "  timesteps_since_restore: 4780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4780000\n",
      "  training_iteration: 478\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8533 s, 478 iter, 4780000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-09-46\n",
      "  done: false\n",
      "  episode_len_mean: 131.64\n",
      "  episode_reward_max: 206.30843508597644\n",
      "  episode_reward_mean: 168.76656517930326\n",
      "  episode_reward_min: 124.36165173524975\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 36657\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.901011050945666e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1012253761291504\n",
      "      kl: 0.02155369333922863\n",
      "      policy_loss: 0.0035226650070399046\n",
      "      total_loss: 23.627161026000977\n",
      "      vf_explained_var: 0.9912236332893372\n",
      "      vf_loss: 23.62363624572754\n",
      "    grad_time_ms: 1536.387\n",
      "    load_time_ms: 1.367\n",
      "    num_steps_sampled: 4790000\n",
      "    num_steps_trained: 4790000\n",
      "    sample_time_ms: 15526.846\n",
      "    update_time_ms: 4.341\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8551.143264770508\n",
      "  time_this_iter_s: 17.14922547340393\n",
      "  time_total_s: 8551.143264770508\n",
      "  timestamp: 1550624986\n",
      "  timesteps_since_restore: 4790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4790000\n",
      "  training_iteration: 479\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8551 s, 479 iter, 4790000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-10-04\n",
      "  done: false\n",
      "  episode_len_mean: 131.02\n",
      "  episode_reward_max: 199.96706320957682\n",
      "  episode_reward_mean: 164.6355595462406\n",
      "  episode_reward_min: -41.7632859566129\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 36734\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.901011050945666e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.953349232673645\n",
      "      kl: 0.0272926464676857\n",
      "      policy_loss: -0.0008163749007508159\n",
      "      total_loss: 88.39238739013672\n",
      "      vf_explained_var: 0.9720070958137512\n",
      "      vf_loss: 88.39319610595703\n",
      "    grad_time_ms: 1535.301\n",
      "    load_time_ms: 1.302\n",
      "    num_steps_sampled: 4800000\n",
      "    num_steps_trained: 4800000\n",
      "    sample_time_ms: 15549.527\n",
      "    update_time_ms: 4.203\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8568.446325778961\n",
      "  time_this_iter_s: 17.30306100845337\n",
      "  time_total_s: 8568.446325778961\n",
      "  timestamp: 1550625004\n",
      "  timesteps_since_restore: 4800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4800000\n",
      "  training_iteration: 480\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8568 s, 480 iter, 4800000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-10-21\n",
      "  done: false\n",
      "  episode_len_mean: 132.24\n",
      "  episode_reward_max: 203.2984478174166\n",
      "  episode_reward_mean: 157.52195275302049\n",
      "  episode_reward_min: -45.540673637301616\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 36810\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.901011050945666e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9529050588607788\n",
      "      kl: 0.026987776160240173\n",
      "      policy_loss: 0.003219036618247628\n",
      "      total_loss: 61.21527099609375\n",
      "      vf_explained_var: 0.9806980490684509\n",
      "      vf_loss: 61.212059020996094\n",
      "    grad_time_ms: 1535.152\n",
      "    load_time_ms: 1.295\n",
      "    num_steps_sampled: 4810000\n",
      "    num_steps_trained: 4810000\n",
      "    sample_time_ms: 15556.05\n",
      "    update_time_ms: 4.223\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8585.571438789368\n",
      "  time_this_iter_s: 17.125113010406494\n",
      "  time_total_s: 8585.571438789368\n",
      "  timestamp: 1550625021\n",
      "  timesteps_since_restore: 4810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4810000\n",
      "  training_iteration: 481\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8585 s, 481 iter, 4810000 ts, 158 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-10-38\n",
      "  done: false\n",
      "  episode_len_mean: 126.26\n",
      "  episode_reward_max: 203.36125280560526\n",
      "  episode_reward_mean: 150.72316288960266\n",
      "  episode_reward_min: -45.540673637301616\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 36890\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.901011050945666e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.917354702949524\n",
      "      kl: 0.020242488011717796\n",
      "      policy_loss: 0.000408056250307709\n",
      "      total_loss: 104.54313659667969\n",
      "      vf_explained_var: 0.967774510383606\n",
      "      vf_loss: 104.54273986816406\n",
      "    grad_time_ms: 1537.111\n",
      "    load_time_ms: 1.324\n",
      "    num_steps_sampled: 4820000\n",
      "    num_steps_trained: 4820000\n",
      "    sample_time_ms: 15555.643\n",
      "    update_time_ms: 4.312\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8602.996327877045\n",
      "  time_this_iter_s: 17.424889087677002\n",
      "  time_total_s: 8602.996327877045\n",
      "  timestamp: 1550625038\n",
      "  timesteps_since_restore: 4820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4820000\n",
      "  training_iteration: 482\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8602 s, 482 iter, 4820000 ts, 151 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-10-56\n",
      "  done: false\n",
      "  episode_len_mean: 127.33\n",
      "  episode_reward_max: 205.786783020464\n",
      "  episode_reward_mean: 161.30938000155336\n",
      "  episode_reward_min: -49.73627063277921\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 36968\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.901011050945666e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8895846605300903\n",
      "      kl: 0.04810066521167755\n",
      "      policy_loss: 0.00797125045210123\n",
      "      total_loss: 65.77129364013672\n",
      "      vf_explained_var: 0.9773211479187012\n",
      "      vf_loss: 65.76331329345703\n",
      "    grad_time_ms: 1534.749\n",
      "    load_time_ms: 1.328\n",
      "    num_steps_sampled: 4830000\n",
      "    num_steps_trained: 4830000\n",
      "    sample_time_ms: 15587.015\n",
      "    update_time_ms: 4.178\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8620.356794834137\n",
      "  time_this_iter_s: 17.360466957092285\n",
      "  time_total_s: 8620.356794834137\n",
      "  timestamp: 1550625056\n",
      "  timesteps_since_restore: 4830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4830000\n",
      "  training_iteration: 483\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8620 s, 483 iter, 4830000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-11-13\n",
      "  done: false\n",
      "  episode_len_mean: 128.31\n",
      "  episode_reward_max: 215.09021392242397\n",
      "  episode_reward_mean: 159.55625842505162\n",
      "  episode_reward_min: -49.431888830543755\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 37047\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9176770448684692\n",
      "      kl: 0.012655144557356834\n",
      "      policy_loss: 0.0014457771321758628\n",
      "      total_loss: 43.59442138671875\n",
      "      vf_explained_var: 0.9857082962989807\n",
      "      vf_loss: 43.59297180175781\n",
      "    grad_time_ms: 1534.235\n",
      "    load_time_ms: 1.391\n",
      "    num_steps_sampled: 4840000\n",
      "    num_steps_trained: 4840000\n",
      "    sample_time_ms: 15637.323\n",
      "    update_time_ms: 4.052\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8637.589081764221\n",
      "  time_this_iter_s: 17.23228693008423\n",
      "  time_total_s: 8637.589081764221\n",
      "  timestamp: 1550625073\n",
      "  timesteps_since_restore: 4840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4840000\n",
      "  training_iteration: 484\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8637 s, 484 iter, 4840000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-11-30\n",
      "  done: false\n",
      "  episode_len_mean: 131.08\n",
      "  episode_reward_max: 223.7174679431881\n",
      "  episode_reward_mean: 164.12370916176357\n",
      "  episode_reward_min: -41.12673174272669\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 37122\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1514551639556885\n",
      "      kl: 0.017052913084626198\n",
      "      policy_loss: 0.001418911968357861\n",
      "      total_loss: 12.372637748718262\n",
      "      vf_explained_var: 0.9952576756477356\n",
      "      vf_loss: 12.37121868133545\n",
      "    grad_time_ms: 1534.264\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 4850000\n",
      "    num_steps_trained: 4850000\n",
      "    sample_time_ms: 15658.967\n",
      "    update_time_ms: 3.924\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8654.92069554329\n",
      "  time_this_iter_s: 17.331613779067993\n",
      "  time_total_s: 8654.92069554329\n",
      "  timestamp: 1550625090\n",
      "  timesteps_since_restore: 4850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4850000\n",
      "  training_iteration: 485\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8654 s, 485 iter, 4850000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-11-48\n",
      "  done: false\n",
      "  episode_len_mean: 129.93\n",
      "  episode_reward_max: 211.93291570556045\n",
      "  episode_reward_mean: 167.7945650225322\n",
      "  episode_reward_min: -50.877408304279385\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 37200\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8865407705307007\n",
      "      kl: 0.019987894222140312\n",
      "      policy_loss: -0.00087503477698192\n",
      "      total_loss: 39.13505172729492\n",
      "      vf_explained_var: 0.9867419600486755\n",
      "      vf_loss: 39.13593292236328\n",
      "    grad_time_ms: 1534.465\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 4860000\n",
      "    num_steps_trained: 4860000\n",
      "    sample_time_ms: 15687.978\n",
      "    update_time_ms: 3.959\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8672.361341238022\n",
      "  time_this_iter_s: 17.440645694732666\n",
      "  time_total_s: 8672.361341238022\n",
      "  timestamp: 1550625108\n",
      "  timesteps_since_restore: 4860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4860000\n",
      "  training_iteration: 486\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8672 s, 486 iter, 4860000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-12-05\n",
      "  done: false\n",
      "  episode_len_mean: 127.68\n",
      "  episode_reward_max: 205.32678414541905\n",
      "  episode_reward_mean: 160.4186762153232\n",
      "  episode_reward_min: -45.88530874031015\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 37278\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6929330825805664\n",
      "      kl: 0.022685958072543144\n",
      "      policy_loss: -0.0013657258823513985\n",
      "      total_loss: 122.27915954589844\n",
      "      vf_explained_var: 0.9627377390861511\n",
      "      vf_loss: 122.28052520751953\n",
      "    grad_time_ms: 1536.148\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 4870000\n",
      "    num_steps_trained: 4870000\n",
      "    sample_time_ms: 15740.064\n",
      "    update_time_ms: 3.986\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8689.896391868591\n",
      "  time_this_iter_s: 17.535050630569458\n",
      "  time_total_s: 8689.896391868591\n",
      "  timestamp: 1550625125\n",
      "  timesteps_since_restore: 4870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4870000\n",
      "  training_iteration: 487\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8689 s, 487 iter, 4870000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-12-23\n",
      "  done: false\n",
      "  episode_len_mean: 127.61\n",
      "  episode_reward_max: 207.93519530755157\n",
      "  episode_reward_mean: 159.31343617179874\n",
      "  episode_reward_min: -47.232660574340585\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 37355\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.010988235473633\n",
      "      kl: 0.021070178598165512\n",
      "      policy_loss: -0.002920754486694932\n",
      "      total_loss: 50.399085998535156\n",
      "      vf_explained_var: 0.9839690923690796\n",
      "      vf_loss: 50.40200424194336\n",
      "    grad_time_ms: 1561.004\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 4880000\n",
      "    num_steps_trained: 4880000\n",
      "    sample_time_ms: 15800.381\n",
      "    update_time_ms: 3.955\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8707.79903292656\n",
      "  time_this_iter_s: 17.90264105796814\n",
      "  time_total_s: 8707.79903292656\n",
      "  timestamp: 1550625143\n",
      "  timesteps_since_restore: 4880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4880000\n",
      "  training_iteration: 488\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8707 s, 488 iter, 4880000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-12-41\n",
      "  done: false\n",
      "  episode_len_mean: 129.14\n",
      "  episode_reward_max: 217.8667612696194\n",
      "  episode_reward_mean: 164.69538903528638\n",
      "  episode_reward_min: -41.71799289767105\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 37433\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9539095163345337\n",
      "      kl: 0.014027104713022709\n",
      "      policy_loss: 0.0032411653082817793\n",
      "      total_loss: 49.5140266418457\n",
      "      vf_explained_var: 0.9825999736785889\n",
      "      vf_loss: 49.51078414916992\n",
      "    grad_time_ms: 1562.449\n",
      "    load_time_ms: 1.471\n",
      "    num_steps_sampled: 4890000\n",
      "    num_steps_trained: 4890000\n",
      "    sample_time_ms: 15848.718\n",
      "    update_time_ms: 3.914\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8725.446396827698\n",
      "  time_this_iter_s: 17.647363901138306\n",
      "  time_total_s: 8725.446396827698\n",
      "  timestamp: 1550625161\n",
      "  timesteps_since_restore: 4890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4890000\n",
      "  training_iteration: 489\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8725 s, 489 iter, 4890000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-12-58\n",
      "  done: false\n",
      "  episode_len_mean: 124.61\n",
      "  episode_reward_max: 204.36281553530466\n",
      "  episode_reward_mean: 153.8383763759061\n",
      "  episode_reward_min: -47.0847647491068\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 37514\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8233609199523926\n",
      "      kl: 0.030563974753022194\n",
      "      policy_loss: -0.0050936113111674786\n",
      "      total_loss: 97.18535614013672\n",
      "      vf_explained_var: 0.9668373465538025\n",
      "      vf_loss: 97.19044494628906\n",
      "    grad_time_ms: 1566.11\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 4900000\n",
      "    num_steps_trained: 4900000\n",
      "    sample_time_ms: 15858.205\n",
      "    update_time_ms: 4.037\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8742.882200241089\n",
      "  time_this_iter_s: 17.435803413391113\n",
      "  time_total_s: 8742.882200241089\n",
      "  timestamp: 1550625178\n",
      "  timesteps_since_restore: 4900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4900000\n",
      "  training_iteration: 490\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8742 s, 490 iter, 4900000 ts, 154 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-13-16\n",
      "  done: false\n",
      "  episode_len_mean: 127.12\n",
      "  episode_reward_max: 208.27316592855044\n",
      "  episode_reward_mean: 164.29902000517356\n",
      "  episode_reward_min: -42.93853687059761\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 37592\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.849574327468872\n",
      "      kl: 0.027581673115491867\n",
      "      policy_loss: 0.0018918953137472272\n",
      "      total_loss: 102.93270111083984\n",
      "      vf_explained_var: 0.9642767310142517\n",
      "      vf_loss: 102.93080139160156\n",
      "    grad_time_ms: 1567.482\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 4910000\n",
      "    num_steps_trained: 4910000\n",
      "    sample_time_ms: 15911.113\n",
      "    update_time_ms: 4.013\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8760.550264120102\n",
      "  time_this_iter_s: 17.66806387901306\n",
      "  time_total_s: 8760.550264120102\n",
      "  timestamp: 1550625196\n",
      "  timesteps_since_restore: 4910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4910000\n",
      "  training_iteration: 491\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8760 s, 491 iter, 4910000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-13-34\n",
      "  done: false\n",
      "  episode_len_mean: 129.8\n",
      "  episode_reward_max: 203.02031577105583\n",
      "  episode_reward_mean: 167.15427131022574\n",
      "  episode_reward_min: -47.359559864100845\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 37669\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9398983716964722\n",
      "      kl: 0.025143787264823914\n",
      "      policy_loss: 0.0012713620672002435\n",
      "      total_loss: 26.681156158447266\n",
      "      vf_explained_var: 0.9904031157493591\n",
      "      vf_loss: 26.679887771606445\n",
      "    grad_time_ms: 1566.989\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 4920000\n",
      "    num_steps_trained: 4920000\n",
      "    sample_time_ms: 15919.193\n",
      "    update_time_ms: 4.066\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8778.050973892212\n",
      "  time_this_iter_s: 17.500709772109985\n",
      "  time_total_s: 8778.050973892212\n",
      "  timestamp: 1550625214\n",
      "  timesteps_since_restore: 4920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4920000\n",
      "  training_iteration: 492\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8778 s, 492 iter, 4920000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-13-51\n",
      "  done: false\n",
      "  episode_len_mean: 129.04\n",
      "  episode_reward_max: 204.4178595560612\n",
      "  episode_reward_mean: 165.05168101576987\n",
      "  episode_reward_min: -45.791618486884786\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 37746\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9181127548217773\n",
      "      kl: 0.019728312268853188\n",
      "      policy_loss: -0.00047027377877384424\n",
      "      total_loss: 43.71390914916992\n",
      "      vf_explained_var: 0.9868832230567932\n",
      "      vf_loss: 43.71437454223633\n",
      "    grad_time_ms: 1569.458\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 4930000\n",
      "    num_steps_trained: 4930000\n",
      "    sample_time_ms: 15966.224\n",
      "    update_time_ms: 4.13\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8795.904088973999\n",
      "  time_this_iter_s: 17.85311508178711\n",
      "  time_total_s: 8795.904088973999\n",
      "  timestamp: 1550625231\n",
      "  timesteps_since_restore: 4930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4930000\n",
      "  training_iteration: 493\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8795 s, 493 iter, 4930000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-14-09\n",
      "  done: false\n",
      "  episode_len_mean: 129.17\n",
      "  episode_reward_max: 214.23746528941214\n",
      "  episode_reward_mean: 162.29335057844028\n",
      "  episode_reward_min: -42.78119687809804\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 37824\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.945642352104187\n",
      "      kl: 0.013932266272604465\n",
      "      policy_loss: -0.0029678666032850742\n",
      "      total_loss: 90.49650573730469\n",
      "      vf_explained_var: 0.9710449576377869\n",
      "      vf_loss: 90.49947357177734\n",
      "    grad_time_ms: 1572.712\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 4940000\n",
      "    num_steps_trained: 4940000\n",
      "    sample_time_ms: 15961.092\n",
      "    update_time_ms: 4.193\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8813.115347146988\n",
      "  time_this_iter_s: 17.21125817298889\n",
      "  time_total_s: 8813.115347146988\n",
      "  timestamp: 1550625249\n",
      "  timesteps_since_restore: 4940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4940000\n",
      "  training_iteration: 494\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8813 s, 494 iter, 4940000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-14-26\n",
      "  done: false\n",
      "  episode_len_mean: 126.22\n",
      "  episode_reward_max: 208.0511861160249\n",
      "  episode_reward_mean: 151.78963392200905\n",
      "  episode_reward_min: -44.18667906301444\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 37903\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8678085803985596\n",
      "      kl: 0.026224549859762192\n",
      "      policy_loss: 0.00033676670864224434\n",
      "      total_loss: 76.66997528076172\n",
      "      vf_explained_var: 0.9766680598258972\n",
      "      vf_loss: 76.66962432861328\n",
      "    grad_time_ms: 1571.872\n",
      "    load_time_ms: 1.344\n",
      "    num_steps_sampled: 4950000\n",
      "    num_steps_trained: 4950000\n",
      "    sample_time_ms: 15989.67\n",
      "    update_time_ms: 4.232\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8830.723465442657\n",
      "  time_this_iter_s: 17.608118295669556\n",
      "  time_total_s: 8830.723465442657\n",
      "  timestamp: 1550625266\n",
      "  timesteps_since_restore: 4950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4950000\n",
      "  training_iteration: 495\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8830 s, 495 iter, 4950000 ts, 152 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 130.67\n",
      "  episode_reward_max: 205.97439073918787\n",
      "  episode_reward_mean: 165.6911512272136\n",
      "  episode_reward_min: -43.6789060937296\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 37980\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8404358625411987\n",
      "      kl: 0.016611648723483086\n",
      "      policy_loss: 0.002830319805070758\n",
      "      total_loss: 62.49116134643555\n",
      "      vf_explained_var: 0.9786096215248108\n",
      "      vf_loss: 62.48833084106445\n",
      "    grad_time_ms: 1580.347\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 4960000\n",
      "    num_steps_trained: 4960000\n",
      "    sample_time_ms: 15975.337\n",
      "    update_time_ms: 4.219\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8848.106665611267\n",
      "  time_this_iter_s: 17.38320016860962\n",
      "  time_total_s: 8848.106665611267\n",
      "  timestamp: 1550625284\n",
      "  timesteps_since_restore: 4960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4960000\n",
      "  training_iteration: 496\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8848 s, 496 iter, 4960000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-15-01\n",
      "  done: false\n",
      "  episode_len_mean: 128.55\n",
      "  episode_reward_max: 210.46298543599875\n",
      "  episode_reward_mean: 166.26118815375293\n",
      "  episode_reward_min: -50.98165014415682\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 38056\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9264360666275024\n",
      "      kl: 0.01936235837638378\n",
      "      policy_loss: 0.00246605696156621\n",
      "      total_loss: 66.45799255371094\n",
      "      vf_explained_var: 0.9758769273757935\n",
      "      vf_loss: 66.45552825927734\n",
      "    grad_time_ms: 1584.845\n",
      "    load_time_ms: 1.308\n",
      "    num_steps_sampled: 4970000\n",
      "    num_steps_trained: 4970000\n",
      "    sample_time_ms: 15985.309\n",
      "    update_time_ms: 4.293\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8865.784909248352\n",
      "  time_this_iter_s: 17.67824363708496\n",
      "  time_total_s: 8865.784909248352\n",
      "  timestamp: 1550625301\n",
      "  timesteps_since_restore: 4970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4970000\n",
      "  training_iteration: 497\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8865 s, 497 iter, 4970000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-15-19\n",
      "  done: false\n",
      "  episode_len_mean: 130.57\n",
      "  episode_reward_max: 215.61569918614657\n",
      "  episode_reward_mean: 165.2971636239351\n",
      "  episode_reward_min: -45.969457904891215\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 38132\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0014915466308594\n",
      "      kl: 0.0166518222540617\n",
      "      policy_loss: -0.00029706821078434587\n",
      "      total_loss: 53.86492919921875\n",
      "      vf_explained_var: 0.9809232950210571\n",
      "      vf_loss: 53.86522674560547\n",
      "    grad_time_ms: 1562.247\n",
      "    load_time_ms: 1.296\n",
      "    num_steps_sampled: 4980000\n",
      "    num_steps_trained: 4980000\n",
      "    sample_time_ms: 15973.815\n",
      "    update_time_ms: 4.371\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8883.345823764801\n",
      "  time_this_iter_s: 17.560914516448975\n",
      "  time_total_s: 8883.345823764801\n",
      "  timestamp: 1550625319\n",
      "  timesteps_since_restore: 4980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4980000\n",
      "  training_iteration: 498\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8883 s, 498 iter, 4980000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 126.61\n",
      "  episode_reward_max: 215.61569918614657\n",
      "  episode_reward_mean: 158.69863489066518\n",
      "  episode_reward_min: -48.578132437376105\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 38213\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8643442392349243\n",
      "      kl: 0.02198689803481102\n",
      "      policy_loss: 0.0021134100388735533\n",
      "      total_loss: 66.55303192138672\n",
      "      vf_explained_var: 0.9795697331428528\n",
      "      vf_loss: 66.55093383789062\n",
      "    grad_time_ms: 1560.564\n",
      "    load_time_ms: 1.341\n",
      "    num_steps_sampled: 4990000\n",
      "    num_steps_trained: 4990000\n",
      "    sample_time_ms: 16032.997\n",
      "    update_time_ms: 4.32\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8901.571231126785\n",
      "  time_this_iter_s: 18.225407361984253\n",
      "  time_total_s: 8901.571231126785\n",
      "  timestamp: 1550625337\n",
      "  timesteps_since_restore: 4990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4990000\n",
      "  training_iteration: 499\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8901 s, 499 iter, 4990000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-15-55\n",
      "  done: false\n",
      "  episode_len_mean: 128.0\n",
      "  episode_reward_max: 203.95190803042726\n",
      "  episode_reward_mean: 160.50514823929223\n",
      "  episode_reward_min: -45.44836499372328\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 38290\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.043588161468506\n",
      "      kl: 0.020664146170020103\n",
      "      policy_loss: -0.0016665844013914466\n",
      "      total_loss: 41.36292266845703\n",
      "      vf_explained_var: 0.985921323299408\n",
      "      vf_loss: 41.364593505859375\n",
      "    grad_time_ms: 1558.873\n",
      "    load_time_ms: 1.34\n",
      "    num_steps_sampled: 5000000\n",
      "    num_steps_trained: 5000000\n",
      "    sample_time_ms: 16029.934\n",
      "    update_time_ms: 4.321\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8918.959918260574\n",
      "  time_this_iter_s: 17.388687133789062\n",
      "  time_total_s: 8918.959918260574\n",
      "  timestamp: 1550625355\n",
      "  timesteps_since_restore: 5000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5000000\n",
      "  training_iteration: 500\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8918 s, 500 iter, 5000000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-16-13\n",
      "  done: false\n",
      "  episode_len_mean: 128.34\n",
      "  episode_reward_max: 209.9994320978623\n",
      "  episode_reward_mean: 158.66700771859286\n",
      "  episode_reward_min: -49.611117878025134\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 38367\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0108859539031982\n",
      "      kl: 0.015896325930953026\n",
      "      policy_loss: -0.0008115473319776356\n",
      "      total_loss: 56.37446975708008\n",
      "      vf_explained_var: 0.9814581274986267\n",
      "      vf_loss: 56.37528610229492\n",
      "    grad_time_ms: 1557.901\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 5010000\n",
      "    num_steps_trained: 5010000\n",
      "    sample_time_ms: 16049.766\n",
      "    update_time_ms: 4.348\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8936.816462993622\n",
      "  time_this_iter_s: 17.856544733047485\n",
      "  time_total_s: 8936.816462993622\n",
      "  timestamp: 1550625373\n",
      "  timesteps_since_restore: 5010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5010000\n",
      "  training_iteration: 501\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8936 s, 501 iter, 5010000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 128.13\n",
      "  episode_reward_max: 202.7279250399016\n",
      "  episode_reward_mean: 162.394450802136\n",
      "  episode_reward_min: -43.13302536928417\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 38446\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.887595772743225\n",
      "      kl: 0.03483618423342705\n",
      "      policy_loss: 0.003805371467024088\n",
      "      total_loss: 75.95787048339844\n",
      "      vf_explained_var: 0.9753103852272034\n",
      "      vf_loss: 75.95407104492188\n",
      "    grad_time_ms: 1559.283\n",
      "    load_time_ms: 1.39\n",
      "    num_steps_sampled: 5020000\n",
      "    num_steps_trained: 5020000\n",
      "    sample_time_ms: 16030.226\n",
      "    update_time_ms: 4.335\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8954.137728691101\n",
      "  time_this_iter_s: 17.321265697479248\n",
      "  time_total_s: 8954.137728691101\n",
      "  timestamp: 1550625390\n",
      "  timesteps_since_restore: 5020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5020000\n",
      "  training_iteration: 502\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8954 s, 502 iter, 5020000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-16-48\n",
      "  done: false\n",
      "  episode_len_mean: 129.92\n",
      "  episode_reward_max: 209.13850578864896\n",
      "  episode_reward_mean: 166.52005803593877\n",
      "  episode_reward_min: -43.13302536928417\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 38523\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8977081775665283\n",
      "      kl: 0.015076114796102047\n",
      "      policy_loss: 0.00015145349607337266\n",
      "      total_loss: 14.49447250366211\n",
      "      vf_explained_var: 0.9946708679199219\n",
      "      vf_loss: 14.494321823120117\n",
      "    grad_time_ms: 1557.545\n",
      "    load_time_ms: 1.352\n",
      "    num_steps_sampled: 5030000\n",
      "    num_steps_trained: 5030000\n",
      "    sample_time_ms: 16002.092\n",
      "    update_time_ms: 4.313\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8971.690097093582\n",
      "  time_this_iter_s: 17.55236840248108\n",
      "  time_total_s: 8971.690097093582\n",
      "  timestamp: 1550625408\n",
      "  timesteps_since_restore: 5030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5030000\n",
      "  training_iteration: 503\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8971 s, 503 iter, 5030000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-17-05\n",
      "  done: false\n",
      "  episode_len_mean: 128.9\n",
      "  episode_reward_max: 215.86940262828136\n",
      "  episode_reward_mean: 165.63821688325206\n",
      "  episode_reward_min: -46.10464974854251\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 38600\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9113818407058716\n",
      "      kl: 0.03537359461188316\n",
      "      policy_loss: 0.0005685598007403314\n",
      "      total_loss: 73.62326049804688\n",
      "      vf_explained_var: 0.9748160243034363\n",
      "      vf_loss: 73.62268829345703\n",
      "    grad_time_ms: 1553.783\n",
      "    load_time_ms: 1.354\n",
      "    num_steps_sampled: 5040000\n",
      "    num_steps_trained: 5040000\n",
      "    sample_time_ms: 16047.767\n",
      "    update_time_ms: 4.317\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 8989.320367097855\n",
      "  time_this_iter_s: 17.63027000427246\n",
      "  time_total_s: 8989.320367097855\n",
      "  timestamp: 1550625425\n",
      "  timesteps_since_restore: 5040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5040000\n",
      "  training_iteration: 504\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 8989 s, 504 iter, 5040000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-17-22\n",
      "  done: false\n",
      "  episode_len_mean: 127.9\n",
      "  episode_reward_max: 200.7625771054244\n",
      "  episode_reward_mean: 155.61518578736445\n",
      "  episode_reward_min: -50.20481378002331\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 38679\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9530881643295288\n",
      "      kl: 0.018278280273079872\n",
      "      policy_loss: -0.003055951092392206\n",
      "      total_loss: 85.41859436035156\n",
      "      vf_explained_var: 0.9725953340530396\n",
      "      vf_loss: 85.42164611816406\n",
      "    grad_time_ms: 1555.451\n",
      "    load_time_ms: 1.354\n",
      "    num_steps_sampled: 5050000\n",
      "    num_steps_trained: 5050000\n",
      "    sample_time_ms: 15997.092\n",
      "    update_time_ms: 4.368\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9006.439156770706\n",
      "  time_this_iter_s: 17.118789672851562\n",
      "  time_total_s: 9006.439156770706\n",
      "  timestamp: 1550625442\n",
      "  timesteps_since_restore: 5050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5050000\n",
      "  training_iteration: 505\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9006 s, 505 iter, 5050000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-17-40\n",
      "  done: false\n",
      "  episode_len_mean: 126.15\n",
      "  episode_reward_max: 207.36302144869705\n",
      "  episode_reward_mean: 157.2090356823581\n",
      "  episode_reward_min: -45.93220388815545\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 38758\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.870836853981018\n",
      "      kl: 0.016591588035225868\n",
      "      policy_loss: 0.0005091596976853907\n",
      "      total_loss: 64.93994903564453\n",
      "      vf_explained_var: 0.9789527654647827\n",
      "      vf_loss: 64.93944549560547\n",
      "    grad_time_ms: 1547.621\n",
      "    load_time_ms: 1.337\n",
      "    num_steps_sampled: 5060000\n",
      "    num_steps_trained: 5060000\n",
      "    sample_time_ms: 16058.322\n",
      "    update_time_ms: 4.471\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9024.35432934761\n",
      "  time_this_iter_s: 17.915172576904297\n",
      "  time_total_s: 9024.35432934761\n",
      "  timestamp: 1550625460\n",
      "  timesteps_since_restore: 5060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5060000\n",
      "  training_iteration: 506\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9024 s, 506 iter, 5060000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-17-58\n",
      "  done: false\n",
      "  episode_len_mean: 127.14\n",
      "  episode_reward_max: 209.2474066466832\n",
      "  episode_reward_mean: 159.3464191954745\n",
      "  episode_reward_min: -49.75490721691364\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 38838\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9957470893859863\n",
      "      kl: 0.014404882676899433\n",
      "      policy_loss: -0.001079401234164834\n",
      "      total_loss: 47.41787338256836\n",
      "      vf_explained_var: 0.9851373434066772\n",
      "      vf_loss: 47.41895294189453\n",
      "    grad_time_ms: 1541.702\n",
      "    load_time_ms: 1.372\n",
      "    num_steps_sampled: 5070000\n",
      "    num_steps_trained: 5070000\n",
      "    sample_time_ms: 16035.669\n",
      "    update_time_ms: 4.417\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9041.74583530426\n",
      "  time_this_iter_s: 17.39150595664978\n",
      "  time_total_s: 9041.74583530426\n",
      "  timestamp: 1550625478\n",
      "  timesteps_since_restore: 5070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5070000\n",
      "  training_iteration: 507\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9041 s, 507 iter, 5070000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-18-15\n",
      "  done: false\n",
      "  episode_len_mean: 128.22\n",
      "  episode_reward_max: 202.97047725437878\n",
      "  episode_reward_mean: 163.17896809174613\n",
      "  episode_reward_min: -43.569962096391336\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 38915\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.971899390220642\n",
      "      kl: 0.03425786271691322\n",
      "      policy_loss: 0.0021234052255749702\n",
      "      total_loss: 50.531497955322266\n",
      "      vf_explained_var: 0.9814860820770264\n",
      "      vf_loss: 50.52937698364258\n",
      "    grad_time_ms: 1543.717\n",
      "    load_time_ms: 1.336\n",
      "    num_steps_sampled: 5080000\n",
      "    num_steps_trained: 5080000\n",
      "    sample_time_ms: 15992.095\n",
      "    update_time_ms: 4.357\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9058.888873815536\n",
      "  time_this_iter_s: 17.143038511276245\n",
      "  time_total_s: 9058.888873815536\n",
      "  timestamp: 1550625495\n",
      "  timesteps_since_restore: 5080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5080000\n",
      "  training_iteration: 508\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9058 s, 508 iter, 5080000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-18-33\n",
      "  done: false\n",
      "  episode_len_mean: 128.55\n",
      "  episode_reward_max: 208.55150721008243\n",
      "  episode_reward_mean: 159.8485648457859\n",
      "  episode_reward_min: -45.21448056960459\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 38993\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9291547536849976\n",
      "      kl: 0.013770508579909801\n",
      "      policy_loss: -0.00148413993883878\n",
      "      total_loss: 62.05989074707031\n",
      "      vf_explained_var: 0.9825029373168945\n",
      "      vf_loss: 62.06136703491211\n",
      "    grad_time_ms: 1543.411\n",
      "    load_time_ms: 1.342\n",
      "    num_steps_sampled: 5090000\n",
      "    num_steps_trained: 5090000\n",
      "    sample_time_ms: 15927.3\n",
      "    update_time_ms: 4.408\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9076.461658239365\n",
      "  time_this_iter_s: 17.572784423828125\n",
      "  time_total_s: 9076.461658239365\n",
      "  timestamp: 1550625513\n",
      "  timesteps_since_restore: 5090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5090000\n",
      "  training_iteration: 509\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9076 s, 509 iter, 5090000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-18-50\n",
      "  done: false\n",
      "  episode_len_mean: 134.83\n",
      "  episode_reward_max: 208.55150721008243\n",
      "  episode_reward_mean: 161.88966066851123\n",
      "  episode_reward_min: -45.21448056960459\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 39066\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0763585567474365\n",
      "      kl: 0.01804826594889164\n",
      "      policy_loss: -0.0028166798874735832\n",
      "      total_loss: 60.41039276123047\n",
      "      vf_explained_var: 0.9807168841362\n",
      "      vf_loss: 60.413211822509766\n",
      "    grad_time_ms: 1541.184\n",
      "    load_time_ms: 1.342\n",
      "    num_steps_sampled: 5100000\n",
      "    num_steps_trained: 5100000\n",
      "    sample_time_ms: 15934.603\n",
      "    update_time_ms: 4.389\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9093.90086722374\n",
      "  time_this_iter_s: 17.439208984375\n",
      "  time_total_s: 9093.90086722374\n",
      "  timestamp: 1550625530\n",
      "  timesteps_since_restore: 5100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5100000\n",
      "  training_iteration: 510\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9093 s, 510 iter, 5100000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-19-07\n",
      "  done: false\n",
      "  episode_len_mean: 126.56\n",
      "  episode_reward_max: 209.67330265723834\n",
      "  episode_reward_mean: 160.5187531765669\n",
      "  episode_reward_min: -39.6976975372227\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 39145\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7676012516021729\n",
      "      kl: 0.03892306610941887\n",
      "      policy_loss: 0.005758336279541254\n",
      "      total_loss: 39.124393463134766\n",
      "      vf_explained_var: 0.9869086146354675\n",
      "      vf_loss: 39.1186408996582\n",
      "    grad_time_ms: 1542.672\n",
      "    load_time_ms: 1.388\n",
      "    num_steps_sampled: 5110000\n",
      "    num_steps_trained: 5110000\n",
      "    sample_time_ms: 15884.925\n",
      "    update_time_ms: 4.443\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9111.278932094574\n",
      "  time_this_iter_s: 17.37806487083435\n",
      "  time_total_s: 9111.278932094574\n",
      "  timestamp: 1550625547\n",
      "  timesteps_since_restore: 5110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5110000\n",
      "  training_iteration: 511\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9111 s, 511 iter, 5110000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-19-25\n",
      "  done: false\n",
      "  episode_len_mean: 127.79\n",
      "  episode_reward_max: 206.87648603880746\n",
      "  episode_reward_mean: 162.7557194274011\n",
      "  episode_reward_min: -42.763970637085414\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 39224\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9607431888580322\n",
      "      kl: 0.029699781909585\n",
      "      policy_loss: -0.0024250263813883066\n",
      "      total_loss: 105.76780700683594\n",
      "      vf_explained_var: 0.9618582129478455\n",
      "      vf_loss: 105.77024841308594\n",
      "    grad_time_ms: 1541.955\n",
      "    load_time_ms: 1.359\n",
      "    num_steps_sampled: 5120000\n",
      "    num_steps_trained: 5120000\n",
      "    sample_time_ms: 15885.853\n",
      "    update_time_ms: 4.341\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9128.598147392273\n",
      "  time_this_iter_s: 17.319215297698975\n",
      "  time_total_s: 9128.598147392273\n",
      "  timestamp: 1550625565\n",
      "  timesteps_since_restore: 5120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5120000\n",
      "  training_iteration: 512\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9128 s, 512 iter, 5120000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-19-42\n",
      "  done: false\n",
      "  episode_len_mean: 127.92\n",
      "  episode_reward_max: 205.9873846092142\n",
      "  episode_reward_mean: 156.17707416876524\n",
      "  episode_reward_min: -45.195925627604545\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39301\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0154318809509277\n",
      "      kl: 0.020031021907925606\n",
      "      policy_loss: 0.00209719967097044\n",
      "      total_loss: 103.0621337890625\n",
      "      vf_explained_var: 0.9682275056838989\n",
      "      vf_loss: 103.0600357055664\n",
      "    grad_time_ms: 1541.988\n",
      "    load_time_ms: 1.362\n",
      "    num_steps_sampled: 5130000\n",
      "    num_steps_trained: 5130000\n",
      "    sample_time_ms: 15842.87\n",
      "    update_time_ms: 4.362\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9145.721584558487\n",
      "  time_this_iter_s: 17.12343716621399\n",
      "  time_total_s: 9145.721584558487\n",
      "  timestamp: 1550625582\n",
      "  timesteps_since_restore: 5130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5130000\n",
      "  training_iteration: 513\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9145 s, 513 iter, 5130000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-19-59\n",
      "  done: false\n",
      "  episode_len_mean: 132.0\n",
      "  episode_reward_max: 204.77485974351777\n",
      "  episode_reward_mean: 162.8118747985707\n",
      "  episode_reward_min: -45.19095982655439\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 39377\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0061044692993164\n",
      "      kl: 0.03988519310951233\n",
      "      policy_loss: 0.008573629893362522\n",
      "      total_loss: 60.336639404296875\n",
      "      vf_explained_var: 0.9796954393386841\n",
      "      vf_loss: 60.32805633544922\n",
      "    grad_time_ms: 1543.139\n",
      "    load_time_ms: 1.406\n",
      "    num_steps_sampled: 5140000\n",
      "    num_steps_trained: 5140000\n",
      "    sample_time_ms: 15763.867\n",
      "    update_time_ms: 4.324\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9162.573749303818\n",
      "  time_this_iter_s: 16.85216474533081\n",
      "  time_total_s: 9162.573749303818\n",
      "  timestamp: 1550625599\n",
      "  timesteps_since_restore: 5140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5140000\n",
      "  training_iteration: 514\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9162 s, 514 iter, 5140000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-20-16\n",
      "  done: false\n",
      "  episode_len_mean: 131.16\n",
      "  episode_reward_max: 214.6112330143551\n",
      "  episode_reward_mean: 166.93209548314843\n",
      "  episode_reward_min: -49.07652673560497\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39454\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.08300518989563\n",
      "      kl: 0.014141212217509747\n",
      "      policy_loss: -0.00021713756723329425\n",
      "      total_loss: 20.551795959472656\n",
      "      vf_explained_var: 0.9924575686454773\n",
      "      vf_loss: 20.552017211914062\n",
      "    grad_time_ms: 1543.089\n",
      "    load_time_ms: 1.447\n",
      "    num_steps_sampled: 5150000\n",
      "    num_steps_trained: 5150000\n",
      "    sample_time_ms: 15721.412\n",
      "    update_time_ms: 4.327\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9179.269563674927\n",
      "  time_this_iter_s: 16.69581437110901\n",
      "  time_total_s: 9179.269563674927\n",
      "  timestamp: 1550625616\n",
      "  timesteps_since_restore: 5150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5150000\n",
      "  training_iteration: 515\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9179 s, 515 iter, 5150000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-20-32\n",
      "  done: false\n",
      "  episode_len_mean: 130.19\n",
      "  episode_reward_max: 216.05584967785555\n",
      "  episode_reward_mean: 162.46930376722568\n",
      "  episode_reward_min: -49.967755746428324\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39531\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0643863677978516\n",
      "      kl: 0.011390572413802147\n",
      "      policy_loss: -0.0034449046943336725\n",
      "      total_loss: 43.84958267211914\n",
      "      vf_explained_var: 0.9852494597434998\n",
      "      vf_loss: 43.853023529052734\n",
      "    grad_time_ms: 1543.51\n",
      "    load_time_ms: 1.406\n",
      "    num_steps_sampled: 5160000\n",
      "    num_steps_trained: 5160000\n",
      "    sample_time_ms: 15617.142\n",
      "    update_time_ms: 4.258\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9196.143516778946\n",
      "  time_this_iter_s: 16.873953104019165\n",
      "  time_total_s: 9196.143516778946\n",
      "  timestamp: 1550625632\n",
      "  timesteps_since_restore: 5160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5160000\n",
      "  training_iteration: 516\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9196 s, 516 iter, 5160000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-20-49\n",
      "  done: false\n",
      "  episode_len_mean: 128.72\n",
      "  episode_reward_max: 207.68448759438363\n",
      "  episode_reward_mean: 161.495531650832\n",
      "  episode_reward_min: -48.51710667247227\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39608\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9163336753845215\n",
      "      kl: 0.01571754179894924\n",
      "      policy_loss: 0.0003594402805902064\n",
      "      total_loss: 51.386131286621094\n",
      "      vf_explained_var: 0.9825781583786011\n",
      "      vf_loss: 51.385772705078125\n",
      "    grad_time_ms: 1545.024\n",
      "    load_time_ms: 1.365\n",
      "    num_steps_sampled: 5170000\n",
      "    num_steps_trained: 5170000\n",
      "    sample_time_ms: 15574.912\n",
      "    update_time_ms: 4.207\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9213.12735748291\n",
      "  time_this_iter_s: 16.983840703964233\n",
      "  time_total_s: 9213.12735748291\n",
      "  timestamp: 1550625649\n",
      "  timesteps_since_restore: 5170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5170000\n",
      "  training_iteration: 517\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9213 s, 517 iter, 5170000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-21-07\n",
      "  done: false\n",
      "  episode_len_mean: 132.3\n",
      "  episode_reward_max: 212.86890435196693\n",
      "  episode_reward_mean: 167.11459576756278\n",
      "  episode_reward_min: -39.91078559714968\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 39683\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.087228536605835\n",
      "      kl: 0.018024496734142303\n",
      "      policy_loss: -0.0005633167456835508\n",
      "      total_loss: 23.65425682067871\n",
      "      vf_explained_var: 0.992122232913971\n",
      "      vf_loss: 23.65481948852539\n",
      "    grad_time_ms: 1542.176\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 5180000\n",
      "    num_steps_trained: 5180000\n",
      "    sample_time_ms: 15596.023\n",
      "    update_time_ms: 4.209\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9230.454777240753\n",
      "  time_this_iter_s: 17.327419757843018\n",
      "  time_total_s: 9230.454777240753\n",
      "  timestamp: 1550625667\n",
      "  timesteps_since_restore: 5180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5180000\n",
      "  training_iteration: 518\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9230 s, 518 iter, 5180000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-21-24\n",
      "  done: false\n",
      "  episode_len_mean: 130.06\n",
      "  episode_reward_max: 206.33207483515883\n",
      "  episode_reward_mean: 163.51457037640796\n",
      "  episode_reward_min: -48.44632042173556\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39760\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9887014627456665\n",
      "      kl: 0.013248845934867859\n",
      "      policy_loss: 0.0011367601109668612\n",
      "      total_loss: 44.799652099609375\n",
      "      vf_explained_var: 0.9850720167160034\n",
      "      vf_loss: 44.79851150512695\n",
      "    grad_time_ms: 1555.868\n",
      "    load_time_ms: 1.393\n",
      "    num_steps_sampled: 5190000\n",
      "    num_steps_trained: 5190000\n",
      "    sample_time_ms: 15576.709\n",
      "    update_time_ms: 4.18\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9247.968750238419\n",
      "  time_this_iter_s: 17.513972997665405\n",
      "  time_total_s: 9247.968750238419\n",
      "  timestamp: 1550625684\n",
      "  timesteps_since_restore: 5190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5190000\n",
      "  training_iteration: 519\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9247 s, 519 iter, 5190000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-21-42\n",
      "  done: false\n",
      "  episode_len_mean: 128.44\n",
      "  episode_reward_max: 207.86804119386875\n",
      "  episode_reward_mean: 157.0852469199175\n",
      "  episode_reward_min: -48.44632042173556\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39837\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.000957727432251\n",
      "      kl: 0.013669510371983051\n",
      "      policy_loss: 0.0015704425750300288\n",
      "      total_loss: 50.91519546508789\n",
      "      vf_explained_var: 0.9807862639427185\n",
      "      vf_loss: 50.91361618041992\n",
      "    grad_time_ms: 1557.966\n",
      "    load_time_ms: 1.396\n",
      "    num_steps_sampled: 5200000\n",
      "    num_steps_trained: 5200000\n",
      "    sample_time_ms: 15583.477\n",
      "    update_time_ms: 4.141\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9265.497983455658\n",
      "  time_this_iter_s: 17.52923321723938\n",
      "  time_total_s: 9265.497983455658\n",
      "  timestamp: 1550625702\n",
      "  timesteps_since_restore: 5200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5200000\n",
      "  training_iteration: 520\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9265 s, 520 iter, 5200000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-21-59\n",
      "  done: false\n",
      "  episode_len_mean: 128.92\n",
      "  episode_reward_max: 211.7234901858144\n",
      "  episode_reward_mean: 160.67249636309353\n",
      "  episode_reward_min: -45.083853194914255\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 39915\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9296300411224365\n",
      "      kl: 0.027933746576309204\n",
      "      policy_loss: -0.001818750868551433\n",
      "      total_loss: 76.18260192871094\n",
      "      vf_explained_var: 0.9754403829574585\n",
      "      vf_loss: 76.1844253540039\n",
      "    grad_time_ms: 1557.188\n",
      "    load_time_ms: 1.327\n",
      "    num_steps_sampled: 5210000\n",
      "    num_steps_trained: 5210000\n",
      "    sample_time_ms: 15574.246\n",
      "    update_time_ms: 4.137\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9282.771824121475\n",
      "  time_this_iter_s: 17.27384066581726\n",
      "  time_total_s: 9282.771824121475\n",
      "  timestamp: 1550625719\n",
      "  timesteps_since_restore: 5210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5210000\n",
      "  training_iteration: 521\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9282 s, 521 iter, 5210000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-22-17\n",
      "  done: false\n",
      "  episode_len_mean: 128.55\n",
      "  episode_reward_max: 207.2065916486306\n",
      "  episode_reward_mean: 161.33645067155837\n",
      "  episode_reward_min: -47.91307475528504\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39992\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0253806114196777\n",
      "      kl: 0.01725773513317108\n",
      "      policy_loss: -0.000808139331638813\n",
      "      total_loss: 38.73173141479492\n",
      "      vf_explained_var: 0.9865896701812744\n",
      "      vf_loss: 38.73253631591797\n",
      "    grad_time_ms: 1556.898\n",
      "    load_time_ms: 1.38\n",
      "    num_steps_sampled: 5220000\n",
      "    num_steps_trained: 5220000\n",
      "    sample_time_ms: 15628.911\n",
      "    update_time_ms: 4.391\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9300.638513326645\n",
      "  time_this_iter_s: 17.866689205169678\n",
      "  time_total_s: 9300.638513326645\n",
      "  timestamp: 1550625737\n",
      "  timesteps_since_restore: 5220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5220000\n",
      "  training_iteration: 522\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9300 s, 522 iter, 5220000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-22-35\n",
      "  done: false\n",
      "  episode_len_mean: 128.98\n",
      "  episode_reward_max: 204.887763680171\n",
      "  episode_reward_mean: 165.6148262628511\n",
      "  episode_reward_min: -44.64171419403343\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 40071\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.850962519645691\n",
      "      kl: 0.03938129171729088\n",
      "      policy_loss: -0.001429439871571958\n",
      "      total_loss: 136.3807373046875\n",
      "      vf_explained_var: 0.9598515629768372\n",
      "      vf_loss: 136.38217163085938\n",
      "    grad_time_ms: 1557.599\n",
      "    load_time_ms: 1.374\n",
      "    num_steps_sampled: 5230000\n",
      "    num_steps_trained: 5230000\n",
      "    sample_time_ms: 15702.911\n",
      "    update_time_ms: 4.457\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9318.509600162506\n",
      "  time_this_iter_s: 17.871086835861206\n",
      "  time_total_s: 9318.509600162506\n",
      "  timestamp: 1550625755\n",
      "  timesteps_since_restore: 5230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5230000\n",
      "  training_iteration: 523\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9318 s, 523 iter, 5230000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-22-52\n",
      "  done: false\n",
      "  episode_len_mean: 127.88\n",
      "  episode_reward_max: 223.65641923160257\n",
      "  episode_reward_mean: 166.11211578790474\n",
      "  episode_reward_min: -44.64171419403343\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40148\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7432106733322144\n",
      "      kl: 0.014626100659370422\n",
      "      policy_loss: -0.0018618118483573198\n",
      "      total_loss: 42.8074836730957\n",
      "      vf_explained_var: 0.9859294295310974\n",
      "      vf_loss: 42.80934524536133\n",
      "    grad_time_ms: 1558.348\n",
      "    load_time_ms: 1.38\n",
      "    num_steps_sampled: 5240000\n",
      "    num_steps_trained: 5240000\n",
      "    sample_time_ms: 15710.941\n",
      "    update_time_ms: 4.523\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9335.45148730278\n",
      "  time_this_iter_s: 16.941887140274048\n",
      "  time_total_s: 9335.45148730278\n",
      "  timestamp: 1550625772\n",
      "  timesteps_since_restore: 5240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5240000\n",
      "  training_iteration: 524\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9335 s, 524 iter, 5240000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-23-09\n",
      "  done: false\n",
      "  episode_len_mean: 131.52\n",
      "  episode_reward_max: 223.65641923160257\n",
      "  episode_reward_mean: 164.60170921765916\n",
      "  episode_reward_min: -42.942069783511705\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40224\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.117790937423706\n",
      "      kl: 0.017292728647589684\n",
      "      policy_loss: 0.0010725186439231038\n",
      "      total_loss: 66.3231201171875\n",
      "      vf_explained_var: 0.9778309464454651\n",
      "      vf_loss: 66.32205963134766\n",
      "    grad_time_ms: 1558.1\n",
      "    load_time_ms: 1.372\n",
      "    num_steps_sampled: 5250000\n",
      "    num_steps_trained: 5250000\n",
      "    sample_time_ms: 15772.31\n",
      "    update_time_ms: 4.658\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9352.758576154709\n",
      "  time_this_iter_s: 17.30708885192871\n",
      "  time_total_s: 9352.758576154709\n",
      "  timestamp: 1550625789\n",
      "  timesteps_since_restore: 5250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5250000\n",
      "  training_iteration: 525\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9352 s, 525 iter, 5250000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-23-27\n",
      "  done: false\n",
      "  episode_len_mean: 131.1\n",
      "  episode_reward_max: 207.19549281577952\n",
      "  episode_reward_mean: 166.51888892338783\n",
      "  episode_reward_min: -42.99977084581214\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40301\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.858668565750122\n",
      "      kl: 0.021860238164663315\n",
      "      policy_loss: 0.0037636947818100452\n",
      "      total_loss: 27.361270904541016\n",
      "      vf_explained_var: 0.9911843538284302\n",
      "      vf_loss: 27.35750961303711\n",
      "    grad_time_ms: 1558.101\n",
      "    load_time_ms: 1.375\n",
      "    num_steps_sampled: 5260000\n",
      "    num_steps_trained: 5260000\n",
      "    sample_time_ms: 15813.1\n",
      "    update_time_ms: 4.646\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9370.040621995926\n",
      "  time_this_iter_s: 17.28204584121704\n",
      "  time_total_s: 9370.040621995926\n",
      "  timestamp: 1550625807\n",
      "  timesteps_since_restore: 5260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5260000\n",
      "  training_iteration: 526\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9370 s, 526 iter, 5260000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-23-44\n",
      "  done: false\n",
      "  episode_len_mean: 130.09\n",
      "  episode_reward_max: 210.8330409227325\n",
      "  episode_reward_mean: 161.08910884049354\n",
      "  episode_reward_min: -44.11608019825255\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40377\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.974526047706604\n",
      "      kl: 0.03321002423763275\n",
      "      policy_loss: -0.004471011459827423\n",
      "      total_loss: 77.23619079589844\n",
      "      vf_explained_var: 0.9761505126953125\n",
      "      vf_loss: 77.24066162109375\n",
      "    grad_time_ms: 1560.032\n",
      "    load_time_ms: 1.373\n",
      "    num_steps_sampled: 5270000\n",
      "    num_steps_trained: 5270000\n",
      "    sample_time_ms: 15823.962\n",
      "    update_time_ms: 4.628\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9387.152759313583\n",
      "  time_this_iter_s: 17.11213731765747\n",
      "  time_total_s: 9387.152759313583\n",
      "  timestamp: 1550625824\n",
      "  timesteps_since_restore: 5270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5270000\n",
      "  training_iteration: 527\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9387 s, 527 iter, 5270000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-24-01\n",
      "  done: false\n",
      "  episode_len_mean: 132.98\n",
      "  episode_reward_max: 222.28559729294608\n",
      "  episode_reward_mean: 168.6212407159436\n",
      "  episode_reward_min: -45.808827380290126\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40453\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9656784534454346\n",
      "      kl: 0.014961113221943378\n",
      "      policy_loss: -0.001998236635699868\n",
      "      total_loss: 54.754676818847656\n",
      "      vf_explained_var: 0.9848073124885559\n",
      "      vf_loss: 54.75668716430664\n",
      "    grad_time_ms: 1560.982\n",
      "    load_time_ms: 1.329\n",
      "    num_steps_sampled: 5280000\n",
      "    num_steps_trained: 5280000\n",
      "    sample_time_ms: 15820.406\n",
      "    update_time_ms: 4.555\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9404.451537132263\n",
      "  time_this_iter_s: 17.29877781867981\n",
      "  time_total_s: 9404.451537132263\n",
      "  timestamp: 1550625841\n",
      "  timesteps_since_restore: 5280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5280000\n",
      "  training_iteration: 528\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9404 s, 528 iter, 5280000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-24-18\n",
      "  done: false\n",
      "  episode_len_mean: 130.54\n",
      "  episode_reward_max: 209.8114535640371\n",
      "  episode_reward_mean: 169.33886884336903\n",
      "  episode_reward_min: -45.808827380290126\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40530\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9253076314926147\n",
      "      kl: 0.013115043751895428\n",
      "      policy_loss: -0.00040414585964754224\n",
      "      total_loss: 25.230562210083008\n",
      "      vf_explained_var: 0.9917250275611877\n",
      "      vf_loss: 25.23096466064453\n",
      "    grad_time_ms: 1548.131\n",
      "    load_time_ms: 1.303\n",
      "    num_steps_sampled: 5290000\n",
      "    num_steps_trained: 5290000\n",
      "    sample_time_ms: 15738.266\n",
      "    update_time_ms: 4.677\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9421.01764369011\n",
      "  time_this_iter_s: 16.56610655784607\n",
      "  time_total_s: 9421.01764369011\n",
      "  timestamp: 1550625858\n",
      "  timesteps_since_restore: 5290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5290000\n",
      "  training_iteration: 529\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9421 s, 529 iter, 5290000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-24-35\n",
      "  done: false\n",
      "  episode_len_mean: 133.12\n",
      "  episode_reward_max: 203.4761798475859\n",
      "  episode_reward_mean: 167.21087320925565\n",
      "  episode_reward_min: -44.36241796114805\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 40604\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.1544606685638428\n",
      "      kl: 0.013911662623286247\n",
      "      policy_loss: -0.0009377828100696206\n",
      "      total_loss: 23.07005500793457\n",
      "      vf_explained_var: 0.9922204613685608\n",
      "      vf_loss: 23.070993423461914\n",
      "    grad_time_ms: 1547.609\n",
      "    load_time_ms: 1.386\n",
      "    num_steps_sampled: 5300000\n",
      "    num_steps_trained: 5300000\n",
      "    sample_time_ms: 15729.041\n",
      "    update_time_ms: 4.636\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9438.44989323616\n",
      "  time_this_iter_s: 17.432249546051025\n",
      "  time_total_s: 9438.44989323616\n",
      "  timestamp: 1550625875\n",
      "  timesteps_since_restore: 5300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5300000\n",
      "  training_iteration: 530\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9438 s, 530 iter, 5300000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-24-52\n",
      "  done: false\n",
      "  episode_len_mean: 132.92\n",
      "  episode_reward_max: 215.30863109408034\n",
      "  episode_reward_mean: 168.2295759175911\n",
      "  episode_reward_min: -47.245092952457995\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40680\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0114877223968506\n",
      "      kl: 0.01320753525942564\n",
      "      policy_loss: -0.0019811883103102446\n",
      "      total_loss: 33.47652053833008\n",
      "      vf_explained_var: 0.9883469939231873\n",
      "      vf_loss: 33.4785041809082\n",
      "    grad_time_ms: 1548.295\n",
      "    load_time_ms: 1.428\n",
      "    num_steps_sampled: 5310000\n",
      "    num_steps_trained: 5310000\n",
      "    sample_time_ms: 15694.009\n",
      "    update_time_ms: 4.62\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9455.383119344711\n",
      "  time_this_iter_s: 16.933226108551025\n",
      "  time_total_s: 9455.383119344711\n",
      "  timestamp: 1550625892\n",
      "  timesteps_since_restore: 5310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5310000\n",
      "  training_iteration: 531\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9455 s, 531 iter, 5310000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-25-10\n",
      "  done: false\n",
      "  episode_len_mean: 129.25\n",
      "  episode_reward_max: 216.52259931130578\n",
      "  episode_reward_mean: 165.53086122748638\n",
      "  episode_reward_min: -47.245092952457995\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40757\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9010614156723022\n",
      "      kl: 0.015342307277023792\n",
      "      policy_loss: 0.0015286284033209085\n",
      "      total_loss: 22.785675048828125\n",
      "      vf_explained_var: 0.992159903049469\n",
      "      vf_loss: 22.784149169921875\n",
      "    grad_time_ms: 1547.242\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 5320000\n",
      "    num_steps_trained: 5320000\n",
      "    sample_time_ms: 15701.978\n",
      "    update_time_ms: 4.455\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9473.318499088287\n",
      "  time_this_iter_s: 17.93537974357605\n",
      "  time_total_s: 9473.318499088287\n",
      "  timestamp: 1550625910\n",
      "  timesteps_since_restore: 5320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5320000\n",
      "  training_iteration: 532\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9473 s, 532 iter, 5320000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-25-28\n",
      "  done: false\n",
      "  episode_len_mean: 130.11\n",
      "  episode_reward_max: 216.52259931130578\n",
      "  episode_reward_mean: 165.12332896852485\n",
      "  episode_reward_min: -42.52161468831029\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40834\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8488324880599976\n",
      "      kl: 0.015220127068459988\n",
      "      policy_loss: -0.002020077547058463\n",
      "      total_loss: 62.79378128051758\n",
      "      vf_explained_var: 0.9801799058914185\n",
      "      vf_loss: 62.79580307006836\n",
      "    grad_time_ms: 1546.726\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 5330000\n",
      "    num_steps_trained: 5330000\n",
      "    sample_time_ms: 15659.704\n",
      "    update_time_ms: 4.387\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9490.76318693161\n",
      "  time_this_iter_s: 17.444687843322754\n",
      "  time_total_s: 9490.76318693161\n",
      "  timestamp: 1550625928\n",
      "  timesteps_since_restore: 5330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5330000\n",
      "  training_iteration: 533\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9490 s, 533 iter, 5330000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-25-45\n",
      "  done: false\n",
      "  episode_len_mean: 130.89\n",
      "  episode_reward_max: 212.32833040394996\n",
      "  episode_reward_mean: 166.28138582812363\n",
      "  episode_reward_min: -47.01101248394145\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40911\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0008904933929443\n",
      "      kl: 0.029018616303801537\n",
      "      policy_loss: -0.002305453410372138\n",
      "      total_loss: 55.88407516479492\n",
      "      vf_explained_var: 0.9810865521430969\n",
      "      vf_loss: 55.88638687133789\n",
      "    grad_time_ms: 1546.375\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 5340000\n",
      "    num_steps_trained: 5340000\n",
      "    sample_time_ms: 15714.41\n",
      "    update_time_ms: 4.345\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9508.249047279358\n",
      "  time_this_iter_s: 17.485860347747803\n",
      "  time_total_s: 9508.249047279358\n",
      "  timestamp: 1550625945\n",
      "  timesteps_since_restore: 5340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5340000\n",
      "  training_iteration: 534\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9508 s, 534 iter, 5340000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-26-03\n",
      "  done: false\n",
      "  episode_len_mean: 132.72\n",
      "  episode_reward_max: 212.32833040394996\n",
      "  episode_reward_mean: 170.6967706833324\n",
      "  episode_reward_min: -43.83870189083682\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 40986\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8817144632339478\n",
      "      kl: 0.029551075771450996\n",
      "      policy_loss: -0.000929150846786797\n",
      "      total_loss: 107.38639068603516\n",
      "      vf_explained_var: 0.9655972719192505\n",
      "      vf_loss: 107.3873062133789\n",
      "    grad_time_ms: 1545.229\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 5350000\n",
      "    num_steps_trained: 5350000\n",
      "    sample_time_ms: 15748.009\n",
      "    update_time_ms: 4.171\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9525.878859519958\n",
      "  time_this_iter_s: 17.629812240600586\n",
      "  time_total_s: 9525.878859519958\n",
      "  timestamp: 1550625963\n",
      "  timesteps_since_restore: 5350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5350000\n",
      "  training_iteration: 535\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9525 s, 535 iter, 5350000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-26-20\n",
      "  done: false\n",
      "  episode_len_mean: 127.14\n",
      "  episode_reward_max: 215.12565221844028\n",
      "  episode_reward_mean: 156.8857995431756\n",
      "  episode_reward_min: -46.175160498902336\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 41066\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.791372299194336\n",
      "      kl: 0.02672731876373291\n",
      "      policy_loss: -0.0029909436125308275\n",
      "      total_loss: 90.4225845336914\n",
      "      vf_explained_var: 0.9779196381568909\n",
      "      vf_loss: 90.42559051513672\n",
      "    grad_time_ms: 1545.356\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 5360000\n",
      "    num_steps_trained: 5360000\n",
      "    sample_time_ms: 15724.122\n",
      "    update_time_ms: 4.194\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9542.923258543015\n",
      "  time_this_iter_s: 17.04439902305603\n",
      "  time_total_s: 9542.923258543015\n",
      "  timestamp: 1550625980\n",
      "  timesteps_since_restore: 5360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5360000\n",
      "  training_iteration: 536\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9542 s, 536 iter, 5360000 ts, 157 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-26-37\n",
      "  done: false\n",
      "  episode_len_mean: 127.71\n",
      "  episode_reward_max: 210.3476425524395\n",
      "  episode_reward_mean: 162.8780685360295\n",
      "  episode_reward_min: -48.25352847118782\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 41144\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7140710353851318\n",
      "      kl: 0.02565322257578373\n",
      "      policy_loss: -0.0029113360214978456\n",
      "      total_loss: 71.76116943359375\n",
      "      vf_explained_var: 0.9788010716438293\n",
      "      vf_loss: 71.76407623291016\n",
      "    grad_time_ms: 1541.287\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 5370000\n",
      "    num_steps_trained: 5370000\n",
      "    sample_time_ms: 15749.032\n",
      "    update_time_ms: 4.3\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9560.246584177017\n",
      "  time_this_iter_s: 17.323325634002686\n",
      "  time_total_s: 9560.246584177017\n",
      "  timestamp: 1550625997\n",
      "  timesteps_since_restore: 5370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5370000\n",
      "  training_iteration: 537\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9560 s, 537 iter, 5370000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-26-55\n",
      "  done: false\n",
      "  episode_len_mean: 127.14\n",
      "  episode_reward_max: 217.40683843247092\n",
      "  episode_reward_mean: 160.73694003028945\n",
      "  episode_reward_min: -45.03238458968331\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 41222\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7783266305923462\n",
      "      kl: 0.021804818883538246\n",
      "      policy_loss: -0.003263654885813594\n",
      "      total_loss: 30.597612380981445\n",
      "      vf_explained_var: 0.9909210205078125\n",
      "      vf_loss: 30.60087013244629\n",
      "    grad_time_ms: 1539.22\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 5380000\n",
      "    num_steps_trained: 5380000\n",
      "    sample_time_ms: 15772.945\n",
      "    update_time_ms: 4.373\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9577.766487121582\n",
      "  time_this_iter_s: 17.51990294456482\n",
      "  time_total_s: 9577.766487121582\n",
      "  timestamp: 1550626015\n",
      "  timesteps_since_restore: 5380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5380000\n",
      "  training_iteration: 538\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9577 s, 538 iter, 5380000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-27-12\n",
      "  done: false\n",
      "  episode_len_mean: 130.41\n",
      "  episode_reward_max: 211.21200576852468\n",
      "  episode_reward_mean: 164.8852470284307\n",
      "  episode_reward_min: -46.61353458176448\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 41298\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.023073196411133\n",
      "      kl: 0.019603306427598\n",
      "      policy_loss: -0.003355917753651738\n",
      "      total_loss: 49.566585540771484\n",
      "      vf_explained_var: 0.9832890033721924\n",
      "      vf_loss: 49.569950103759766\n",
      "    grad_time_ms: 1536.959\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 5390000\n",
      "    num_steps_trained: 5390000\n",
      "    sample_time_ms: 15840.613\n",
      "    update_time_ms: 4.312\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9594.987119436264\n",
      "  time_this_iter_s: 17.220632314682007\n",
      "  time_total_s: 9594.987119436264\n",
      "  timestamp: 1550626032\n",
      "  timesteps_since_restore: 5390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5390000\n",
      "  training_iteration: 539\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9594 s, 539 iter, 5390000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-27-29\n",
      "  done: false\n",
      "  episode_len_mean: 130.87\n",
      "  episode_reward_max: 211.2159758334112\n",
      "  episode_reward_mean: 169.7248099742902\n",
      "  episode_reward_min: -47.26044062438355\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 41375\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7891302108764648\n",
      "      kl: 0.018863944336771965\n",
      "      policy_loss: 0.0005011047469452024\n",
      "      total_loss: 39.44660949707031\n",
      "      vf_explained_var: 0.9874264597892761\n",
      "      vf_loss: 39.446109771728516\n",
      "    grad_time_ms: 1538.669\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 5400000\n",
      "    num_steps_trained: 5400000\n",
      "    sample_time_ms: 15806.163\n",
      "    update_time_ms: 4.417\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9612.090913772583\n",
      "  time_this_iter_s: 17.10379433631897\n",
      "  time_total_s: 9612.090913772583\n",
      "  timestamp: 1550626049\n",
      "  timesteps_since_restore: 5400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5400000\n",
      "  training_iteration: 540\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9612 s, 540 iter, 5400000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-27-46\n",
      "  done: false\n",
      "  episode_len_mean: 129.64\n",
      "  episode_reward_max: 212.90234836294215\n",
      "  episode_reward_mean: 165.60388674859857\n",
      "  episode_reward_min: -48.69166979296964\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 41452\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8008050918579102\n",
      "      kl: 0.018814953044056892\n",
      "      policy_loss: -8.194224938051775e-05\n",
      "      total_loss: 52.250648498535156\n",
      "      vf_explained_var: 0.9842798113822937\n",
      "      vf_loss: 52.25072479248047\n",
      "    grad_time_ms: 1537.768\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 5410000\n",
      "    num_steps_trained: 5410000\n",
      "    sample_time_ms: 15823.998\n",
      "    update_time_ms: 4.402\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9629.192528247833\n",
      "  time_this_iter_s: 17.101614475250244\n",
      "  time_total_s: 9629.192528247833\n",
      "  timestamp: 1550626066\n",
      "  timesteps_since_restore: 5410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5410000\n",
      "  training_iteration: 541\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9629 s, 541 iter, 5410000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-28-03\n",
      "  done: false\n",
      "  episode_len_mean: 133.55\n",
      "  episode_reward_max: 219.07760208505815\n",
      "  episode_reward_mean: 172.92824855526527\n",
      "  episode_reward_min: 98.40042140150436\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 41527\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9419193267822266\n",
      "      kl: 0.01686980575323105\n",
      "      policy_loss: -0.0005031946348026395\n",
      "      total_loss: 22.726003646850586\n",
      "      vf_explained_var: 0.99234938621521\n",
      "      vf_loss: 22.72650909423828\n",
      "    grad_time_ms: 1539.445\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 5420000\n",
      "    num_steps_trained: 5420000\n",
      "    sample_time_ms: 15716.077\n",
      "    update_time_ms: 4.415\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9646.063167572021\n",
      "  time_this_iter_s: 16.870639324188232\n",
      "  time_total_s: 9646.063167572021\n",
      "  timestamp: 1550626083\n",
      "  timesteps_since_restore: 5420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5420000\n",
      "  training_iteration: 542\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9646 s, 542 iter, 5420000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-28-20\n",
      "  done: false\n",
      "  episode_len_mean: 132.42\n",
      "  episode_reward_max: 211.17706094623202\n",
      "  episode_reward_mean: 172.37807947544468\n",
      "  episode_reward_min: -35.0857104544002\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 41603\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.901993751525879\n",
      "      kl: 0.0356573723256588\n",
      "      policy_loss: 0.0020911446772515774\n",
      "      total_loss: 49.59290313720703\n",
      "      vf_explained_var: 0.9822542071342468\n",
      "      vf_loss: 49.59080505371094\n",
      "    grad_time_ms: 1538.896\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 5430000\n",
      "    num_steps_trained: 5430000\n",
      "    sample_time_ms: 15677.385\n",
      "    update_time_ms: 4.458\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9663.115171670914\n",
      "  time_this_iter_s: 17.052004098892212\n",
      "  time_total_s: 9663.115171670914\n",
      "  timestamp: 1550626100\n",
      "  timesteps_since_restore: 5430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5430000\n",
      "  training_iteration: 543\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9663 s, 543 iter, 5430000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-28-38\n",
      "  done: false\n",
      "  episode_len_mean: 130.91\n",
      "  episode_reward_max: 214.8201285760739\n",
      "  episode_reward_mean: 172.61146463055064\n",
      "  episode_reward_min: -39.133264685473804\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 41678\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.72344172000885\n",
      "      kl: 0.015524087473750114\n",
      "      policy_loss: -0.002415003487840295\n",
      "      total_loss: 27.457271575927734\n",
      "      vf_explained_var: 0.9907827973365784\n",
      "      vf_loss: 27.459686279296875\n",
      "    grad_time_ms: 1539.695\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 5440000\n",
      "    num_steps_trained: 5440000\n",
      "    sample_time_ms: 15653.337\n",
      "    update_time_ms: 4.67\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9680.368115186691\n",
      "  time_this_iter_s: 17.252943515777588\n",
      "  time_total_s: 9680.368115186691\n",
      "  timestamp: 1550626118\n",
      "  timesteps_since_restore: 5440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5440000\n",
      "  training_iteration: 544\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9680 s, 544 iter, 5440000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-28-55\n",
      "  done: false\n",
      "  episode_len_mean: 129.19\n",
      "  episode_reward_max: 214.2011616983922\n",
      "  episode_reward_mean: 161.94160693884558\n",
      "  episode_reward_min: -45.28737312909401\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 41755\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8508813381195068\n",
      "      kl: 0.0225447416305542\n",
      "      policy_loss: 0.0005559414275921881\n",
      "      total_loss: 195.1324920654297\n",
      "      vf_explained_var: 0.95011967420578\n",
      "      vf_loss: 195.13194274902344\n",
      "    grad_time_ms: 1540.537\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 5450000\n",
      "    num_steps_trained: 5450000\n",
      "    sample_time_ms: 15636.951\n",
      "    update_time_ms: 4.593\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9697.83992600441\n",
      "  time_this_iter_s: 17.471810817718506\n",
      "  time_total_s: 9697.83992600441\n",
      "  timestamp: 1550626135\n",
      "  timesteps_since_restore: 5450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5450000\n",
      "  training_iteration: 545\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9697 s, 545 iter, 5450000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-29-12\n",
      "  done: false\n",
      "  episode_len_mean: 131.65\n",
      "  episode_reward_max: 217.42799731838218\n",
      "  episode_reward_mean: 162.4552039230977\n",
      "  episode_reward_min: -42.60180599839969\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 41831\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9111343622207642\n",
      "      kl: 0.015124866738915443\n",
      "      policy_loss: 0.00029811932472512126\n",
      "      total_loss: 42.23494338989258\n",
      "      vf_explained_var: 0.9873051047325134\n",
      "      vf_loss: 42.23464584350586\n",
      "    grad_time_ms: 1539.457\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 5460000\n",
      "    num_steps_trained: 5460000\n",
      "    sample_time_ms: 15582.665\n",
      "    update_time_ms: 4.627\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9714.33151602745\n",
      "  time_this_iter_s: 16.49159002304077\n",
      "  time_total_s: 9714.33151602745\n",
      "  timestamp: 1550626152\n",
      "  timesteps_since_restore: 5460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5460000\n",
      "  training_iteration: 546\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9714 s, 546 iter, 5460000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 131.15\n",
      "  episode_reward_max: 209.77615651097346\n",
      "  episode_reward_mean: 161.34683905471354\n",
      "  episode_reward_min: -46.316135132961925\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 41908\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.805979609489441\n",
      "      kl: 0.03235555812716484\n",
      "      policy_loss: -0.0035090430174022913\n",
      "      total_loss: 119.20368957519531\n",
      "      vf_explained_var: 0.9658807516098022\n",
      "      vf_loss: 119.20720672607422\n",
      "    grad_time_ms: 1541.458\n",
      "    load_time_ms: 1.376\n",
      "    num_steps_sampled: 5470000\n",
      "    num_steps_trained: 5470000\n",
      "    sample_time_ms: 15541.372\n",
      "    update_time_ms: 4.656\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9731.260437726974\n",
      "  time_this_iter_s: 16.928921699523926\n",
      "  time_total_s: 9731.260437726974\n",
      "  timestamp: 1550626169\n",
      "  timesteps_since_restore: 5470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5470000\n",
      "  training_iteration: 547\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9731 s, 547 iter, 5470000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-29-46\n",
      "  done: false\n",
      "  episode_len_mean: 130.14\n",
      "  episode_reward_max: 212.54834785467332\n",
      "  episode_reward_mean: 161.0991126985857\n",
      "  episode_reward_min: -43.50862725742973\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 41986\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9106881618499756\n",
      "      kl: 0.01704217493534088\n",
      "      policy_loss: -0.0027306091506034136\n",
      "      total_loss: 39.093788146972656\n",
      "      vf_explained_var: 0.9877459406852722\n",
      "      vf_loss: 39.09651565551758\n",
      "    grad_time_ms: 1541.407\n",
      "    load_time_ms: 1.345\n",
      "    num_steps_sampled: 5480000\n",
      "    num_steps_trained: 5480000\n",
      "    sample_time_ms: 15537.243\n",
      "    update_time_ms: 4.612\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9748.737985372543\n",
      "  time_this_iter_s: 17.477547645568848\n",
      "  time_total_s: 9748.737985372543\n",
      "  timestamp: 1550626186\n",
      "  timesteps_since_restore: 5480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5480000\n",
      "  training_iteration: 548\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9748 s, 548 iter, 5480000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-30-04\n",
      "  done: false\n",
      "  episode_len_mean: 130.36\n",
      "  episode_reward_max: 212.54834785467332\n",
      "  episode_reward_mean: 166.4411970071038\n",
      "  episode_reward_min: -43.299932661327986\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 42062\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7678295373916626\n",
      "      kl: 0.018782857805490494\n",
      "      policy_loss: -0.005317920818924904\n",
      "      total_loss: 56.70760726928711\n",
      "      vf_explained_var: 0.9806987047195435\n",
      "      vf_loss: 56.712928771972656\n",
      "    grad_time_ms: 1544.196\n",
      "    load_time_ms: 1.323\n",
      "    num_steps_sampled: 5490000\n",
      "    num_steps_trained: 5490000\n",
      "    sample_time_ms: 15576.843\n",
      "    update_time_ms: 4.646\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9766.381833076477\n",
      "  time_this_iter_s: 17.643847703933716\n",
      "  time_total_s: 9766.381833076477\n",
      "  timestamp: 1550626204\n",
      "  timesteps_since_restore: 5490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5490000\n",
      "  training_iteration: 549\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9766 s, 549 iter, 5490000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-30-21\n",
      "  done: false\n",
      "  episode_len_mean: 127.08\n",
      "  episode_reward_max: 209.00766728936443\n",
      "  episode_reward_mean: 164.60028782094602\n",
      "  episode_reward_min: -42.23394912149352\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 42140\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6531872749328613\n",
      "      kl: 0.02535547874867916\n",
      "      policy_loss: 0.0020455350168049335\n",
      "      total_loss: 23.68989372253418\n",
      "      vf_explained_var: 0.9920372366905212\n",
      "      vf_loss: 23.687850952148438\n",
      "    grad_time_ms: 1543.19\n",
      "    load_time_ms: 1.352\n",
      "    num_steps_sampled: 5500000\n",
      "    num_steps_trained: 5500000\n",
      "    sample_time_ms: 15559.177\n",
      "    update_time_ms: 4.71\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9783.300243616104\n",
      "  time_this_iter_s: 16.918410539627075\n",
      "  time_total_s: 9783.300243616104\n",
      "  timestamp: 1550626221\n",
      "  timesteps_since_restore: 5500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5500000\n",
      "  training_iteration: 550\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9783 s, 550 iter, 5500000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-30-38\n",
      "  done: false\n",
      "  episode_len_mean: 131.41\n",
      "  episode_reward_max: 211.47023476129132\n",
      "  episode_reward_mean: 169.3161393401002\n",
      "  episode_reward_min: 41.598981008818896\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 42216\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8072034120559692\n",
      "      kl: 0.012307471595704556\n",
      "      policy_loss: -0.0005399279179982841\n",
      "      total_loss: 47.2331657409668\n",
      "      vf_explained_var: 0.9855093359947205\n",
      "      vf_loss: 47.23370361328125\n",
      "    grad_time_ms: 1543.351\n",
      "    load_time_ms: 1.341\n",
      "    num_steps_sampled: 5510000\n",
      "    num_steps_trained: 5510000\n",
      "    sample_time_ms: 15581.272\n",
      "    update_time_ms: 4.66\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9800.624195814133\n",
      "  time_this_iter_s: 17.323952198028564\n",
      "  time_total_s: 9800.624195814133\n",
      "  timestamp: 1550626238\n",
      "  timesteps_since_restore: 5510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5510000\n",
      "  training_iteration: 551\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9800 s, 551 iter, 5510000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-30-55\n",
      "  done: false\n",
      "  episode_len_mean: 130.39\n",
      "  episode_reward_max: 210.0736017684537\n",
      "  episode_reward_mean: 159.80274027398937\n",
      "  episode_reward_min: -46.67099007536275\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 42294\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7988660335540771\n",
      "      kl: 0.015958374366164207\n",
      "      policy_loss: -0.000709006329998374\n",
      "      total_loss: 119.15589904785156\n",
      "      vf_explained_var: 0.9638209342956543\n",
      "      vf_loss: 119.1566162109375\n",
      "    grad_time_ms: 1541.954\n",
      "    load_time_ms: 1.378\n",
      "    num_steps_sampled: 5520000\n",
      "    num_steps_trained: 5520000\n",
      "    sample_time_ms: 15620.527\n",
      "    update_time_ms: 4.668\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9817.87631368637\n",
      "  time_this_iter_s: 17.25211787223816\n",
      "  time_total_s: 9817.87631368637\n",
      "  timestamp: 1550626255\n",
      "  timesteps_since_restore: 5520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5520000\n",
      "  training_iteration: 552\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9817 s, 552 iter, 5520000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 128.91\n",
      "  episode_reward_max: 208.21458023565225\n",
      "  episode_reward_mean: 159.23684666607073\n",
      "  episode_reward_min: -46.67099007536275\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 42370\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9370343685150146\n",
      "      kl: 0.025366634130477905\n",
      "      policy_loss: -0.0014239501906558871\n",
      "      total_loss: 84.9944839477539\n",
      "      vf_explained_var: 0.976850152015686\n",
      "      vf_loss: 84.99592590332031\n",
      "    grad_time_ms: 1542.744\n",
      "    load_time_ms: 1.318\n",
      "    num_steps_sampled: 5530000\n",
      "    num_steps_trained: 5530000\n",
      "    sample_time_ms: 15634.072\n",
      "    update_time_ms: 4.661\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9835.06912612915\n",
      "  time_this_iter_s: 17.19281244277954\n",
      "  time_total_s: 9835.06912612915\n",
      "  timestamp: 1550626273\n",
      "  timesteps_since_restore: 5530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5530000\n",
      "  training_iteration: 553\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9835 s, 553 iter, 5530000 ts, 159 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-31-30\n",
      "  done: false\n",
      "  episode_len_mean: 130.85\n",
      "  episode_reward_max: 222.1084853300809\n",
      "  episode_reward_mean: 165.12415979697784\n",
      "  episode_reward_min: -46.66643341763482\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 42446\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 2.0185697078704834\n",
      "      kl: 0.012601472437381744\n",
      "      policy_loss: -0.0025972817093133926\n",
      "      total_loss: 22.33058738708496\n",
      "      vf_explained_var: 0.9923614263534546\n",
      "      vf_loss: 22.33318328857422\n",
      "    grad_time_ms: 1542.656\n",
      "    load_time_ms: 1.311\n",
      "    num_steps_sampled: 5540000\n",
      "    num_steps_trained: 5540000\n",
      "    sample_time_ms: 15682.448\n",
      "    update_time_ms: 4.483\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9852.802096366882\n",
      "  time_this_iter_s: 17.732970237731934\n",
      "  time_total_s: 9852.802096366882\n",
      "  timestamp: 1550626290\n",
      "  timesteps_since_restore: 5540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5540000\n",
      "  training_iteration: 554\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9852 s, 554 iter, 5540000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-31-48\n",
      "  done: false\n",
      "  episode_len_mean: 132.1\n",
      "  episode_reward_max: 222.1084853300809\n",
      "  episode_reward_mean: 168.41563439692865\n",
      "  episode_reward_min: -41.02194926076302\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 42523\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7767212390899658\n",
      "      kl: 0.01635754480957985\n",
      "      policy_loss: -0.0028507455717772245\n",
      "      total_loss: 30.87265968322754\n",
      "      vf_explained_var: 0.9902971982955933\n",
      "      vf_loss: 30.87550926208496\n",
      "    grad_time_ms: 1541.863\n",
      "    load_time_ms: 1.313\n",
      "    num_steps_sampled: 5550000\n",
      "    num_steps_trained: 5550000\n",
      "    sample_time_ms: 15673.465\n",
      "    update_time_ms: 4.468\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9870.175832748413\n",
      "  time_this_iter_s: 17.37373638153076\n",
      "  time_total_s: 9870.175832748413\n",
      "  timestamp: 1550626308\n",
      "  timesteps_since_restore: 5550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5550000\n",
      "  training_iteration: 555\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9870 s, 555 iter, 5550000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-32-06\n",
      "  done: false\n",
      "  episode_len_mean: 132.75\n",
      "  episode_reward_max: 216.7177562402322\n",
      "  episode_reward_mean: 167.88589510800028\n",
      "  episode_reward_min: -41.02194926076302\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 42598\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.35151673419068e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9282501935958862\n",
      "      kl: 0.009779088199138641\n",
      "      policy_loss: -0.00020418812346179038\n",
      "      total_loss: 34.73686218261719\n",
      "      vf_explained_var: 0.9893090724945068\n",
      "      vf_loss: 34.73706817626953\n",
      "    grad_time_ms: 1542.814\n",
      "    load_time_ms: 1.309\n",
      "    num_steps_sampled: 5560000\n",
      "    num_steps_trained: 5560000\n",
      "    sample_time_ms: 15814.93\n",
      "    update_time_ms: 4.468\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9888.092491865158\n",
      "  time_this_iter_s: 17.916659116744995\n",
      "  time_total_s: 9888.092491865158\n",
      "  timestamp: 1550626326\n",
      "  timesteps_since_restore: 5560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5560000\n",
      "  training_iteration: 556\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9888 s, 556 iter, 5560000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-32-24\n",
      "  done: false\n",
      "  episode_len_mean: 128.97\n",
      "  episode_reward_max: 209.6339835013346\n",
      "  episode_reward_mean: 160.93621559844362\n",
      "  episode_reward_min: -48.27095111363595\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 42677\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7691357135772705\n",
      "      kl: 0.027942892163991928\n",
      "      policy_loss: -0.002230079611763358\n",
      "      total_loss: 113.76873016357422\n",
      "      vf_explained_var: 0.9675281047821045\n",
      "      vf_loss: 113.77095794677734\n",
      "    grad_time_ms: 1563.432\n",
      "    load_time_ms: 1.295\n",
      "    num_steps_sampled: 5570000\n",
      "    num_steps_trained: 5570000\n",
      "    sample_time_ms: 15886.295\n",
      "    update_time_ms: 4.373\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9905.941001176834\n",
      "  time_this_iter_s: 17.848509311676025\n",
      "  time_total_s: 9905.941001176834\n",
      "  timestamp: 1550626344\n",
      "  timesteps_since_restore: 5570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5570000\n",
      "  training_iteration: 557\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9905 s, 557 iter, 5570000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-32-41\n",
      "  done: false\n",
      "  episode_len_mean: 129.33\n",
      "  episode_reward_max: 220.69224309972907\n",
      "  episode_reward_mean: 163.66297493273524\n",
      "  episode_reward_min: -48.27095111363595\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 42753\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7266430854797363\n",
      "      kl: 0.018799012526869774\n",
      "      policy_loss: -0.00319591979496181\n",
      "      total_loss: 55.51686477661133\n",
      "      vf_explained_var: 0.9824380874633789\n",
      "      vf_loss: 55.52006912231445\n",
      "    grad_time_ms: 1565.052\n",
      "    load_time_ms: 1.286\n",
      "    num_steps_sampled: 5580000\n",
      "    num_steps_trained: 5580000\n",
      "    sample_time_ms: 15869.889\n",
      "    update_time_ms: 4.457\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9923.27021408081\n",
      "  time_this_iter_s: 17.32921290397644\n",
      "  time_total_s: 9923.27021408081\n",
      "  timestamp: 1550626361\n",
      "  timesteps_since_restore: 5580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5580000\n",
      "  training_iteration: 558\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9923 s, 558 iter, 5580000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-32-58\n",
      "  done: false\n",
      "  episode_len_mean: 131.22\n",
      "  episode_reward_max: 215.47028651649111\n",
      "  episode_reward_mean: 167.35576135328915\n",
      "  episode_reward_min: -45.72358766744043\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 42829\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7814700603485107\n",
      "      kl: 0.031095782294869423\n",
      "      policy_loss: 0.0002710181288421154\n",
      "      total_loss: 53.11026382446289\n",
      "      vf_explained_var: 0.9827497601509094\n",
      "      vf_loss: 53.109989166259766\n",
      "    grad_time_ms: 1567.341\n",
      "    load_time_ms: 1.274\n",
      "    num_steps_sampled: 5590000\n",
      "    num_steps_trained: 5590000\n",
      "    sample_time_ms: 15794.863\n",
      "    update_time_ms: 4.441\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9940.18601822853\n",
      "  time_this_iter_s: 16.915804147720337\n",
      "  time_total_s: 9940.18601822853\n",
      "  timestamp: 1550626378\n",
      "  timesteps_since_restore: 5590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5590000\n",
      "  training_iteration: 559\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9940 s, 559 iter, 5590000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-33-15\n",
      "  done: false\n",
      "  episode_len_mean: 131.95\n",
      "  episode_reward_max: 218.56189154302427\n",
      "  episode_reward_mean: 166.5668358660144\n",
      "  episode_reward_min: -41.632154241573105\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 42905\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.823838472366333\n",
      "      kl: 0.027831312268972397\n",
      "      policy_loss: -0.0023474260233342648\n",
      "      total_loss: 78.44873046875\n",
      "      vf_explained_var: 0.9769220352172852\n",
      "      vf_loss: 78.45108795166016\n",
      "    grad_time_ms: 1566.678\n",
      "    load_time_ms: 1.278\n",
      "    num_steps_sampled: 5600000\n",
      "    num_steps_trained: 5600000\n",
      "    sample_time_ms: 15818.159\n",
      "    update_time_ms: 4.252\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9957.330803871155\n",
      "  time_this_iter_s: 17.1447856426239\n",
      "  time_total_s: 9957.330803871155\n",
      "  timestamp: 1550626395\n",
      "  timesteps_since_restore: 5600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5600000\n",
      "  training_iteration: 560\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9957 s, 560 iter, 5600000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-33-32\n",
      "  done: false\n",
      "  episode_len_mean: 130.35\n",
      "  episode_reward_max: 213.3619353678999\n",
      "  episode_reward_mean: 169.7881220715144\n",
      "  episode_reward_min: -39.481164019886826\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 42982\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6031478643417358\n",
      "      kl: 0.030680842697620392\n",
      "      policy_loss: 5.616687121801078e-05\n",
      "      total_loss: 31.255435943603516\n",
      "      vf_explained_var: 0.9901683330535889\n",
      "      vf_loss: 31.255386352539062\n",
      "    grad_time_ms: 1567.003\n",
      "    load_time_ms: 1.243\n",
      "    num_steps_sampled: 5610000\n",
      "    num_steps_trained: 5610000\n",
      "    sample_time_ms: 15801.586\n",
      "    update_time_ms: 4.316\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9974.491571426392\n",
      "  time_this_iter_s: 17.160767555236816\n",
      "  time_total_s: 9974.491571426392\n",
      "  timestamp: 1550626412\n",
      "  timesteps_since_restore: 5610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5610000\n",
      "  training_iteration: 561\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9974 s, 561 iter, 5610000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-33-50\n",
      "  done: false\n",
      "  episode_len_mean: 130.73\n",
      "  episode_reward_max: 212.67047708352456\n",
      "  episode_reward_mean: 168.57520412480503\n",
      "  episode_reward_min: -48.47721338338486\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 43058\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7899242639541626\n",
      "      kl: 0.018376486375927925\n",
      "      policy_loss: -0.0019351732917129993\n",
      "      total_loss: 82.95478820800781\n",
      "      vf_explained_var: 0.9772079586982727\n",
      "      vf_loss: 82.95673370361328\n",
      "    grad_time_ms: 1567.962\n",
      "    load_time_ms: 1.307\n",
      "    num_steps_sampled: 5620000\n",
      "    num_steps_trained: 5620000\n",
      "    sample_time_ms: 15862.779\n",
      "    update_time_ms: 4.339\n",
      "  iterations_since_restore: 562\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 9992.366389513016\n",
      "  time_this_iter_s: 17.874818086624146\n",
      "  time_total_s: 9992.366389513016\n",
      "  timestamp: 1550626430\n",
      "  timesteps_since_restore: 5620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5620000\n",
      "  training_iteration: 562\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 9992 s, 562 iter, 5620000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-34-08\n",
      "  done: false\n",
      "  episode_len_mean: 130.19\n",
      "  episode_reward_max: 206.93803099247782\n",
      "  episode_reward_mean: 163.94418981047045\n",
      "  episode_reward_min: -45.74574507219663\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 43136\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.56960928440094\n",
      "      kl: 0.01912524923682213\n",
      "      policy_loss: -0.002450963482260704\n",
      "      total_loss: 77.98516845703125\n",
      "      vf_explained_var: 0.9788557291030884\n",
      "      vf_loss: 77.98761749267578\n",
      "    grad_time_ms: 1565.854\n",
      "    load_time_ms: 1.306\n",
      "    num_steps_sampled: 5630000\n",
      "    num_steps_trained: 5630000\n",
      "    sample_time_ms: 15910.297\n",
      "    update_time_ms: 4.298\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10010.013219833374\n",
      "  time_this_iter_s: 17.646830320358276\n",
      "  time_total_s: 10010.013219833374\n",
      "  timestamp: 1550626448\n",
      "  timesteps_since_restore: 5630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5630000\n",
      "  training_iteration: 563\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10010 s, 563 iter, 5630000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-34-25\n",
      "  done: false\n",
      "  episode_len_mean: 131.99\n",
      "  episode_reward_max: 223.3975916003233\n",
      "  episode_reward_mean: 169.01315230590484\n",
      "  episode_reward_min: -44.66530025521719\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 43211\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.82777738571167\n",
      "      kl: 0.03940122202038765\n",
      "      policy_loss: 0.0005521182902157307\n",
      "      total_loss: 55.47578048706055\n",
      "      vf_explained_var: 0.9825448989868164\n",
      "      vf_loss: 55.475223541259766\n",
      "    grad_time_ms: 1564.566\n",
      "    load_time_ms: 1.31\n",
      "    num_steps_sampled: 5640000\n",
      "    num_steps_trained: 5640000\n",
      "    sample_time_ms: 15853.085\n",
      "    update_time_ms: 4.348\n",
      "  iterations_since_restore: 564\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10027.16396522522\n",
      "  time_this_iter_s: 17.150745391845703\n",
      "  time_total_s: 10027.16396522522\n",
      "  timestamp: 1550626465\n",
      "  timesteps_since_restore: 5640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5640000\n",
      "  training_iteration: 564\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10027 s, 564 iter, 5640000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-34-42\n",
      "  done: false\n",
      "  episode_len_mean: 132.06\n",
      "  episode_reward_max: 218.59362257246153\n",
      "  episode_reward_mean: 167.34332881050193\n",
      "  episode_reward_min: -48.04579656644918\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 43287\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.786407709121704\n",
      "      kl: 0.01986265741288662\n",
      "      policy_loss: -0.003706064075231552\n",
      "      total_loss: 82.69567108154297\n",
      "      vf_explained_var: 0.9750520586967468\n",
      "      vf_loss: 82.69938659667969\n",
      "    grad_time_ms: 1564.76\n",
      "    load_time_ms: 1.306\n",
      "    num_steps_sampled: 5650000\n",
      "    num_steps_trained: 5650000\n",
      "    sample_time_ms: 15810.459\n",
      "    update_time_ms: 4.404\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10044.1155834198\n",
      "  time_this_iter_s: 16.951618194580078\n",
      "  time_total_s: 10044.1155834198\n",
      "  timestamp: 1550626482\n",
      "  timesteps_since_restore: 5650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5650000\n",
      "  training_iteration: 565\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10044 s, 565 iter, 5650000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-35-00\n",
      "  done: false\n",
      "  episode_len_mean: 129.65\n",
      "  episode_reward_max: 211.08473321360228\n",
      "  episode_reward_mean: 166.92938991766087\n",
      "  episode_reward_min: -48.48989590397566\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 43364\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6962954998016357\n",
      "      kl: 0.023827923461794853\n",
      "      policy_loss: -0.0003617035399656743\n",
      "      total_loss: 33.27201461791992\n",
      "      vf_explained_var: 0.989709198474884\n",
      "      vf_loss: 33.27238082885742\n",
      "    grad_time_ms: 1565.942\n",
      "    load_time_ms: 1.314\n",
      "    num_steps_sampled: 5660000\n",
      "    num_steps_trained: 5660000\n",
      "    sample_time_ms: 15760.451\n",
      "    update_time_ms: 4.488\n",
      "  iterations_since_restore: 566\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10061.543903112411\n",
      "  time_this_iter_s: 17.428319692611694\n",
      "  time_total_s: 10061.543903112411\n",
      "  timestamp: 1550626500\n",
      "  timesteps_since_restore: 5660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5660000\n",
      "  training_iteration: 566\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10061 s, 566 iter, 5660000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-35-17\n",
      "  done: false\n",
      "  episode_len_mean: 130.49\n",
      "  episode_reward_max: 228.21650629527488\n",
      "  episode_reward_mean: 160.4129124585198\n",
      "  episode_reward_min: -48.48989590397566\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 43440\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7361719608306885\n",
      "      kl: 0.0174929890781641\n",
      "      policy_loss: -0.0011421532835811377\n",
      "      total_loss: 103.34691619873047\n",
      "      vf_explained_var: 0.9704852104187012\n",
      "      vf_loss: 103.34806060791016\n",
      "    grad_time_ms: 1545.607\n",
      "    load_time_ms: 1.327\n",
      "    num_steps_sampled: 5670000\n",
      "    num_steps_trained: 5670000\n",
      "    sample_time_ms: 15744.993\n",
      "    update_time_ms: 4.489\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10079.033975839615\n",
      "  time_this_iter_s: 17.49007272720337\n",
      "  time_total_s: 10079.033975839615\n",
      "  timestamp: 1550626517\n",
      "  timesteps_since_restore: 5670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5670000\n",
      "  training_iteration: 567\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10079 s, 567 iter, 5670000 ts, 160 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-35-34\n",
      "  done: false\n",
      "  episode_len_mean: 129.93\n",
      "  episode_reward_max: 228.21650629527488\n",
      "  episode_reward_mean: 166.07407406960826\n",
      "  episode_reward_min: -50.38599279552405\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 43517\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.682098627090454\n",
      "      kl: 0.027103405445814133\n",
      "      policy_loss: -0.0013996066991239786\n",
      "      total_loss: 44.61301040649414\n",
      "      vf_explained_var: 0.9853955507278442\n",
      "      vf_loss: 44.614410400390625\n",
      "    grad_time_ms: 1544.427\n",
      "    load_time_ms: 1.406\n",
      "    num_steps_sampled: 5680000\n",
      "    num_steps_trained: 5680000\n",
      "    sample_time_ms: 15736.215\n",
      "    update_time_ms: 4.41\n",
      "  iterations_since_restore: 568\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10096.26566362381\n",
      "  time_this_iter_s: 17.231687784194946\n",
      "  time_total_s: 10096.26566362381\n",
      "  timestamp: 1550626534\n",
      "  timesteps_since_restore: 5680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5680000\n",
      "  training_iteration: 568\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10096 s, 568 iter, 5680000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-35-52\n",
      "  done: false\n",
      "  episode_len_mean: 130.95\n",
      "  episode_reward_max: 223.21729122843627\n",
      "  episode_reward_mean: 168.8991750303402\n",
      "  episode_reward_min: -48.2518446913155\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 43593\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7494289875030518\n",
      "      kl: 0.011292455717921257\n",
      "      policy_loss: -0.001710101030766964\n",
      "      total_loss: 50.222774505615234\n",
      "      vf_explained_var: 0.9839683175086975\n",
      "      vf_loss: 50.224491119384766\n",
      "    grad_time_ms: 1541.236\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 5690000\n",
      "    num_steps_trained: 5690000\n",
      "    sample_time_ms: 15794.284\n",
      "    update_time_ms: 4.256\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10113.72982788086\n",
      "  time_this_iter_s: 17.46416425704956\n",
      "  time_total_s: 10113.72982788086\n",
      "  timestamp: 1550626552\n",
      "  timesteps_since_restore: 5690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5690000\n",
      "  training_iteration: 569\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10113 s, 569 iter, 5690000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-36-09\n",
      "  done: false\n",
      "  episode_len_mean: 133.46\n",
      "  episode_reward_max: 221.7717151604594\n",
      "  episode_reward_mean: 174.74710083471072\n",
      "  episode_reward_min: 103.4724868835495\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 43668\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.793727993965149\n",
      "      kl: 0.012134358286857605\n",
      "      policy_loss: -0.002995553659275174\n",
      "      total_loss: 19.492328643798828\n",
      "      vf_explained_var: 0.9933719038963318\n",
      "      vf_loss: 19.495323181152344\n",
      "    grad_time_ms: 1542.801\n",
      "    load_time_ms: 1.421\n",
      "    num_steps_sampled: 5700000\n",
      "    num_steps_trained: 5700000\n",
      "    sample_time_ms: 15814.657\n",
      "    update_time_ms: 4.341\n",
      "  iterations_since_restore: 570\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10131.091948270798\n",
      "  time_this_iter_s: 17.362120389938354\n",
      "  time_total_s: 10131.091948270798\n",
      "  timestamp: 1550626569\n",
      "  timesteps_since_restore: 5700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5700000\n",
      "  training_iteration: 570\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10131 s, 570 iter, 5700000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-36-27\n",
      "  done: false\n",
      "  episode_len_mean: 131.76\n",
      "  episode_reward_max: 209.55082172347173\n",
      "  episode_reward_mean: 171.6973749027081\n",
      "  episode_reward_min: -47.113081759745505\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 43744\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6865378618240356\n",
      "      kl: 0.01819867640733719\n",
      "      policy_loss: -0.002267020521685481\n",
      "      total_loss: 57.927608489990234\n",
      "      vf_explained_var: 0.9825212359428406\n",
      "      vf_loss: 57.92988204956055\n",
      "    grad_time_ms: 1540.133\n",
      "    load_time_ms: 1.412\n",
      "    num_steps_sampled: 5710000\n",
      "    num_steps_trained: 5710000\n",
      "    sample_time_ms: 15852.259\n",
      "    update_time_ms: 4.335\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10148.602472543716\n",
      "  time_this_iter_s: 17.5105242729187\n",
      "  time_total_s: 10148.602472543716\n",
      "  timestamp: 1550626587\n",
      "  timesteps_since_restore: 5710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5710000\n",
      "  training_iteration: 571\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10148 s, 571 iter, 5710000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-36-44\n",
      "  done: false\n",
      "  episode_len_mean: 128.97\n",
      "  episode_reward_max: 221.71331056760667\n",
      "  episode_reward_mean: 161.88616114524135\n",
      "  episode_reward_min: -48.47070265524459\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 43823\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5621100664138794\n",
      "      kl: 0.024639593437314034\n",
      "      policy_loss: -0.0047574169002473354\n",
      "      total_loss: 72.5453872680664\n",
      "      vf_explained_var: 0.9822995066642761\n",
      "      vf_loss: 72.5501480102539\n",
      "    grad_time_ms: 1539.457\n",
      "    load_time_ms: 1.365\n",
      "    num_steps_sampled: 5720000\n",
      "    num_steps_trained: 5720000\n",
      "    sample_time_ms: 15814.782\n",
      "    update_time_ms: 4.301\n",
      "  iterations_since_restore: 572\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10166.09403181076\n",
      "  time_this_iter_s: 17.491559267044067\n",
      "  time_total_s: 10166.09403181076\n",
      "  timestamp: 1550626604\n",
      "  timesteps_since_restore: 5720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5720000\n",
      "  training_iteration: 572\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10166 s, 572 iter, 5720000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-37-02\n",
      "  done: false\n",
      "  episode_len_mean: 131.66\n",
      "  episode_reward_max: 215.1053272215741\n",
      "  episode_reward_mean: 163.87410265915022\n",
      "  episode_reward_min: -48.47070265524459\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 43897\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.946461796760559\n",
      "      kl: 0.015213431790471077\n",
      "      policy_loss: -0.003077565925195813\n",
      "      total_loss: 55.831661224365234\n",
      "      vf_explained_var: 0.9826574921607971\n",
      "      vf_loss: 55.83474349975586\n",
      "    grad_time_ms: 1541.0\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 5730000\n",
      "    num_steps_trained: 5730000\n",
      "    sample_time_ms: 15844.243\n",
      "    update_time_ms: 4.357\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10184.052739143372\n",
      "  time_this_iter_s: 17.958707332611084\n",
      "  time_total_s: 10184.052739143372\n",
      "  timestamp: 1550626622\n",
      "  timesteps_since_restore: 5730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5730000\n",
      "  training_iteration: 573\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10184 s, 573 iter, 5730000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-37-20\n",
      "  done: false\n",
      "  episode_len_mean: 134.34\n",
      "  episode_reward_max: 208.95390686496063\n",
      "  episode_reward_mean: 168.64336133909075\n",
      "  episode_reward_min: -42.847327362303396\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 43972\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8841506242752075\n",
      "      kl: 0.01711425371468067\n",
      "      policy_loss: -0.0016692241188138723\n",
      "      total_loss: 27.460023880004883\n",
      "      vf_explained_var: 0.9911984205245972\n",
      "      vf_loss: 27.46169090270996\n",
      "    grad_time_ms: 1542.226\n",
      "    load_time_ms: 1.357\n",
      "    num_steps_sampled: 5740000\n",
      "    num_steps_trained: 5740000\n",
      "    sample_time_ms: 15906.264\n",
      "    update_time_ms: 4.204\n",
      "  iterations_since_restore: 574\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10201.832599639893\n",
      "  time_this_iter_s: 17.779860496520996\n",
      "  time_total_s: 10201.832599639893\n",
      "  timestamp: 1550626640\n",
      "  timesteps_since_restore: 5740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5740000\n",
      "  training_iteration: 574\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10201 s, 574 iter, 5740000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-37-38\n",
      "  done: false\n",
      "  episode_len_mean: 133.6\n",
      "  episode_reward_max: 212.38309905700177\n",
      "  episode_reward_mean: 172.27976345069163\n",
      "  episode_reward_min: -41.17483698982414\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 44047\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7300418615341187\n",
      "      kl: 0.018064817413687706\n",
      "      policy_loss: -0.0002680558536667377\n",
      "      total_loss: 51.39839172363281\n",
      "      vf_explained_var: 0.9845263361930847\n",
      "      vf_loss: 51.39866638183594\n",
      "    grad_time_ms: 1540.298\n",
      "    load_time_ms: 1.362\n",
      "    num_steps_sampled: 5750000\n",
      "    num_steps_trained: 5750000\n",
      "    sample_time_ms: 15959.098\n",
      "    update_time_ms: 4.29\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10219.294610977173\n",
      "  time_this_iter_s: 17.462011337280273\n",
      "  time_total_s: 10219.294610977173\n",
      "  timestamp: 1550626658\n",
      "  timesteps_since_restore: 5750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5750000\n",
      "  training_iteration: 575\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10219 s, 575 iter, 5750000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 130.38\n",
      "  episode_reward_max: 211.3919116562545\n",
      "  episode_reward_mean: 167.40327146819007\n",
      "  episode_reward_min: -43.51089478999672\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 44125\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.801261067390442\n",
      "      kl: 0.013249053619801998\n",
      "      policy_loss: -0.0015276072081178427\n",
      "      total_loss: 17.42950439453125\n",
      "      vf_explained_var: 0.9942818880081177\n",
      "      vf_loss: 17.431028366088867\n",
      "    grad_time_ms: 1539.326\n",
      "    load_time_ms: 1.365\n",
      "    num_steps_sampled: 5760000\n",
      "    num_steps_trained: 5760000\n",
      "    sample_time_ms: 15941.992\n",
      "    update_time_ms: 4.153\n",
      "  iterations_since_restore: 576\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10236.541652917862\n",
      "  time_this_iter_s: 17.247041940689087\n",
      "  time_total_s: 10236.541652917862\n",
      "  timestamp: 1550626675\n",
      "  timesteps_since_restore: 5760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5760000\n",
      "  training_iteration: 576\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10236 s, 576 iter, 5760000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-38-12\n",
      "  done: false\n",
      "  episode_len_mean: 134.85\n",
      "  episode_reward_max: 220.45537295926482\n",
      "  episode_reward_mean: 171.84137629200384\n",
      "  episode_reward_min: -46.40951158039935\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 44197\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8147058486938477\n",
      "      kl: 0.026323208585381508\n",
      "      policy_loss: -0.0026828625705093145\n",
      "      total_loss: 65.2239990234375\n",
      "      vf_explained_var: 0.9816131591796875\n",
      "      vf_loss: 65.2266845703125\n",
      "    grad_time_ms: 1537.519\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 5770000\n",
      "    num_steps_trained: 5770000\n",
      "    sample_time_ms: 15915.481\n",
      "    update_time_ms: 4.171\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10253.748540878296\n",
      "  time_this_iter_s: 17.20688796043396\n",
      "  time_total_s: 10253.748540878296\n",
      "  timestamp: 1550626692\n",
      "  timesteps_since_restore: 5770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5770000\n",
      "  training_iteration: 577\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10253 s, 577 iter, 5770000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-38-29\n",
      "  done: false\n",
      "  episode_len_mean: 134.16\n",
      "  episode_reward_max: 219.53410965373934\n",
      "  episode_reward_mean: 171.29868607803198\n",
      "  episode_reward_min: -46.40951158039935\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 44272\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6993542909622192\n",
      "      kl: 0.02381652221083641\n",
      "      policy_loss: 0.00029862241353839636\n",
      "      total_loss: 32.525779724121094\n",
      "      vf_explained_var: 0.9904603958129883\n",
      "      vf_loss: 32.525482177734375\n",
      "    grad_time_ms: 1536.373\n",
      "    load_time_ms: 1.34\n",
      "    num_steps_sampled: 5780000\n",
      "    num_steps_trained: 5780000\n",
      "    sample_time_ms: 15899.32\n",
      "    update_time_ms: 4.241\n",
      "  iterations_since_restore: 578\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10270.806771993637\n",
      "  time_this_iter_s: 17.058231115341187\n",
      "  time_total_s: 10270.806771993637\n",
      "  timestamp: 1550626709\n",
      "  timesteps_since_restore: 5780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5780000\n",
      "  training_iteration: 578\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10270 s, 578 iter, 5780000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-38-47\n",
      "  done: false\n",
      "  episode_len_mean: 132.29\n",
      "  episode_reward_max: 215.10108030646458\n",
      "  episode_reward_mean: 169.23349754418498\n",
      "  episode_reward_min: -47.87548300033749\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 44348\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6317294836044312\n",
      "      kl: 0.014104679226875305\n",
      "      policy_loss: -0.0010815939167514443\n",
      "      total_loss: 32.95280075073242\n",
      "      vf_explained_var: 0.9903450012207031\n",
      "      vf_loss: 32.953880310058594\n",
      "    grad_time_ms: 1535.358\n",
      "    load_time_ms: 1.323\n",
      "    num_steps_sampled: 5790000\n",
      "    num_steps_trained: 5790000\n",
      "    sample_time_ms: 15912.799\n",
      "    update_time_ms: 4.438\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10288.398112773895\n",
      "  time_this_iter_s: 17.59134078025818\n",
      "  time_total_s: 10288.398112773895\n",
      "  timestamp: 1550626727\n",
      "  timesteps_since_restore: 5790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5790000\n",
      "  training_iteration: 579\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10288 s, 579 iter, 5790000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-39-04\n",
      "  done: false\n",
      "  episode_len_mean: 131.79\n",
      "  episode_reward_max: 217.78341300412552\n",
      "  episode_reward_mean: 169.73173049503566\n",
      "  episode_reward_min: -42.89650844273591\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 44424\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7392947673797607\n",
      "      kl: 0.019761361181735992\n",
      "      policy_loss: -0.003121225629001856\n",
      "      total_loss: 40.26047897338867\n",
      "      vf_explained_var: 0.9869961142539978\n",
      "      vf_loss: 40.26359939575195\n",
      "    grad_time_ms: 1532.0\n",
      "    load_time_ms: 1.329\n",
      "    num_steps_sampled: 5800000\n",
      "    num_steps_trained: 5800000\n",
      "    sample_time_ms: 15925.111\n",
      "    update_time_ms: 4.363\n",
      "  iterations_since_restore: 580\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10305.84879374504\n",
      "  time_this_iter_s: 17.45068097114563\n",
      "  time_total_s: 10305.84879374504\n",
      "  timestamp: 1550626744\n",
      "  timesteps_since_restore: 5800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5800000\n",
      "  training_iteration: 580\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10305 s, 580 iter, 5800000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-39-22\n",
      "  done: false\n",
      "  episode_len_mean: 133.39\n",
      "  episode_reward_max: 210.52012710214254\n",
      "  episode_reward_mean: 171.3605829964885\n",
      "  episode_reward_min: -42.88844943341642\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 44500\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.824072241783142\n",
      "      kl: 0.01464772503823042\n",
      "      policy_loss: 0.0006921103340573609\n",
      "      total_loss: 29.209747314453125\n",
      "      vf_explained_var: 0.9908238053321838\n",
      "      vf_loss: 29.209062576293945\n",
      "    grad_time_ms: 1534.402\n",
      "    load_time_ms: 1.333\n",
      "    num_steps_sampled: 5810000\n",
      "    num_steps_trained: 5810000\n",
      "    sample_time_ms: 15911.262\n",
      "    update_time_ms: 4.307\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10323.243872642517\n",
      "  time_this_iter_s: 17.395078897476196\n",
      "  time_total_s: 10323.243872642517\n",
      "  timestamp: 1550626762\n",
      "  timesteps_since_restore: 5810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5810000\n",
      "  training_iteration: 581\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10323 s, 581 iter, 5810000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-39-40\n",
      "  done: false\n",
      "  episode_len_mean: 134.34\n",
      "  episode_reward_max: 213.95915385217646\n",
      "  episode_reward_mean: 169.35199061905615\n",
      "  episode_reward_min: -45.46672595771822\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 44574\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7776861190795898\n",
      "      kl: 0.011949467472732067\n",
      "      policy_loss: -0.0015186821110546589\n",
      "      total_loss: 29.979095458984375\n",
      "      vf_explained_var: 0.9912409782409668\n",
      "      vf_loss: 29.980609893798828\n",
      "    grad_time_ms: 1539.083\n",
      "    load_time_ms: 1.324\n",
      "    num_steps_sampled: 5820000\n",
      "    num_steps_trained: 5820000\n",
      "    sample_time_ms: 15954.912\n",
      "    update_time_ms: 4.215\n",
      "  iterations_since_restore: 582\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10341.217353343964\n",
      "  time_this_iter_s: 17.973480701446533\n",
      "  time_total_s: 10341.217353343964\n",
      "  timestamp: 1550626780\n",
      "  timesteps_since_restore: 5820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5820000\n",
      "  training_iteration: 582\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10341 s, 582 iter, 5820000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-39-57\n",
      "  done: false\n",
      "  episode_len_mean: 133.24\n",
      "  episode_reward_max: 208.15285069429052\n",
      "  episode_reward_mean: 175.0719425798399\n",
      "  episode_reward_min: -39.68415561259382\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 44650\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4198194742202759\n",
      "      kl: 0.010831386782228947\n",
      "      policy_loss: -0.0006111191469244659\n",
      "      total_loss: 20.331920623779297\n",
      "      vf_explained_var: 0.9935658574104309\n",
      "      vf_loss: 20.33253288269043\n",
      "    grad_time_ms: 1539.982\n",
      "    load_time_ms: 1.326\n",
      "    num_steps_sampled: 5830000\n",
      "    num_steps_trained: 5830000\n",
      "    sample_time_ms: 15916.625\n",
      "    update_time_ms: 4.228\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10358.80148601532\n",
      "  time_this_iter_s: 17.5841326713562\n",
      "  time_total_s: 10358.80148601532\n",
      "  timestamp: 1550626797\n",
      "  timesteps_since_restore: 5830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5830000\n",
      "  training_iteration: 583\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10358 s, 583 iter, 5830000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-40-15\n",
      "  done: false\n",
      "  episode_len_mean: 131.01\n",
      "  episode_reward_max: 215.72855038549932\n",
      "  episode_reward_mean: 170.0148172259122\n",
      "  episode_reward_min: -44.81947584664173\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 44726\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5540152788162231\n",
      "      kl: 0.022141478955745697\n",
      "      policy_loss: -0.0010541805531829596\n",
      "      total_loss: 50.31435012817383\n",
      "      vf_explained_var: 0.9851994514465332\n",
      "      vf_loss: 50.31540298461914\n",
      "    grad_time_ms: 1538.767\n",
      "    load_time_ms: 1.329\n",
      "    num_steps_sampled: 5840000\n",
      "    num_steps_trained: 5840000\n",
      "    sample_time_ms: 15872.407\n",
      "    update_time_ms: 4.39\n",
      "  iterations_since_restore: 584\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10376.128717899323\n",
      "  time_this_iter_s: 17.327231884002686\n",
      "  time_total_s: 10376.128717899323\n",
      "  timestamp: 1550626815\n",
      "  timesteps_since_restore: 5840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5840000\n",
      "  training_iteration: 584\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10376 s, 584 iter, 5840000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-40-32\n",
      "  done: false\n",
      "  episode_len_mean: 132.41\n",
      "  episode_reward_max: 218.07709190953938\n",
      "  episode_reward_mean: 172.82129264485323\n",
      "  episode_reward_min: -47.6353957276828\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 44801\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6292150020599365\n",
      "      kl: 0.022114325314760208\n",
      "      policy_loss: -0.006380478385835886\n",
      "      total_loss: 56.40218734741211\n",
      "      vf_explained_var: 0.9829858541488647\n",
      "      vf_loss: 56.408565521240234\n",
      "    grad_time_ms: 1541.731\n",
      "    load_time_ms: 1.363\n",
      "    num_steps_sampled: 5850000\n",
      "    num_steps_trained: 5850000\n",
      "    sample_time_ms: 15863.833\n",
      "    update_time_ms: 4.352\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10393.536384820938\n",
      "  time_this_iter_s: 17.4076669216156\n",
      "  time_total_s: 10393.536384820938\n",
      "  timestamp: 1550626832\n",
      "  timesteps_since_restore: 5850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5850000\n",
      "  training_iteration: 585\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10393 s, 585 iter, 5850000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-40-50\n",
      "  done: false\n",
      "  episode_len_mean: 130.62\n",
      "  episode_reward_max: 218.07709190953938\n",
      "  episode_reward_mean: 167.26660575887047\n",
      "  episode_reward_min: -47.94180927300218\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 44879\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5208690166473389\n",
      "      kl: 0.01943417638540268\n",
      "      policy_loss: -0.0010632268385961652\n",
      "      total_loss: 55.41510009765625\n",
      "      vf_explained_var: 0.9845881462097168\n",
      "      vf_loss: 55.416160583496094\n",
      "    grad_time_ms: 1541.882\n",
      "    load_time_ms: 1.381\n",
      "    num_steps_sampled: 5860000\n",
      "    num_steps_trained: 5860000\n",
      "    sample_time_ms: 15889.562\n",
      "    update_time_ms: 4.482\n",
      "  iterations_since_restore: 586\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10411.043549537659\n",
      "  time_this_iter_s: 17.50716471672058\n",
      "  time_total_s: 10411.043549537659\n",
      "  timestamp: 1550626850\n",
      "  timesteps_since_restore: 5860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5860000\n",
      "  training_iteration: 586\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10411 s, 586 iter, 5860000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-41-07\n",
      "  done: false\n",
      "  episode_len_mean: 131.85\n",
      "  episode_reward_max: 216.2232594029\n",
      "  episode_reward_mean: 167.37858921321393\n",
      "  episode_reward_min: -47.572999751951436\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 44955\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7780615091323853\n",
      "      kl: 0.016069313511252403\n",
      "      policy_loss: -0.0017948586028069258\n",
      "      total_loss: 115.01921844482422\n",
      "      vf_explained_var: 0.9648425579071045\n",
      "      vf_loss: 115.02099609375\n",
      "    grad_time_ms: 1541.875\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 5870000\n",
      "    num_steps_trained: 5870000\n",
      "    sample_time_ms: 15909.517\n",
      "    update_time_ms: 4.39\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10428.44787144661\n",
      "  time_this_iter_s: 17.404321908950806\n",
      "  time_total_s: 10428.44787144661\n",
      "  timestamp: 1550626867\n",
      "  timesteps_since_restore: 5870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5870000\n",
      "  training_iteration: 587\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10428 s, 587 iter, 5870000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-41-25\n",
      "  done: false\n",
      "  episode_len_mean: 131.75\n",
      "  episode_reward_max: 213.9210596375979\n",
      "  episode_reward_mean: 172.15014594770807\n",
      "  episode_reward_min: -47.572999751951436\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 45030\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4219387769699097\n",
      "      kl: 0.03231604024767876\n",
      "      policy_loss: 0.001215481897816062\n",
      "      total_loss: 60.04798126220703\n",
      "      vf_explained_var: 0.9801255464553833\n",
      "      vf_loss: 60.04677963256836\n",
      "    grad_time_ms: 1543.133\n",
      "    load_time_ms: 1.319\n",
      "    num_steps_sampled: 5880000\n",
      "    num_steps_trained: 5880000\n",
      "    sample_time_ms: 15961.836\n",
      "    update_time_ms: 4.304\n",
      "  iterations_since_restore: 588\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10446.03939318657\n",
      "  time_this_iter_s: 17.591521739959717\n",
      "  time_total_s: 10446.03939318657\n",
      "  timestamp: 1550626885\n",
      "  timesteps_since_restore: 5880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5880000\n",
      "  training_iteration: 588\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10446 s, 588 iter, 5880000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-41-42\n",
      "  done: false\n",
      "  episode_len_mean: 133.72\n",
      "  episode_reward_max: 219.86505036561366\n",
      "  episode_reward_mean: 173.83563214772687\n",
      "  episode_reward_min: -45.75658288830429\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 45105\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7374097108840942\n",
      "      kl: 0.014535258524119854\n",
      "      policy_loss: -0.00035120421671308577\n",
      "      total_loss: 34.19807052612305\n",
      "      vf_explained_var: 0.9897703528404236\n",
      "      vf_loss: 34.19842529296875\n",
      "    grad_time_ms: 1542.601\n",
      "    load_time_ms: 1.273\n",
      "    num_steps_sampled: 5890000\n",
      "    num_steps_trained: 5890000\n",
      "    sample_time_ms: 15920.544\n",
      "    update_time_ms: 4.119\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10463.210460186005\n",
      "  time_this_iter_s: 17.171066999435425\n",
      "  time_total_s: 10463.210460186005\n",
      "  timestamp: 1550626902\n",
      "  timesteps_since_restore: 5890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5890000\n",
      "  training_iteration: 589\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10463 s, 589 iter, 5890000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-42-00\n",
      "  done: false\n",
      "  episode_len_mean: 132.35\n",
      "  episode_reward_max: 221.25300946625157\n",
      "  episode_reward_mean: 168.76984632330382\n",
      "  episode_reward_min: -42.970346805556574\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 45181\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.545632004737854\n",
      "      kl: 0.018578680232167244\n",
      "      policy_loss: -0.0040817842818796635\n",
      "      total_loss: 74.3440170288086\n",
      "      vf_explained_var: 0.9785902500152588\n",
      "      vf_loss: 74.34809112548828\n",
      "    grad_time_ms: 1545.115\n",
      "    load_time_ms: 1.33\n",
      "    num_steps_sampled: 5900000\n",
      "    num_steps_trained: 5900000\n",
      "    sample_time_ms: 15934.976\n",
      "    update_time_ms: 4.126\n",
      "  iterations_since_restore: 590\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10480.832234621048\n",
      "  time_this_iter_s: 17.621774435043335\n",
      "  time_total_s: 10480.832234621048\n",
      "  timestamp: 1550626920\n",
      "  timesteps_since_restore: 5900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5900000\n",
      "  training_iteration: 590\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10480 s, 590 iter, 5900000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-42-17\n",
      "  done: false\n",
      "  episode_len_mean: 133.03\n",
      "  episode_reward_max: 214.8857880562984\n",
      "  episode_reward_mean: 168.49055930403557\n",
      "  episode_reward_min: -42.970346805556574\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 45255\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6585592031478882\n",
      "      kl: 0.03769582137465477\n",
      "      policy_loss: 0.00126554723829031\n",
      "      total_loss: 104.93016815185547\n",
      "      vf_explained_var: 0.9701084494590759\n",
      "      vf_loss: 104.92890167236328\n",
      "    grad_time_ms: 1544.439\n",
      "    load_time_ms: 1.364\n",
      "    num_steps_sampled: 5910000\n",
      "    num_steps_trained: 5910000\n",
      "    sample_time_ms: 15924.072\n",
      "    update_time_ms: 4.225\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10498.112646102905\n",
      "  time_this_iter_s: 17.2804114818573\n",
      "  time_total_s: 10498.112646102905\n",
      "  timestamp: 1550626937\n",
      "  timesteps_since_restore: 5910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5910000\n",
      "  training_iteration: 591\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10498 s, 591 iter, 5910000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-42-34\n",
      "  done: false\n",
      "  episode_len_mean: 133.8\n",
      "  episode_reward_max: 218.06677316424285\n",
      "  episode_reward_mean: 171.9243607268903\n",
      "  episode_reward_min: -43.141265810421196\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 45330\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6238499879837036\n",
      "      kl: 0.032032787799835205\n",
      "      policy_loss: -0.0025065671652555466\n",
      "      total_loss: 91.78179931640625\n",
      "      vf_explained_var: 0.9728860259056091\n",
      "      vf_loss: 91.7843017578125\n",
      "    grad_time_ms: 1541.044\n",
      "    load_time_ms: 1.317\n",
      "    num_steps_sampled: 5920000\n",
      "    num_steps_trained: 5920000\n",
      "    sample_time_ms: 15858.51\n",
      "    update_time_ms: 4.191\n",
      "  iterations_since_restore: 592\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10515.394720077515\n",
      "  time_this_iter_s: 17.282073974609375\n",
      "  time_total_s: 10515.394720077515\n",
      "  timestamp: 1550626954\n",
      "  timesteps_since_restore: 5920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5920000\n",
      "  training_iteration: 592\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10515 s, 592 iter, 5920000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-42-52\n",
      "  done: false\n",
      "  episode_len_mean: 132.78\n",
      "  episode_reward_max: 217.74019332827615\n",
      "  episode_reward_mean: 169.42575347857118\n",
      "  episode_reward_min: -43.81108814492674\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 45405\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.8221185207366943\n",
      "      kl: 0.024424411356449127\n",
      "      policy_loss: -0.0008541464922018349\n",
      "      total_loss: 36.91389083862305\n",
      "      vf_explained_var: 0.9878636002540588\n",
      "      vf_loss: 36.914737701416016\n",
      "    grad_time_ms: 1541.74\n",
      "    load_time_ms: 1.315\n",
      "    num_steps_sampled: 5930000\n",
      "    num_steps_trained: 5930000\n",
      "    sample_time_ms: 15842.618\n",
      "    update_time_ms: 4.135\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10532.826167106628\n",
      "  time_this_iter_s: 17.43144702911377\n",
      "  time_total_s: 10532.826167106628\n",
      "  timestamp: 1550626972\n",
      "  timesteps_since_restore: 5930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5930000\n",
      "  training_iteration: 593\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10532 s, 593 iter, 5930000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-43-10\n",
      "  done: false\n",
      "  episode_len_mean: 132.06\n",
      "  episode_reward_max: 217.76659614950574\n",
      "  episode_reward_mean: 174.5792503647717\n",
      "  episode_reward_min: -43.81108814492674\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 45480\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6754379272460938\n",
      "      kl: 0.015888111665844917\n",
      "      policy_loss: 0.0014407142298296094\n",
      "      total_loss: 13.313422203063965\n",
      "      vf_explained_var: 0.99549800157547\n",
      "      vf_loss: 13.311982154846191\n",
      "    grad_time_ms: 1542.3\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 5940000\n",
      "    num_steps_trained: 5940000\n",
      "    sample_time_ms: 15880.839\n",
      "    update_time_ms: 4.057\n",
      "  iterations_since_restore: 594\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10550.541457653046\n",
      "  time_this_iter_s: 17.715290546417236\n",
      "  time_total_s: 10550.541457653046\n",
      "  timestamp: 1550626990\n",
      "  timesteps_since_restore: 5940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5940000\n",
      "  training_iteration: 594\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10550 s, 594 iter, 5940000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-43-26\n",
      "  done: false\n",
      "  episode_len_mean: 136.09\n",
      "  episode_reward_max: 216.06092964263976\n",
      "  episode_reward_mean: 176.39224359386034\n",
      "  episode_reward_min: 64.96678142190575\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 45554\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7951879501342773\n",
      "      kl: 0.010541117750108242\n",
      "      policy_loss: -0.0011583808809518814\n",
      "      total_loss: 45.42346954345703\n",
      "      vf_explained_var: 0.9856880307197571\n",
      "      vf_loss: 45.424625396728516\n",
      "    grad_time_ms: 1543.041\n",
      "    load_time_ms: 1.317\n",
      "    num_steps_sampled: 5950000\n",
      "    num_steps_trained: 5950000\n",
      "    sample_time_ms: 15814.499\n",
      "    update_time_ms: 4.108\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10567.2904753685\n",
      "  time_this_iter_s: 16.7490177154541\n",
      "  time_total_s: 10567.2904753685\n",
      "  timestamp: 1550627006\n",
      "  timesteps_since_restore: 5950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5950000\n",
      "  training_iteration: 595\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10567 s, 595 iter, 5950000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-43-44\n",
      "  done: false\n",
      "  episode_len_mean: 134.54\n",
      "  episode_reward_max: 223.26933500251843\n",
      "  episode_reward_mean: 175.8938959151375\n",
      "  episode_reward_min: 91.65261642243877\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 45628\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5858052968978882\n",
      "      kl: 0.01790066435933113\n",
      "      policy_loss: -0.0003074135456699878\n",
      "      total_loss: 13.186127662658691\n",
      "      vf_explained_var: 0.9955758452415466\n",
      "      vf_loss: 13.18643569946289\n",
      "    grad_time_ms: 1543.888\n",
      "    load_time_ms: 1.294\n",
      "    num_steps_sampled: 5960000\n",
      "    num_steps_trained: 5960000\n",
      "    sample_time_ms: 15798.01\n",
      "    update_time_ms: 4.053\n",
      "  iterations_since_restore: 596\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10584.63975429535\n",
      "  time_this_iter_s: 17.349278926849365\n",
      "  time_total_s: 10584.63975429535\n",
      "  timestamp: 1550627024\n",
      "  timesteps_since_restore: 5960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5960000\n",
      "  training_iteration: 596\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10584 s, 596 iter, 5960000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-44-01\n",
      "  done: false\n",
      "  episode_len_mean: 133.17\n",
      "  episode_reward_max: 222.08752207118695\n",
      "  episode_reward_mean: 172.6357602583868\n",
      "  episode_reward_min: -36.50745784174095\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 45703\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.469716191291809\n",
      "      kl: 0.025990843772888184\n",
      "      policy_loss: 0.000720812997315079\n",
      "      total_loss: 90.89266204833984\n",
      "      vf_explained_var: 0.9721774458885193\n",
      "      vf_loss: 90.89192962646484\n",
      "    grad_time_ms: 1546.965\n",
      "    load_time_ms: 1.311\n",
      "    num_steps_sampled: 5970000\n",
      "    num_steps_trained: 5970000\n",
      "    sample_time_ms: 15813.801\n",
      "    update_time_ms: 4.234\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10602.236964702606\n",
      "  time_this_iter_s: 17.59721040725708\n",
      "  time_total_s: 10602.236964702606\n",
      "  timestamp: 1550627041\n",
      "  timesteps_since_restore: 5970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5970000\n",
      "  training_iteration: 597\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10602 s, 597 iter, 5970000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-44-19\n",
      "  done: false\n",
      "  episode_len_mean: 130.54\n",
      "  episode_reward_max: 216.20454630986\n",
      "  episode_reward_mean: 166.19430146821017\n",
      "  episode_reward_min: -44.02689961971032\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 45780\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4334381818771362\n",
      "      kl: 0.02945987693965435\n",
      "      policy_loss: -0.0008917060331441462\n",
      "      total_loss: 123.87625122070312\n",
      "      vf_explained_var: 0.9679667353630066\n",
      "      vf_loss: 123.87714385986328\n",
      "    grad_time_ms: 1548.385\n",
      "    load_time_ms: 1.372\n",
      "    num_steps_sampled: 5980000\n",
      "    num_steps_trained: 5980000\n",
      "    sample_time_ms: 15767.205\n",
      "    update_time_ms: 4.342\n",
      "  iterations_since_restore: 598\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10619.38033080101\n",
      "  time_this_iter_s: 17.14336609840393\n",
      "  time_total_s: 10619.38033080101\n",
      "  timestamp: 1550627059\n",
      "  timesteps_since_restore: 5980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5980000\n",
      "  training_iteration: 598\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10619 s, 598 iter, 5980000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-44-36\n",
      "  done: false\n",
      "  episode_len_mean: 135.21\n",
      "  episode_reward_max: 223.18092319232838\n",
      "  episode_reward_mean: 174.13907686986772\n",
      "  episode_reward_min: -40.112115981518336\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 45853\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.827431559562683\n",
      "      kl: 0.0232575424015522\n",
      "      policy_loss: -0.0015375615330412984\n",
      "      total_loss: 33.5437126159668\n",
      "      vf_explained_var: 0.9900416135787964\n",
      "      vf_loss: 33.545249938964844\n",
      "    grad_time_ms: 1548.981\n",
      "    load_time_ms: 1.365\n",
      "    num_steps_sampled: 5990000\n",
      "    num_steps_trained: 5990000\n",
      "    sample_time_ms: 15769.163\n",
      "    update_time_ms: 4.373\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10636.576397895813\n",
      "  time_this_iter_s: 17.196067094802856\n",
      "  time_total_s: 10636.576397895813\n",
      "  timestamp: 1550627076\n",
      "  timesteps_since_restore: 5990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5990000\n",
      "  training_iteration: 599\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10636 s, 599 iter, 5990000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-44-54\n",
      "  done: false\n",
      "  episode_len_mean: 134.75\n",
      "  episode_reward_max: 226.4176155319159\n",
      "  episode_reward_mean: 173.30466678080086\n",
      "  episode_reward_min: -47.965972680930456\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 45929\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.75810968875885\n",
      "      kl: 0.026382843032479286\n",
      "      policy_loss: -0.0014757224125787616\n",
      "      total_loss: 23.27577781677246\n",
      "      vf_explained_var: 0.9927722215652466\n",
      "      vf_loss: 23.277254104614258\n",
      "    grad_time_ms: 1568.341\n",
      "    load_time_ms: 1.35\n",
      "    num_steps_sampled: 6000000\n",
      "    num_steps_trained: 6000000\n",
      "    sample_time_ms: 15779.145\n",
      "    update_time_ms: 4.383\n",
      "  iterations_since_restore: 600\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10654.492712020874\n",
      "  time_this_iter_s: 17.916314125061035\n",
      "  time_total_s: 10654.492712020874\n",
      "  timestamp: 1550627094\n",
      "  timesteps_since_restore: 6000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6000000\n",
      "  training_iteration: 600\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10654 s, 600 iter, 6000000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-45-11\n",
      "  done: false\n",
      "  episode_len_mean: 131.26\n",
      "  episode_reward_max: 212.25170867602435\n",
      "  episode_reward_mean: 163.06090961354406\n",
      "  episode_reward_min: -46.67335470876481\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 46005\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5039217472076416\n",
      "      kl: 0.022926975041627884\n",
      "      policy_loss: -0.006099720951169729\n",
      "      total_loss: 111.46714782714844\n",
      "      vf_explained_var: 0.9711634516716003\n",
      "      vf_loss: 111.4732437133789\n",
      "    grad_time_ms: 1568.985\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 6010000\n",
      "    num_steps_trained: 6010000\n",
      "    sample_time_ms: 15736.005\n",
      "    update_time_ms: 4.383\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10671.348664283752\n",
      "  time_this_iter_s: 16.855952262878418\n",
      "  time_total_s: 10671.348664283752\n",
      "  timestamp: 1550627111\n",
      "  timesteps_since_restore: 6010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6010000\n",
      "  training_iteration: 601\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10671 s, 601 iter, 6010000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-45-28\n",
      "  done: false\n",
      "  episode_len_mean: 134.21\n",
      "  episode_reward_max: 218.41821979797717\n",
      "  episode_reward_mean: 169.0743789379255\n",
      "  episode_reward_min: -41.23194676342575\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 46079\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7648882865905762\n",
      "      kl: 0.02669370546936989\n",
      "      policy_loss: -0.0016271475469693542\n",
      "      total_loss: 70.27247619628906\n",
      "      vf_explained_var: 0.9780989289283752\n",
      "      vf_loss: 70.27410888671875\n",
      "    grad_time_ms: 1567.222\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 6020000\n",
      "    num_steps_trained: 6020000\n",
      "    sample_time_ms: 15739.259\n",
      "    update_time_ms: 4.524\n",
      "  iterations_since_restore: 602\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10688.649870872498\n",
      "  time_this_iter_s: 17.301206588745117\n",
      "  time_total_s: 10688.649870872498\n",
      "  timestamp: 1550627128\n",
      "  timesteps_since_restore: 6020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6020000\n",
      "  training_iteration: 602\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10688 s, 602 iter, 6020000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-45-46\n",
      "  done: false\n",
      "  episode_len_mean: 133.66\n",
      "  episode_reward_max: 219.40202783162493\n",
      "  episode_reward_mean: 173.87646292878665\n",
      "  episode_reward_min: -41.23194676342575\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 46154\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6308469772338867\n",
      "      kl: 0.026351846754550934\n",
      "      policy_loss: -0.002185860648751259\n",
      "      total_loss: 76.69679260253906\n",
      "      vf_explained_var: 0.9754108786582947\n",
      "      vf_loss: 76.69898223876953\n",
      "    grad_time_ms: 1567.03\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 6030000\n",
      "    num_steps_trained: 6030000\n",
      "    sample_time_ms: 15749.205\n",
      "    update_time_ms: 4.49\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10706.179334402084\n",
      "  time_this_iter_s: 17.529463529586792\n",
      "  time_total_s: 10706.179334402084\n",
      "  timestamp: 1550627146\n",
      "  timesteps_since_restore: 6030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6030000\n",
      "  training_iteration: 603\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10706 s, 603 iter, 6030000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-46-03\n",
      "  done: false\n",
      "  episode_len_mean: 134.88\n",
      "  episode_reward_max: 224.2917085896145\n",
      "  episode_reward_mean: 174.96441091478607\n",
      "  episode_reward_min: -47.909929762197905\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 46227\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5550885200500488\n",
      "      kl: 0.017997177317738533\n",
      "      policy_loss: -0.0024939184077084064\n",
      "      total_loss: 60.88996887207031\n",
      "      vf_explained_var: 0.9825849533081055\n",
      "      vf_loss: 60.892452239990234\n",
      "    grad_time_ms: 1569.594\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 6040000\n",
      "    num_steps_trained: 6040000\n",
      "    sample_time_ms: 15747.987\n",
      "    update_time_ms: 4.424\n",
      "  iterations_since_restore: 604\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10723.908553361893\n",
      "  time_this_iter_s: 17.72921895980835\n",
      "  time_total_s: 10723.908553361893\n",
      "  timestamp: 1550627163\n",
      "  timesteps_since_restore: 6040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6040000\n",
      "  training_iteration: 604\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10723 s, 604 iter, 6040000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-46-21\n",
      "  done: false\n",
      "  episode_len_mean: 135.82\n",
      "  episode_reward_max: 224.2917085896145\n",
      "  episode_reward_mean: 173.02313757918893\n",
      "  episode_reward_min: -41.981750226109334\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 46301\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.752514362335205\n",
      "      kl: 0.02480548992753029\n",
      "      policy_loss: -0.0015624144580215216\n",
      "      total_loss: 62.43119430541992\n",
      "      vf_explained_var: 0.9813046455383301\n",
      "      vf_loss: 62.43276596069336\n",
      "    grad_time_ms: 1568.381\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 6050000\n",
      "    num_steps_trained: 6050000\n",
      "    sample_time_ms: 15797.273\n",
      "    update_time_ms: 4.389\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10741.138511419296\n",
      "  time_this_iter_s: 17.229958057403564\n",
      "  time_total_s: 10741.138511419296\n",
      "  timestamp: 1550627181\n",
      "  timesteps_since_restore: 6050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6050000\n",
      "  training_iteration: 605\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10741 s, 605 iter, 6050000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-46-38\n",
      "  done: false\n",
      "  episode_len_mean: 132.3\n",
      "  episode_reward_max: 222.59739013163767\n",
      "  episode_reward_mean: 162.57672847394397\n",
      "  episode_reward_min: -41.981750226109334\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 46375\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5620592832565308\n",
      "      kl: 0.016393359750509262\n",
      "      policy_loss: -0.0027354215271770954\n",
      "      total_loss: 91.10758209228516\n",
      "      vf_explained_var: 0.975864827632904\n",
      "      vf_loss: 91.1103286743164\n",
      "    grad_time_ms: 1566.686\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 6060000\n",
      "    num_steps_trained: 6060000\n",
      "    sample_time_ms: 15784.999\n",
      "    update_time_ms: 4.239\n",
      "  iterations_since_restore: 606\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10758.348502397537\n",
      "  time_this_iter_s: 17.209990978240967\n",
      "  time_total_s: 10758.348502397537\n",
      "  timestamp: 1550627198\n",
      "  timesteps_since_restore: 6060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6060000\n",
      "  training_iteration: 606\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10758 s, 606 iter, 6060000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-46-55\n",
      "  done: false\n",
      "  episode_len_mean: 130.59\n",
      "  episode_reward_max: 217.66505265704333\n",
      "  episode_reward_mean: 164.75029305058274\n",
      "  episode_reward_min: -40.62823718668211\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 46453\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3748046159744263\n",
      "      kl: 0.0338018499314785\n",
      "      policy_loss: -0.0007252400973811746\n",
      "      total_loss: 123.7647476196289\n",
      "      vf_explained_var: 0.9648440480232239\n",
      "      vf_loss: 123.7655029296875\n",
      "    grad_time_ms: 1565.967\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 6070000\n",
      "    num_steps_trained: 6070000\n",
      "    sample_time_ms: 15766.724\n",
      "    update_time_ms: 4.224\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10775.756031751633\n",
      "  time_this_iter_s: 17.40752935409546\n",
      "  time_total_s: 10775.756031751633\n",
      "  timestamp: 1550627215\n",
      "  timesteps_since_restore: 6070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6070000\n",
      "  training_iteration: 607\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10775 s, 607 iter, 6070000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-47-13\n",
      "  done: false\n",
      "  episode_len_mean: 132.56\n",
      "  episode_reward_max: 217.66505265704333\n",
      "  episode_reward_mean: 168.22359796683577\n",
      "  episode_reward_min: -43.37300972478224\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 46528\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5951237678527832\n",
      "      kl: 0.022662099450826645\n",
      "      policy_loss: 0.00043942066258750856\n",
      "      total_loss: 41.38077926635742\n",
      "      vf_explained_var: 0.9876419305801392\n",
      "      vf_loss: 41.380340576171875\n",
      "    grad_time_ms: 1565.082\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 6080000\n",
      "    num_steps_trained: 6080000\n",
      "    sample_time_ms: 15788.177\n",
      "    update_time_ms: 4.172\n",
      "  iterations_since_restore: 608\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10793.102957963943\n",
      "  time_this_iter_s: 17.34692621231079\n",
      "  time_total_s: 10793.102957963943\n",
      "  timestamp: 1550627233\n",
      "  timesteps_since_restore: 6080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6080000\n",
      "  training_iteration: 608\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10793 s, 608 iter, 6080000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-47-30\n",
      "  done: false\n",
      "  episode_len_mean: 132.68\n",
      "  episode_reward_max: 219.6690824111498\n",
      "  episode_reward_mean: 167.88977022978867\n",
      "  episode_reward_min: -48.07753880543286\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 46603\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6173402070999146\n",
      "      kl: 0.020064081996679306\n",
      "      policy_loss: 0.0007719380082562566\n",
      "      total_loss: 70.2181396484375\n",
      "      vf_explained_var: 0.9791609644889832\n",
      "      vf_loss: 70.21736907958984\n",
      "    grad_time_ms: 1568.187\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 6090000\n",
      "    num_steps_trained: 6090000\n",
      "    sample_time_ms: 15829.703\n",
      "    update_time_ms: 4.191\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10810.745288610458\n",
      "  time_this_iter_s: 17.642330646514893\n",
      "  time_total_s: 10810.745288610458\n",
      "  timestamp: 1550627250\n",
      "  timesteps_since_restore: 6090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6090000\n",
      "  training_iteration: 609\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10810 s, 609 iter, 6090000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-47-48\n",
      "  done: false\n",
      "  episode_len_mean: 130.25\n",
      "  episode_reward_max: 221.5384446187037\n",
      "  episode_reward_mean: 156.3031729197702\n",
      "  episode_reward_min: -49.2758941575147\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 46679\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.538887619972229\n",
      "      kl: 0.02223859168589115\n",
      "      policy_loss: -0.0028890573885291815\n",
      "      total_loss: 92.35287475585938\n",
      "      vf_explained_var: 0.9749531149864197\n",
      "      vf_loss: 92.35576629638672\n",
      "    grad_time_ms: 1547.847\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 6100000\n",
      "    num_steps_trained: 6100000\n",
      "    sample_time_ms: 15822.917\n",
      "    update_time_ms: 4.24\n",
      "  iterations_since_restore: 610\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10828.391478776932\n",
      "  time_this_iter_s: 17.64619016647339\n",
      "  time_total_s: 10828.391478776932\n",
      "  timestamp: 1550627268\n",
      "  timesteps_since_restore: 6100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6100000\n",
      "  training_iteration: 610\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10828 s, 610 iter, 6100000 ts, 156 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-48-06\n",
      "  done: false\n",
      "  episode_len_mean: 131.93\n",
      "  episode_reward_max: 219.075495248015\n",
      "  episode_reward_mean: 164.33094470051333\n",
      "  episode_reward_min: -48.82025509364532\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 46754\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.17575836709534e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5871806144714355\n",
      "      kl: 0.05270848423242569\n",
      "      policy_loss: 0.00644964724779129\n",
      "      total_loss: 49.94987869262695\n",
      "      vf_explained_var: 0.9845492243766785\n",
      "      vf_loss: 49.94343566894531\n",
      "    grad_time_ms: 1547.761\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 6110000\n",
      "    num_steps_trained: 6110000\n",
      "    sample_time_ms: 15919.109\n",
      "    update_time_ms: 4.17\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10846.20695233345\n",
      "  time_this_iter_s: 17.815473556518555\n",
      "  time_total_s: 10846.20695233345\n",
      "  timestamp: 1550627286\n",
      "  timesteps_since_restore: 6110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6110000\n",
      "  training_iteration: 611\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10846 s, 611 iter, 6110000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-48-24\n",
      "  done: false\n",
      "  episode_len_mean: 134.37\n",
      "  episode_reward_max: 219.33486546266184\n",
      "  episode_reward_mean: 166.59188732162443\n",
      "  episode_reward_min: -44.5042131478059\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 46829\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.263636525123833e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.625392198562622\n",
      "      kl: 0.021052973344922066\n",
      "      policy_loss: -0.0016795981209725142\n",
      "      total_loss: 62.6848258972168\n",
      "      vf_explained_var: 0.98199063539505\n",
      "      vf_loss: 62.68650436401367\n",
      "    grad_time_ms: 1569.871\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 6120000\n",
      "    num_steps_trained: 6120000\n",
      "    sample_time_ms: 15947.85\n",
      "    update_time_ms: 4.166\n",
      "  iterations_since_restore: 612\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10864.013988494873\n",
      "  time_this_iter_s: 17.80703616142273\n",
      "  time_total_s: 10864.013988494873\n",
      "  timestamp: 1550627304\n",
      "  timesteps_since_restore: 6120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6120000\n",
      "  training_iteration: 612\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10864 s, 612 iter, 6120000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-48-41\n",
      "  done: false\n",
      "  episode_len_mean: 132.48\n",
      "  episode_reward_max: 214.2354069574928\n",
      "  episode_reward_mean: 164.90071373876086\n",
      "  episode_reward_min: -43.61555216712231\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 46905\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.263636525123833e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5661144256591797\n",
      "      kl: 0.032107532024383545\n",
      "      policy_loss: -0.003956742584705353\n",
      "      total_loss: 121.24144744873047\n",
      "      vf_explained_var: 0.96494460105896\n",
      "      vf_loss: 121.24539184570312\n",
      "    grad_time_ms: 1568.374\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 6130000\n",
      "    num_steps_trained: 6130000\n",
      "    sample_time_ms: 15896.855\n",
      "    update_time_ms: 4.262\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10881.019945383072\n",
      "  time_this_iter_s: 17.005956888198853\n",
      "  time_total_s: 10881.019945383072\n",
      "  timestamp: 1550627321\n",
      "  timesteps_since_restore: 6130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6130000\n",
      "  training_iteration: 613\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10881 s, 613 iter, 6130000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-48-58\n",
      "  done: false\n",
      "  episode_len_mean: 132.85\n",
      "  episode_reward_max: 220.20794977435833\n",
      "  episode_reward_mean: 166.69752604925867\n",
      "  episode_reward_min: -44.58133721904883\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 46981\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.263636525123833e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7017297744750977\n",
      "      kl: 0.024122361093759537\n",
      "      policy_loss: 0.0002584483299870044\n",
      "      total_loss: 66.53849792480469\n",
      "      vf_explained_var: 0.980228841304779\n",
      "      vf_loss: 66.5382308959961\n",
      "    grad_time_ms: 1566.936\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 6140000\n",
      "    num_steps_trained: 6140000\n",
      "    sample_time_ms: 15893.83\n",
      "    update_time_ms: 4.292\n",
      "  iterations_since_restore: 614\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10898.702964544296\n",
      "  time_this_iter_s: 17.683019161224365\n",
      "  time_total_s: 10898.702964544296\n",
      "  timestamp: 1550627338\n",
      "  timesteps_since_restore: 6140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6140000\n",
      "  training_iteration: 614\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10898 s, 614 iter, 6140000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-49-16\n",
      "  done: false\n",
      "  episode_len_mean: 131.68\n",
      "  episode_reward_max: 221.36883707774246\n",
      "  episode_reward_mean: 171.94719891302054\n",
      "  episode_reward_min: -41.92014892532094\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 47056\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.263636525123833e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3600598573684692\n",
      "      kl: 0.019290799275040627\n",
      "      policy_loss: -0.0027285171672701836\n",
      "      total_loss: 67.7283706665039\n",
      "      vf_explained_var: 0.9792375564575195\n",
      "      vf_loss: 67.73109436035156\n",
      "    grad_time_ms: 1565.773\n",
      "    load_time_ms: 1.394\n",
      "    num_steps_sampled: 6150000\n",
      "    num_steps_trained: 6150000\n",
      "    sample_time_ms: 15872.788\n",
      "    update_time_ms: 4.281\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10915.709770202637\n",
      "  time_this_iter_s: 17.006805658340454\n",
      "  time_total_s: 10915.709770202637\n",
      "  timestamp: 1550627356\n",
      "  timesteps_since_restore: 6150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6150000\n",
      "  training_iteration: 615\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10915 s, 615 iter, 6150000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-49-34\n",
      "  done: false\n",
      "  episode_len_mean: 132.7\n",
      "  episode_reward_max: 218.07994486598105\n",
      "  episode_reward_mean: 169.350908736608\n",
      "  episode_reward_min: -44.36891836473848\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 47132\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.263636525123833e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5855917930603027\n",
      "      kl: 0.05424236133694649\n",
      "      policy_loss: 0.0026344198267906904\n",
      "      total_loss: 111.22822570800781\n",
      "      vf_explained_var: 0.9670254588127136\n",
      "      vf_loss: 111.2255859375\n",
      "    grad_time_ms: 1566.765\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 6160000\n",
      "    num_steps_trained: 6160000\n",
      "    sample_time_ms: 15986.678\n",
      "    update_time_ms: 4.372\n",
      "  iterations_since_restore: 616\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10934.069672107697\n",
      "  time_this_iter_s: 18.359901905059814\n",
      "  time_total_s: 10934.069672107697\n",
      "  timestamp: 1550627374\n",
      "  timesteps_since_restore: 6160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6160000\n",
      "  training_iteration: 616\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10934 s, 616 iter, 6160000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 128.74\n",
      "  episode_reward_max: 218.2103625564367\n",
      "  episode_reward_mean: 161.33275490403793\n",
      "  episode_reward_min: -50.52800448069183\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 47209\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3017082214355469\n",
      "      kl: 0.03550034388899803\n",
      "      policy_loss: 0.0011196085251867771\n",
      "      total_loss: 75.39375305175781\n",
      "      vf_explained_var: 0.9791988730430603\n",
      "      vf_loss: 75.39263153076172\n",
      "    grad_time_ms: 1565.978\n",
      "    load_time_ms: 1.327\n",
      "    num_steps_sampled: 6170000\n",
      "    num_steps_trained: 6170000\n",
      "    sample_time_ms: 16008.063\n",
      "    update_time_ms: 4.307\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10951.681089401245\n",
      "  time_this_iter_s: 17.611417293548584\n",
      "  time_total_s: 10951.681089401245\n",
      "  timestamp: 1550627392\n",
      "  timesteps_since_restore: 6170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6170000\n",
      "  training_iteration: 617\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10951 s, 617 iter, 6170000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-50-09\n",
      "  done: false\n",
      "  episode_len_mean: 132.16\n",
      "  episode_reward_max: 220.29485606025963\n",
      "  episode_reward_mean: 166.9689499614591\n",
      "  episode_reward_min: -50.52800448069183\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 47283\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5842678546905518\n",
      "      kl: 0.010152899660170078\n",
      "      policy_loss: -0.0020143757574260235\n",
      "      total_loss: 41.11564254760742\n",
      "      vf_explained_var: 0.9878007173538208\n",
      "      vf_loss: 41.11766052246094\n",
      "    grad_time_ms: 1563.534\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 6180000\n",
      "    num_steps_trained: 6180000\n",
      "    sample_time_ms: 16020.004\n",
      "    update_time_ms: 4.236\n",
      "  iterations_since_restore: 618\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10969.121849298477\n",
      "  time_this_iter_s: 17.440759897232056\n",
      "  time_total_s: 10969.121849298477\n",
      "  timestamp: 1550627409\n",
      "  timesteps_since_restore: 6180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6180000\n",
      "  training_iteration: 618\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10969 s, 618 iter, 6180000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-50-26\n",
      "  done: false\n",
      "  episode_len_mean: 133.04\n",
      "  episode_reward_max: 220.29485606025963\n",
      "  episode_reward_mean: 175.20106101866673\n",
      "  episode_reward_min: -45.80807914164396\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 47358\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4687825441360474\n",
      "      kl: 0.029141368344426155\n",
      "      policy_loss: -0.006850224453955889\n",
      "      total_loss: 61.078975677490234\n",
      "      vf_explained_var: 0.9826657176017761\n",
      "      vf_loss: 61.085819244384766\n",
      "    grad_time_ms: 1559.97\n",
      "    load_time_ms: 1.363\n",
      "    num_steps_sampled: 6190000\n",
      "    num_steps_trained: 6190000\n",
      "    sample_time_ms: 15992.066\n",
      "    update_time_ms: 4.237\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 10986.448283672333\n",
      "  time_this_iter_s: 17.32643437385559\n",
      "  time_total_s: 10986.448283672333\n",
      "  timestamp: 1550627426\n",
      "  timesteps_since_restore: 6190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6190000\n",
      "  training_iteration: 619\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 10986 s, 619 iter, 6190000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-50-44\n",
      "  done: false\n",
      "  episode_len_mean: 132.19\n",
      "  episode_reward_max: 220.69000399680726\n",
      "  episode_reward_mean: 170.11790814057346\n",
      "  episode_reward_min: -45.80807914164396\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 47434\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5881235599517822\n",
      "      kl: 0.016773900017142296\n",
      "      policy_loss: -0.001602110336534679\n",
      "      total_loss: 33.37420654296875\n",
      "      vf_explained_var: 0.9892951846122742\n",
      "      vf_loss: 33.37581253051758\n",
      "    grad_time_ms: 1559.028\n",
      "    load_time_ms: 1.287\n",
      "    num_steps_sampled: 6200000\n",
      "    num_steps_trained: 6200000\n",
      "    sample_time_ms: 15967.811\n",
      "    update_time_ms: 4.128\n",
      "  iterations_since_restore: 620\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11003.840001821518\n",
      "  time_this_iter_s: 17.39171814918518\n",
      "  time_total_s: 11003.840001821518\n",
      "  timestamp: 1550627444\n",
      "  timesteps_since_restore: 6200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6200000\n",
      "  training_iteration: 620\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11003 s, 620 iter, 6200000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-51-01\n",
      "  done: false\n",
      "  episode_len_mean: 134.86\n",
      "  episode_reward_max: 221.9228590098346\n",
      "  episode_reward_mean: 168.98422015402346\n",
      "  episode_reward_min: -39.448504147553194\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 47507\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5314263105392456\n",
      "      kl: 0.025225412100553513\n",
      "      policy_loss: -0.002237252425402403\n",
      "      total_loss: 113.33960723876953\n",
      "      vf_explained_var: 0.9671223163604736\n",
      "      vf_loss: 113.34183502197266\n",
      "    grad_time_ms: 1560.768\n",
      "    load_time_ms: 1.291\n",
      "    num_steps_sampled: 6210000\n",
      "    num_steps_trained: 6210000\n",
      "    sample_time_ms: 15946.705\n",
      "    update_time_ms: 4.148\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11021.463193655014\n",
      "  time_this_iter_s: 17.623191833496094\n",
      "  time_total_s: 11021.463193655014\n",
      "  timestamp: 1550627461\n",
      "  timesteps_since_restore: 6210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6210000\n",
      "  training_iteration: 621\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11021 s, 621 iter, 6210000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-51-19\n",
      "  done: false\n",
      "  episode_len_mean: 134.51\n",
      "  episode_reward_max: 221.9228590098346\n",
      "  episode_reward_mean: 171.42818883048048\n",
      "  episode_reward_min: -43.39068246145944\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 47582\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4708188772201538\n",
      "      kl: 0.024061063304543495\n",
      "      policy_loss: -0.002507178345695138\n",
      "      total_loss: 64.57162475585938\n",
      "      vf_explained_var: 0.980695366859436\n",
      "      vf_loss: 64.57414245605469\n",
      "    grad_time_ms: 1540.346\n",
      "    load_time_ms: 1.26\n",
      "    num_steps_sampled: 6220000\n",
      "    num_steps_trained: 6220000\n",
      "    sample_time_ms: 15925.722\n",
      "    update_time_ms: 4.108\n",
      "  iterations_since_restore: 622\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11038.854614973068\n",
      "  time_this_iter_s: 17.3914213180542\n",
      "  time_total_s: 11038.854614973068\n",
      "  timestamp: 1550627479\n",
      "  timesteps_since_restore: 6220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6220000\n",
      "  training_iteration: 622\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11038 s, 622 iter, 6220000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-51-37\n",
      "  done: false\n",
      "  episode_len_mean: 134.0\n",
      "  episode_reward_max: 217.39971674495558\n",
      "  episode_reward_mean: 177.28683824995423\n",
      "  episode_reward_min: -42.88567020692448\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 47657\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4091261625289917\n",
      "      kl: 0.01416777353733778\n",
      "      policy_loss: -0.0024273607414215803\n",
      "      total_loss: 53.65822982788086\n",
      "      vf_explained_var: 0.9825742840766907\n",
      "      vf_loss: 53.6606559753418\n",
      "    grad_time_ms: 1541.739\n",
      "    load_time_ms: 1.263\n",
      "    num_steps_sampled: 6230000\n",
      "    num_steps_trained: 6230000\n",
      "    sample_time_ms: 16009.61\n",
      "    update_time_ms: 4.042\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11056.711719036102\n",
      "  time_this_iter_s: 17.857104063034058\n",
      "  time_total_s: 11056.711719036102\n",
      "  timestamp: 1550627497\n",
      "  timesteps_since_restore: 6230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6230000\n",
      "  training_iteration: 623\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11056 s, 623 iter, 6230000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-51-54\n",
      "  done: false\n",
      "  episode_len_mean: 131.61\n",
      "  episode_reward_max: 215.8570771707904\n",
      "  episode_reward_mean: 169.70309911530137\n",
      "  episode_reward_min: -43.29294436697912\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 47733\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.703969955444336\n",
      "      kl: 0.03970380499958992\n",
      "      policy_loss: 0.004918950609862804\n",
      "      total_loss: 52.043113708496094\n",
      "      vf_explained_var: 0.9822857975959778\n",
      "      vf_loss: 52.03819274902344\n",
      "    grad_time_ms: 1556.963\n",
      "    load_time_ms: 1.289\n",
      "    num_steps_sampled: 6240000\n",
      "    num_steps_trained: 6240000\n",
      "    sample_time_ms: 15981.665\n",
      "    update_time_ms: 4.006\n",
      "  iterations_since_restore: 624\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11074.26808834076\n",
      "  time_this_iter_s: 17.556369304656982\n",
      "  time_total_s: 11074.26808834076\n",
      "  timestamp: 1550627514\n",
      "  timesteps_since_restore: 6240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6240000\n",
      "  training_iteration: 624\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11074 s, 624 iter, 6240000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-52-12\n",
      "  done: false\n",
      "  episode_len_mean: 132.3\n",
      "  episode_reward_max: 211.8882272540786\n",
      "  episode_reward_mean: 169.75258257608482\n",
      "  episode_reward_min: -39.43629651435529\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 47809\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5519028902053833\n",
      "      kl: 0.026385197415947914\n",
      "      policy_loss: -0.001144061447121203\n",
      "      total_loss: 75.5492172241211\n",
      "      vf_explained_var: 0.9757281541824341\n",
      "      vf_loss: 75.55036163330078\n",
      "    grad_time_ms: 1558.094\n",
      "    load_time_ms: 1.335\n",
      "    num_steps_sampled: 6250000\n",
      "    num_steps_trained: 6250000\n",
      "    sample_time_ms: 16049.198\n",
      "    update_time_ms: 4.055\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11091.963242530823\n",
      "  time_this_iter_s: 17.695154190063477\n",
      "  time_total_s: 11091.963242530823\n",
      "  timestamp: 1550627532\n",
      "  timesteps_since_restore: 6250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6250000\n",
      "  training_iteration: 625\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11091 s, 625 iter, 6250000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-52-30\n",
      "  done: false\n",
      "  episode_len_mean: 133.95\n",
      "  episode_reward_max: 217.73194266409413\n",
      "  episode_reward_mean: 175.5826515293217\n",
      "  episode_reward_min: -38.326901528799894\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 47883\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.8954568387241033e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5382686853408813\n",
      "      kl: 0.04302477464079857\n",
      "      policy_loss: 0.0036494785454124212\n",
      "      total_loss: 74.45016479492188\n",
      "      vf_explained_var: 0.976206362247467\n",
      "      vf_loss: 74.44651794433594\n",
      "    grad_time_ms: 1557.373\n",
      "    load_time_ms: 1.331\n",
      "    num_steps_sampled: 6260000\n",
      "    num_steps_trained: 6260000\n",
      "    sample_time_ms: 15951.763\n",
      "    update_time_ms: 3.964\n",
      "  iterations_since_restore: 626\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11109.340226650238\n",
      "  time_this_iter_s: 17.376984119415283\n",
      "  time_total_s: 11109.340226650238\n",
      "  timestamp: 1550627550\n",
      "  timesteps_since_restore: 6260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6260000\n",
      "  training_iteration: 626\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11109 s, 626 iter, 6260000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-52-47\n",
      "  done: false\n",
      "  episode_len_mean: 134.28\n",
      "  episode_reward_max: 226.68921846903783\n",
      "  episode_reward_mean: 175.15781236668565\n",
      "  episode_reward_min: -45.16652992367742\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 47958\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.343181156009448e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3562202453613281\n",
      "      kl: 0.0166910570114851\n",
      "      policy_loss: -0.0013221962144598365\n",
      "      total_loss: 54.92502975463867\n",
      "      vf_explained_var: 0.9841963648796082\n",
      "      vf_loss: 54.92634963989258\n",
      "    grad_time_ms: 1556.808\n",
      "    load_time_ms: 1.4\n",
      "    num_steps_sampled: 6270000\n",
      "    num_steps_trained: 6270000\n",
      "    sample_time_ms: 15937.049\n",
      "    update_time_ms: 4.16\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11126.802521944046\n",
      "  time_this_iter_s: 17.462295293807983\n",
      "  time_total_s: 11126.802521944046\n",
      "  timestamp: 1550627567\n",
      "  timesteps_since_restore: 6270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6270000\n",
      "  training_iteration: 627\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11126 s, 627 iter, 6270000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-53-05\n",
      "  done: false\n",
      "  episode_len_mean: 136.68\n",
      "  episode_reward_max: 226.68921846903783\n",
      "  episode_reward_mean: 176.64182080649735\n",
      "  episode_reward_min: -46.302733740003966\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 48031\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.343181156009448e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4871845245361328\n",
      "      kl: 0.02777685597538948\n",
      "      policy_loss: -0.0013393035624176264\n",
      "      total_loss: 59.52539825439453\n",
      "      vf_explained_var: 0.9821261167526245\n",
      "      vf_loss: 59.526729583740234\n",
      "    grad_time_ms: 1557.682\n",
      "    load_time_ms: 1.349\n",
      "    num_steps_sampled: 6280000\n",
      "    num_steps_trained: 6280000\n",
      "    sample_time_ms: 15951.259\n",
      "    update_time_ms: 4.327\n",
      "  iterations_since_restore: 628\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11144.395530939102\n",
      "  time_this_iter_s: 17.593008995056152\n",
      "  time_total_s: 11144.395530939102\n",
      "  timestamp: 1550627585\n",
      "  timesteps_since_restore: 6280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6280000\n",
      "  training_iteration: 628\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11144 s, 628 iter, 6280000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 134.26\n",
      "  episode_reward_max: 220.1371417840076\n",
      "  episode_reward_mean: 169.6871666849499\n",
      "  episode_reward_min: -39.072542397692644\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 48106\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.343181156009448e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6704546213150024\n",
      "      kl: 0.05394803732633591\n",
      "      policy_loss: -0.0006258221110329032\n",
      "      total_loss: 53.88655471801758\n",
      "      vf_explained_var: 0.9817811846733093\n",
      "      vf_loss: 53.88718795776367\n",
      "    grad_time_ms: 1559.699\n",
      "    load_time_ms: 1.409\n",
      "    num_steps_sampled: 6290000\n",
      "    num_steps_trained: 6290000\n",
      "    sample_time_ms: 15957.451\n",
      "    update_time_ms: 4.411\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11161.807118177414\n",
      "  time_this_iter_s: 17.411587238311768\n",
      "  time_total_s: 11161.807118177414\n",
      "  timestamp: 1550627602\n",
      "  timesteps_since_restore: 6290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6290000\n",
      "  training_iteration: 629\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11161 s, 629 iter, 6290000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-53-40\n",
      "  done: false\n",
      "  episode_len_mean: 135.51\n",
      "  episode_reward_max: 220.17955893396135\n",
      "  episode_reward_mean: 175.38620357188512\n",
      "  episode_reward_min: -33.77233317265711\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 48179\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.1014772680647258e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5691118240356445\n",
      "      kl: 0.022758079692721367\n",
      "      policy_loss: -0.0022530232090502977\n",
      "      total_loss: 39.00989532470703\n",
      "      vf_explained_var: 0.9881756901741028\n",
      "      vf_loss: 39.01214599609375\n",
      "    grad_time_ms: 1566.557\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 6300000\n",
      "    num_steps_trained: 6300000\n",
      "    sample_time_ms: 15952.372\n",
      "    update_time_ms: 4.535\n",
      "  iterations_since_restore: 630\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11179.21645617485\n",
      "  time_this_iter_s: 17.409337997436523\n",
      "  time_total_s: 11179.21645617485\n",
      "  timestamp: 1550627620\n",
      "  timesteps_since_restore: 6300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6300000\n",
      "  training_iteration: 630\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11179 s, 630 iter, 6300000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-53-57\n",
      "  done: false\n",
      "  episode_len_mean: 133.53\n",
      "  episode_reward_max: 223.29394543303715\n",
      "  episode_reward_mean: 171.86869119656768\n",
      "  episode_reward_min: -41.223232808089485\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 48255\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.1014772680647258e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4952765703201294\n",
      "      kl: 0.04236675053834915\n",
      "      policy_loss: 0.002468407154083252\n",
      "      total_loss: 122.49529266357422\n",
      "      vf_explained_var: 0.9649967551231384\n",
      "      vf_loss: 122.49282836914062\n",
      "    grad_time_ms: 1564.658\n",
      "    load_time_ms: 1.5\n",
      "    num_steps_sampled: 6310000\n",
      "    num_steps_trained: 6310000\n",
      "    sample_time_ms: 15919.08\n",
      "    update_time_ms: 4.51\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11196.488531827927\n",
      "  time_this_iter_s: 17.272075653076172\n",
      "  time_total_s: 11196.488531827927\n",
      "  timestamp: 1550627637\n",
      "  timesteps_since_restore: 6310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6310000\n",
      "  training_iteration: 631\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11196 s, 631 iter, 6310000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-54-14\n",
      "  done: false\n",
      "  episode_len_mean: 132.21\n",
      "  episode_reward_max: 222.3302033585635\n",
      "  episode_reward_mean: 162.49836950785377\n",
      "  episode_reward_min: -45.69074038110008\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 48331\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4640874862670898\n",
      "      kl: 0.011525756679475307\n",
      "      policy_loss: -0.0013058182084932923\n",
      "      total_loss: 90.260986328125\n",
      "      vf_explained_var: 0.9767804145812988\n",
      "      vf_loss: 90.26229095458984\n",
      "    grad_time_ms: 1564.269\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 6320000\n",
      "    num_steps_trained: 6320000\n",
      "    sample_time_ms: 15894.089\n",
      "    update_time_ms: 4.49\n",
      "  iterations_since_restore: 632\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11213.627758979797\n",
      "  time_this_iter_s: 17.139227151870728\n",
      "  time_total_s: 11213.627758979797\n",
      "  timestamp: 1550627654\n",
      "  timesteps_since_restore: 6320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6320000\n",
      "  training_iteration: 632\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11213 s, 632 iter, 6320000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-54-31\n",
      "  done: false\n",
      "  episode_len_mean: 132.63\n",
      "  episode_reward_max: 218.72667489768855\n",
      "  episode_reward_mean: 166.36545150703753\n",
      "  episode_reward_min: -45.02741157971691\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 48405\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.567811369895935\n",
      "      kl: 0.03993161395192146\n",
      "      policy_loss: -0.0033706342801451683\n",
      "      total_loss: 57.055938720703125\n",
      "      vf_explained_var: 0.9833233952522278\n",
      "      vf_loss: 57.05930709838867\n",
      "    grad_time_ms: 1563.966\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 6330000\n",
      "    num_steps_trained: 6330000\n",
      "    sample_time_ms: 15801.326\n",
      "    update_time_ms: 4.531\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11230.556696414948\n",
      "  time_this_iter_s: 16.928937435150146\n",
      "  time_total_s: 11230.556696414948\n",
      "  timestamp: 1550627671\n",
      "  timesteps_since_restore: 6330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6330000\n",
      "  training_iteration: 633\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11230 s, 633 iter, 6330000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-54-48\n",
      "  done: false\n",
      "  episode_len_mean: 134.27\n",
      "  episode_reward_max: 223.26505512332022\n",
      "  episode_reward_mean: 169.89185906855155\n",
      "  episode_reward_min: -44.6868003629111\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 48481\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5435923337936401\n",
      "      kl: 0.01782715693116188\n",
      "      policy_loss: -0.000707227096427232\n",
      "      total_loss: 76.91053009033203\n",
      "      vf_explained_var: 0.977900505065918\n",
      "      vf_loss: 76.91124725341797\n",
      "    grad_time_ms: 1547.584\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 6340000\n",
      "    num_steps_trained: 6340000\n",
      "    sample_time_ms: 15756.497\n",
      "    update_time_ms: 4.567\n",
      "  iterations_since_restore: 634\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11247.500247716904\n",
      "  time_this_iter_s: 16.943551301956177\n",
      "  time_total_s: 11247.500247716904\n",
      "  timestamp: 1550627688\n",
      "  timesteps_since_restore: 6340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6340000\n",
      "  training_iteration: 634\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11247 s, 634 iter, 6340000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-55-05\n",
      "  done: false\n",
      "  episode_len_mean: 134.96\n",
      "  episode_reward_max: 219.19409415774075\n",
      "  episode_reward_mean: 177.38666841011573\n",
      "  episode_reward_min: -37.59792408022552\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 48555\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3920129537582397\n",
      "      kl: 0.01979006640613079\n",
      "      policy_loss: -0.0011973388027399778\n",
      "      total_loss: 24.65941619873047\n",
      "      vf_explained_var: 0.9920936226844788\n",
      "      vf_loss: 24.660615921020508\n",
      "    grad_time_ms: 1548.399\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 6350000\n",
      "    num_steps_trained: 6350000\n",
      "    sample_time_ms: 15728.619\n",
      "    update_time_ms: 4.514\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11264.926220655441\n",
      "  time_this_iter_s: 17.425972938537598\n",
      "  time_total_s: 11264.926220655441\n",
      "  timestamp: 1550627705\n",
      "  timesteps_since_restore: 6350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6350000\n",
      "  training_iteration: 635\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11264 s, 635 iter, 6350000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 130.9\n",
      "  episode_reward_max: 215.18095003227054\n",
      "  episode_reward_mean: 167.18994839419068\n",
      "  episode_reward_min: -41.42276752201637\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 48632\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3364323377609253\n",
      "      kl: 0.022323686629533768\n",
      "      policy_loss: 0.00017382859368808568\n",
      "      total_loss: 120.16767883300781\n",
      "      vf_explained_var: 0.9660418629646301\n",
      "      vf_loss: 120.1675033569336\n",
      "    grad_time_ms: 1566.685\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 6360000\n",
      "    num_steps_trained: 6360000\n",
      "    sample_time_ms: 15744.031\n",
      "    update_time_ms: 4.554\n",
      "  iterations_since_restore: 636\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11282.63914513588\n",
      "  time_this_iter_s: 17.712924480438232\n",
      "  time_total_s: 11282.63914513588\n",
      "  timestamp: 1550627723\n",
      "  timesteps_since_restore: 6360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6360000\n",
      "  training_iteration: 636\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11282 s, 636 iter, 6360000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-55-41\n",
      "  done: false\n",
      "  episode_len_mean: 134.44\n",
      "  episode_reward_max: 223.84379055181356\n",
      "  episode_reward_mean: 176.28282838505956\n",
      "  episode_reward_min: -41.42276752201637\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 48705\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5301820039749146\n",
      "      kl: 0.018696093931794167\n",
      "      policy_loss: -0.00020214379765093327\n",
      "      total_loss: 23.475200653076172\n",
      "      vf_explained_var: 0.9927339553833008\n",
      "      vf_loss: 23.475406646728516\n",
      "    grad_time_ms: 1570.981\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 6370000\n",
      "    num_steps_trained: 6370000\n",
      "    sample_time_ms: 15731.205\n",
      "    update_time_ms: 4.338\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11300.012719154358\n",
      "  time_this_iter_s: 17.373574018478394\n",
      "  time_total_s: 11300.012719154358\n",
      "  timestamp: 1550627741\n",
      "  timesteps_since_restore: 6370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6370000\n",
      "  training_iteration: 637\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11300 s, 637 iter, 6370000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-55-58\n",
      "  done: false\n",
      "  episode_len_mean: 135.52\n",
      "  episode_reward_max: 216.3443264486916\n",
      "  episode_reward_mean: 173.44979817427082\n",
      "  episode_reward_min: -40.59953246468511\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 48780\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5880398750305176\n",
      "      kl: 0.01704983599483967\n",
      "      policy_loss: -0.001331925974227488\n",
      "      total_loss: 42.16484832763672\n",
      "      vf_explained_var: 0.9870145916938782\n",
      "      vf_loss: 42.16617965698242\n",
      "    grad_time_ms: 1570.803\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 6380000\n",
      "    num_steps_trained: 6380000\n",
      "    sample_time_ms: 15670.893\n",
      "    update_time_ms: 4.191\n",
      "  iterations_since_restore: 638\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11317.001306056976\n",
      "  time_this_iter_s: 16.988586902618408\n",
      "  time_total_s: 11317.001306056976\n",
      "  timestamp: 1550627758\n",
      "  timesteps_since_restore: 6380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6380000\n",
      "  training_iteration: 638\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11317 s, 638 iter, 6380000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-56-15\n",
      "  done: false\n",
      "  episode_len_mean: 133.47\n",
      "  episode_reward_max: 224.29183260746086\n",
      "  episode_reward_mean: 170.56304892724046\n",
      "  episode_reward_min: -47.283039360205734\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 48855\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4871290922164917\n",
      "      kl: 0.019064107909798622\n",
      "      policy_loss: 0.002172834938392043\n",
      "      total_loss: 72.495849609375\n",
      "      vf_explained_var: 0.9793810844421387\n",
      "      vf_loss: 72.49366760253906\n",
      "    grad_time_ms: 1571.704\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 6390000\n",
      "    num_steps_trained: 6390000\n",
      "    sample_time_ms: 15668.111\n",
      "    update_time_ms: 4.204\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11334.394531726837\n",
      "  time_this_iter_s: 17.39322566986084\n",
      "  time_total_s: 11334.394531726837\n",
      "  timestamp: 1550627775\n",
      "  timesteps_since_restore: 6390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6390000\n",
      "  training_iteration: 639\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11334 s, 639 iter, 6390000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-56-33\n",
      "  done: false\n",
      "  episode_len_mean: 133.03\n",
      "  episode_reward_max: 223.8419679994557\n",
      "  episode_reward_mean: 168.53791854354043\n",
      "  episode_reward_min: -46.5199737991437\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 48929\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4954073429107666\n",
      "      kl: 0.026344910264015198\n",
      "      policy_loss: -0.0013457044260576367\n",
      "      total_loss: 64.91355895996094\n",
      "      vf_explained_var: 0.9833734035491943\n",
      "      vf_loss: 64.91490936279297\n",
      "    grad_time_ms: 1566.652\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 6400000\n",
      "    num_steps_trained: 6400000\n",
      "    sample_time_ms: 15709.117\n",
      "    update_time_ms: 4.296\n",
      "  iterations_since_restore: 640\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11352.1648209095\n",
      "  time_this_iter_s: 17.770289182662964\n",
      "  time_total_s: 11352.1648209095\n",
      "  timestamp: 1550627793\n",
      "  timesteps_since_restore: 6400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6400000\n",
      "  training_iteration: 640\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11352 s, 640 iter, 6400000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-56-50\n",
      "  done: false\n",
      "  episode_len_mean: 134.37\n",
      "  episode_reward_max: 220.7301364890346\n",
      "  episode_reward_mean: 165.71086227760264\n",
      "  episode_reward_min: -46.5199737991437\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 49002\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.712300181388855\n",
      "      kl: 0.019737428054213524\n",
      "      policy_loss: -0.0003858577401842922\n",
      "      total_loss: 63.014434814453125\n",
      "      vf_explained_var: 0.9825923442840576\n",
      "      vf_loss: 63.01483154296875\n",
      "    grad_time_ms: 1566.632\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 6410000\n",
      "    num_steps_trained: 6410000\n",
      "    sample_time_ms: 15673.509\n",
      "    update_time_ms: 4.389\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11369.080329418182\n",
      "  time_this_iter_s: 16.91550850868225\n",
      "  time_total_s: 11369.080329418182\n",
      "  timestamp: 1550627810\n",
      "  timesteps_since_restore: 6410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6410000\n",
      "  training_iteration: 641\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11369 s, 641 iter, 6410000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-57-07\n",
      "  done: false\n",
      "  episode_len_mean: 133.18\n",
      "  episode_reward_max: 214.92960858381915\n",
      "  episode_reward_mean: 176.18355442436692\n",
      "  episode_reward_min: -44.22860529089328\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 49078\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5316020250320435\n",
      "      kl: 0.019548309966921806\n",
      "      policy_loss: -0.0016189065063372254\n",
      "      total_loss: 57.38294219970703\n",
      "      vf_explained_var: 0.982056736946106\n",
      "      vf_loss: 57.384552001953125\n",
      "    grad_time_ms: 1565.43\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 6420000\n",
      "    num_steps_trained: 6420000\n",
      "    sample_time_ms: 15690.913\n",
      "    update_time_ms: 4.4\n",
      "  iterations_since_restore: 642\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11386.379504680634\n",
      "  time_this_iter_s: 17.299175262451172\n",
      "  time_total_s: 11386.379504680634\n",
      "  timestamp: 1550627827\n",
      "  timesteps_since_restore: 6420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6420000\n",
      "  training_iteration: 642\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11386 s, 642 iter, 6420000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-57-25\n",
      "  done: false\n",
      "  episode_len_mean: 133.18\n",
      "  episode_reward_max: 221.06108000354473\n",
      "  episode_reward_mean: 173.1865249854686\n",
      "  episode_reward_min: -44.22860529089328\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 49152\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5959447622299194\n",
      "      kl: 0.018808702006936073\n",
      "      policy_loss: -0.0014128208858892322\n",
      "      total_loss: 66.64783477783203\n",
      "      vf_explained_var: 0.979426920413971\n",
      "      vf_loss: 66.64923858642578\n",
      "    grad_time_ms: 1565.101\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 6430000\n",
      "    num_steps_trained: 6430000\n",
      "    sample_time_ms: 15740.737\n",
      "    update_time_ms: 4.363\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11403.800538778305\n",
      "  time_this_iter_s: 17.42103409767151\n",
      "  time_total_s: 11403.800538778305\n",
      "  timestamp: 1550627845\n",
      "  timesteps_since_restore: 6430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6430000\n",
      "  training_iteration: 643\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11403 s, 643 iter, 6430000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-57-42\n",
      "  done: false\n",
      "  episode_len_mean: 134.14\n",
      "  episode_reward_max: 222.9771649935606\n",
      "  episode_reward_mean: 176.73333427362027\n",
      "  episode_reward_min: -41.51674104843399\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 49227\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.525768756866455\n",
      "      kl: 0.03271716460585594\n",
      "      policy_loss: 0.00111244001891464\n",
      "      total_loss: 54.38460922241211\n",
      "      vf_explained_var: 0.9824866056442261\n",
      "      vf_loss: 54.38350296020508\n",
      "    grad_time_ms: 1566.555\n",
      "    load_time_ms: 1.401\n",
      "    num_steps_sampled: 6440000\n",
      "    num_steps_trained: 6440000\n",
      "    sample_time_ms: 15818.542\n",
      "    update_time_ms: 4.459\n",
      "  iterations_since_restore: 644\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11421.537180900574\n",
      "  time_this_iter_s: 17.736642122268677\n",
      "  time_total_s: 11421.537180900574\n",
      "  timestamp: 1550627862\n",
      "  timesteps_since_restore: 6440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6440000\n",
      "  training_iteration: 644\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11421 s, 644 iter, 6440000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-58-00\n",
      "  done: false\n",
      "  episode_len_mean: 133.14\n",
      "  episode_reward_max: 226.67191176811735\n",
      "  episode_reward_mean: 177.42751596796407\n",
      "  episode_reward_min: -36.38076209926077\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 49303\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2803674936294556\n",
      "      kl: 0.016438189893960953\n",
      "      policy_loss: -0.0017693921690806746\n",
      "      total_loss: 35.24481964111328\n",
      "      vf_explained_var: 0.9895167350769043\n",
      "      vf_loss: 35.246585845947266\n",
      "    grad_time_ms: 1566.168\n",
      "    load_time_ms: 1.371\n",
      "    num_steps_sampled: 6450000\n",
      "    num_steps_trained: 6450000\n",
      "    sample_time_ms: 15807.555\n",
      "    update_time_ms: 4.501\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11438.847645044327\n",
      "  time_this_iter_s: 17.31046414375305\n",
      "  time_total_s: 11438.847645044327\n",
      "  timestamp: 1550627880\n",
      "  timesteps_since_restore: 6450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6450000\n",
      "  training_iteration: 645\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11438 s, 645 iter, 6450000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-58-17\n",
      "  done: false\n",
      "  episode_len_mean: 131.24\n",
      "  episode_reward_max: 215.67940519056702\n",
      "  episode_reward_mean: 168.15158753868857\n",
      "  episode_reward_min: -45.752252922273485\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 49379\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4911285638809204\n",
      "      kl: 0.026319894939661026\n",
      "      policy_loss: -0.0021063182502985\n",
      "      total_loss: 24.38858985900879\n",
      "      vf_explained_var: 0.9924502968788147\n",
      "      vf_loss: 24.39069175720215\n",
      "    grad_time_ms: 1547.153\n",
      "    load_time_ms: 1.405\n",
      "    num_steps_sampled: 6460000\n",
      "    num_steps_trained: 6460000\n",
      "    sample_time_ms: 15779.325\n",
      "    update_time_ms: 4.505\n",
      "  iterations_since_restore: 646\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11456.090011835098\n",
      "  time_this_iter_s: 17.242366790771484\n",
      "  time_total_s: 11456.090011835098\n",
      "  timestamp: 1550627897\n",
      "  timesteps_since_restore: 6460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6460000\n",
      "  training_iteration: 646\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11456 s, 646 iter, 6460000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-58-35\n",
      "  done: false\n",
      "  episode_len_mean: 132.31\n",
      "  episode_reward_max: 219.6697561063683\n",
      "  episode_reward_mean: 165.12257340342404\n",
      "  episode_reward_min: -45.752252922273485\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 49453\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7443857192993164\n",
      "      kl: 0.016675518825650215\n",
      "      policy_loss: -0.001239754376001656\n",
      "      total_loss: 51.35620880126953\n",
      "      vf_explained_var: 0.9839029312133789\n",
      "      vf_loss: 51.35744857788086\n",
      "    grad_time_ms: 1544.227\n",
      "    load_time_ms: 1.393\n",
      "    num_steps_sampled: 6470000\n",
      "    num_steps_trained: 6470000\n",
      "    sample_time_ms: 15795.427\n",
      "    update_time_ms: 4.63\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11473.59643316269\n",
      "  time_this_iter_s: 17.506421327590942\n",
      "  time_total_s: 11473.59643316269\n",
      "  timestamp: 1550627915\n",
      "  timesteps_since_restore: 6470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6470000\n",
      "  training_iteration: 647\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11473 s, 647 iter, 6470000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 134.42\n",
      "  episode_reward_max: 220.4447462506371\n",
      "  episode_reward_mean: 168.58014192623523\n",
      "  episode_reward_min: -40.89539721372102\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 49528\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4256565570831299\n",
      "      kl: 0.01991148665547371\n",
      "      policy_loss: 0.0008953391225077212\n",
      "      total_loss: 74.06159973144531\n",
      "      vf_explained_var: 0.9793141484260559\n",
      "      vf_loss: 74.06071472167969\n",
      "    grad_time_ms: 1546.895\n",
      "    load_time_ms: 1.336\n",
      "    num_steps_sampled: 6480000\n",
      "    num_steps_trained: 6480000\n",
      "    sample_time_ms: 15814.309\n",
      "    update_time_ms: 4.631\n",
      "  iterations_since_restore: 648\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11490.797349214554\n",
      "  time_this_iter_s: 17.200916051864624\n",
      "  time_total_s: 11490.797349214554\n",
      "  timestamp: 1550627932\n",
      "  timesteps_since_restore: 6480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6480000\n",
      "  training_iteration: 648\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11490 s, 648 iter, 6480000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-59-09\n",
      "  done: false\n",
      "  episode_len_mean: 135.27\n",
      "  episode_reward_max: 216.5166465659987\n",
      "  episode_reward_mean: 173.41286271976927\n",
      "  episode_reward_min: -39.4526105366721\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 49602\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5421894788742065\n",
      "      kl: 0.02467610500752926\n",
      "      policy_loss: -0.004659375175833702\n",
      "      total_loss: 72.62720489501953\n",
      "      vf_explained_var: 0.9798745512962341\n",
      "      vf_loss: 72.6318588256836\n",
      "    grad_time_ms: 1546.922\n",
      "    load_time_ms: 1.305\n",
      "    num_steps_sampled: 6490000\n",
      "    num_steps_trained: 6490000\n",
      "    sample_time_ms: 15809.386\n",
      "    update_time_ms: 4.544\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11508.140644073486\n",
      "  time_this_iter_s: 17.343294858932495\n",
      "  time_total_s: 11508.140644073486\n",
      "  timestamp: 1550627949\n",
      "  timesteps_since_restore: 6490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6490000\n",
      "  training_iteration: 649\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11508 s, 649 iter, 6490000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-59-27\n",
      "  done: false\n",
      "  episode_len_mean: 134.57\n",
      "  episode_reward_max: 213.97926811195254\n",
      "  episode_reward_mean: 172.06805572406628\n",
      "  episode_reward_min: -42.08443751252524\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 49676\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6292643547058105\n",
      "      kl: 0.01846236363053322\n",
      "      policy_loss: -0.0014949517790228128\n",
      "      total_loss: 79.26227569580078\n",
      "      vf_explained_var: 0.9778659343719482\n",
      "      vf_loss: 79.2637710571289\n",
      "    grad_time_ms: 1545.682\n",
      "    load_time_ms: 1.306\n",
      "    num_steps_sampled: 6500000\n",
      "    num_steps_trained: 6500000\n",
      "    sample_time_ms: 15771.879\n",
      "    update_time_ms: 4.347\n",
      "  iterations_since_restore: 650\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11525.521215200424\n",
      "  time_this_iter_s: 17.380571126937866\n",
      "  time_total_s: 11525.521215200424\n",
      "  timestamp: 1550627967\n",
      "  timesteps_since_restore: 6500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6500000\n",
      "  training_iteration: 650\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11525 s, 650 iter, 6500000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_02-59-44\n",
      "  done: false\n",
      "  episode_len_mean: 135.13\n",
      "  episode_reward_max: 213.97926811195254\n",
      "  episode_reward_mean: 173.8880078101333\n",
      "  episode_reward_min: -41.61836348215837\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 49750\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.635345220565796\n",
      "      kl: 0.011394383385777473\n",
      "      policy_loss: -0.001129739684984088\n",
      "      total_loss: 39.497711181640625\n",
      "      vf_explained_var: 0.9873278737068176\n",
      "      vf_loss: 39.49884796142578\n",
      "    grad_time_ms: 1549.309\n",
      "    load_time_ms: 1.271\n",
      "    num_steps_sampled: 6510000\n",
      "    num_steps_trained: 6510000\n",
      "    sample_time_ms: 15813.664\n",
      "    update_time_ms: 4.337\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11542.890900611877\n",
      "  time_this_iter_s: 17.369685411453247\n",
      "  time_total_s: 11542.890900611877\n",
      "  timestamp: 1550627984\n",
      "  timesteps_since_restore: 6510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6510000\n",
      "  training_iteration: 651\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11542 s, 651 iter, 6510000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-00-01\n",
      "  done: false\n",
      "  episode_len_mean: 136.1\n",
      "  episode_reward_max: 217.748046688219\n",
      "  episode_reward_mean: 178.99204676402883\n",
      "  episode_reward_min: 136.62171343514822\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 49823\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5982252359390259\n",
      "      kl: 0.01902233622968197\n",
      "      policy_loss: 0.0012214856687933207\n",
      "      total_loss: 18.883594512939453\n",
      "      vf_explained_var: 0.9945106506347656\n",
      "      vf_loss: 18.88237190246582\n",
      "    grad_time_ms: 1546.577\n",
      "    load_time_ms: 1.275\n",
      "    num_steps_sampled: 6520000\n",
      "    num_steps_trained: 6520000\n",
      "    sample_time_ms: 15805.649\n",
      "    update_time_ms: 4.345\n",
      "  iterations_since_restore: 652\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11560.083343744278\n",
      "  time_this_iter_s: 17.192443132400513\n",
      "  time_total_s: 11560.083343744278\n",
      "  timestamp: 1550628001\n",
      "  timesteps_since_restore: 6520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6520000\n",
      "  training_iteration: 652\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11560 s, 652 iter, 6520000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-00-18\n",
      "  done: false\n",
      "  episode_len_mean: 135.41\n",
      "  episode_reward_max: 224.5968168747453\n",
      "  episode_reward_mean: 180.5009241516983\n",
      "  episode_reward_min: -39.50109518186588\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 49897\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3678269386291504\n",
      "      kl: 0.02186674252152443\n",
      "      policy_loss: 0.00011484821880003437\n",
      "      total_loss: 22.60487174987793\n",
      "      vf_explained_var: 0.9929158091545105\n",
      "      vf_loss: 22.604753494262695\n",
      "    grad_time_ms: 1546.49\n",
      "    load_time_ms: 1.275\n",
      "    num_steps_sampled: 6530000\n",
      "    num_steps_trained: 6530000\n",
      "    sample_time_ms: 15787.514\n",
      "    update_time_ms: 4.407\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11577.32276391983\n",
      "  time_this_iter_s: 17.239420175552368\n",
      "  time_total_s: 11577.32276391983\n",
      "  timestamp: 1550628018\n",
      "  timesteps_since_restore: 6530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6530000\n",
      "  training_iteration: 653\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11577 s, 653 iter, 6530000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-00-36\n",
      "  done: false\n",
      "  episode_len_mean: 132.66\n",
      "  episode_reward_max: 218.81265879245368\n",
      "  episode_reward_mean: 173.50510504751065\n",
      "  episode_reward_min: -39.50109518186588\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 49973\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6522161545325784e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.469744324684143\n",
      "      kl: 0.05089506506919861\n",
      "      policy_loss: -0.002380106598138809\n",
      "      total_loss: 46.140384674072266\n",
      "      vf_explained_var: 0.9868869185447693\n",
      "      vf_loss: 46.14276123046875\n",
      "    grad_time_ms: 1544.138\n",
      "    load_time_ms: 1.313\n",
      "    num_steps_sampled: 6540000\n",
      "    num_steps_trained: 6540000\n",
      "    sample_time_ms: 15772.479\n",
      "    update_time_ms: 4.413\n",
      "  iterations_since_restore: 654\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11594.88741350174\n",
      "  time_this_iter_s: 17.56464958190918\n",
      "  time_total_s: 11594.88741350174\n",
      "  timestamp: 1550628036\n",
      "  timesteps_since_restore: 6540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6540000\n",
      "  training_iteration: 654\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11594 s, 654 iter, 6540000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-00-53\n",
      "  done: false\n",
      "  episode_len_mean: 133.86\n",
      "  episode_reward_max: 220.1311422374727\n",
      "  episode_reward_mean: 170.7469910883823\n",
      "  episode_reward_min: -34.74618527621473\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50048\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.604383111000061\n",
      "      kl: 0.025910576805472374\n",
      "      policy_loss: 0.00022352863743435591\n",
      "      total_loss: 30.290489196777344\n",
      "      vf_explained_var: 0.991346001625061\n",
      "      vf_loss: 30.29026985168457\n",
      "    grad_time_ms: 1561.827\n",
      "    load_time_ms: 1.314\n",
      "    num_steps_sampled: 6550000\n",
      "    num_steps_trained: 6550000\n",
      "    sample_time_ms: 15746.376\n",
      "    update_time_ms: 4.315\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11612.111671209335\n",
      "  time_this_iter_s: 17.224257707595825\n",
      "  time_total_s: 11612.111671209335\n",
      "  timestamp: 1550628053\n",
      "  timesteps_since_restore: 6550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6550000\n",
      "  training_iteration: 655\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11612 s, 655 iter, 6550000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-01-10\n",
      "  done: false\n",
      "  episode_len_mean: 132.37\n",
      "  episode_reward_max: 220.1311422374727\n",
      "  episode_reward_mean: 169.45233954698114\n",
      "  episode_reward_min: -49.33610737205732\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50123\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4569183588027954\n",
      "      kl: 0.021562360227108\n",
      "      policy_loss: -0.0029413257725536823\n",
      "      total_loss: 35.27545928955078\n",
      "      vf_explained_var: 0.9899438619613647\n",
      "      vf_loss: 35.278404235839844\n",
      "    grad_time_ms: 1562.14\n",
      "    load_time_ms: 1.335\n",
      "    num_steps_sampled: 6560000\n",
      "    num_steps_trained: 6560000\n",
      "    sample_time_ms: 15726.158\n",
      "    update_time_ms: 4.47\n",
      "  iterations_since_restore: 656\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11629.155920028687\n",
      "  time_this_iter_s: 17.044248819351196\n",
      "  time_total_s: 11629.155920028687\n",
      "  timestamp: 1550628070\n",
      "  timesteps_since_restore: 6560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6560000\n",
      "  training_iteration: 656\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11629 s, 656 iter, 6560000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-01-28\n",
      "  done: false\n",
      "  episode_len_mean: 133.01\n",
      "  episode_reward_max: 213.9518693508487\n",
      "  episode_reward_mean: 169.50263824949008\n",
      "  episode_reward_min: -44.747676046546715\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50198\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.505692481994629\n",
      "      kl: 0.026182403787970543\n",
      "      policy_loss: 0.0027972948737442493\n",
      "      total_loss: 93.36631774902344\n",
      "      vf_explained_var: 0.9714680314064026\n",
      "      vf_loss: 93.36351776123047\n",
      "    grad_time_ms: 1561.271\n",
      "    load_time_ms: 1.407\n",
      "    num_steps_sampled: 6570000\n",
      "    num_steps_trained: 6570000\n",
      "    sample_time_ms: 15722.208\n",
      "    update_time_ms: 4.244\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11646.613371610641\n",
      "  time_this_iter_s: 17.457451581954956\n",
      "  time_total_s: 11646.613371610641\n",
      "  timestamp: 1550628088\n",
      "  timesteps_since_restore: 6570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6570000\n",
      "  training_iteration: 657\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11646 s, 657 iter, 6570000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-01-46\n",
      "  done: false\n",
      "  episode_len_mean: 134.75\n",
      "  episode_reward_max: 217.64093674269338\n",
      "  episode_reward_mean: 173.28369055100825\n",
      "  episode_reward_min: -45.06498171130915\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 50272\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4854644536972046\n",
      "      kl: 0.017775366082787514\n",
      "      policy_loss: -0.0019809086807072163\n",
      "      total_loss: 50.19496536254883\n",
      "      vf_explained_var: 0.9844142198562622\n",
      "      vf_loss: 50.19694137573242\n",
      "    grad_time_ms: 1559.133\n",
      "    load_time_ms: 1.406\n",
      "    num_steps_sampled: 6580000\n",
      "    num_steps_trained: 6580000\n",
      "    sample_time_ms: 15785.811\n",
      "    update_time_ms: 4.315\n",
      "  iterations_since_restore: 658\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11664.430388212204\n",
      "  time_this_iter_s: 17.8170166015625\n",
      "  time_total_s: 11664.430388212204\n",
      "  timestamp: 1550628106\n",
      "  timesteps_since_restore: 6580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6580000\n",
      "  training_iteration: 658\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11664 s, 658 iter, 6580000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-02-04\n",
      "  done: false\n",
      "  episode_len_mean: 133.81\n",
      "  episode_reward_max: 219.75758462402936\n",
      "  episode_reward_mean: 162.8376869977759\n",
      "  episode_reward_min: -45.111423760505005\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50347\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6681506633758545\n",
      "      kl: 0.023899581283330917\n",
      "      policy_loss: 0.0008447636500932276\n",
      "      total_loss: 104.77920532226562\n",
      "      vf_explained_var: 0.9718626141548157\n",
      "      vf_loss: 104.77838134765625\n",
      "    grad_time_ms: 1557.008\n",
      "    load_time_ms: 1.364\n",
      "    num_steps_sampled: 6590000\n",
      "    num_steps_trained: 6590000\n",
      "    sample_time_ms: 15826.006\n",
      "    update_time_ms: 4.341\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11682.15386557579\n",
      "  time_this_iter_s: 17.723477363586426\n",
      "  time_total_s: 11682.15386557579\n",
      "  timestamp: 1550628124\n",
      "  timesteps_since_restore: 6590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6590000\n",
      "  training_iteration: 659\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11682 s, 659 iter, 6590000 ts, 163 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-02-21\n",
      "  done: false\n",
      "  episode_len_mean: 133.04\n",
      "  episode_reward_max: 219.75758462402936\n",
      "  episode_reward_mean: 166.50940027428197\n",
      "  episode_reward_min: -45.111423760505005\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50422\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6387875080108643\n",
      "      kl: 0.027082180604338646\n",
      "      policy_loss: -0.0007106136181391776\n",
      "      total_loss: 37.95257568359375\n",
      "      vf_explained_var: 0.9881966710090637\n",
      "      vf_loss: 37.95328140258789\n",
      "    grad_time_ms: 1559.798\n",
      "    load_time_ms: 1.401\n",
      "    num_steps_sampled: 6600000\n",
      "    num_steps_trained: 6600000\n",
      "    sample_time_ms: 15855.772\n",
      "    update_time_ms: 4.407\n",
      "  iterations_since_restore: 660\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11699.86220574379\n",
      "  time_this_iter_s: 17.708340167999268\n",
      "  time_total_s: 11699.86220574379\n",
      "  timestamp: 1550628141\n",
      "  timesteps_since_restore: 6600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6600000\n",
      "  training_iteration: 660\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11699 s, 660 iter, 6600000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-02-39\n",
      "  done: false\n",
      "  episode_len_mean: 132.3\n",
      "  episode_reward_max: 214.94024310397478\n",
      "  episode_reward_mean: 168.43171555496627\n",
      "  episode_reward_min: -42.73096817490268\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50497\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3566035032272339\n",
      "      kl: 0.018531573936343193\n",
      "      policy_loss: -0.0001704013702692464\n",
      "      total_loss: 48.8043212890625\n",
      "      vf_explained_var: 0.9858404994010925\n",
      "      vf_loss: 48.804500579833984\n",
      "    grad_time_ms: 1556.498\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 6610000\n",
      "    num_steps_trained: 6610000\n",
      "    sample_time_ms: 15913.985\n",
      "    update_time_ms: 4.354\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11717.78007030487\n",
      "  time_this_iter_s: 17.917864561080933\n",
      "  time_total_s: 11717.78007030487\n",
      "  timestamp: 1550628159\n",
      "  timesteps_since_restore: 6610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6610000\n",
      "  training_iteration: 661\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11717 s, 661 iter, 6610000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-02-57\n",
      "  done: false\n",
      "  episode_len_mean: 135.77\n",
      "  episode_reward_max: 234.68064256809143\n",
      "  episode_reward_mean: 175.91748029956727\n",
      "  episode_reward_min: -42.73096817490268\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 50570\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6516733169555664\n",
      "      kl: 0.02153485268354416\n",
      "      policy_loss: 3.64071674994193e-05\n",
      "      total_loss: 19.517322540283203\n",
      "      vf_explained_var: 0.9940961003303528\n",
      "      vf_loss: 19.517292022705078\n",
      "    grad_time_ms: 1560.934\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 6620000\n",
      "    num_steps_trained: 6620000\n",
      "    sample_time_ms: 15924.426\n",
      "    update_time_ms: 4.294\n",
      "  iterations_since_restore: 662\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11735.123282194138\n",
      "  time_this_iter_s: 17.343211889266968\n",
      "  time_total_s: 11735.123282194138\n",
      "  timestamp: 1550628177\n",
      "  timesteps_since_restore: 6620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6620000\n",
      "  training_iteration: 662\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11735 s, 662 iter, 6620000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-03-14\n",
      "  done: false\n",
      "  episode_len_mean: 133.88\n",
      "  episode_reward_max: 234.68064256809143\n",
      "  episode_reward_mean: 175.01885534839542\n",
      "  episode_reward_min: -45.796559928298585\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50645\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4604682922363281\n",
      "      kl: 0.02777259424328804\n",
      "      policy_loss: 0.004768919665366411\n",
      "      total_loss: 17.648761749267578\n",
      "      vf_explained_var: 0.9948146343231201\n",
      "      vf_loss: 17.643993377685547\n",
      "    grad_time_ms: 1562.807\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 6630000\n",
      "    num_steps_trained: 6630000\n",
      "    sample_time_ms: 15940.238\n",
      "    update_time_ms: 4.15\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11752.53935599327\n",
      "  time_this_iter_s: 17.4160737991333\n",
      "  time_total_s: 11752.53935599327\n",
      "  timestamp: 1550628194\n",
      "  timesteps_since_restore: 6630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6630000\n",
      "  training_iteration: 663\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11752 s, 663 iter, 6630000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-03-31\n",
      "  done: false\n",
      "  episode_len_mean: 134.35\n",
      "  episode_reward_max: 215.55261170900974\n",
      "  episode_reward_mean: 174.4482891441577\n",
      "  episode_reward_min: -37.88068295410363\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50720\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4783247997787193e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.584282636642456\n",
      "      kl: 0.0532657615840435\n",
      "      policy_loss: 0.004077069461345673\n",
      "      total_loss: 60.286014556884766\n",
      "      vf_explained_var: 0.981066107749939\n",
      "      vf_loss: 60.281944274902344\n",
      "    grad_time_ms: 1568.208\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 6640000\n",
      "    num_steps_trained: 6640000\n",
      "    sample_time_ms: 15875.877\n",
      "    update_time_ms: 4.088\n",
      "  iterations_since_restore: 664\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11769.513216495514\n",
      "  time_this_iter_s: 16.973860502243042\n",
      "  time_total_s: 11769.513216495514\n",
      "  timestamp: 1550628211\n",
      "  timesteps_since_restore: 6640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6640000\n",
      "  training_iteration: 664\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11769 s, 664 iter, 6640000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-03-48\n",
      "  done: false\n",
      "  episode_len_mean: 133.96\n",
      "  episode_reward_max: 226.50900347405434\n",
      "  episode_reward_mean: 169.73992808177613\n",
      "  episode_reward_min: -39.017681232570574\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 50795\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.717487199668079e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5285911560058594\n",
      "      kl: 0.02060120739042759\n",
      "      policy_loss: 3.633466621977277e-05\n",
      "      total_loss: 120.58494567871094\n",
      "      vf_explained_var: 0.968397855758667\n",
      "      vf_loss: 120.58490753173828\n",
      "    grad_time_ms: 1549.575\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 6650000\n",
      "    num_steps_trained: 6650000\n",
      "    sample_time_ms: 15892.881\n",
      "    update_time_ms: 4.135\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11786.722653865814\n",
      "  time_this_iter_s: 17.209437370300293\n",
      "  time_total_s: 11786.722653865814\n",
      "  timestamp: 1550628228\n",
      "  timesteps_since_restore: 6650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6650000\n",
      "  training_iteration: 665\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11786 s, 665 iter, 6650000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-04-06\n",
      "  done: false\n",
      "  episode_len_mean: 130.66\n",
      "  episode_reward_max: 221.11468992950287\n",
      "  episode_reward_mean: 165.30634728880395\n",
      "  episode_reward_min: -49.89047754873144\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 50871\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.717487199668079e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.315907597541809\n",
      "      kl: 0.03385413810610771\n",
      "      policy_loss: 0.0010370885720476508\n",
      "      total_loss: 138.83319091796875\n",
      "      vf_explained_var: 0.9607829451560974\n",
      "      vf_loss: 138.83218383789062\n",
      "    grad_time_ms: 1549.496\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 6660000\n",
      "    num_steps_trained: 6660000\n",
      "    sample_time_ms: 15922.192\n",
      "    update_time_ms: 4.064\n",
      "  iterations_since_restore: 666\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11804.058906316757\n",
      "  time_this_iter_s: 17.336252450942993\n",
      "  time_total_s: 11804.058906316757\n",
      "  timestamp: 1550628246\n",
      "  timesteps_since_restore: 6660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6660000\n",
      "  training_iteration: 666\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11804 s, 666 iter, 6660000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-04-23\n",
      "  done: false\n",
      "  episode_len_mean: 133.76\n",
      "  episode_reward_max: 222.45785905642077\n",
      "  episode_reward_mean: 174.1342763959708\n",
      "  episode_reward_min: -49.89047754873144\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 50944\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.717487199668079e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5628479719161987\n",
      "      kl: 0.029004601761698723\n",
      "      policy_loss: 0.00012848549522459507\n",
      "      total_loss: 45.1756591796875\n",
      "      vf_explained_var: 0.9859342575073242\n",
      "      vf_loss: 45.17552947998047\n",
      "    grad_time_ms: 1567.566\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 6670000\n",
      "    num_steps_trained: 6670000\n",
      "    sample_time_ms: 15908.757\n",
      "    update_time_ms: 4.135\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11821.562991380692\n",
      "  time_this_iter_s: 17.504085063934326\n",
      "  time_total_s: 11821.562991380692\n",
      "  timestamp: 1550628263\n",
      "  timesteps_since_restore: 6670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6670000\n",
      "  training_iteration: 667\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11821 s, 667 iter, 6670000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-04-41\n",
      "  done: false\n",
      "  episode_len_mean: 134.2\n",
      "  episode_reward_max: 219.97142729354977\n",
      "  episode_reward_mean: 168.10476294690096\n",
      "  episode_reward_min: -49.3779724619471\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 51019\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.717487199668079e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6967525482177734\n",
      "      kl: 0.013166866265237331\n",
      "      policy_loss: -0.0011369769927114248\n",
      "      total_loss: 69.6844482421875\n",
      "      vf_explained_var: 0.980133056640625\n",
      "      vf_loss: 69.68558502197266\n",
      "    grad_time_ms: 1568.361\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 6680000\n",
      "    num_steps_trained: 6680000\n",
      "    sample_time_ms: 15882.232\n",
      "    update_time_ms: 4.155\n",
      "  iterations_since_restore: 668\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11839.125868082047\n",
      "  time_this_iter_s: 17.56287670135498\n",
      "  time_total_s: 11839.125868082047\n",
      "  timestamp: 1550628281\n",
      "  timesteps_since_restore: 6680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6680000\n",
      "  training_iteration: 668\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11839 s, 668 iter, 6680000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-04-59\n",
      "  done: false\n",
      "  episode_len_mean: 133.19\n",
      "  episode_reward_max: 227.48330570329523\n",
      "  episode_reward_mean: 168.22991790625682\n",
      "  episode_reward_min: -49.3779724619471\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 51095\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.717487199668079e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4706525802612305\n",
      "      kl: 0.017328033223748207\n",
      "      policy_loss: -0.0008578875567764044\n",
      "      total_loss: 65.42496490478516\n",
      "      vf_explained_var: 0.9814915657043457\n",
      "      vf_loss: 65.42582702636719\n",
      "    grad_time_ms: 1568.995\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 6690000\n",
      "    num_steps_trained: 6690000\n",
      "    sample_time_ms: 15917.461\n",
      "    update_time_ms: 4.173\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11857.20830488205\n",
      "  time_this_iter_s: 18.08243680000305\n",
      "  time_total_s: 11857.20830488205\n",
      "  timestamp: 1550628299\n",
      "  timesteps_since_restore: 6690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6690000\n",
      "  training_iteration: 669\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11857 s, 669 iter, 6690000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-05-16\n",
      "  done: false\n",
      "  episode_len_mean: 132.33\n",
      "  episode_reward_max: 215.96241049586547\n",
      "  episode_reward_mean: 172.31547568224684\n",
      "  episode_reward_min: -48.004848490957855\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 51170\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.717487199668079e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5328820943832397\n",
      "      kl: 0.04112779721617699\n",
      "      policy_loss: 0.001248416374437511\n",
      "      total_loss: 38.91204833984375\n",
      "      vf_explained_var: 0.9876931309700012\n",
      "      vf_loss: 38.910804748535156\n",
      "    grad_time_ms: 1565.864\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 6700000\n",
      "    num_steps_trained: 6700000\n",
      "    sample_time_ms: 15883.335\n",
      "    update_time_ms: 4.208\n",
      "  iterations_since_restore: 670\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11874.542185544968\n",
      "  time_this_iter_s: 17.33388066291809\n",
      "  time_total_s: 11874.542185544968\n",
      "  timestamp: 1550628316\n",
      "  timesteps_since_restore: 6700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6700000\n",
      "  training_iteration: 670\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11874 s, 670 iter, 6700000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-05-34\n",
      "  done: false\n",
      "  episode_len_mean: 128.99\n",
      "  episode_reward_max: 227.46041353061656\n",
      "  episode_reward_mean: 167.2141733299119\n",
      "  episode_reward_min: -48.73257297019262\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 51247\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.576230294631139e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3126680850982666\n",
      "      kl: 0.017978450283408165\n",
      "      policy_loss: -0.001725924899801612\n",
      "      total_loss: 29.006851196289062\n",
      "      vf_explained_var: 0.992408275604248\n",
      "      vf_loss: 29.00857925415039\n",
      "    grad_time_ms: 1566.904\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 6710000\n",
      "    num_steps_trained: 6710000\n",
      "    sample_time_ms: 15840.672\n",
      "    update_time_ms: 4.219\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11892.041965961456\n",
      "  time_this_iter_s: 17.499780416488647\n",
      "  time_total_s: 11892.041965961456\n",
      "  timestamp: 1550628334\n",
      "  timesteps_since_restore: 6710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6710000\n",
      "  training_iteration: 671\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11892 s, 671 iter, 6710000 ts, 167 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-05-52\n",
      "  done: false\n",
      "  episode_len_mean: 130.57\n",
      "  episode_reward_max: 218.37230507535213\n",
      "  episode_reward_mean: 166.2698896821707\n",
      "  episode_reward_min: -48.02642444395783\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 51324\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.576230294631139e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5471543073654175\n",
      "      kl: 0.025307873263955116\n",
      "      policy_loss: -0.002093703020364046\n",
      "      total_loss: 111.20830535888672\n",
      "      vf_explained_var: 0.9688708186149597\n",
      "      vf_loss: 111.21039581298828\n",
      "    grad_time_ms: 1564.177\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 6720000\n",
      "    num_steps_trained: 6720000\n",
      "    sample_time_ms: 15918.575\n",
      "    update_time_ms: 4.323\n",
      "  iterations_since_restore: 672\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11910.137038230896\n",
      "  time_this_iter_s: 18.095072269439697\n",
      "  time_total_s: 11910.137038230896\n",
      "  timestamp: 1550628352\n",
      "  timesteps_since_restore: 6720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6720000\n",
      "  training_iteration: 672\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11910 s, 672 iter, 6720000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-06-09\n",
      "  done: false\n",
      "  episode_len_mean: 132.86\n",
      "  episode_reward_max: 218.37230507535213\n",
      "  episode_reward_mean: 172.73921637971017\n",
      "  episode_reward_min: -40.70011347650303\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 51399\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.576230294631139e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6426078081130981\n",
      "      kl: 0.030141647905111313\n",
      "      policy_loss: -0.002100657671689987\n",
      "      total_loss: 34.85280990600586\n",
      "      vf_explained_var: 0.9889171123504639\n",
      "      vf_loss: 34.85490417480469\n",
      "    grad_time_ms: 1563.412\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 6730000\n",
      "    num_steps_trained: 6730000\n",
      "    sample_time_ms: 15874.475\n",
      "    update_time_ms: 4.486\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11927.103403806686\n",
      "  time_this_iter_s: 16.966365575790405\n",
      "  time_total_s: 11927.103403806686\n",
      "  timestamp: 1550628369\n",
      "  timesteps_since_restore: 6730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6730000\n",
      "  training_iteration: 673\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11927 s, 673 iter, 6730000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-06-26\n",
      "  done: false\n",
      "  episode_len_mean: 135.55\n",
      "  episode_reward_max: 217.75019808932404\n",
      "  episode_reward_mean: 174.85881267060958\n",
      "  episode_reward_min: -40.70011347650303\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 51472\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.576230294631139e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7418664693832397\n",
      "      kl: 0.03948236256837845\n",
      "      policy_loss: 0.004078717436641455\n",
      "      total_loss: 56.73426055908203\n",
      "      vf_explained_var: 0.9826784133911133\n",
      "      vf_loss: 56.730186462402344\n",
      "    grad_time_ms: 1558.356\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 6740000\n",
      "    num_steps_trained: 6740000\n",
      "    sample_time_ms: 15866.819\n",
      "    update_time_ms: 4.491\n",
      "  iterations_since_restore: 674\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11943.951560497284\n",
      "  time_this_iter_s: 16.848156690597534\n",
      "  time_total_s: 11943.951560497284\n",
      "  timestamp: 1550628386\n",
      "  timesteps_since_restore: 6740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6740000\n",
      "  training_iteration: 674\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11943 s, 674 iter, 6740000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-06-42\n",
      "  done: false\n",
      "  episode_len_mean: 135.21\n",
      "  episode_reward_max: 218.62969750883337\n",
      "  episode_reward_mean: 181.8702249925487\n",
      "  episode_reward_min: -42.330505637691736\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 51546\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.576230294631139e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.56132972240448\n",
      "      kl: 0.020381230860948563\n",
      "      policy_loss: -0.00010641859989846125\n",
      "      total_loss: 16.093473434448242\n",
      "      vf_explained_var: 0.9946957230567932\n",
      "      vf_loss: 16.09358024597168\n",
      "    grad_time_ms: 1558.87\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 6750000\n",
      "    num_steps_trained: 6750000\n",
      "    sample_time_ms: 15784.582\n",
      "    update_time_ms: 4.48\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11960.343317508698\n",
      "  time_this_iter_s: 16.391757011413574\n",
      "  time_total_s: 11960.343317508698\n",
      "  timestamp: 1550628402\n",
      "  timesteps_since_restore: 6750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6750000\n",
      "  training_iteration: 675\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11960 s, 675 iter, 6750000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-06-59\n",
      "  done: false\n",
      "  episode_len_mean: 133.84\n",
      "  episode_reward_max: 218.94032710702103\n",
      "  episode_reward_mean: 174.66000314445097\n",
      "  episode_reward_min: -39.992378026542106\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 51621\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.576230294631139e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5094505548477173\n",
      "      kl: 0.027727851644158363\n",
      "      policy_loss: -0.00023271831742022187\n",
      "      total_loss: 100.10423278808594\n",
      "      vf_explained_var: 0.9697912931442261\n",
      "      vf_loss: 100.1044692993164\n",
      "    grad_time_ms: 1559.559\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 6760000\n",
      "    num_steps_trained: 6760000\n",
      "    sample_time_ms: 15753.691\n",
      "    update_time_ms: 4.431\n",
      "  iterations_since_restore: 676\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11977.376742601395\n",
      "  time_this_iter_s: 17.033425092697144\n",
      "  time_total_s: 11977.376742601395\n",
      "  timestamp: 1550628419\n",
      "  timesteps_since_restore: 6760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6760000\n",
      "  training_iteration: 676\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11977 s, 676 iter, 6760000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-07-16\n",
      "  done: false\n",
      "  episode_len_mean: 133.5\n",
      "  episode_reward_max: 213.76674418579216\n",
      "  episode_reward_mean: 168.89880717841402\n",
      "  episode_reward_min: -45.713845393150145\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 51696\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.576230294631139e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5825135707855225\n",
      "      kl: 0.02223592810332775\n",
      "      policy_loss: -0.0007342994213104248\n",
      "      total_loss: 67.26396942138672\n",
      "      vf_explained_var: 0.9802871346473694\n",
      "      vf_loss: 67.26470184326172\n",
      "    grad_time_ms: 1543.242\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 6770000\n",
      "    num_steps_trained: 6770000\n",
      "    sample_time_ms: 15710.636\n",
      "    update_time_ms: 4.51\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 11994.287360668182\n",
      "  time_this_iter_s: 16.91061806678772\n",
      "  time_total_s: 11994.287360668182\n",
      "  timestamp: 1550628436\n",
      "  timesteps_since_restore: 6770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6770000\n",
      "  training_iteration: 677\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 11994 s, 677 iter, 6770000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-07-34\n",
      "  done: false\n",
      "  episode_len_mean: 131.4\n",
      "  episode_reward_max: 213.45324570811027\n",
      "  episode_reward_mean: 165.3926051413244\n",
      "  episode_reward_min: -45.713845393150145\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 51771\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.576230294631139e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6849472522735596\n",
      "      kl: 1.3043895959854126\n",
      "      policy_loss: 0.05095255374908447\n",
      "      total_loss: 82.05490112304688\n",
      "      vf_explained_var: 0.9762469530105591\n",
      "      vf_loss: 82.00394439697266\n",
      "    grad_time_ms: 1544.461\n",
      "    load_time_ms: 1.417\n",
      "    num_steps_sampled: 6780000\n",
      "    num_steps_trained: 6780000\n",
      "    sample_time_ms: 15697.83\n",
      "    update_time_ms: 4.484\n",
      "  iterations_since_restore: 678\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12011.730813503265\n",
      "  time_this_iter_s: 17.443452835083008\n",
      "  time_total_s: 12011.730813503265\n",
      "  timestamp: 1550628454\n",
      "  timesteps_since_restore: 6780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6780000\n",
      "  training_iteration: 678\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12011 s, 678 iter, 6780000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-07-51\n",
      "  done: false\n",
      "  episode_len_mean: 134.8\n",
      "  episode_reward_max: 218.69755815913797\n",
      "  episode_reward_mean: 177.30455736156196\n",
      "  episode_reward_min: -47.72029798057412\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 51845\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4590489864349365\n",
      "      kl: 0.021465599536895752\n",
      "      policy_loss: 0.0012414465891197324\n",
      "      total_loss: 24.941631317138672\n",
      "      vf_explained_var: 0.9924588203430176\n",
      "      vf_loss: 24.940393447875977\n",
      "    grad_time_ms: 1544.202\n",
      "    load_time_ms: 1.352\n",
      "    num_steps_sampled: 6790000\n",
      "    num_steps_trained: 6790000\n",
      "    sample_time_ms: 15599.346\n",
      "    update_time_ms: 4.402\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12028.82323551178\n",
      "  time_this_iter_s: 17.092422008514404\n",
      "  time_total_s: 12028.82323551178\n",
      "  timestamp: 1550628471\n",
      "  timesteps_since_restore: 6790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6790000\n",
      "  training_iteration: 679\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12028 s, 679 iter, 6790000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-08-08\n",
      "  done: false\n",
      "  episode_len_mean: 133.45\n",
      "  episode_reward_max: 214.99365052979167\n",
      "  episode_reward_mean: 170.4433386293054\n",
      "  episode_reward_min: -44.22632387346855\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 51921\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6209142208099365\n",
      "      kl: 0.026998186483979225\n",
      "      policy_loss: -0.001352888299152255\n",
      "      total_loss: 46.48276138305664\n",
      "      vf_explained_var: 0.9863793849945068\n",
      "      vf_loss: 46.48411178588867\n",
      "    grad_time_ms: 1545.849\n",
      "    load_time_ms: 1.343\n",
      "    num_steps_sampled: 6800000\n",
      "    num_steps_trained: 6800000\n",
      "    sample_time_ms: 15610.926\n",
      "    update_time_ms: 4.407\n",
      "  iterations_since_restore: 680\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12046.290324926376\n",
      "  time_this_iter_s: 17.467089414596558\n",
      "  time_total_s: 12046.290324926376\n",
      "  timestamp: 1550628488\n",
      "  timesteps_since_restore: 6800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6800000\n",
      "  training_iteration: 680\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12046 s, 680 iter, 6800000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-08-25\n",
      "  done: false\n",
      "  episode_len_mean: 133.62\n",
      "  episode_reward_max: 217.58392006926005\n",
      "  episode_reward_mean: 172.18007972611812\n",
      "  episode_reward_min: -48.83692195834497\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 51995\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5003163814544678\n",
      "      kl: 0.023158887401223183\n",
      "      policy_loss: -0.00027171606780029833\n",
      "      total_loss: 37.3032112121582\n",
      "      vf_explained_var: 0.9889110922813416\n",
      "      vf_loss: 37.30348205566406\n",
      "    grad_time_ms: 1544.412\n",
      "    load_time_ms: 1.352\n",
      "    num_steps_sampled: 6810000\n",
      "    num_steps_trained: 6810000\n",
      "    sample_time_ms: 15565.353\n",
      "    update_time_ms: 4.362\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12063.321130752563\n",
      "  time_this_iter_s: 17.030805826187134\n",
      "  time_total_s: 12063.321130752563\n",
      "  timestamp: 1550628505\n",
      "  timesteps_since_restore: 6810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6810000\n",
      "  training_iteration: 681\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12063 s, 681 iter, 6810000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-08-42\n",
      "  done: false\n",
      "  episode_len_mean: 131.67\n",
      "  episode_reward_max: 217.58392006926005\n",
      "  episode_reward_mean: 171.04055837185194\n",
      "  episode_reward_min: -48.83692195834497\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 52070\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4666290283203125\n",
      "      kl: 0.03156157210469246\n",
      "      policy_loss: 0.0009113456471823156\n",
      "      total_loss: 34.89353942871094\n",
      "      vf_explained_var: 0.9901568293571472\n",
      "      vf_loss: 34.89262008666992\n",
      "    grad_time_ms: 1545.402\n",
      "    load_time_ms: 1.328\n",
      "    num_steps_sampled: 6820000\n",
      "    num_steps_trained: 6820000\n",
      "    sample_time_ms: 15452.461\n",
      "    update_time_ms: 4.289\n",
      "  iterations_since_restore: 682\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12080.296972751617\n",
      "  time_this_iter_s: 16.975841999053955\n",
      "  time_total_s: 12080.296972751617\n",
      "  timestamp: 1550628522\n",
      "  timesteps_since_restore: 6820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6820000\n",
      "  training_iteration: 682\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12080 s, 682 iter, 6820000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-09-00\n",
      "  done: false\n",
      "  episode_len_mean: 133.26\n",
      "  episode_reward_max: 230.18424112604234\n",
      "  episode_reward_mean: 172.6849757289062\n",
      "  episode_reward_min: -47.481140682234035\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 52147\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3967740535736084\n",
      "      kl: 0.03346985578536987\n",
      "      policy_loss: -0.0015214045997709036\n",
      "      total_loss: 37.39725875854492\n",
      "      vf_explained_var: 0.9891485571861267\n",
      "      vf_loss: 37.398780822753906\n",
      "    grad_time_ms: 1544.613\n",
      "    load_time_ms: 1.33\n",
      "    num_steps_sampled: 6830000\n",
      "    num_steps_trained: 6830000\n",
      "    sample_time_ms: 15513.783\n",
      "    update_time_ms: 4.236\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12097.871042966843\n",
      "  time_this_iter_s: 17.57407021522522\n",
      "  time_total_s: 12097.871042966843\n",
      "  timestamp: 1550628540\n",
      "  timesteps_since_restore: 6830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6830000\n",
      "  training_iteration: 683\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12097 s, 683 iter, 6830000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-09-17\n",
      "  done: false\n",
      "  episode_len_mean: 131.45\n",
      "  episode_reward_max: 224.07749348834588\n",
      "  episode_reward_mean: 167.77379254345226\n",
      "  episode_reward_min: -47.481140682234035\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 52223\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.403171181678772\n",
      "      kl: 0.037631213665008545\n",
      "      policy_loss: 0.0045496136881411076\n",
      "      total_loss: 43.49760055541992\n",
      "      vf_explained_var: 0.9878309369087219\n",
      "      vf_loss: 43.4930534362793\n",
      "    grad_time_ms: 1544.969\n",
      "    load_time_ms: 1.321\n",
      "    num_steps_sampled: 6840000\n",
      "    num_steps_trained: 6840000\n",
      "    sample_time_ms: 15557.98\n",
      "    update_time_ms: 4.234\n",
      "  iterations_since_restore: 684\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12115.164480686188\n",
      "  time_this_iter_s: 17.293437719345093\n",
      "  time_total_s: 12115.164480686188\n",
      "  timestamp: 1550628557\n",
      "  timesteps_since_restore: 6840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6840000\n",
      "  training_iteration: 684\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12115 s, 684 iter, 6840000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-09-35\n",
      "  done: false\n",
      "  episode_len_mean: 131.69\n",
      "  episode_reward_max: 230.87928735582832\n",
      "  episode_reward_mean: 165.34778413206794\n",
      "  episode_reward_min: -43.05079215433044\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 52298\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3633366823196411\n",
      "      kl: 0.030213817954063416\n",
      "      policy_loss: 0.0006126348744146526\n",
      "      total_loss: 96.46875762939453\n",
      "      vf_explained_var: 0.9737015962600708\n",
      "      vf_loss: 96.46813201904297\n",
      "    grad_time_ms: 1545.395\n",
      "    load_time_ms: 1.334\n",
      "    num_steps_sampled: 6850000\n",
      "    num_steps_trained: 6850000\n",
      "    sample_time_ms: 15658.854\n",
      "    update_time_ms: 4.272\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12132.571420192719\n",
      "  time_this_iter_s: 17.40693950653076\n",
      "  time_total_s: 12132.571420192719\n",
      "  timestamp: 1550628575\n",
      "  timesteps_since_restore: 6850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6850000\n",
      "  training_iteration: 685\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12132 s, 685 iter, 6850000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-09-52\n",
      "  done: false\n",
      "  episode_len_mean: 134.13\n",
      "  episode_reward_max: 226.54818929975283\n",
      "  episode_reward_mean: 171.59648222310273\n",
      "  episode_reward_min: -38.747418411371136\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 52372\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.419011116027832\n",
      "      kl: 0.02001364529132843\n",
      "      policy_loss: -0.0016302543226629496\n",
      "      total_loss: 54.9953727722168\n",
      "      vf_explained_var: 0.9843403697013855\n",
      "      vf_loss: 54.99700927734375\n",
      "    grad_time_ms: 1545.721\n",
      "    load_time_ms: 1.373\n",
      "    num_steps_sampled: 6860000\n",
      "    num_steps_trained: 6860000\n",
      "    sample_time_ms: 15682.892\n",
      "    update_time_ms: 4.275\n",
      "  iterations_since_restore: 686\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12149.848941087723\n",
      "  time_this_iter_s: 17.277520895004272\n",
      "  time_total_s: 12149.848941087723\n",
      "  timestamp: 1550628592\n",
      "  timesteps_since_restore: 6860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6860000\n",
      "  training_iteration: 686\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12149 s, 686 iter, 6860000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-10-10\n",
      "  done: false\n",
      "  episode_len_mean: 135.1\n",
      "  episode_reward_max: 223.6137483212912\n",
      "  episode_reward_mean: 183.82465613949395\n",
      "  episode_reward_min: 113.29713301847468\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 52446\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.417392373085022\n",
      "      kl: 0.019271625205874443\n",
      "      policy_loss: -0.001026054727844894\n",
      "      total_loss: 10.557165145874023\n",
      "      vf_explained_var: 0.9965037107467651\n",
      "      vf_loss: 10.55819034576416\n",
      "    grad_time_ms: 1545.881\n",
      "    load_time_ms: 1.347\n",
      "    num_steps_sampled: 6870000\n",
      "    num_steps_trained: 6870000\n",
      "    sample_time_ms: 15777.843\n",
      "    update_time_ms: 4.238\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12167.708774328232\n",
      "  time_this_iter_s: 17.859833240509033\n",
      "  time_total_s: 12167.708774328232\n",
      "  timestamp: 1550628610\n",
      "  timesteps_since_restore: 6870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6870000\n",
      "  training_iteration: 687\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12167 s, 687 iter, 6870000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-10-28\n",
      "  done: false\n",
      "  episode_len_mean: 132.58\n",
      "  episode_reward_max: 227.76726919399724\n",
      "  episode_reward_mean: 170.9981238563515\n",
      "  episode_reward_min: -43.956387517918444\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 52522\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5044093132019043\n",
      "      kl: 0.020361946895718575\n",
      "      policy_loss: -0.00233445898629725\n",
      "      total_loss: 150.21041870117188\n",
      "      vf_explained_var: 0.9605668783187866\n",
      "      vf_loss: 150.2127227783203\n",
      "    grad_time_ms: 1544.718\n",
      "    load_time_ms: 1.342\n",
      "    num_steps_sampled: 6880000\n",
      "    num_steps_trained: 6880000\n",
      "    sample_time_ms: 15827.064\n",
      "    update_time_ms: 4.204\n",
      "  iterations_since_restore: 688\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12185.632744550705\n",
      "  time_this_iter_s: 17.923970222473145\n",
      "  time_total_s: 12185.632744550705\n",
      "  timestamp: 1550628628\n",
      "  timesteps_since_restore: 6880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6880000\n",
      "  training_iteration: 688\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12185 s, 688 iter, 6880000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-10-46\n",
      "  done: false\n",
      "  episode_len_mean: 131.62\n",
      "  episode_reward_max: 227.76726919399724\n",
      "  episode_reward_mean: 169.8118582816678\n",
      "  episode_reward_min: -43.956387517918444\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 52597\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4257370233535767\n",
      "      kl: 0.012657469138503075\n",
      "      policy_loss: -0.0006591497221961617\n",
      "      total_loss: 45.895877838134766\n",
      "      vf_explained_var: 0.9867030382156372\n",
      "      vf_loss: 45.89653015136719\n",
      "    grad_time_ms: 1546.272\n",
      "    load_time_ms: 1.387\n",
      "    num_steps_sampled: 6890000\n",
      "    num_steps_trained: 6890000\n",
      "    sample_time_ms: 15861.742\n",
      "    update_time_ms: 4.273\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12203.089307546616\n",
      "  time_this_iter_s: 17.456562995910645\n",
      "  time_total_s: 12203.089307546616\n",
      "  timestamp: 1550628646\n",
      "  timesteps_since_restore: 6890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6890000\n",
      "  training_iteration: 689\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12203 s, 689 iter, 6890000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-11-03\n",
      "  done: false\n",
      "  episode_len_mean: 132.88\n",
      "  episode_reward_max: 230.2499405161321\n",
      "  episode_reward_mean: 172.80036165477514\n",
      "  episode_reward_min: -46.98046908763673\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 52673\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.495954155921936\n",
      "      kl: 0.034039393067359924\n",
      "      policy_loss: -0.0043230508454144\n",
      "      total_loss: 83.34721374511719\n",
      "      vf_explained_var: 0.9782417416572571\n",
      "      vf_loss: 83.35153198242188\n",
      "    grad_time_ms: 1547.916\n",
      "    load_time_ms: 1.39\n",
      "    num_steps_sampled: 6900000\n",
      "    num_steps_trained: 6900000\n",
      "    sample_time_ms: 15893.646\n",
      "    update_time_ms: 4.277\n",
      "  iterations_since_restore: 690\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12220.89226436615\n",
      "  time_this_iter_s: 17.8029568195343\n",
      "  time_total_s: 12220.89226436615\n",
      "  timestamp: 1550628663\n",
      "  timesteps_since_restore: 6900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6900000\n",
      "  training_iteration: 690\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12220 s, 690 iter, 6900000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-11-21\n",
      "  done: false\n",
      "  episode_len_mean: 132.17\n",
      "  episode_reward_max: 228.97642822914037\n",
      "  episode_reward_mean: 170.18697085253487\n",
      "  episode_reward_min: -41.14643112280505\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 52749\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.364345946817688e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2529839277267456\n",
      "      kl: 0.040266383439302444\n",
      "      policy_loss: 2.901829248003196e-05\n",
      "      total_loss: 121.57249450683594\n",
      "      vf_explained_var: 0.970971941947937\n",
      "      vf_loss: 121.57246398925781\n",
      "    grad_time_ms: 1548.372\n",
      "    load_time_ms: 1.402\n",
      "    num_steps_sampled: 6910000\n",
      "    num_steps_trained: 6910000\n",
      "    sample_time_ms: 15957.597\n",
      "    update_time_ms: 4.279\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12238.567706823349\n",
      "  time_this_iter_s: 17.675442457199097\n",
      "  time_total_s: 12238.567706823349\n",
      "  timestamp: 1550628681\n",
      "  timesteps_since_restore: 6910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6910000\n",
      "  training_iteration: 691\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12238 s, 691 iter, 6910000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-11-38\n",
      "  done: false\n",
      "  episode_len_mean: 133.61\n",
      "  episode_reward_max: 221.8715968101036\n",
      "  episode_reward_mean: 173.36315032187198\n",
      "  episode_reward_min: -46.64886949845766\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 52823\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.480443000793457\n",
      "      kl: 0.03298084810376167\n",
      "      policy_loss: 0.0016868734965100884\n",
      "      total_loss: 53.549678802490234\n",
      "      vf_explained_var: 0.9840768575668335\n",
      "      vf_loss: 53.54798126220703\n",
      "    grad_time_ms: 1547.817\n",
      "    load_time_ms: 1.438\n",
      "    num_steps_sampled: 6920000\n",
      "    num_steps_trained: 6920000\n",
      "    sample_time_ms: 15973.726\n",
      "    update_time_ms: 4.383\n",
      "  iterations_since_restore: 692\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12255.700640439987\n",
      "  time_this_iter_s: 17.132933616638184\n",
      "  time_total_s: 12255.700640439987\n",
      "  timestamp: 1550628698\n",
      "  timesteps_since_restore: 6920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6920000\n",
      "  training_iteration: 692\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12255 s, 692 iter, 6920000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-11-56\n",
      "  done: false\n",
      "  episode_len_mean: 134.89\n",
      "  episode_reward_max: 226.80170644159514\n",
      "  episode_reward_mean: 179.21609024825847\n",
      "  episode_reward_min: -40.10787612686652\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 52897\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.445676565170288\n",
      "      kl: 0.02825639769434929\n",
      "      policy_loss: 0.002450032392516732\n",
      "      total_loss: 31.241485595703125\n",
      "      vf_explained_var: 0.9902874827384949\n",
      "      vf_loss: 31.239038467407227\n",
      "    grad_time_ms: 1548.54\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 6930000\n",
      "    num_steps_trained: 6930000\n",
      "    sample_time_ms: 15985.681\n",
      "    update_time_ms: 4.353\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12273.402088165283\n",
      "  time_this_iter_s: 17.70144772529602\n",
      "  time_total_s: 12273.402088165283\n",
      "  timestamp: 1550628716\n",
      "  timesteps_since_restore: 6930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6930000\n",
      "  training_iteration: 693\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12273 s, 693 iter, 6930000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-12-13\n",
      "  done: false\n",
      "  episode_len_mean: 131.98\n",
      "  episode_reward_max: 218.80076697800706\n",
      "  episode_reward_mean: 168.00738686751612\n",
      "  episode_reward_min: -48.19524299331232\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 52973\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5508781671524048\n",
      "      kl: 0.01090605091303587\n",
      "      policy_loss: -0.0017620306462049484\n",
      "      total_loss: 72.52284240722656\n",
      "      vf_explained_var: 0.9789082407951355\n",
      "      vf_loss: 72.52460479736328\n",
      "    grad_time_ms: 1551.578\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 6940000\n",
      "    num_steps_trained: 6940000\n",
      "    sample_time_ms: 15948.815\n",
      "    update_time_ms: 4.563\n",
      "  iterations_since_restore: 694\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12290.356483697891\n",
      "  time_this_iter_s: 16.954395532608032\n",
      "  time_total_s: 12290.356483697891\n",
      "  timestamp: 1550628733\n",
      "  timesteps_since_restore: 6940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6940000\n",
      "  training_iteration: 694\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12290 s, 694 iter, 6940000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-12-31\n",
      "  done: false\n",
      "  episode_len_mean: 139.24\n",
      "  episode_reward_max: 219.27979521777962\n",
      "  episode_reward_mean: 175.2009158077186\n",
      "  episode_reward_min: -44.83786299920613\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 53044\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7883083820343018\n",
      "      kl: 0.02852119505405426\n",
      "      policy_loss: -0.0003370758786331862\n",
      "      total_loss: 82.87896728515625\n",
      "      vf_explained_var: 0.9763650298118591\n",
      "      vf_loss: 82.87931060791016\n",
      "    grad_time_ms: 1552.313\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 6950000\n",
      "    num_steps_trained: 6950000\n",
      "    sample_time_ms: 15995.483\n",
      "    update_time_ms: 4.554\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12308.238477230072\n",
      "  time_this_iter_s: 17.881993532180786\n",
      "  time_total_s: 12308.238477230072\n",
      "  timestamp: 1550628751\n",
      "  timesteps_since_restore: 6950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6950000\n",
      "  training_iteration: 695\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12308 s, 695 iter, 6950000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-12-48\n",
      "  done: false\n",
      "  episode_len_mean: 136.13\n",
      "  episode_reward_max: 227.7052131389625\n",
      "  episode_reward_mean: 168.09400372906413\n",
      "  episode_reward_min: -44.83786299920613\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 53118\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5487369298934937\n",
      "      kl: 0.01980309747159481\n",
      "      policy_loss: -0.004593835212290287\n",
      "      total_loss: 95.78740692138672\n",
      "      vf_explained_var: 0.9748225808143616\n",
      "      vf_loss: 95.79200744628906\n",
      "    grad_time_ms: 1552.445\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 6960000\n",
      "    num_steps_trained: 6960000\n",
      "    sample_time_ms: 15961.568\n",
      "    update_time_ms: 4.599\n",
      "  iterations_since_restore: 696\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12325.177647352219\n",
      "  time_this_iter_s: 16.939170122146606\n",
      "  time_total_s: 12325.177647352219\n",
      "  timestamp: 1550628768\n",
      "  timesteps_since_restore: 6960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6960000\n",
      "  training_iteration: 696\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12325 s, 696 iter, 6960000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-13-06\n",
      "  done: false\n",
      "  episode_len_mean: 135.65\n",
      "  episode_reward_max: 227.7052131389625\n",
      "  episode_reward_mean: 172.4036382980048\n",
      "  episode_reward_min: -42.80297046722753\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 53192\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.497890591621399\n",
      "      kl: 0.017238004133105278\n",
      "      policy_loss: -0.0012343674898147583\n",
      "      total_loss: 82.77982330322266\n",
      "      vf_explained_var: 0.9767318367958069\n",
      "      vf_loss: 82.78105926513672\n",
      "    grad_time_ms: 1549.831\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 6970000\n",
      "    num_steps_trained: 6970000\n",
      "    sample_time_ms: 15949.885\n",
      "    update_time_ms: 4.612\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12342.895811319351\n",
      "  time_this_iter_s: 17.71816396713257\n",
      "  time_total_s: 12342.895811319351\n",
      "  timestamp: 1550628786\n",
      "  timesteps_since_restore: 6970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6970000\n",
      "  training_iteration: 697\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12342 s, 697 iter, 6970000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-13-23\n",
      "  done: false\n",
      "  episode_len_mean: 136.38\n",
      "  episode_reward_max: 221.56095745621036\n",
      "  episode_reward_mean: 178.53143992747755\n",
      "  episode_reward_min: -34.84654535375313\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 53265\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.479082465171814\n",
      "      kl: 0.030375417321920395\n",
      "      policy_loss: -0.004128494765609503\n",
      "      total_loss: 50.61760330200195\n",
      "      vf_explained_var: 0.9862446784973145\n",
      "      vf_loss: 50.621734619140625\n",
      "    grad_time_ms: 1566.329\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 6980000\n",
      "    num_steps_trained: 6980000\n",
      "    sample_time_ms: 15927.009\n",
      "    update_time_ms: 4.675\n",
      "  iterations_since_restore: 698\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12360.756726026535\n",
      "  time_this_iter_s: 17.860914707183838\n",
      "  time_total_s: 12360.756726026535\n",
      "  timestamp: 1550628803\n",
      "  timesteps_since_restore: 6980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6980000\n",
      "  training_iteration: 698\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12360 s, 698 iter, 6980000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-13-41\n",
      "  done: false\n",
      "  episode_len_mean: 135.98\n",
      "  episode_reward_max: 225.0200958773492\n",
      "  episode_reward_mean: 173.04327328773775\n",
      "  episode_reward_min: -36.42003709966739\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 53339\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.475507378578186\n",
      "      kl: 0.024643778800964355\n",
      "      policy_loss: -0.0031394879333674908\n",
      "      total_loss: 93.9271469116211\n",
      "      vf_explained_var: 0.9725195169448853\n",
      "      vf_loss: 93.93026733398438\n",
      "    grad_time_ms: 1568.52\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 6990000\n",
      "    num_steps_trained: 6990000\n",
      "    sample_time_ms: 15928.237\n",
      "    update_time_ms: 4.69\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12378.25027179718\n",
      "  time_this_iter_s: 17.49354577064514\n",
      "  time_total_s: 12378.25027179718\n",
      "  timestamp: 1550628821\n",
      "  timesteps_since_restore: 6990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6990000\n",
      "  training_iteration: 699\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12378 s, 699 iter, 6990000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-13-58\n",
      "  done: false\n",
      "  episode_len_mean: 135.59\n",
      "  episode_reward_max: 221.3690008820581\n",
      "  episode_reward_mean: 164.57483274396196\n",
      "  episode_reward_min: -44.03358713808554\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 53413\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5534026622772217\n",
      "      kl: 0.018313663080334663\n",
      "      policy_loss: -0.001521783065982163\n",
      "      total_loss: 98.15094757080078\n",
      "      vf_explained_var: 0.9732574820518494\n",
      "      vf_loss: 98.15247344970703\n",
      "    grad_time_ms: 1569.209\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 7000000\n",
      "    num_steps_trained: 7000000\n",
      "    sample_time_ms: 15873.878\n",
      "    update_time_ms: 4.659\n",
      "  iterations_since_restore: 700\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12395.517266511917\n",
      "  time_this_iter_s: 17.26699471473694\n",
      "  time_total_s: 12395.517266511917\n",
      "  timestamp: 1550628838\n",
      "  timesteps_since_restore: 7000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7000000\n",
      "  training_iteration: 700\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12395 s, 700 iter, 7000000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-14-15\n",
      "  done: false\n",
      "  episode_len_mean: 131.99\n",
      "  episode_reward_max: 224.36594514061926\n",
      "  episode_reward_mean: 171.14647391410332\n",
      "  episode_reward_min: -42.870793458037426\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 53488\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2809219360351562\n",
      "      kl: 0.036314040422439575\n",
      "      policy_loss: 0.0004902653745375574\n",
      "      total_loss: 89.86051177978516\n",
      "      vf_explained_var: 0.9750181436538696\n",
      "      vf_loss: 89.8600082397461\n",
      "    grad_time_ms: 1569.754\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 7010000\n",
      "    num_steps_trained: 7010000\n",
      "    sample_time_ms: 15819.836\n",
      "    update_time_ms: 4.761\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12412.658086538315\n",
      "  time_this_iter_s: 17.140820026397705\n",
      "  time_total_s: 12412.658086538315\n",
      "  timestamp: 1550628855\n",
      "  timesteps_since_restore: 7010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7010000\n",
      "  training_iteration: 701\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12412 s, 701 iter, 7010000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-14-33\n",
      "  done: false\n",
      "  episode_len_mean: 135.08\n",
      "  episode_reward_max: 227.44025303128328\n",
      "  episode_reward_mean: 179.1058391344017\n",
      "  episode_reward_min: -41.78607087656119\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 53562\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4509761333465576\n",
      "      kl: 0.030381718650460243\n",
      "      policy_loss: -0.0021577985025942326\n",
      "      total_loss: 33.29998779296875\n",
      "      vf_explained_var: 0.9892999529838562\n",
      "      vf_loss: 33.302146911621094\n",
      "    grad_time_ms: 1571.404\n",
      "    load_time_ms: 1.4\n",
      "    num_steps_sampled: 7020000\n",
      "    num_steps_trained: 7020000\n",
      "    sample_time_ms: 15829.209\n",
      "    update_time_ms: 4.626\n",
      "  iterations_since_restore: 702\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12429.898081302643\n",
      "  time_this_iter_s: 17.239994764328003\n",
      "  time_total_s: 12429.898081302643\n",
      "  timestamp: 1550628873\n",
      "  timesteps_since_restore: 7020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7020000\n",
      "  training_iteration: 702\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12429 s, 702 iter, 7020000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-14-50\n",
      "  done: false\n",
      "  episode_len_mean: 137.96\n",
      "  episode_reward_max: 231.4120635712648\n",
      "  episode_reward_mean: 179.4181945555162\n",
      "  episode_reward_min: 71.62747854237801\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 53634\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5501701831817627\n",
      "      kl: 0.011610440909862518\n",
      "      policy_loss: -0.0018133687553927302\n",
      "      total_loss: 76.7119369506836\n",
      "      vf_explained_var: 0.978151261806488\n",
      "      vf_loss: 76.71375274658203\n",
      "    grad_time_ms: 1570.445\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 7030000\n",
      "    num_steps_trained: 7030000\n",
      "    sample_time_ms: 15779.331\n",
      "    update_time_ms: 4.671\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12447.091313838959\n",
      "  time_this_iter_s: 17.193232536315918\n",
      "  time_total_s: 12447.091313838959\n",
      "  timestamp: 1550628890\n",
      "  timesteps_since_restore: 7030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7030000\n",
      "  training_iteration: 703\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12447 s, 703 iter, 7030000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-15-08\n",
      "  done: false\n",
      "  episode_len_mean: 137.27\n",
      "  episode_reward_max: 223.69143444078395\n",
      "  episode_reward_mean: 179.9122642346805\n",
      "  episode_reward_min: 65.74753733602645\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 53707\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4890059232711792\n",
      "      kl: 0.026473065838217735\n",
      "      policy_loss: -3.2006930268835276e-05\n",
      "      total_loss: 38.34393310546875\n",
      "      vf_explained_var: 0.9875982999801636\n",
      "      vf_loss: 38.34396743774414\n",
      "    grad_time_ms: 1568.127\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 7040000\n",
      "    num_steps_trained: 7040000\n",
      "    sample_time_ms: 15891.48\n",
      "    update_time_ms: 4.432\n",
      "  iterations_since_restore: 704\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12465.142837762833\n",
      "  time_this_iter_s: 18.0515239238739\n",
      "  time_total_s: 12465.142837762833\n",
      "  timestamp: 1550628908\n",
      "  timesteps_since_restore: 7040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7040000\n",
      "  training_iteration: 704\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12465 s, 704 iter, 7040000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-15-26\n",
      "  done: false\n",
      "  episode_len_mean: 131.98\n",
      "  episode_reward_max: 223.69143444078395\n",
      "  episode_reward_mean: 166.2481077190687\n",
      "  episode_reward_min: -45.95008806707243\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 53784\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4775464534759521\n",
      "      kl: 0.021414021030068398\n",
      "      policy_loss: 0.001283133402466774\n",
      "      total_loss: 82.92680358886719\n",
      "      vf_explained_var: 0.9803133010864258\n",
      "      vf_loss: 82.92552185058594\n",
      "    grad_time_ms: 1567.129\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 7050000\n",
      "    num_steps_trained: 7050000\n",
      "    sample_time_ms: 15918.085\n",
      "    update_time_ms: 4.334\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12483.277045249939\n",
      "  time_this_iter_s: 18.134207487106323\n",
      "  time_total_s: 12483.277045249939\n",
      "  timestamp: 1550628926\n",
      "  timesteps_since_restore: 7050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7050000\n",
      "  training_iteration: 705\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12483 s, 705 iter, 7050000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-15-44\n",
      "  done: false\n",
      "  episode_len_mean: 134.5\n",
      "  episode_reward_max: 228.56366195905912\n",
      "  episode_reward_mean: 161.38090021536692\n",
      "  episode_reward_min: -45.95008806707243\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 53857\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7237436771392822\n",
      "      kl: 0.017619339749217033\n",
      "      policy_loss: -0.0005750228301621974\n",
      "      total_loss: 67.05542755126953\n",
      "      vf_explained_var: 0.9807000756263733\n",
      "      vf_loss: 67.05599975585938\n",
      "    grad_time_ms: 1567.196\n",
      "    load_time_ms: 1.322\n",
      "    num_steps_sampled: 7060000\n",
      "    num_steps_trained: 7060000\n",
      "    sample_time_ms: 15990.806\n",
      "    update_time_ms: 4.319\n",
      "  iterations_since_restore: 706\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12500.943911075592\n",
      "  time_this_iter_s: 17.666865825653076\n",
      "  time_total_s: 12500.943911075592\n",
      "  timestamp: 1550628944\n",
      "  timesteps_since_restore: 7060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7060000\n",
      "  training_iteration: 706\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12500 s, 706 iter, 7060000 ts, 161 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-16-01\n",
      "  done: false\n",
      "  episode_len_mean: 137.22\n",
      "  episode_reward_max: 229.6294524511045\n",
      "  episode_reward_mean: 177.1424489997501\n",
      "  episode_reward_min: -34.15239553854312\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 53930\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4971797466278076\n",
      "      kl: 0.0384395532310009\n",
      "      policy_loss: 0.00014309317339211702\n",
      "      total_loss: 61.63866424560547\n",
      "      vf_explained_var: 0.9818598628044128\n",
      "      vf_loss: 61.63853454589844\n",
      "    grad_time_ms: 1571.621\n",
      "    load_time_ms: 1.259\n",
      "    num_steps_sampled: 7070000\n",
      "    num_steps_trained: 7070000\n",
      "    sample_time_ms: 15909.272\n",
      "    update_time_ms: 4.296\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12517.890285491943\n",
      "  time_this_iter_s: 16.94637441635132\n",
      "  time_total_s: 12517.890285491943\n",
      "  timestamp: 1550628961\n",
      "  timesteps_since_restore: 7070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7070000\n",
      "  training_iteration: 707\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12517 s, 707 iter, 7070000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-16-19\n",
      "  done: false\n",
      "  episode_len_mean: 134.14\n",
      "  episode_reward_max: 229.6294524511045\n",
      "  episode_reward_mean: 178.9363485749674\n",
      "  episode_reward_min: -41.76559736535396\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 54005\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3366997241973877\n",
      "      kl: 0.010273990221321583\n",
      "      policy_loss: -0.001946594100445509\n",
      "      total_loss: 33.81681442260742\n",
      "      vf_explained_var: 0.9894764423370361\n",
      "      vf_loss: 33.81875991821289\n",
      "    grad_time_ms: 1554.747\n",
      "    load_time_ms: 1.279\n",
      "    num_steps_sampled: 7080000\n",
      "    num_steps_trained: 7080000\n",
      "    sample_time_ms: 15902.038\n",
      "    update_time_ms: 4.198\n",
      "  iterations_since_restore: 708\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12535.508935689926\n",
      "  time_this_iter_s: 17.618650197982788\n",
      "  time_total_s: 12535.508935689926\n",
      "  timestamp: 1550628979\n",
      "  timesteps_since_restore: 7080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7080000\n",
      "  training_iteration: 708\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12535 s, 708 iter, 7080000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 133.8\n",
      "  episode_reward_max: 223.16136056110977\n",
      "  episode_reward_mean: 171.2581185934413\n",
      "  episode_reward_min: -45.5910636321964\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 54080\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4703387022018433\n",
      "      kl: 0.0176750048995018\n",
      "      policy_loss: -0.0008129760390147567\n",
      "      total_loss: 69.35859680175781\n",
      "      vf_explained_var: 0.980288565158844\n",
      "      vf_loss: 69.35940551757812\n",
      "    grad_time_ms: 1549.882\n",
      "    load_time_ms: 1.26\n",
      "    num_steps_sampled: 7090000\n",
      "    num_steps_trained: 7090000\n",
      "    sample_time_ms: 15917.817\n",
      "    update_time_ms: 4.17\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12553.109355449677\n",
      "  time_this_iter_s: 17.600419759750366\n",
      "  time_total_s: 12553.109355449677\n",
      "  timestamp: 1550628996\n",
      "  timesteps_since_restore: 7090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7090000\n",
      "  training_iteration: 709\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12553 s, 709 iter, 7090000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-16-54\n",
      "  done: false\n",
      "  episode_len_mean: 135.33\n",
      "  episode_reward_max: 222.17138390243048\n",
      "  episode_reward_mean: 169.42780190227066\n",
      "  episode_reward_min: -45.5910636321964\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 54154\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5795917510986328\n",
      "      kl: 0.01785299740731716\n",
      "      policy_loss: -0.004029276315122843\n",
      "      total_loss: 84.29744720458984\n",
      "      vf_explained_var: 0.9728825092315674\n",
      "      vf_loss: 84.3014907836914\n",
      "    grad_time_ms: 1566.829\n",
      "    load_time_ms: 1.254\n",
      "    num_steps_sampled: 7100000\n",
      "    num_steps_trained: 7100000\n",
      "    sample_time_ms: 15934.668\n",
      "    update_time_ms: 4.105\n",
      "  iterations_since_restore: 710\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12570.712834596634\n",
      "  time_this_iter_s: 17.603479146957397\n",
      "  time_total_s: 12570.712834596634\n",
      "  timestamp: 1550629014\n",
      "  timesteps_since_restore: 7100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7100000\n",
      "  training_iteration: 710\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12570 s, 710 iter, 7100000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-17-11\n",
      "  done: false\n",
      "  episode_len_mean: 135.3\n",
      "  episode_reward_max: 222.17138390243048\n",
      "  episode_reward_mean: 175.95508924583442\n",
      "  episode_reward_min: -45.42070398140366\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 54228\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5320303440093994\n",
      "      kl: 0.019407004117965698\n",
      "      policy_loss: 0.0003114192222710699\n",
      "      total_loss: 69.21255493164062\n",
      "      vf_explained_var: 0.9790353178977966\n",
      "      vf_loss: 69.21224212646484\n",
      "    grad_time_ms: 1566.86\n",
      "    load_time_ms: 1.383\n",
      "    num_steps_sampled: 7110000\n",
      "    num_steps_trained: 7110000\n",
      "    sample_time_ms: 15974.892\n",
      "    update_time_ms: 4.041\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12588.258589744568\n",
      "  time_this_iter_s: 17.54575514793396\n",
      "  time_total_s: 12588.258589744568\n",
      "  timestamp: 1550629031\n",
      "  timesteps_since_restore: 7110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7110000\n",
      "  training_iteration: 711\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12588 s, 711 iter, 7110000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 135.36\n",
      "  episode_reward_max: 221.18646813634004\n",
      "  episode_reward_mean: 175.48076334002275\n",
      "  episode_reward_min: -45.42070398140366\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 54301\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5350582599639893\n",
      "      kl: 0.013667195104062557\n",
      "      policy_loss: -0.001520870835520327\n",
      "      total_loss: 35.32168197631836\n",
      "      vf_explained_var: 0.9888174533843994\n",
      "      vf_loss: 35.32320785522461\n",
      "    grad_time_ms: 1566.781\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 7120000\n",
      "    num_steps_trained: 7120000\n",
      "    sample_time_ms: 15985.992\n",
      "    update_time_ms: 4.059\n",
      "  iterations_since_restore: 712\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12605.610424280167\n",
      "  time_this_iter_s: 17.351834535598755\n",
      "  time_total_s: 12605.610424280167\n",
      "  timestamp: 1550629049\n",
      "  timesteps_since_restore: 7120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7120000\n",
      "  training_iteration: 712\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12605 s, 712 iter, 7120000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-17-46\n",
      "  done: false\n",
      "  episode_len_mean: 134.87\n",
      "  episode_reward_max: 228.2531393592311\n",
      "  episode_reward_mean: 175.19880315796772\n",
      "  episode_reward_min: -43.60570694520924\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 54374\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5588637590408325\n",
      "      kl: 0.015992946922779083\n",
      "      policy_loss: -0.0007414961000904441\n",
      "      total_loss: 75.92469787597656\n",
      "      vf_explained_var: 0.9778239727020264\n",
      "      vf_loss: 75.9254379272461\n",
      "    grad_time_ms: 1567.928\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 7130000\n",
      "    num_steps_trained: 7130000\n",
      "    sample_time_ms: 16004.687\n",
      "    update_time_ms: 4.112\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12623.002117156982\n",
      "  time_this_iter_s: 17.391692876815796\n",
      "  time_total_s: 12623.002117156982\n",
      "  timestamp: 1550629066\n",
      "  timesteps_since_restore: 7130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7130000\n",
      "  training_iteration: 713\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12623 s, 713 iter, 7130000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-18-04\n",
      "  done: false\n",
      "  episode_len_mean: 132.55\n",
      "  episode_reward_max: 228.2531393592311\n",
      "  episode_reward_mean: 166.17097713590522\n",
      "  episode_reward_min: -45.85028196251626\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 54451\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6404536962509155\n",
      "      kl: 0.019440004602074623\n",
      "      policy_loss: -0.005087865982204676\n",
      "      total_loss: 95.0851821899414\n",
      "      vf_explained_var: 0.9735514521598816\n",
      "      vf_loss: 95.09027099609375\n",
      "    grad_time_ms: 1565.984\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 7140000\n",
      "    num_steps_trained: 7140000\n",
      "    sample_time_ms: 15937.663\n",
      "    update_time_ms: 4.154\n",
      "  iterations_since_restore: 714\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12640.363874435425\n",
      "  time_this_iter_s: 17.361757278442383\n",
      "  time_total_s: 12640.363874435425\n",
      "  timestamp: 1550629084\n",
      "  timesteps_since_restore: 7140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7140000\n",
      "  training_iteration: 714\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12640 s, 714 iter, 7140000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-18-21\n",
      "  done: false\n",
      "  episode_len_mean: 134.82\n",
      "  episode_reward_max: 227.69457190679296\n",
      "  episode_reward_mean: 175.20345538430425\n",
      "  episode_reward_min: -43.67882382346889\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 54523\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4962657690048218\n",
      "      kl: 0.016226215288043022\n",
      "      policy_loss: -0.001756885088980198\n",
      "      total_loss: 48.07154083251953\n",
      "      vf_explained_var: 0.9854702353477478\n",
      "      vf_loss: 48.07329177856445\n",
      "    grad_time_ms: 1564.272\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 7150000\n",
      "    num_steps_trained: 7150000\n",
      "    sample_time_ms: 15839.416\n",
      "    update_time_ms: 4.264\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12657.499704837799\n",
      "  time_this_iter_s: 17.135830402374268\n",
      "  time_total_s: 12657.499704837799\n",
      "  timestamp: 1550629101\n",
      "  timesteps_since_restore: 7150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7150000\n",
      "  training_iteration: 715\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12657 s, 715 iter, 7150000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-18-39\n",
      "  done: false\n",
      "  episode_len_mean: 136.85\n",
      "  episode_reward_max: 225.47965898969696\n",
      "  episode_reward_mean: 185.51085604641867\n",
      "  episode_reward_min: 138.38721486394945\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 54596\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5547549724578857\n",
      "      kl: 0.01847844384610653\n",
      "      policy_loss: -0.0008759989286772907\n",
      "      total_loss: 15.200002670288086\n",
      "      vf_explained_var: 0.9950437545776367\n",
      "      vf_loss: 15.20087718963623\n",
      "    grad_time_ms: 1565.454\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 7160000\n",
      "    num_steps_trained: 7160000\n",
      "    sample_time_ms: 15842.358\n",
      "    update_time_ms: 4.219\n",
      "  iterations_since_restore: 716\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12675.20829486847\n",
      "  time_this_iter_s: 17.708590030670166\n",
      "  time_total_s: 12675.20829486847\n",
      "  timestamp: 1550629119\n",
      "  timesteps_since_restore: 7160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7160000\n",
      "  training_iteration: 716\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12675 s, 716 iter, 7160000 ts, 186 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-18-56\n",
      "  done: false\n",
      "  episode_len_mean: 136.8\n",
      "  episode_reward_max: 221.14410051548563\n",
      "  episode_reward_mean: 176.2423805647973\n",
      "  episode_reward_min: -41.33031986757081\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 54669\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5593056678771973\n",
      "      kl: 0.015335717238485813\n",
      "      policy_loss: -0.0032880057115107775\n",
      "      total_loss: 99.11014556884766\n",
      "      vf_explained_var: 0.9718220829963684\n",
      "      vf_loss: 99.11343383789062\n",
      "    grad_time_ms: 1561.004\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 7170000\n",
      "    num_steps_trained: 7170000\n",
      "    sample_time_ms: 15911.109\n",
      "    update_time_ms: 4.303\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12692.799948453903\n",
      "  time_this_iter_s: 17.59165358543396\n",
      "  time_total_s: 12692.799948453903\n",
      "  timestamp: 1550629136\n",
      "  timesteps_since_restore: 7170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7170000\n",
      "  training_iteration: 717\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12692 s, 717 iter, 7170000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-19-14\n",
      "  done: false\n",
      "  episode_len_mean: 136.11\n",
      "  episode_reward_max: 226.79607143337904\n",
      "  episode_reward_mean: 174.91471017376344\n",
      "  episode_reward_min: -45.090010610473605\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 54742\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4982482194900513\n",
      "      kl: 0.020558873191475868\n",
      "      policy_loss: -0.0019350703805685043\n",
      "      total_loss: 95.22265625\n",
      "      vf_explained_var: 0.9743490219116211\n",
      "      vf_loss: 95.2245864868164\n",
      "    grad_time_ms: 1562.966\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 7180000\n",
      "    num_steps_trained: 7180000\n",
      "    sample_time_ms: 15872.727\n",
      "    update_time_ms: 4.346\n",
      "  iterations_since_restore: 718\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12710.055209159851\n",
      "  time_this_iter_s: 17.255260705947876\n",
      "  time_total_s: 12710.055209159851\n",
      "  timestamp: 1550629154\n",
      "  timesteps_since_restore: 7180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7180000\n",
      "  training_iteration: 718\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12710 s, 718 iter, 7180000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-19-31\n",
      "  done: false\n",
      "  episode_len_mean: 134.03\n",
      "  episode_reward_max: 224.36991453831007\n",
      "  episode_reward_mean: 170.9973166453093\n",
      "  episode_reward_min: -38.876888294215526\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 54817\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4341341257095337\n",
      "      kl: 0.01844756491482258\n",
      "      policy_loss: -0.001236742245964706\n",
      "      total_loss: 130.0405731201172\n",
      "      vf_explained_var: 0.9659326076507568\n",
      "      vf_loss: 130.04180908203125\n",
      "    grad_time_ms: 1568.95\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 7190000\n",
      "    num_steps_trained: 7190000\n",
      "    sample_time_ms: 15865.919\n",
      "    update_time_ms: 4.391\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12727.647744894028\n",
      "  time_this_iter_s: 17.592535734176636\n",
      "  time_total_s: 12727.647744894028\n",
      "  timestamp: 1550629171\n",
      "  timesteps_since_restore: 7190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7190000\n",
      "  training_iteration: 719\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12727 s, 719 iter, 7190000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-19-48\n",
      "  done: false\n",
      "  episode_len_mean: 134.98\n",
      "  episode_reward_max: 222.62571546759932\n",
      "  episode_reward_mean: 168.3928710334242\n",
      "  episode_reward_min: -40.04659744189814\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 54891\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.385170817375183\n",
      "      kl: 0.01602741703391075\n",
      "      policy_loss: -0.0026792811695486307\n",
      "      total_loss: 113.90632629394531\n",
      "      vf_explained_var: 0.970233142375946\n",
      "      vf_loss: 113.90901947021484\n",
      "    grad_time_ms: 1547.95\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 7200000\n",
      "    num_steps_trained: 7200000\n",
      "    sample_time_ms: 15841.803\n",
      "    update_time_ms: 4.493\n",
      "  iterations_since_restore: 720\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12744.802072763443\n",
      "  time_this_iter_s: 17.154327869415283\n",
      "  time_total_s: 12744.802072763443\n",
      "  timestamp: 1550629188\n",
      "  timesteps_since_restore: 7200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7200000\n",
      "  training_iteration: 720\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12744 s, 720 iter, 7200000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-20-05\n",
      "  done: false\n",
      "  episode_len_mean: 134.12\n",
      "  episode_reward_max: 224.00117601793593\n",
      "  episode_reward_mean: 168.64465128530196\n",
      "  episode_reward_min: -40.04659744189814\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 54965\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4858458042144775\n",
      "      kl: 0.01651189848780632\n",
      "      policy_loss: -0.002170429565012455\n",
      "      total_loss: 83.18230438232422\n",
      "      vf_explained_var: 0.9759793281555176\n",
      "      vf_loss: 83.1844711303711\n",
      "    grad_time_ms: 1548.119\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 7210000\n",
      "    num_steps_trained: 7210000\n",
      "    sample_time_ms: 15801.337\n",
      "    update_time_ms: 4.503\n",
      "  iterations_since_restore: 721\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12761.941201925278\n",
      "  time_this_iter_s: 17.139129161834717\n",
      "  time_total_s: 12761.941201925278\n",
      "  timestamp: 1550629205\n",
      "  timesteps_since_restore: 7210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7210000\n",
      "  training_iteration: 721\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12761 s, 721 iter, 7210000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-20-22\n",
      "  done: false\n",
      "  episode_len_mean: 136.2\n",
      "  episode_reward_max: 218.71771860648278\n",
      "  episode_reward_mean: 176.0829707693928\n",
      "  episode_reward_min: -39.117288035073194\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55039\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5932331085205078\n",
      "      kl: 0.016608648002147675\n",
      "      policy_loss: -0.00034985251841135323\n",
      "      total_loss: 58.120460510253906\n",
      "      vf_explained_var: 0.9831091165542603\n",
      "      vf_loss: 58.12080001831055\n",
      "    grad_time_ms: 1547.551\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 7220000\n",
      "    num_steps_trained: 7220000\n",
      "    sample_time_ms: 15738.222\n",
      "    update_time_ms: 4.664\n",
      "  iterations_since_restore: 722\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12778.655636310577\n",
      "  time_this_iter_s: 16.714434385299683\n",
      "  time_total_s: 12778.655636310577\n",
      "  timestamp: 1550629222\n",
      "  timesteps_since_restore: 7220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7220000\n",
      "  training_iteration: 722\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12778 s, 722 iter, 7220000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-20-40\n",
      "  done: false\n",
      "  episode_len_mean: 136.85\n",
      "  episode_reward_max: 222.85988806291397\n",
      "  episode_reward_mean: 176.9420177165961\n",
      "  episode_reward_min: -43.41710731298614\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 55112\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6110411882400513\n",
      "      kl: 0.015070846304297447\n",
      "      policy_loss: -0.0006679407088086009\n",
      "      total_loss: 36.90654373168945\n",
      "      vf_explained_var: 0.9883854985237122\n",
      "      vf_loss: 36.9072151184082\n",
      "    grad_time_ms: 1545.576\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 7230000\n",
      "    num_steps_trained: 7230000\n",
      "    sample_time_ms: 15758.071\n",
      "    update_time_ms: 4.626\n",
      "  iterations_since_restore: 723\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12796.225612163544\n",
      "  time_this_iter_s: 17.56997585296631\n",
      "  time_total_s: 12796.225612163544\n",
      "  timestamp: 1550629240\n",
      "  timesteps_since_restore: 7230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7230000\n",
      "  training_iteration: 723\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12796 s, 723 iter, 7230000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-20-57\n",
      "  done: false\n",
      "  episode_len_mean: 134.8\n",
      "  episode_reward_max: 225.44330120189932\n",
      "  episode_reward_mean: 178.06235347933784\n",
      "  episode_reward_min: -43.860066519884185\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55186\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3706071376800537\n",
      "      kl: 0.025645531713962555\n",
      "      policy_loss: -0.0026069937739521265\n",
      "      total_loss: 38.75438690185547\n",
      "      vf_explained_var: 0.9885679483413696\n",
      "      vf_loss: 38.75699234008789\n",
      "    grad_time_ms: 1547.077\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 7240000\n",
      "    num_steps_trained: 7240000\n",
      "    sample_time_ms: 15749.288\n",
      "    update_time_ms: 4.57\n",
      "  iterations_since_restore: 724\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12813.516391992569\n",
      "  time_this_iter_s: 17.29077982902527\n",
      "  time_total_s: 12813.516391992569\n",
      "  timestamp: 1550629257\n",
      "  timesteps_since_restore: 7240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7240000\n",
      "  training_iteration: 724\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12813 s, 724 iter, 7240000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-21-14\n",
      "  done: false\n",
      "  episode_len_mean: 136.97\n",
      "  episode_reward_max: 226.2924318861695\n",
      "  episode_reward_mean: 180.49562547215194\n",
      "  episode_reward_min: 74.11817709699568\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 55259\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4860233068466187\n",
      "      kl: 0.020840538665652275\n",
      "      policy_loss: 0.0001061368893715553\n",
      "      total_loss: 57.08921813964844\n",
      "      vf_explained_var: 0.9834614396095276\n",
      "      vf_loss: 57.08911895751953\n",
      "    grad_time_ms: 1547.718\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 7250000\n",
      "    num_steps_trained: 7250000\n",
      "    sample_time_ms: 15759.676\n",
      "    update_time_ms: 4.49\n",
      "  iterations_since_restore: 725\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12830.765273332596\n",
      "  time_this_iter_s: 17.248881340026855\n",
      "  time_total_s: 12830.765273332596\n",
      "  timestamp: 1550629274\n",
      "  timesteps_since_restore: 7250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7250000\n",
      "  training_iteration: 725\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12830 s, 725 iter, 7250000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-21-32\n",
      "  done: false\n",
      "  episode_len_mean: 137.5\n",
      "  episode_reward_max: 218.57203596454158\n",
      "  episode_reward_mean: 182.39563282281932\n",
      "  episode_reward_min: 89.15440411740298\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 55332\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4289695024490356\n",
      "      kl: 0.019166793674230576\n",
      "      policy_loss: -0.0030207510571926832\n",
      "      total_loss: 23.897769927978516\n",
      "      vf_explained_var: 0.9922686815261841\n",
      "      vf_loss: 23.900789260864258\n",
      "    grad_time_ms: 1548.025\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 7260000\n",
      "    num_steps_trained: 7260000\n",
      "    sample_time_ms: 15725.474\n",
      "    update_time_ms: 4.452\n",
      "  iterations_since_restore: 726\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12848.133135557175\n",
      "  time_this_iter_s: 17.367862224578857\n",
      "  time_total_s: 12848.133135557175\n",
      "  timestamp: 1550629292\n",
      "  timesteps_since_restore: 7260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7260000\n",
      "  training_iteration: 726\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12848 s, 726 iter, 7260000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-21-49\n",
      "  done: false\n",
      "  episode_len_mean: 133.87\n",
      "  episode_reward_max: 225.71113594577147\n",
      "  episode_reward_mean: 168.53069433782636\n",
      "  episode_reward_min: -42.046461144517565\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 55407\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.352436900138855\n",
      "      kl: 0.01953180506825447\n",
      "      policy_loss: -0.0009590742411091924\n",
      "      total_loss: 122.84542846679688\n",
      "      vf_explained_var: 0.9676231145858765\n",
      "      vf_loss: 122.84640502929688\n",
      "    grad_time_ms: 1548.433\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 7270000\n",
      "    num_steps_trained: 7270000\n",
      "    sample_time_ms: 15717.008\n",
      "    update_time_ms: 4.332\n",
      "  iterations_since_restore: 727\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12865.643343687057\n",
      "  time_this_iter_s: 17.510208129882812\n",
      "  time_total_s: 12865.643343687057\n",
      "  timestamp: 1550629309\n",
      "  timesteps_since_restore: 7270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7270000\n",
      "  training_iteration: 727\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12865 s, 727 iter, 7270000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-22-06\n",
      "  done: false\n",
      "  episode_len_mean: 132.92\n",
      "  episode_reward_max: 221.4905042341072\n",
      "  episode_reward_mean: 161.856393174808\n",
      "  episode_reward_min: -43.64908488021041\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55481\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5389832258224487\n",
      "      kl: 0.01953919231891632\n",
      "      policy_loss: -0.0024739676155149937\n",
      "      total_loss: 107.37962341308594\n",
      "      vf_explained_var: 0.9693310260772705\n",
      "      vf_loss: 107.38211059570312\n",
      "    grad_time_ms: 1546.939\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 7280000\n",
      "    num_steps_trained: 7280000\n",
      "    sample_time_ms: 15693.628\n",
      "    update_time_ms: 4.413\n",
      "  iterations_since_restore: 728\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12882.65056180954\n",
      "  time_this_iter_s: 17.0072181224823\n",
      "  time_total_s: 12882.65056180954\n",
      "  timestamp: 1550629326\n",
      "  timesteps_since_restore: 7280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7280000\n",
      "  training_iteration: 728\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12882 s, 728 iter, 7280000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-22-24\n",
      "  done: false\n",
      "  episode_len_mean: 136.2\n",
      "  episode_reward_max: 221.15034968531367\n",
      "  episode_reward_mean: 169.88354863643403\n",
      "  episode_reward_min: -43.64908488021041\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55555\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5061545372009277\n",
      "      kl: 0.020462283864617348\n",
      "      policy_loss: -0.0031222100369632244\n",
      "      total_loss: 84.54409790039062\n",
      "      vf_explained_var: 0.9742776155471802\n",
      "      vf_loss: 84.5472183227539\n",
      "    grad_time_ms: 1563.399\n",
      "    load_time_ms: 1.383\n",
      "    num_steps_sampled: 7290000\n",
      "    num_steps_trained: 7290000\n",
      "    sample_time_ms: 15668.987\n",
      "    update_time_ms: 4.371\n",
      "  iterations_since_restore: 729\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12900.160266637802\n",
      "  time_this_iter_s: 17.50970482826233\n",
      "  time_total_s: 12900.160266637802\n",
      "  timestamp: 1550629344\n",
      "  timesteps_since_restore: 7290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7290000\n",
      "  training_iteration: 729\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12900 s, 729 iter, 7290000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-22-41\n",
      "  done: false\n",
      "  episode_len_mean: 136.09\n",
      "  episode_reward_max: 224.53771880033014\n",
      "  episode_reward_mean: 173.76738206710758\n",
      "  episode_reward_min: -44.74354651706793\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55629\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5242611169815063\n",
      "      kl: 0.02445180155336857\n",
      "      policy_loss: -0.0030736024491488934\n",
      "      total_loss: 88.26688385009766\n",
      "      vf_explained_var: 0.9751834273338318\n",
      "      vf_loss: 88.26995849609375\n",
      "    grad_time_ms: 1564.304\n",
      "    load_time_ms: 1.372\n",
      "    num_steps_sampled: 7300000\n",
      "    num_steps_trained: 7300000\n",
      "    sample_time_ms: 15696.617\n",
      "    update_time_ms: 4.335\n",
      "  iterations_since_restore: 730\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12917.599233865738\n",
      "  time_this_iter_s: 17.43896722793579\n",
      "  time_total_s: 12917.599233865738\n",
      "  timestamp: 1550629361\n",
      "  timesteps_since_restore: 7300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7300000\n",
      "  training_iteration: 730\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12917 s, 730 iter, 7300000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-22-59\n",
      "  done: false\n",
      "  episode_len_mean: 133.17\n",
      "  episode_reward_max: 222.06187273886525\n",
      "  episode_reward_mean: 174.0713623762318\n",
      "  episode_reward_min: -41.413729353853974\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55703\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4704521894454956\n",
      "      kl: 0.023997632786631584\n",
      "      policy_loss: -0.0028848706278949976\n",
      "      total_loss: 33.60731506347656\n",
      "      vf_explained_var: 0.9902440309524536\n",
      "      vf_loss: 33.61019515991211\n",
      "    grad_time_ms: 1564.365\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 7310000\n",
      "    num_steps_trained: 7310000\n",
      "    sample_time_ms: 15707.128\n",
      "    update_time_ms: 4.284\n",
      "  iterations_since_restore: 731\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12934.844822883606\n",
      "  time_this_iter_s: 17.245589017868042\n",
      "  time_total_s: 12934.844822883606\n",
      "  timestamp: 1550629379\n",
      "  timesteps_since_restore: 7310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7310000\n",
      "  training_iteration: 731\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12934 s, 731 iter, 7310000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-23-16\n",
      "  done: false\n",
      "  episode_len_mean: 134.72\n",
      "  episode_reward_max: 229.72646089370306\n",
      "  episode_reward_mean: 173.53721228769976\n",
      "  episode_reward_min: -40.67311143506282\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 55778\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.360037922859192\n",
      "      kl: 0.022784831002354622\n",
      "      policy_loss: -0.002606598660349846\n",
      "      total_loss: 128.64881896972656\n",
      "      vf_explained_var: 0.966439962387085\n",
      "      vf_loss: 128.65142822265625\n",
      "    grad_time_ms: 1567.55\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 7320000\n",
      "    num_steps_trained: 7320000\n",
      "    sample_time_ms: 15781.396\n",
      "    update_time_ms: 4.106\n",
      "  iterations_since_restore: 732\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12952.333199262619\n",
      "  time_this_iter_s: 17.48837637901306\n",
      "  time_total_s: 12952.333199262619\n",
      "  timestamp: 1550629396\n",
      "  timesteps_since_restore: 7320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7320000\n",
      "  training_iteration: 732\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12952 s, 732 iter, 7320000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-23-33\n",
      "  done: false\n",
      "  episode_len_mean: 135.82\n",
      "  episode_reward_max: 229.72646089370306\n",
      "  episode_reward_mean: 177.5830487737636\n",
      "  episode_reward_min: 62.40405399226927\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 55851\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4629024267196655\n",
      "      kl: 0.021751267835497856\n",
      "      policy_loss: 0.0002949402551166713\n",
      "      total_loss: 46.43889236450195\n",
      "      vf_explained_var: 0.985480010509491\n",
      "      vf_loss: 46.4385986328125\n",
      "    grad_time_ms: 1568.383\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 7330000\n",
      "    num_steps_trained: 7330000\n",
      "    sample_time_ms: 15728.786\n",
      "    update_time_ms: 4.171\n",
      "  iterations_since_restore: 733\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12969.385546684265\n",
      "  time_this_iter_s: 17.052347421646118\n",
      "  time_total_s: 12969.385546684265\n",
      "  timestamp: 1550629413\n",
      "  timesteps_since_restore: 7330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7330000\n",
      "  training_iteration: 733\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12969 s, 733 iter, 7330000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-23-51\n",
      "  done: false\n",
      "  episode_len_mean: 134.01\n",
      "  episode_reward_max: 227.67007149066228\n",
      "  episode_reward_mean: 168.71711146778995\n",
      "  episode_reward_min: -41.53751535875961\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55925\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5325769186019897\n",
      "      kl: 0.020618434995412827\n",
      "      policy_loss: -0.0020116548985242844\n",
      "      total_loss: 108.8199462890625\n",
      "      vf_explained_var: 0.9707527160644531\n",
      "      vf_loss: 108.82193756103516\n",
      "    grad_time_ms: 1570.202\n",
      "    load_time_ms: 1.374\n",
      "    num_steps_sampled: 7340000\n",
      "    num_steps_trained: 7340000\n",
      "    sample_time_ms: 15730.537\n",
      "    update_time_ms: 4.2\n",
      "  iterations_since_restore: 734\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 12986.710143089294\n",
      "  time_this_iter_s: 17.324596405029297\n",
      "  time_total_s: 12986.710143089294\n",
      "  timestamp: 1550629431\n",
      "  timesteps_since_restore: 7340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7340000\n",
      "  training_iteration: 734\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 12986 s, 734 iter, 7340000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-24-08\n",
      "  done: false\n",
      "  episode_len_mean: 134.65\n",
      "  episode_reward_max: 229.67483979301295\n",
      "  episode_reward_mean: 165.0850894600422\n",
      "  episode_reward_min: -42.63185831885972\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55999\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.556098222732544\n",
      "      kl: 0.027317175641655922\n",
      "      policy_loss: -0.0016036400338634849\n",
      "      total_loss: 129.34652709960938\n",
      "      vf_explained_var: 0.9646880030632019\n",
      "      vf_loss: 129.34811401367188\n",
      "    grad_time_ms: 1570.452\n",
      "    load_time_ms: 1.318\n",
      "    num_steps_sampled: 7350000\n",
      "    num_steps_trained: 7350000\n",
      "    sample_time_ms: 15741.368\n",
      "    update_time_ms: 4.217\n",
      "  iterations_since_restore: 735\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13004.067659139633\n",
      "  time_this_iter_s: 17.357516050338745\n",
      "  time_total_s: 13004.067659139633\n",
      "  timestamp: 1550629448\n",
      "  timesteps_since_restore: 7350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7350000\n",
      "  training_iteration: 735\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13004 s, 735 iter, 7350000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-24-25\n",
      "  done: false\n",
      "  episode_len_mean: 136.65\n",
      "  episode_reward_max: 221.91997902877256\n",
      "  episode_reward_mean: 168.85842698664547\n",
      "  episode_reward_min: -41.76287286311832\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 56072\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5015133619308472\n",
      "      kl: 0.01611575111746788\n",
      "      policy_loss: -0.0013557402417063713\n",
      "      total_loss: 143.6448516845703\n",
      "      vf_explained_var: 0.9620783925056458\n",
      "      vf_loss: 143.64620971679688\n",
      "    grad_time_ms: 1568.162\n",
      "    load_time_ms: 1.338\n",
      "    num_steps_sampled: 7360000\n",
      "    num_steps_trained: 7360000\n",
      "    sample_time_ms: 15725.395\n",
      "    update_time_ms: 4.231\n",
      "  iterations_since_restore: 736\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13021.255549669266\n",
      "  time_this_iter_s: 17.18789052963257\n",
      "  time_total_s: 13021.255549669266\n",
      "  timestamp: 1550629465\n",
      "  timesteps_since_restore: 7360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7360000\n",
      "  training_iteration: 736\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13021 s, 736 iter, 7360000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-24-43\n",
      "  done: false\n",
      "  episode_len_mean: 133.75\n",
      "  episode_reward_max: 227.08471750737263\n",
      "  episode_reward_mean: 168.28533419236285\n",
      "  episode_reward_min: -41.76287286311832\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 56147\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2204052209854126\n",
      "      kl: 0.023778842762112617\n",
      "      policy_loss: -0.001502768020145595\n",
      "      total_loss: 104.62979888916016\n",
      "      vf_explained_var: 0.972036600112915\n",
      "      vf_loss: 104.63129425048828\n",
      "    grad_time_ms: 1568.189\n",
      "    load_time_ms: 1.339\n",
      "    num_steps_sampled: 7370000\n",
      "    num_steps_trained: 7370000\n",
      "    sample_time_ms: 15705.786\n",
      "    update_time_ms: 4.443\n",
      "  iterations_since_restore: 737\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13038.569854736328\n",
      "  time_this_iter_s: 17.314305067062378\n",
      "  time_total_s: 13038.569854736328\n",
      "  timestamp: 1550629483\n",
      "  timesteps_since_restore: 7370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7370000\n",
      "  training_iteration: 737\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13038 s, 737 iter, 7370000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-25-00\n",
      "  done: false\n",
      "  episode_len_mean: 135.78\n",
      "  episode_reward_max: 223.99755303133836\n",
      "  episode_reward_mean: 178.19228195090443\n",
      "  episode_reward_min: -43.76161122200366\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 56220\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3604519367218018\n",
      "      kl: 0.022081099450588226\n",
      "      policy_loss: -0.0004501069488469511\n",
      "      total_loss: 85.07228088378906\n",
      "      vf_explained_var: 0.9755879640579224\n",
      "      vf_loss: 85.07273864746094\n",
      "    grad_time_ms: 1568.545\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 7380000\n",
      "    num_steps_trained: 7380000\n",
      "    sample_time_ms: 15706.485\n",
      "    update_time_ms: 4.307\n",
      "  iterations_since_restore: 738\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13055.589469909668\n",
      "  time_this_iter_s: 17.019615173339844\n",
      "  time_total_s: 13055.589469909668\n",
      "  timestamp: 1550629500\n",
      "  timesteps_since_restore: 7380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7380000\n",
      "  training_iteration: 738\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13055 s, 738 iter, 7380000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-25-17\n",
      "  done: false\n",
      "  episode_len_mean: 134.37\n",
      "  episode_reward_max: 222.16576491735208\n",
      "  episode_reward_mean: 169.81819383276888\n",
      "  episode_reward_min: -43.76161122200366\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 56295\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3831899166107178\n",
      "      kl: 0.017153123393654823\n",
      "      policy_loss: -0.004247171338647604\n",
      "      total_loss: 95.25105285644531\n",
      "      vf_explained_var: 0.9729850888252258\n",
      "      vf_loss: 95.25529479980469\n",
      "    grad_time_ms: 1548.91\n",
      "    load_time_ms: 1.421\n",
      "    num_steps_sampled: 7390000\n",
      "    num_steps_trained: 7390000\n",
      "    sample_time_ms: 15667.735\n",
      "    update_time_ms: 4.322\n",
      "  iterations_since_restore: 739\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13072.51516532898\n",
      "  time_this_iter_s: 16.925695419311523\n",
      "  time_total_s: 13072.51516532898\n",
      "  timestamp: 1550629517\n",
      "  timesteps_since_restore: 7390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7390000\n",
      "  training_iteration: 739\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13072 s, 739 iter, 7390000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-25-34\n",
      "  done: false\n",
      "  episode_len_mean: 135.56\n",
      "  episode_reward_max: 221.17433559341285\n",
      "  episode_reward_mean: 173.79795693680543\n",
      "  episode_reward_min: -41.039815220981836\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 56368\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2842789888381958\n",
      "      kl: 0.01480625569820404\n",
      "      policy_loss: -0.0016150149749591947\n",
      "      total_loss: 68.2288818359375\n",
      "      vf_explained_var: 0.9798739552497864\n",
      "      vf_loss: 68.23048400878906\n",
      "    grad_time_ms: 1548.673\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 7400000\n",
      "    num_steps_trained: 7400000\n",
      "    sample_time_ms: 15676.726\n",
      "    update_time_ms: 4.369\n",
      "  iterations_since_restore: 740\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13090.041019916534\n",
      "  time_this_iter_s: 17.52585458755493\n",
      "  time_total_s: 13090.041019916534\n",
      "  timestamp: 1550629534\n",
      "  timesteps_since_restore: 7400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7400000\n",
      "  training_iteration: 740\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13090 s, 740 iter, 7400000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-25-52\n",
      "  done: false\n",
      "  episode_len_mean: 133.09\n",
      "  episode_reward_max: 218.50739388750617\n",
      "  episode_reward_mean: 168.16450989798753\n",
      "  episode_reward_min: -42.49804867756099\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 56444\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2821733951568604\n",
      "      kl: 0.018903832882642746\n",
      "      policy_loss: -0.0013596054632216692\n",
      "      total_loss: 91.80843353271484\n",
      "      vf_explained_var: 0.9771071076393127\n",
      "      vf_loss: 91.8097915649414\n",
      "    grad_time_ms: 1547.989\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 7410000\n",
      "    num_steps_trained: 7410000\n",
      "    sample_time_ms: 15699.747\n",
      "    update_time_ms: 4.344\n",
      "  iterations_since_restore: 741\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13107.509843826294\n",
      "  time_this_iter_s: 17.46882390975952\n",
      "  time_total_s: 13107.509843826294\n",
      "  timestamp: 1550629552\n",
      "  timesteps_since_restore: 7410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7410000\n",
      "  training_iteration: 741\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13107 s, 741 iter, 7410000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-26-09\n",
      "  done: false\n",
      "  episode_len_mean: 135.46\n",
      "  episode_reward_max: 220.6598640699494\n",
      "  episode_reward_mean: 171.58456479517335\n",
      "  episode_reward_min: -38.035213217286795\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 56517\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5158149003982544\n",
      "      kl: 0.02226262167096138\n",
      "      policy_loss: -0.0037367381155490875\n",
      "      total_loss: 118.43603515625\n",
      "      vf_explained_var: 0.9654873609542847\n",
      "      vf_loss: 118.43978118896484\n",
      "    grad_time_ms: 1545.859\n",
      "    load_time_ms: 1.452\n",
      "    num_steps_sampled: 7420000\n",
      "    num_steps_trained: 7420000\n",
      "    sample_time_ms: 15677.2\n",
      "    update_time_ms: 4.553\n",
      "  iterations_since_restore: 742\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13124.759204149246\n",
      "  time_this_iter_s: 17.24936032295227\n",
      "  time_total_s: 13124.759204149246\n",
      "  timestamp: 1550629569\n",
      "  timesteps_since_restore: 7420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7420000\n",
      "  training_iteration: 742\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13124 s, 742 iter, 7420000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-26-26\n",
      "  done: false\n",
      "  episode_len_mean: 134.86\n",
      "  episode_reward_max: 224.8786178958595\n",
      "  episode_reward_mean: 173.79781975894278\n",
      "  episode_reward_min: -37.98206943155515\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 56592\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4640038013458252\n",
      "      kl: 0.0338120311498642\n",
      "      policy_loss: 0.0023859040811657906\n",
      "      total_loss: 57.94157409667969\n",
      "      vf_explained_var: 0.9812234044075012\n",
      "      vf_loss: 57.939178466796875\n",
      "    grad_time_ms: 1546.281\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 7430000\n",
      "    num_steps_trained: 7430000\n",
      "    sample_time_ms: 15707.709\n",
      "    update_time_ms: 4.414\n",
      "  iterations_since_restore: 743\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13142.119024515152\n",
      "  time_this_iter_s: 17.35982036590576\n",
      "  time_total_s: 13142.119024515152\n",
      "  timestamp: 1550629586\n",
      "  timesteps_since_restore: 7430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7430000\n",
      "  training_iteration: 743\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13142 s, 743 iter, 7430000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-26-43\n",
      "  done: false\n",
      "  episode_len_mean: 136.76\n",
      "  episode_reward_max: 218.49208761390182\n",
      "  episode_reward_mean: 178.60143056376745\n",
      "  episode_reward_min: 83.35101017319036\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 56664\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5331170558929443\n",
      "      kl: 0.019856072962284088\n",
      "      policy_loss: -0.002605366287752986\n",
      "      total_loss: 62.99236297607422\n",
      "      vf_explained_var: 0.9813957214355469\n",
      "      vf_loss: 62.994972229003906\n",
      "    grad_time_ms: 1545.741\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 7440000\n",
      "    num_steps_trained: 7440000\n",
      "    sample_time_ms: 15672.465\n",
      "    update_time_ms: 4.52\n",
      "  iterations_since_restore: 744\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13159.088394641876\n",
      "  time_this_iter_s: 16.969370126724243\n",
      "  time_total_s: 13159.088394641876\n",
      "  timestamp: 1550629603\n",
      "  timesteps_since_restore: 7440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7440000\n",
      "  training_iteration: 744\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13159 s, 744 iter, 7440000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-27-01\n",
      "  done: false\n",
      "  episode_len_mean: 136.79\n",
      "  episode_reward_max: 218.49208761390182\n",
      "  episode_reward_mean: 175.4688698095208\n",
      "  episode_reward_min: -40.45325046727931\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 56738\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.503449559211731\n",
      "      kl: 0.015486114658415318\n",
      "      policy_loss: -0.0011493401834741235\n",
      "      total_loss: 78.48553466796875\n",
      "      vf_explained_var: 0.9766311645507812\n",
      "      vf_loss: 78.48667907714844\n",
      "    grad_time_ms: 1549.103\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 7450000\n",
      "    num_steps_trained: 7450000\n",
      "    sample_time_ms: 15686.491\n",
      "    update_time_ms: 4.584\n",
      "  iterations_since_restore: 745\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13176.621376514435\n",
      "  time_this_iter_s: 17.532981872558594\n",
      "  time_total_s: 13176.621376514435\n",
      "  timestamp: 1550629621\n",
      "  timesteps_since_restore: 7450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7450000\n",
      "  training_iteration: 745\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13176 s, 745 iter, 7450000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-27-18\n",
      "  done: false\n",
      "  episode_len_mean: 134.19\n",
      "  episode_reward_max: 217.00596936187233\n",
      "  episode_reward_mean: 173.1253105166947\n",
      "  episode_reward_min: -41.7507642241988\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 56812\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.447058916091919\n",
      "      kl: 0.020325874909758568\n",
      "      policy_loss: 0.003854915965348482\n",
      "      total_loss: 84.92154693603516\n",
      "      vf_explained_var: 0.9731449484825134\n",
      "      vf_loss: 84.9177017211914\n",
      "    grad_time_ms: 1550.512\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 7460000\n",
      "    num_steps_trained: 7460000\n",
      "    sample_time_ms: 15696.109\n",
      "    update_time_ms: 4.592\n",
      "  iterations_since_restore: 746\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13193.917129278183\n",
      "  time_this_iter_s: 17.29575276374817\n",
      "  time_total_s: 13193.917129278183\n",
      "  timestamp: 1550629638\n",
      "  timesteps_since_restore: 7460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7460000\n",
      "  training_iteration: 746\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13193 s, 746 iter, 7460000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-27-36\n",
      "  done: false\n",
      "  episode_len_mean: 134.54\n",
      "  episode_reward_max: 220.9410347500633\n",
      "  episode_reward_mean: 176.90128849687508\n",
      "  episode_reward_min: 71.73173638322555\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 56886\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2802131175994873\n",
      "      kl: 0.013850383460521698\n",
      "      policy_loss: -0.0019342002924531698\n",
      "      total_loss: 57.24324417114258\n",
      "      vf_explained_var: 0.983209490776062\n",
      "      vf_loss: 57.24517822265625\n",
      "    grad_time_ms: 1551.372\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 7470000\n",
      "    num_steps_trained: 7470000\n",
      "    sample_time_ms: 15676.187\n",
      "    update_time_ms: 4.386\n",
      "  iterations_since_restore: 747\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13211.038928985596\n",
      "  time_this_iter_s: 17.12179970741272\n",
      "  time_total_s: 13211.038928985596\n",
      "  timestamp: 1550629656\n",
      "  timesteps_since_restore: 7470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7470000\n",
      "  training_iteration: 747\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13211 s, 747 iter, 7470000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-27-52\n",
      "  done: false\n",
      "  episode_len_mean: 134.79\n",
      "  episode_reward_max: 224.50416330738676\n",
      "  episode_reward_mean: 181.6387209532376\n",
      "  episode_reward_min: -42.759722891199104\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 56960\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2962427139282227\n",
      "      kl: 0.02142510935664177\n",
      "      policy_loss: -0.003726010210812092\n",
      "      total_loss: 39.63374710083008\n",
      "      vf_explained_var: 0.9874357581138611\n",
      "      vf_loss: 39.63747024536133\n",
      "    grad_time_ms: 1551.364\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 7480000\n",
      "    num_steps_trained: 7480000\n",
      "    sample_time_ms: 15631.327\n",
      "    update_time_ms: 4.506\n",
      "  iterations_since_restore: 748\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13227.607792377472\n",
      "  time_this_iter_s: 16.56886339187622\n",
      "  time_total_s: 13227.607792377472\n",
      "  timestamp: 1550629672\n",
      "  timesteps_since_restore: 7480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7480000\n",
      "  training_iteration: 748\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13227 s, 748 iter, 7480000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-28-09\n",
      "  done: false\n",
      "  episode_len_mean: 133.79\n",
      "  episode_reward_max: 224.34071640493258\n",
      "  episode_reward_mean: 173.42761410676266\n",
      "  episode_reward_min: -42.66728193003055\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 57036\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3852319717407227\n",
      "      kl: 0.014798319898545742\n",
      "      policy_loss: -0.0022706598974764347\n",
      "      total_loss: 59.84275436401367\n",
      "      vf_explained_var: 0.9822385907173157\n",
      "      vf_loss: 59.845027923583984\n",
      "    grad_time_ms: 1553.229\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 7490000\n",
      "    num_steps_trained: 7490000\n",
      "    sample_time_ms: 15649.408\n",
      "    update_time_ms: 4.568\n",
      "  iterations_since_restore: 749\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13244.734526634216\n",
      "  time_this_iter_s: 17.126734256744385\n",
      "  time_total_s: 13244.734526634216\n",
      "  timestamp: 1550629689\n",
      "  timesteps_since_restore: 7490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7490000\n",
      "  training_iteration: 749\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13244 s, 749 iter, 7490000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-28-27\n",
      "  done: false\n",
      "  episode_len_mean: 134.7\n",
      "  episode_reward_max: 222.86857804914217\n",
      "  episode_reward_mean: 170.9091318445709\n",
      "  episode_reward_min: -42.66728193003055\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 57109\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3837958574295044\n",
      "      kl: 0.02746903896331787\n",
      "      policy_loss: -0.00302623538300395\n",
      "      total_loss: 164.231689453125\n",
      "      vf_explained_var: 0.9520403742790222\n",
      "      vf_loss: 164.2346954345703\n",
      "    grad_time_ms: 1554.351\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 7500000\n",
      "    num_steps_trained: 7500000\n",
      "    sample_time_ms: 15664.481\n",
      "    update_time_ms: 4.61\n",
      "  iterations_since_restore: 750\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13262.42755484581\n",
      "  time_this_iter_s: 17.693028211593628\n",
      "  time_total_s: 13262.42755484581\n",
      "  timestamp: 1550629707\n",
      "  timesteps_since_restore: 7500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7500000\n",
      "  training_iteration: 750\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13262 s, 750 iter, 7500000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-28-44\n",
      "  done: false\n",
      "  episode_len_mean: 136.58\n",
      "  episode_reward_max: 228.41116506381354\n",
      "  episode_reward_mean: 174.49966419204588\n",
      "  episode_reward_min: -47.42742297186121\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 57182\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5304306745529175\n",
      "      kl: 0.028566619381308556\n",
      "      policy_loss: -0.000578983745072037\n",
      "      total_loss: 93.76888275146484\n",
      "      vf_explained_var: 0.9742578268051147\n",
      "      vf_loss: 93.76944732666016\n",
      "    grad_time_ms: 1553.763\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 7510000\n",
      "    num_steps_trained: 7510000\n",
      "    sample_time_ms: 15618.232\n",
      "    update_time_ms: 4.602\n",
      "  iterations_since_restore: 751\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13279.42691397667\n",
      "  time_this_iter_s: 16.999359130859375\n",
      "  time_total_s: 13279.42691397667\n",
      "  timestamp: 1550629724\n",
      "  timesteps_since_restore: 7510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7510000\n",
      "  training_iteration: 751\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13279 s, 751 iter, 7510000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-29-01\n",
      "  done: false\n",
      "  episode_len_mean: 135.82\n",
      "  episode_reward_max: 222.63933945764416\n",
      "  episode_reward_mean: 174.79974417404858\n",
      "  episode_reward_min: -37.78065513000631\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 57256\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2546518415355553e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.427093744277954\n",
      "      kl: 0.009368093684315681\n",
      "      policy_loss: -0.0008124594460241497\n",
      "      total_loss: 56.09883499145508\n",
      "      vf_explained_var: 0.9832146763801575\n",
      "      vf_loss: 56.099639892578125\n",
      "    grad_time_ms: 1552.705\n",
      "    load_time_ms: 1.452\n",
      "    num_steps_sampled: 7520000\n",
      "    num_steps_trained: 7520000\n",
      "    sample_time_ms: 15622.368\n",
      "    update_time_ms: 4.443\n",
      "  iterations_since_restore: 752\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13296.699892282486\n",
      "  time_this_iter_s: 17.27297830581665\n",
      "  time_total_s: 13296.699892282486\n",
      "  timestamp: 1550629741\n",
      "  timesteps_since_restore: 7520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7520000\n",
      "  training_iteration: 752\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13296 s, 752 iter, 7520000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-29-19\n",
      "  done: false\n",
      "  episode_len_mean: 137.95\n",
      "  episode_reward_max: 218.4074115062336\n",
      "  episode_reward_mean: 175.7652656718154\n",
      "  episode_reward_min: -42.70771836504193\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 57328\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.273259207677776e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5469845533370972\n",
      "      kl: 0.012645063921809196\n",
      "      policy_loss: -0.0009551848052069545\n",
      "      total_loss: 60.85326385498047\n",
      "      vf_explained_var: 0.9821574687957764\n",
      "      vf_loss: 60.85422897338867\n",
      "    grad_time_ms: 1552.753\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 7530000\n",
      "    num_steps_trained: 7530000\n",
      "    sample_time_ms: 15647.487\n",
      "    update_time_ms: 4.394\n",
      "  iterations_since_restore: 753\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13314.312086820602\n",
      "  time_this_iter_s: 17.612194538116455\n",
      "  time_total_s: 13314.312086820602\n",
      "  timestamp: 1550629759\n",
      "  timesteps_since_restore: 7530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7530000\n",
      "  training_iteration: 753\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13314 s, 753 iter, 7530000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-29-37\n",
      "  done: false\n",
      "  episode_len_mean: 136.19\n",
      "  episode_reward_max: 225.14124552879747\n",
      "  episode_reward_mean: 167.69059213369053\n",
      "  episode_reward_min: -44.78989700412395\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 57403\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.273259207677776e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3905091285705566\n",
      "      kl: 0.031138859689235687\n",
      "      policy_loss: 0.0004146555729676038\n",
      "      total_loss: 93.9228515625\n",
      "      vf_explained_var: 0.9740609526634216\n",
      "      vf_loss: 93.92243194580078\n",
      "    grad_time_ms: 1551.237\n",
      "    load_time_ms: 1.434\n",
      "    num_steps_sampled: 7540000\n",
      "    num_steps_trained: 7540000\n",
      "    sample_time_ms: 15709.941\n",
      "    update_time_ms: 4.4\n",
      "  iterations_since_restore: 754\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13331.89180970192\n",
      "  time_this_iter_s: 17.57972288131714\n",
      "  time_total_s: 13331.89180970192\n",
      "  timestamp: 1550629777\n",
      "  timesteps_since_restore: 7540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7540000\n",
      "  training_iteration: 754\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13331 s, 754 iter, 7540000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-29-54\n",
      "  done: false\n",
      "  episode_len_mean: 132.88\n",
      "  episode_reward_max: 219.6965696283496\n",
      "  episode_reward_mean: 164.47205424824386\n",
      "  episode_reward_min: -44.78989700412395\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 57478\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.273259207677776e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.332570195198059\n",
      "      kl: 0.06704223901033401\n",
      "      policy_loss: 0.011591179296374321\n",
      "      total_loss: 97.21377563476562\n",
      "      vf_explained_var: 0.9738823175430298\n",
      "      vf_loss: 97.20218658447266\n",
      "    grad_time_ms: 1565.647\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 7550000\n",
      "    num_steps_trained: 7550000\n",
      "    sample_time_ms: 15711.213\n",
      "    update_time_ms: 4.463\n",
      "  iterations_since_restore: 755\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13349.580545425415\n",
      "  time_this_iter_s: 17.688735723495483\n",
      "  time_total_s: 13349.580545425415\n",
      "  timestamp: 1550629794\n",
      "  timesteps_since_restore: 7550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7550000\n",
      "  training_iteration: 755\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13349 s, 755 iter, 7550000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-30-12\n",
      "  done: false\n",
      "  episode_len_mean: 134.69\n",
      "  episode_reward_max: 217.88031211930638\n",
      "  episode_reward_mean: 165.8149717110434\n",
      "  episode_reward_min: -45.26901293376293\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 57552\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5779225826263428\n",
      "      kl: 0.023908738046884537\n",
      "      policy_loss: -0.0008254829444922507\n",
      "      total_loss: 105.58861541748047\n",
      "      vf_explained_var: 0.9698915481567383\n",
      "      vf_loss: 105.58943939208984\n",
      "    grad_time_ms: 1564.452\n",
      "    load_time_ms: 1.417\n",
      "    num_steps_sampled: 7560000\n",
      "    num_steps_trained: 7560000\n",
      "    sample_time_ms: 15758.556\n",
      "    update_time_ms: 4.48\n",
      "  iterations_since_restore: 756\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13367.340212345123\n",
      "  time_this_iter_s: 17.759666919708252\n",
      "  time_total_s: 13367.340212345123\n",
      "  timestamp: 1550629812\n",
      "  timesteps_since_restore: 7560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7560000\n",
      "  training_iteration: 756\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13367 s, 756 iter, 7560000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-30-30\n",
      "  done: false\n",
      "  episode_len_mean: 135.79\n",
      "  episode_reward_max: 222.67414580635946\n",
      "  episode_reward_mean: 174.35118550859087\n",
      "  episode_reward_min: -41.3853900344065\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 57625\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3552663326263428\n",
      "      kl: 0.016440819948911667\n",
      "      policy_loss: -0.003522801911458373\n",
      "      total_loss: 59.51251220703125\n",
      "      vf_explained_var: 0.981997549533844\n",
      "      vf_loss: 59.51605224609375\n",
      "    grad_time_ms: 1564.404\n",
      "    load_time_ms: 1.35\n",
      "    num_steps_sampled: 7570000\n",
      "    num_steps_trained: 7570000\n",
      "    sample_time_ms: 15795.692\n",
      "    update_time_ms: 4.518\n",
      "  iterations_since_restore: 757\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13384.832574129105\n",
      "  time_this_iter_s: 17.492361783981323\n",
      "  time_total_s: 13384.832574129105\n",
      "  timestamp: 1550629830\n",
      "  timesteps_since_restore: 7570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7570000\n",
      "  training_iteration: 757\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13384 s, 757 iter, 7570000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-30-47\n",
      "  done: false\n",
      "  episode_len_mean: 130.98\n",
      "  episode_reward_max: 222.67414580635946\n",
      "  episode_reward_mean: 170.7953966207454\n",
      "  episode_reward_min: -42.19979649841193\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 57701\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.296330451965332\n",
      "      kl: 0.026533059775829315\n",
      "      policy_loss: -0.0039571854285895824\n",
      "      total_loss: 69.21444702148438\n",
      "      vf_explained_var: 0.9793501496315002\n",
      "      vf_loss: 69.2184066772461\n",
      "    grad_time_ms: 1563.408\n",
      "    load_time_ms: 1.343\n",
      "    num_steps_sampled: 7580000\n",
      "    num_steps_trained: 7580000\n",
      "    sample_time_ms: 15878.604\n",
      "    update_time_ms: 4.489\n",
      "  iterations_since_restore: 758\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13402.221164226532\n",
      "  time_this_iter_s: 17.388590097427368\n",
      "  time_total_s: 13402.221164226532\n",
      "  timestamp: 1550629847\n",
      "  timesteps_since_restore: 7580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7580000\n",
      "  training_iteration: 758\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13402 s, 758 iter, 7580000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-31-05\n",
      "  done: false\n",
      "  episode_len_mean: 135.97\n",
      "  episode_reward_max: 223.0729854573487\n",
      "  episode_reward_mean: 168.9789854683503\n",
      "  episode_reward_min: -43.36675482558658\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 57774\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4761029481887817\n",
      "      kl: 0.017923932522535324\n",
      "      policy_loss: -0.0016687535680830479\n",
      "      total_loss: 83.66509246826172\n",
      "      vf_explained_var: 0.9761642813682556\n",
      "      vf_loss: 83.66675567626953\n",
      "    grad_time_ms: 1559.642\n",
      "    load_time_ms: 1.316\n",
      "    num_steps_sampled: 7590000\n",
      "    num_steps_trained: 7590000\n",
      "    sample_time_ms: 15909.792\n",
      "    update_time_ms: 4.461\n",
      "  iterations_since_restore: 759\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13419.619946241379\n",
      "  time_this_iter_s: 17.3987820148468\n",
      "  time_total_s: 13419.619946241379\n",
      "  timestamp: 1550629865\n",
      "  timesteps_since_restore: 7590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7590000\n",
      "  training_iteration: 759\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13419 s, 759 iter, 7590000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-31-22\n",
      "  done: false\n",
      "  episode_len_mean: 135.29\n",
      "  episode_reward_max: 223.0729854573487\n",
      "  episode_reward_mean: 162.36114710498362\n",
      "  episode_reward_min: -43.36675482558658\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 57849\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.324678897857666\n",
      "      kl: 0.027999214828014374\n",
      "      policy_loss: -0.00027083634631708264\n",
      "      total_loss: 107.5843505859375\n",
      "      vf_explained_var: 0.9702287316322327\n",
      "      vf_loss: 107.58462524414062\n",
      "    grad_time_ms: 1559.387\n",
      "    load_time_ms: 1.279\n",
      "    num_steps_sampled: 7600000\n",
      "    num_steps_trained: 7600000\n",
      "    sample_time_ms: 15912.803\n",
      "    update_time_ms: 4.389\n",
      "  iterations_since_restore: 760\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13437.334290027618\n",
      "  time_this_iter_s: 17.714343786239624\n",
      "  time_total_s: 13437.334290027618\n",
      "  timestamp: 1550629882\n",
      "  timesteps_since_restore: 7600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7600000\n",
      "  training_iteration: 760\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13437 s, 760 iter, 7600000 ts, 162 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-31-40\n",
      "  done: false\n",
      "  episode_len_mean: 137.01\n",
      "  episode_reward_max: 220.29832780907057\n",
      "  episode_reward_mean: 176.59419400925262\n",
      "  episode_reward_min: -43.208191920551315\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 57921\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4105619192123413\n",
      "      kl: 0.016853494569659233\n",
      "      policy_loss: -0.0006019155844114721\n",
      "      total_loss: 43.03966522216797\n",
      "      vf_explained_var: 0.9869421124458313\n",
      "      vf_loss: 43.04026794433594\n",
      "    grad_time_ms: 1565.054\n",
      "    load_time_ms: 1.344\n",
      "    num_steps_sampled: 7610000\n",
      "    num_steps_trained: 7610000\n",
      "    sample_time_ms: 15994.02\n",
      "    update_time_ms: 4.454\n",
      "  iterations_since_restore: 761\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13455.206215381622\n",
      "  time_this_iter_s: 17.871925354003906\n",
      "  time_total_s: 13455.206215381622\n",
      "  timestamp: 1550629900\n",
      "  timesteps_since_restore: 7610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7610000\n",
      "  training_iteration: 761\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13455 s, 761 iter, 7610000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-31-58\n",
      "  done: false\n",
      "  episode_len_mean: 136.15\n",
      "  episode_reward_max: 220.01033434356657\n",
      "  episode_reward_mean: 176.9321818872039\n",
      "  episode_reward_min: -45.53617994107377\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 57994\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4764207601547241\n",
      "      kl: 0.014780974946916103\n",
      "      policy_loss: -0.0010826743673533201\n",
      "      total_loss: 53.94254684448242\n",
      "      vf_explained_var: 0.9836737513542175\n",
      "      vf_loss: 53.94363021850586\n",
      "    grad_time_ms: 1564.514\n",
      "    load_time_ms: 1.38\n",
      "    num_steps_sampled: 7620000\n",
      "    num_steps_trained: 7620000\n",
      "    sample_time_ms: 16039.881\n",
      "    update_time_ms: 4.574\n",
      "  iterations_since_restore: 762\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13472.932946681976\n",
      "  time_this_iter_s: 17.726731300354004\n",
      "  time_total_s: 13472.932946681976\n",
      "  timestamp: 1550629918\n",
      "  timesteps_since_restore: 7620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7620000\n",
      "  training_iteration: 762\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13472 s, 762 iter, 7620000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-32-15\n",
      "  done: false\n",
      "  episode_len_mean: 132.18\n",
      "  episode_reward_max: 213.96401421858533\n",
      "  episode_reward_mean: 177.51368180593107\n",
      "  episode_reward_min: -35.92106113634486\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 58071\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1921032667160034\n",
      "      kl: 0.02276156097650528\n",
      "      policy_loss: 0.0001990728051168844\n",
      "      total_loss: 45.33014678955078\n",
      "      vf_explained_var: 0.9853787422180176\n",
      "      vf_loss: 45.32994842529297\n",
      "    grad_time_ms: 1561.463\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 7630000\n",
      "    num_steps_trained: 7630000\n",
      "    sample_time_ms: 15996.242\n",
      "    update_time_ms: 4.64\n",
      "  iterations_since_restore: 763\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13490.077602624893\n",
      "  time_this_iter_s: 17.14465594291687\n",
      "  time_total_s: 13490.077602624893\n",
      "  timestamp: 1550629935\n",
      "  timesteps_since_restore: 7630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7630000\n",
      "  training_iteration: 763\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13490 s, 763 iter, 7630000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-32-33\n",
      "  done: false\n",
      "  episode_len_mean: 135.26\n",
      "  episode_reward_max: 225.0988730257838\n",
      "  episode_reward_mean: 180.57643215734387\n",
      "  episode_reward_min: 85.08875514780843\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 58144\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4268906116485596\n",
      "      kl: 0.02178231067955494\n",
      "      policy_loss: -0.0005749651463702321\n",
      "      total_loss: 36.35190200805664\n",
      "      vf_explained_var: 0.9883729815483093\n",
      "      vf_loss: 36.352481842041016\n",
      "    grad_time_ms: 1562.739\n",
      "    load_time_ms: 1.402\n",
      "    num_steps_sampled: 7640000\n",
      "    num_steps_trained: 7640000\n",
      "    sample_time_ms: 16012.76\n",
      "    update_time_ms: 4.58\n",
      "  iterations_since_restore: 764\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13507.832435846329\n",
      "  time_this_iter_s: 17.754833221435547\n",
      "  time_total_s: 13507.832435846329\n",
      "  timestamp: 1550629953\n",
      "  timesteps_since_restore: 7640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7640000\n",
      "  training_iteration: 764\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13507 s, 764 iter, 7640000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-32-50\n",
      "  done: false\n",
      "  episode_len_mean: 136.58\n",
      "  episode_reward_max: 225.0988730257838\n",
      "  episode_reward_mean: 181.31704132091426\n",
      "  episode_reward_min: -37.25983856201615\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 58218\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2052266597747803\n",
      "      kl: 0.01618609018623829\n",
      "      policy_loss: -0.0020967968739569187\n",
      "      total_loss: 49.06684875488281\n",
      "      vf_explained_var: 0.9858524799346924\n",
      "      vf_loss: 49.06894302368164\n",
      "    grad_time_ms: 1544.574\n",
      "    load_time_ms: 1.405\n",
      "    num_steps_sampled: 7650000\n",
      "    num_steps_trained: 7650000\n",
      "    sample_time_ms: 15974.017\n",
      "    update_time_ms: 4.471\n",
      "  iterations_since_restore: 765\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13524.952725887299\n",
      "  time_this_iter_s: 17.12029004096985\n",
      "  time_total_s: 13524.952725887299\n",
      "  timestamp: 1550629970\n",
      "  timesteps_since_restore: 7650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7650000\n",
      "  training_iteration: 765\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13524 s, 765 iter, 7650000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-33-08\n",
      "  done: false\n",
      "  episode_len_mean: 135.54\n",
      "  episode_reward_max: 221.46763043153564\n",
      "  episode_reward_mean: 177.58243891433952\n",
      "  episode_reward_min: -42.461030350610756\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 58291\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3478031158447266\n",
      "      kl: 0.018014371395111084\n",
      "      policy_loss: 0.00027468448388390243\n",
      "      total_loss: 46.58303451538086\n",
      "      vf_explained_var: 0.9859724044799805\n",
      "      vf_loss: 46.58277130126953\n",
      "    grad_time_ms: 1545.05\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 7660000\n",
      "    num_steps_trained: 7660000\n",
      "    sample_time_ms: 15950.185\n",
      "    update_time_ms: 4.431\n",
      "  iterations_since_restore: 766\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13542.476320028305\n",
      "  time_this_iter_s: 17.52359414100647\n",
      "  time_total_s: 13542.476320028305\n",
      "  timestamp: 1550629988\n",
      "  timesteps_since_restore: 7660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7660000\n",
      "  training_iteration: 766\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13542 s, 766 iter, 7660000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 134.67\n",
      "  episode_reward_max: 224.85170029332428\n",
      "  episode_reward_mean: 164.36299630992045\n",
      "  episode_reward_min: -44.69208849088684\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 58366\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3491687774658203\n",
      "      kl: 0.02308966964483261\n",
      "      policy_loss: -0.00046016121632419527\n",
      "      total_loss: 183.21182250976562\n",
      "      vf_explained_var: 0.9537831544876099\n",
      "      vf_loss: 183.21226501464844\n",
      "    grad_time_ms: 1545.137\n",
      "    load_time_ms: 1.407\n",
      "    num_steps_sampled: 7670000\n",
      "    num_steps_trained: 7670000\n",
      "    sample_time_ms: 15936.522\n",
      "    update_time_ms: 4.379\n",
      "  iterations_since_restore: 767\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13559.834406137466\n",
      "  time_this_iter_s: 17.358086109161377\n",
      "  time_total_s: 13559.834406137466\n",
      "  timestamp: 1550630005\n",
      "  timesteps_since_restore: 7670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7670000\n",
      "  training_iteration: 767\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13559 s, 767 iter, 7670000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-33-43\n",
      "  done: false\n",
      "  episode_len_mean: 135.26\n",
      "  episode_reward_max: 224.77944158172542\n",
      "  episode_reward_mean: 175.9902986995561\n",
      "  episode_reward_min: -39.710749377708616\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 58440\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1390407085418701\n",
      "      kl: 0.024559972807765007\n",
      "      policy_loss: 0.0006657138583250344\n",
      "      total_loss: 53.10110092163086\n",
      "      vf_explained_var: 0.984223484992981\n",
      "      vf_loss: 53.10043716430664\n",
      "    grad_time_ms: 1545.379\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 7680000\n",
      "    num_steps_trained: 7680000\n",
      "    sample_time_ms: 15951.539\n",
      "    update_time_ms: 4.401\n",
      "  iterations_since_restore: 768\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13577.377612113953\n",
      "  time_this_iter_s: 17.543205976486206\n",
      "  time_total_s: 13577.377612113953\n",
      "  timestamp: 1550630023\n",
      "  timesteps_since_restore: 7680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7680000\n",
      "  training_iteration: 768\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13577 s, 768 iter, 7680000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-34-00\n",
      "  done: false\n",
      "  episode_len_mean: 134.53\n",
      "  episode_reward_max: 226.0397834557265\n",
      "  episode_reward_mean: 175.14448724759626\n",
      "  episode_reward_min: -40.420905008174415\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 58513\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3315421342849731\n",
      "      kl: 0.03642703592777252\n",
      "      policy_loss: 0.0019041901687160134\n",
      "      total_loss: 59.142127990722656\n",
      "      vf_explained_var: 0.9827257990837097\n",
      "      vf_loss: 59.14021682739258\n",
      "    grad_time_ms: 1545.873\n",
      "    load_time_ms: 1.422\n",
      "    num_steps_sampled: 7690000\n",
      "    num_steps_trained: 7690000\n",
      "    sample_time_ms: 15945.763\n",
      "    update_time_ms: 4.396\n",
      "  iterations_since_restore: 769\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13594.725342988968\n",
      "  time_this_iter_s: 17.34773087501526\n",
      "  time_total_s: 13594.725342988968\n",
      "  timestamp: 1550630040\n",
      "  timesteps_since_restore: 7690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7690000\n",
      "  training_iteration: 769\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13594 s, 769 iter, 7690000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-34-18\n",
      "  done: false\n",
      "  episode_len_mean: 137.1\n",
      "  episode_reward_max: 226.0397834557265\n",
      "  episode_reward_mean: 181.16305141365956\n",
      "  episode_reward_min: 65.96280954306073\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 58586\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2397596836090088\n",
      "      kl: 0.025037266314029694\n",
      "      policy_loss: -0.0008137698168866336\n",
      "      total_loss: 40.723331451416016\n",
      "      vf_explained_var: 0.9876771569252014\n",
      "      vf_loss: 40.72414779663086\n",
      "    grad_time_ms: 1543.495\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 7700000\n",
      "    num_steps_trained: 7700000\n",
      "    sample_time_ms: 15938.93\n",
      "    update_time_ms: 4.451\n",
      "  iterations_since_restore: 770\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13612.35149359703\n",
      "  time_this_iter_s: 17.626150608062744\n",
      "  time_total_s: 13612.35149359703\n",
      "  timestamp: 1550630058\n",
      "  timesteps_since_restore: 7700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7700000\n",
      "  training_iteration: 770\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13612 s, 770 iter, 7700000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-34-35\n",
      "  done: false\n",
      "  episode_len_mean: 136.61\n",
      "  episode_reward_max: 221.69726645385867\n",
      "  episode_reward_mean: 178.03246910125497\n",
      "  episode_reward_min: 70.138785772837\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 58660\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3613314628601074\n",
      "      kl: 0.018912626430392265\n",
      "      policy_loss: 0.002124284626916051\n",
      "      total_loss: 44.2022590637207\n",
      "      vf_explained_var: 0.985400378704071\n",
      "      vf_loss: 44.20013427734375\n",
      "    grad_time_ms: 1537.568\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 7710000\n",
      "    num_steps_trained: 7710000\n",
      "    sample_time_ms: 15904.858\n",
      "    update_time_ms: 4.502\n",
      "  iterations_since_restore: 771\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13629.821801662445\n",
      "  time_this_iter_s: 17.47030806541443\n",
      "  time_total_s: 13629.821801662445\n",
      "  timestamp: 1550630075\n",
      "  timesteps_since_restore: 7710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7710000\n",
      "  training_iteration: 771\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13629 s, 771 iter, 7710000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-34-53\n",
      "  done: false\n",
      "  episode_len_mean: 133.49\n",
      "  episode_reward_max: 224.75968236114704\n",
      "  episode_reward_mean: 171.84682254812049\n",
      "  episode_reward_min: -43.94730985363817\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 58735\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3211158514022827\n",
      "      kl: 0.029820650815963745\n",
      "      policy_loss: -0.002993922447785735\n",
      "      total_loss: 67.42218017578125\n",
      "      vf_explained_var: 0.9797126650810242\n",
      "      vf_loss: 67.42517852783203\n",
      "    grad_time_ms: 1544.434\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 7720000\n",
      "    num_steps_trained: 7720000\n",
      "    sample_time_ms: 15883.602\n",
      "    update_time_ms: 4.383\n",
      "  iterations_since_restore: 772\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13647.407764434814\n",
      "  time_this_iter_s: 17.585962772369385\n",
      "  time_total_s: 13647.407764434814\n",
      "  timestamp: 1550630093\n",
      "  timesteps_since_restore: 7720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7720000\n",
      "  training_iteration: 772\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13647 s, 772 iter, 7720000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-35-11\n",
      "  done: false\n",
      "  episode_len_mean: 133.34\n",
      "  episode_reward_max: 221.38710765422582\n",
      "  episode_reward_mean: 179.82216148803636\n",
      "  episode_reward_min: -43.94730985363817\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 58809\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0841064453125\n",
      "      kl: 0.021265139803290367\n",
      "      policy_loss: 0.0004950317088514566\n",
      "      total_loss: 27.116661071777344\n",
      "      vf_explained_var: 0.9915947318077087\n",
      "      vf_loss: 27.11616325378418\n",
      "    grad_time_ms: 1546.868\n",
      "    load_time_ms: 1.374\n",
      "    num_steps_sampled: 7730000\n",
      "    num_steps_trained: 7730000\n",
      "    sample_time_ms: 15954.038\n",
      "    update_time_ms: 4.295\n",
      "  iterations_since_restore: 773\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13665.281334638596\n",
      "  time_this_iter_s: 17.873570203781128\n",
      "  time_total_s: 13665.281334638596\n",
      "  timestamp: 1550630111\n",
      "  timesteps_since_restore: 7730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7730000\n",
      "  training_iteration: 773\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13665 s, 773 iter, 7730000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-35-28\n",
      "  done: false\n",
      "  episode_len_mean: 131.66\n",
      "  episode_reward_max: 218.0856396272815\n",
      "  episode_reward_mean: 167.69178359489325\n",
      "  episode_reward_min: -42.18812701729415\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 58885\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1317092180252075\n",
      "      kl: 0.023288916796445847\n",
      "      policy_loss: -0.0022919613402336836\n",
      "      total_loss: 145.83348083496094\n",
      "      vf_explained_var: 0.9616600275039673\n",
      "      vf_loss: 145.8357696533203\n",
      "    grad_time_ms: 1546.83\n",
      "    load_time_ms: 1.412\n",
      "    num_steps_sampled: 7740000\n",
      "    num_steps_trained: 7740000\n",
      "    sample_time_ms: 15935.08\n",
      "    update_time_ms: 4.222\n",
      "  iterations_since_restore: 774\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13682.849436044693\n",
      "  time_this_iter_s: 17.568101406097412\n",
      "  time_total_s: 13682.849436044693\n",
      "  timestamp: 1550630128\n",
      "  timesteps_since_restore: 7740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7740000\n",
      "  training_iteration: 774\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13682 s, 774 iter, 7740000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-35-46\n",
      "  done: false\n",
      "  episode_len_mean: 133.07\n",
      "  episode_reward_max: 217.77410467492763\n",
      "  episode_reward_mean: 166.33017907113066\n",
      "  episode_reward_min: -43.15644695191173\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 58960\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2546465396881104\n",
      "      kl: 0.02105768956243992\n",
      "      policy_loss: 0.00047238924889825284\n",
      "      total_loss: 50.77982711791992\n",
      "      vf_explained_var: 0.9853195548057556\n",
      "      vf_loss: 50.77935791015625\n",
      "    grad_time_ms: 1546.425\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 7750000\n",
      "    num_steps_trained: 7750000\n",
      "    sample_time_ms: 15960.855\n",
      "    update_time_ms: 4.241\n",
      "  iterations_since_restore: 775\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13700.223700523376\n",
      "  time_this_iter_s: 17.37426447868347\n",
      "  time_total_s: 13700.223700523376\n",
      "  timestamp: 1550630146\n",
      "  timesteps_since_restore: 7750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7750000\n",
      "  training_iteration: 775\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13700 s, 775 iter, 7750000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-36-03\n",
      "  done: false\n",
      "  episode_len_mean: 135.2\n",
      "  episode_reward_max: 229.04866473085366\n",
      "  episode_reward_mean: 171.22857387950955\n",
      "  episode_reward_min: -43.15644695191173\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 59033\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3885747194290161\n",
      "      kl: 0.030665220692753792\n",
      "      policy_loss: -0.0038134949281811714\n",
      "      total_loss: 114.05005645751953\n",
      "      vf_explained_var: 0.9674310088157654\n",
      "      vf_loss: 114.05384826660156\n",
      "    grad_time_ms: 1547.416\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 7760000\n",
      "    num_steps_trained: 7760000\n",
      "    sample_time_ms: 15901.579\n",
      "    update_time_ms: 4.442\n",
      "  iterations_since_restore: 776\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13717.168642997742\n",
      "  time_this_iter_s: 16.944942474365234\n",
      "  time_total_s: 13717.168642997742\n",
      "  timestamp: 1550630163\n",
      "  timesteps_since_restore: 7760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7760000\n",
      "  training_iteration: 776\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13717 s, 776 iter, 7760000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-36-20\n",
      "  done: false\n",
      "  episode_len_mean: 137.16\n",
      "  episode_reward_max: 225.47310129523584\n",
      "  episode_reward_mean: 176.7582218456708\n",
      "  episode_reward_min: 60.72653860731586\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 59107\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3071893453598022\n",
      "      kl: 0.01932678185403347\n",
      "      policy_loss: -0.0006025689654052258\n",
      "      total_loss: 51.83164978027344\n",
      "      vf_explained_var: 0.9840952754020691\n",
      "      vf_loss: 51.83224868774414\n",
      "    grad_time_ms: 1547.176\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 7770000\n",
      "    num_steps_trained: 7770000\n",
      "    sample_time_ms: 15855.662\n",
      "    update_time_ms: 4.471\n",
      "  iterations_since_restore: 777\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13734.06452345848\n",
      "  time_this_iter_s: 16.895880460739136\n",
      "  time_total_s: 13734.06452345848\n",
      "  timestamp: 1550630180\n",
      "  timesteps_since_restore: 7770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7770000\n",
      "  training_iteration: 777\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13734 s, 777 iter, 7770000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-36-37\n",
      "  done: false\n",
      "  episode_len_mean: 134.37\n",
      "  episode_reward_max: 223.27003111911594\n",
      "  episode_reward_mean: 173.62050696080522\n",
      "  episode_reward_min: -40.03929145958755\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 59182\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3435256481170654\n",
      "      kl: 0.027298884466290474\n",
      "      policy_loss: 0.0012148115783929825\n",
      "      total_loss: 71.4478759765625\n",
      "      vf_explained_var: 0.9797013998031616\n",
      "      vf_loss: 71.44666290283203\n",
      "    grad_time_ms: 1547.523\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 7780000\n",
      "    num_steps_trained: 7780000\n",
      "    sample_time_ms: 15796.402\n",
      "    update_time_ms: 4.417\n",
      "  iterations_since_restore: 778\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13751.017024040222\n",
      "  time_this_iter_s: 16.952500581741333\n",
      "  time_total_s: 13751.017024040222\n",
      "  timestamp: 1550630197\n",
      "  timesteps_since_restore: 7780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7780000\n",
      "  training_iteration: 778\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13751 s, 778 iter, 7780000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-36-54\n",
      "  done: false\n",
      "  episode_len_mean: 133.51\n",
      "  episode_reward_max: 226.31119058133646\n",
      "  episode_reward_mean: 164.51338165880176\n",
      "  episode_reward_min: -40.03929145958755\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 59256\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 9.409888306645685e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3203763961791992\n",
      "      kl: 0.04255521669983864\n",
      "      policy_loss: 0.002204274060204625\n",
      "      total_loss: 137.00050354003906\n",
      "      vf_explained_var: 0.9649839997291565\n",
      "      vf_loss: 136.99830627441406\n",
      "    grad_time_ms: 1567.976\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 7790000\n",
      "    num_steps_trained: 7790000\n",
      "    sample_time_ms: 15752.565\n",
      "    update_time_ms: 4.466\n",
      "  iterations_since_restore: 779\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13768.132386446\n",
      "  time_this_iter_s: 17.115362405776978\n",
      "  time_total_s: 13768.132386446\n",
      "  timestamp: 1550630214\n",
      "  timesteps_since_restore: 7790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7790000\n",
      "  training_iteration: 779\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13768 s, 779 iter, 7790000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-37-11\n",
      "  done: false\n",
      "  episode_len_mean: 135.6\n",
      "  episode_reward_max: 223.08873675866894\n",
      "  episode_reward_mean: 176.83753048414758\n",
      "  episode_reward_min: -37.65725529459443\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 59330\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2634952068328857\n",
      "      kl: 0.01827855221927166\n",
      "      policy_loss: -0.0014543993165716529\n",
      "      total_loss: 21.895097732543945\n",
      "      vf_explained_var: 0.9929530024528503\n",
      "      vf_loss: 21.896554946899414\n",
      "    grad_time_ms: 1571.665\n",
      "    load_time_ms: 1.434\n",
      "    num_steps_sampled: 7800000\n",
      "    num_steps_trained: 7800000\n",
      "    sample_time_ms: 15690.709\n",
      "    update_time_ms: 4.447\n",
      "  iterations_since_restore: 780\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13785.174144029617\n",
      "  time_this_iter_s: 17.041757583618164\n",
      "  time_total_s: 13785.174144029617\n",
      "  timestamp: 1550630231\n",
      "  timesteps_since_restore: 7800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7800000\n",
      "  training_iteration: 780\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13785 s, 780 iter, 7800000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-37-28\n",
      "  done: false\n",
      "  episode_len_mean: 135.74\n",
      "  episode_reward_max: 227.20357848246493\n",
      "  episode_reward_mean: 183.4132354830952\n",
      "  episode_reward_min: 67.6097016327895\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 59404\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.174699306488037\n",
      "      kl: 0.0173142421990633\n",
      "      policy_loss: -0.001214082119986415\n",
      "      total_loss: 54.52970886230469\n",
      "      vf_explained_var: 0.983913004398346\n",
      "      vf_loss: 54.53091812133789\n",
      "    grad_time_ms: 1572.443\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 7810000\n",
      "    num_steps_trained: 7810000\n",
      "    sample_time_ms: 15658.329\n",
      "    update_time_ms: 4.335\n",
      "  iterations_since_restore: 781\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13802.326491832733\n",
      "  time_this_iter_s: 17.152347803115845\n",
      "  time_total_s: 13802.326491832733\n",
      "  timestamp: 1550630248\n",
      "  timesteps_since_restore: 7810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7810000\n",
      "  training_iteration: 781\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13802 s, 781 iter, 7810000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-37-46\n",
      "  done: false\n",
      "  episode_len_mean: 134.17\n",
      "  episode_reward_max: 227.20357848246493\n",
      "  episode_reward_mean: 179.43017033502008\n",
      "  episode_reward_min: -40.656739409680995\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 59479\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0271695852279663\n",
      "      kl: 0.02071976847946644\n",
      "      policy_loss: 0.002200612099841237\n",
      "      total_loss: 30.940834045410156\n",
      "      vf_explained_var: 0.9906402230262756\n",
      "      vf_loss: 30.938636779785156\n",
      "    grad_time_ms: 1565.645\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 7820000\n",
      "    num_steps_trained: 7820000\n",
      "    sample_time_ms: 15649.955\n",
      "    update_time_ms: 4.576\n",
      "  iterations_since_restore: 782\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13819.760150671005\n",
      "  time_this_iter_s: 17.433658838272095\n",
      "  time_total_s: 13819.760150671005\n",
      "  timestamp: 1550630266\n",
      "  timesteps_since_restore: 7820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7820000\n",
      "  training_iteration: 782\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13819 s, 782 iter, 7820000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-38-03\n",
      "  done: false\n",
      "  episode_len_mean: 134.6\n",
      "  episode_reward_max: 220.1784056646397\n",
      "  episode_reward_mean: 184.08240647035942\n",
      "  episode_reward_min: 79.85006997394973\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 59553\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0677770376205444\n",
      "      kl: 0.014869325794279575\n",
      "      policy_loss: -0.0014159606071189046\n",
      "      total_loss: 34.22713088989258\n",
      "      vf_explained_var: 0.9901301264762878\n",
      "      vf_loss: 34.228546142578125\n",
      "    grad_time_ms: 1564.52\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 7830000\n",
      "    num_steps_trained: 7830000\n",
      "    sample_time_ms: 15586.22\n",
      "    update_time_ms: 4.69\n",
      "  iterations_since_restore: 783\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13836.985419511795\n",
      "  time_this_iter_s: 17.225268840789795\n",
      "  time_total_s: 13836.985419511795\n",
      "  timestamp: 1550630283\n",
      "  timesteps_since_restore: 7830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7830000\n",
      "  training_iteration: 783\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13836 s, 783 iter, 7830000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-38-20\n",
      "  done: false\n",
      "  episode_len_mean: 134.48\n",
      "  episode_reward_max: 223.38272810553994\n",
      "  episode_reward_mean: 178.6656356464633\n",
      "  episode_reward_min: -41.553331892679225\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 59627\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2516052722930908\n",
      "      kl: 0.02957409806549549\n",
      "      policy_loss: -0.002374352654442191\n",
      "      total_loss: 93.60038757324219\n",
      "      vf_explained_var: 0.9749685525894165\n",
      "      vf_loss: 93.602783203125\n",
      "    grad_time_ms: 1563.326\n",
      "    load_time_ms: 1.414\n",
      "    num_steps_sampled: 7840000\n",
      "    num_steps_trained: 7840000\n",
      "    sample_time_ms: 15519.512\n",
      "    update_time_ms: 4.669\n",
      "  iterations_since_restore: 784\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13853.871714115143\n",
      "  time_this_iter_s: 16.88629460334778\n",
      "  time_total_s: 13853.871714115143\n",
      "  timestamp: 1550630300\n",
      "  timesteps_since_restore: 7840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7840000\n",
      "  training_iteration: 784\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13853 s, 784 iter, 7840000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-38-37\n",
      "  done: false\n",
      "  episode_len_mean: 135.22\n",
      "  episode_reward_max: 226.29874567709652\n",
      "  episode_reward_mean: 172.35878432084098\n",
      "  episode_reward_min: -41.553331892679225\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 59701\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4282283782958984\n",
      "      kl: 0.02538042888045311\n",
      "      policy_loss: -0.0004313181561883539\n",
      "      total_loss: 58.168212890625\n",
      "      vf_explained_var: 0.9833430051803589\n",
      "      vf_loss: 58.16863250732422\n",
      "    grad_time_ms: 1564.986\n",
      "    load_time_ms: 1.399\n",
      "    num_steps_sampled: 7850000\n",
      "    num_steps_trained: 7850000\n",
      "    sample_time_ms: 15541.644\n",
      "    update_time_ms: 4.727\n",
      "  iterations_since_restore: 785\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13871.482148647308\n",
      "  time_this_iter_s: 17.610434532165527\n",
      "  time_total_s: 13871.482148647308\n",
      "  timestamp: 1550630317\n",
      "  timesteps_since_restore: 7850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7850000\n",
      "  training_iteration: 785\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13871 s, 785 iter, 7850000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-38-54\n",
      "  done: false\n",
      "  episode_len_mean: 136.15\n",
      "  episode_reward_max: 220.14324804483948\n",
      "  episode_reward_mean: 176.61823465208644\n",
      "  episode_reward_min: 105.05819796324522\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 59774\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.467977523803711\n",
      "      kl: 0.01949925534427166\n",
      "      policy_loss: -8.382421219721437e-05\n",
      "      total_loss: 17.992111206054688\n",
      "      vf_explained_var: 0.9939910769462585\n",
      "      vf_loss: 17.992197036743164\n",
      "    grad_time_ms: 1581.605\n",
      "    load_time_ms: 1.297\n",
      "    num_steps_sampled: 7860000\n",
      "    num_steps_trained: 7860000\n",
      "    sample_time_ms: 15504.439\n",
      "    update_time_ms: 4.634\n",
      "  iterations_since_restore: 786\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13888.221764087677\n",
      "  time_this_iter_s: 16.739615440368652\n",
      "  time_total_s: 13888.221764087677\n",
      "  timestamp: 1550630334\n",
      "  timesteps_since_restore: 7860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7860000\n",
      "  training_iteration: 786\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13888 s, 786 iter, 7860000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-39-12\n",
      "  done: false\n",
      "  episode_len_mean: 135.61\n",
      "  episode_reward_max: 222.8134456498014\n",
      "  episode_reward_mean: 178.14781794753296\n",
      "  episode_reward_min: -37.3699179844986\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 59849\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1916563510894775\n",
      "      kl: 0.01599026657640934\n",
      "      policy_loss: -0.0017011991003528237\n",
      "      total_loss: 55.51104736328125\n",
      "      vf_explained_var: 0.9862565398216248\n",
      "      vf_loss: 55.51274490356445\n",
      "    grad_time_ms: 1580.219\n",
      "    load_time_ms: 1.296\n",
      "    num_steps_sampled: 7870000\n",
      "    num_steps_trained: 7870000\n",
      "    sample_time_ms: 15556.881\n",
      "    update_time_ms: 4.646\n",
      "  iterations_since_restore: 787\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13905.627083778381\n",
      "  time_this_iter_s: 17.405319690704346\n",
      "  time_total_s: 13905.627083778381\n",
      "  timestamp: 1550630352\n",
      "  timesteps_since_restore: 7870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7870000\n",
      "  training_iteration: 787\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13905 s, 787 iter, 7870000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-39-29\n",
      "  done: false\n",
      "  episode_len_mean: 136.23\n",
      "  episode_reward_max: 232.50084144194233\n",
      "  episode_reward_mean: 177.95552444747392\n",
      "  episode_reward_min: -37.3699179844986\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 59922\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2516015768051147\n",
      "      kl: 0.025416046380996704\n",
      "      policy_loss: -0.0008559079724363983\n",
      "      total_loss: 49.32456588745117\n",
      "      vf_explained_var: 0.9849460124969482\n",
      "      vf_loss: 49.32543182373047\n",
      "    grad_time_ms: 1580.298\n",
      "    load_time_ms: 1.256\n",
      "    num_steps_sampled: 7880000\n",
      "    num_steps_trained: 7880000\n",
      "    sample_time_ms: 15607.206\n",
      "    update_time_ms: 4.739\n",
      "  iterations_since_restore: 788\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13923.081797599792\n",
      "  time_this_iter_s: 17.454713821411133\n",
      "  time_total_s: 13923.081797599792\n",
      "  timestamp: 1550630369\n",
      "  timesteps_since_restore: 7880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7880000\n",
      "  training_iteration: 788\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13923 s, 788 iter, 7880000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-39-47\n",
      "  done: false\n",
      "  episode_len_mean: 135.16\n",
      "  episode_reward_max: 232.50084144194233\n",
      "  episode_reward_mean: 181.57123072834375\n",
      "  episode_reward_min: -39.7372074577183\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 59996\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.411483145022657e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0436686277389526\n",
      "      kl: 28.72965431213379\n",
      "      policy_loss: 0.004061989486217499\n",
      "      total_loss: 90.66654205322266\n",
      "      vf_explained_var: 0.976312518119812\n",
      "      vf_loss: 90.66248321533203\n",
      "    grad_time_ms: 1559.525\n",
      "    load_time_ms: 1.29\n",
      "    num_steps_sampled: 7890000\n",
      "    num_steps_trained: 7890000\n",
      "    sample_time_ms: 15713.704\n",
      "    update_time_ms: 4.651\n",
      "  iterations_since_restore: 789\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13941.052171230316\n",
      "  time_this_iter_s: 17.97037363052368\n",
      "  time_total_s: 13941.052171230316\n",
      "  timestamp: 1550630387\n",
      "  timesteps_since_restore: 7890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7890000\n",
      "  training_iteration: 789\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13941 s, 789 iter, 7890000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-40-05\n",
      "  done: false\n",
      "  episode_len_mean: 137.0\n",
      "  episode_reward_max: 229.828817748345\n",
      "  episode_reward_mean: 184.22280866264384\n",
      "  episode_reward_min: 96.43392654722268\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 60069\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.1172245155855936e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.155906319618225\n",
      "      kl: 0.02617700584232807\n",
      "      policy_loss: -0.00043362221913412213\n",
      "      total_loss: 23.652097702026367\n",
      "      vf_explained_var: 0.9922814965248108\n",
      "      vf_loss: 23.652530670166016\n",
      "    grad_time_ms: 1558.424\n",
      "    load_time_ms: 1.296\n",
      "    num_steps_sampled: 7900000\n",
      "    num_steps_trained: 7900000\n",
      "    sample_time_ms: 15756.738\n",
      "    update_time_ms: 4.639\n",
      "  iterations_since_restore: 790\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13958.513720989227\n",
      "  time_this_iter_s: 17.461549758911133\n",
      "  time_total_s: 13958.513720989227\n",
      "  timestamp: 1550630405\n",
      "  timesteps_since_restore: 7900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7900000\n",
      "  training_iteration: 790\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13958 s, 790 iter, 7900000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-40-22\n",
      "  done: false\n",
      "  episode_len_mean: 136.97\n",
      "  episode_reward_max: 229.828817748345\n",
      "  episode_reward_mean: 180.64461133470056\n",
      "  episode_reward_min: -37.49809441649085\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 60142\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.1172245155855936e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2407546043395996\n",
      "      kl: 0.041670236736536026\n",
      "      policy_loss: 0.003578170668333769\n",
      "      total_loss: 42.27387237548828\n",
      "      vf_explained_var: 0.9863771200180054\n",
      "      vf_loss: 42.27029037475586\n",
      "    grad_time_ms: 1557.638\n",
      "    load_time_ms: 1.332\n",
      "    num_steps_sampled: 7910000\n",
      "    num_steps_trained: 7910000\n",
      "    sample_time_ms: 15781.113\n",
      "    update_time_ms: 4.619\n",
      "  iterations_since_restore: 791\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13975.901497364044\n",
      "  time_this_iter_s: 17.387776374816895\n",
      "  time_total_s: 13975.901497364044\n",
      "  timestamp: 1550630422\n",
      "  timesteps_since_restore: 7910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7910000\n",
      "  training_iteration: 791\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13975 s, 791 iter, 7910000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-40-40\n",
      "  done: false\n",
      "  episode_len_mean: 136.62\n",
      "  episode_reward_max: 221.92702587332462\n",
      "  episode_reward_mean: 180.43737890300443\n",
      "  episode_reward_min: -36.49423220871701\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 60216\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2015485763549805\n",
      "      kl: 0.018780739977955818\n",
      "      policy_loss: 0.0005348020931705832\n",
      "      total_loss: 41.90778350830078\n",
      "      vf_explained_var: 0.9868900775909424\n",
      "      vf_loss: 41.907249450683594\n",
      "    grad_time_ms: 1556.673\n",
      "    load_time_ms: 1.276\n",
      "    num_steps_sampled: 7920000\n",
      "    num_steps_trained: 7920000\n",
      "    sample_time_ms: 15794.024\n",
      "    update_time_ms: 4.376\n",
      "  iterations_since_restore: 792\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 13993.452554941177\n",
      "  time_this_iter_s: 17.55105757713318\n",
      "  time_total_s: 13993.452554941177\n",
      "  timestamp: 1550630440\n",
      "  timesteps_since_restore: 7920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7920000\n",
      "  training_iteration: 792\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 13993 s, 792 iter, 7920000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-40-57\n",
      "  done: false\n",
      "  episode_len_mean: 137.27\n",
      "  episode_reward_max: 218.48882522981728\n",
      "  episode_reward_mean: 179.20326804909539\n",
      "  episode_reward_min: 84.37608632976469\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 60288\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2099108695983887\n",
      "      kl: 0.02130206488072872\n",
      "      policy_loss: -0.003885305020958185\n",
      "      total_loss: 60.20250701904297\n",
      "      vf_explained_var: 0.9821363687515259\n",
      "      vf_loss: 60.20637893676758\n",
      "    grad_time_ms: 1559.386\n",
      "    load_time_ms: 1.272\n",
      "    num_steps_sampled: 7930000\n",
      "    num_steps_trained: 7930000\n",
      "    sample_time_ms: 15808.459\n",
      "    update_time_ms: 4.402\n",
      "  iterations_since_restore: 793\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14010.848606586456\n",
      "  time_this_iter_s: 17.39605164527893\n",
      "  time_total_s: 14010.848606586456\n",
      "  timestamp: 1550630457\n",
      "  timesteps_since_restore: 7930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7930000\n",
      "  training_iteration: 793\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14010 s, 793 iter, 7930000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-41-14\n",
      "  done: false\n",
      "  episode_len_mean: 135.31\n",
      "  episode_reward_max: 222.4470776382575\n",
      "  episode_reward_mean: 179.34231391769987\n",
      "  episode_reward_min: 87.61523697953112\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 60362\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1233159303665161\n",
      "      kl: 0.019785774871706963\n",
      "      policy_loss: 0.0007811409304849803\n",
      "      total_loss: 23.7327880859375\n",
      "      vf_explained_var: 0.9924563765525818\n",
      "      vf_loss: 23.73200798034668\n",
      "    grad_time_ms: 1558.791\n",
      "    load_time_ms: 1.278\n",
      "    num_steps_sampled: 7940000\n",
      "    num_steps_trained: 7940000\n",
      "    sample_time_ms: 15824.285\n",
      "    update_time_ms: 4.402\n",
      "  iterations_since_restore: 794\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14027.886395692825\n",
      "  time_this_iter_s: 17.03778910636902\n",
      "  time_total_s: 14027.886395692825\n",
      "  timestamp: 1550630474\n",
      "  timesteps_since_restore: 7940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7940000\n",
      "  training_iteration: 794\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14027 s, 794 iter, 7940000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-41-32\n",
      "  done: false\n",
      "  episode_len_mean: 136.95\n",
      "  episode_reward_max: 226.3697313467908\n",
      "  episode_reward_mean: 178.3486122176002\n",
      "  episode_reward_min: -40.2343913957034\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 60434\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2655683755874634\n",
      "      kl: 0.03125496208667755\n",
      "      policy_loss: -0.0083550326526165\n",
      "      total_loss: 75.8178482055664\n",
      "      vf_explained_var: 0.9796847701072693\n",
      "      vf_loss: 75.82618713378906\n",
      "    grad_time_ms: 1558.886\n",
      "    load_time_ms: 1.332\n",
      "    num_steps_sampled: 7950000\n",
      "    num_steps_trained: 7950000\n",
      "    sample_time_ms: 15807.173\n",
      "    update_time_ms: 4.321\n",
      "  iterations_since_restore: 795\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14045.327916622162\n",
      "  time_this_iter_s: 17.441520929336548\n",
      "  time_total_s: 14045.327916622162\n",
      "  timestamp: 1550630492\n",
      "  timesteps_since_restore: 7950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7950000\n",
      "  training_iteration: 795\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14045 s, 795 iter, 7950000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-41-49\n",
      "  done: false\n",
      "  episode_len_mean: 136.09\n",
      "  episode_reward_max: 216.80324147634272\n",
      "  episode_reward_mean: 172.93892880374756\n",
      "  episode_reward_min: -40.2343913957034\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 60508\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0852972269058228\n",
      "      kl: 0.018063507974147797\n",
      "      policy_loss: -0.000758920272346586\n",
      "      total_loss: 30.78348159790039\n",
      "      vf_explained_var: 0.9904515147209167\n",
      "      vf_loss: 30.784242630004883\n",
      "    grad_time_ms: 1541.793\n",
      "    load_time_ms: 1.37\n",
      "    num_steps_sampled: 7960000\n",
      "    num_steps_trained: 7960000\n",
      "    sample_time_ms: 15891.129\n",
      "    update_time_ms: 4.27\n",
      "  iterations_since_restore: 796\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14062.732696771622\n",
      "  time_this_iter_s: 17.40478014945984\n",
      "  time_total_s: 14062.732696771622\n",
      "  timestamp: 1550630509\n",
      "  timesteps_since_restore: 7960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7960000\n",
      "  training_iteration: 796\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14062 s, 796 iter, 7960000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-42-06\n",
      "  done: false\n",
      "  episode_len_mean: 133.02\n",
      "  episode_reward_max: 229.9068121887227\n",
      "  episode_reward_mean: 175.9004493845606\n",
      "  episode_reward_min: -33.26443714995193\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 60583\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9549486041069031\n",
      "      kl: 0.033361468464136124\n",
      "      policy_loss: -3.902537719113752e-05\n",
      "      total_loss: 68.2547607421875\n",
      "      vf_explained_var: 0.9784915447235107\n",
      "      vf_loss: 68.25479888916016\n",
      "    grad_time_ms: 1541.185\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 7970000\n",
      "    num_steps_trained: 7970000\n",
      "    sample_time_ms: 15896.095\n",
      "    update_time_ms: 4.225\n",
      "  iterations_since_restore: 797\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14080.183024168015\n",
      "  time_this_iter_s: 17.450327396392822\n",
      "  time_total_s: 14080.183024168015\n",
      "  timestamp: 1550630526\n",
      "  timesteps_since_restore: 7970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7970000\n",
      "  training_iteration: 797\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14080 s, 797 iter, 7970000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-42-24\n",
      "  done: false\n",
      "  episode_len_mean: 135.92\n",
      "  episode_reward_max: 229.9068121887227\n",
      "  episode_reward_mean: 182.7288604178289\n",
      "  episode_reward_min: -39.92055730053253\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 60657\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9675014019012451\n",
      "      kl: 0.01943211443722248\n",
      "      policy_loss: -0.0019362358143553138\n",
      "      total_loss: 41.516014099121094\n",
      "      vf_explained_var: 0.9878688454627991\n",
      "      vf_loss: 41.51795196533203\n",
      "    grad_time_ms: 1563.669\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 7980000\n",
      "    num_steps_trained: 7980000\n",
      "    sample_time_ms: 15853.836\n",
      "    update_time_ms: 4.089\n",
      "  iterations_since_restore: 798\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14097.43952178955\n",
      "  time_this_iter_s: 17.256497621536255\n",
      "  time_total_s: 14097.43952178955\n",
      "  timestamp: 1550630544\n",
      "  timesteps_since_restore: 7980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7980000\n",
      "  training_iteration: 798\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14097 s, 798 iter, 7980000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-42-41\n",
      "  done: false\n",
      "  episode_len_mean: 135.24\n",
      "  episode_reward_max: 221.7181164225803\n",
      "  episode_reward_mean: 177.1400359293072\n",
      "  episode_reward_min: -41.97688643354003\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 60731\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1214983463287354\n",
      "      kl: 0.02901522070169449\n",
      "      policy_loss: 0.00019964107195846736\n",
      "      total_loss: 85.34322357177734\n",
      "      vf_explained_var: 0.9745891094207764\n",
      "      vf_loss: 85.34302520751953\n",
      "    grad_time_ms: 1563.22\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 7990000\n",
      "    num_steps_trained: 7990000\n",
      "    sample_time_ms: 15801.962\n",
      "    update_time_ms: 4.203\n",
      "  iterations_since_restore: 799\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14114.887375831604\n",
      "  time_this_iter_s: 17.447854042053223\n",
      "  time_total_s: 14114.887375831604\n",
      "  timestamp: 1550630561\n",
      "  timesteps_since_restore: 7990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7990000\n",
      "  training_iteration: 799\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14114 s, 799 iter, 7990000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-42-59\n",
      "  done: false\n",
      "  episode_len_mean: 136.13\n",
      "  episode_reward_max: 221.30825292022152\n",
      "  episode_reward_mean: 181.00805414429726\n",
      "  episode_reward_min: -41.97688643354003\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 60804\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0847747325897217\n",
      "      kl: 0.02027185820043087\n",
      "      policy_loss: -0.002213238039985299\n",
      "      total_loss: 23.00008201599121\n",
      "      vf_explained_var: 0.993013322353363\n",
      "      vf_loss: 23.002296447753906\n",
      "    grad_time_ms: 1561.636\n",
      "    load_time_ms: 1.445\n",
      "    num_steps_sampled: 8000000\n",
      "    num_steps_trained: 8000000\n",
      "    sample_time_ms: 15781.681\n",
      "    update_time_ms: 4.136\n",
      "  iterations_since_restore: 800\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14132.128947734833\n",
      "  time_this_iter_s: 17.24157190322876\n",
      "  time_total_s: 14132.128947734833\n",
      "  timestamp: 1550630579\n",
      "  timesteps_since_restore: 8000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8000000\n",
      "  training_iteration: 800\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14132 s, 800 iter, 8000000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-43-16\n",
      "  done: false\n",
      "  episode_len_mean: 135.86\n",
      "  episode_reward_max: 223.52232198498345\n",
      "  episode_reward_mean: 180.65106264894308\n",
      "  episode_reward_min: 98.14254563903015\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 60878\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0713164806365967\n",
      "      kl: 0.027508458122611046\n",
      "      policy_loss: -0.00032288781949318945\n",
      "      total_loss: 40.98114013671875\n",
      "      vf_explained_var: 0.9878084063529968\n",
      "      vf_loss: 40.9814567565918\n",
      "    grad_time_ms: 1562.678\n",
      "    load_time_ms: 1.407\n",
      "    num_steps_sampled: 8010000\n",
      "    num_steps_trained: 8010000\n",
      "    sample_time_ms: 15812.697\n",
      "    update_time_ms: 4.197\n",
      "  iterations_since_restore: 801\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14149.83806848526\n",
      "  time_this_iter_s: 17.709120750427246\n",
      "  time_total_s: 14149.83806848526\n",
      "  timestamp: 1550630596\n",
      "  timesteps_since_restore: 8010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8010000\n",
      "  training_iteration: 801\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14149 s, 801 iter, 8010000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-43-34\n",
      "  done: false\n",
      "  episode_len_mean: 133.64\n",
      "  episode_reward_max: 214.76987439899318\n",
      "  episode_reward_mean: 172.84897775689336\n",
      "  episode_reward_min: -38.012544965685\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 60953\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0676136016845703\n",
      "      kl: 0.024443868547677994\n",
      "      policy_loss: -0.0027720823418349028\n",
      "      total_loss: 99.01679229736328\n",
      "      vf_explained_var: 0.9687773585319519\n",
      "      vf_loss: 99.01956176757812\n",
      "    grad_time_ms: 1565.027\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 8020000\n",
      "    num_steps_trained: 8020000\n",
      "    sample_time_ms: 15870.833\n",
      "    update_time_ms: 4.239\n",
      "  iterations_since_restore: 802\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14167.99510550499\n",
      "  time_this_iter_s: 18.157037019729614\n",
      "  time_total_s: 14167.99510550499\n",
      "  timestamp: 1550630614\n",
      "  timesteps_since_restore: 8020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8020000\n",
      "  training_iteration: 802\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14167 s, 802 iter, 8020000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-43-52\n",
      "  done: false\n",
      "  episode_len_mean: 138.88\n",
      "  episode_reward_max: 215.8212814471951\n",
      "  episode_reward_mean: 179.2300335092945\n",
      "  episode_reward_min: 85.76711902059245\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 61024\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3329837322235107\n",
      "      kl: 0.015035359188914299\n",
      "      policy_loss: 0.0012281481176614761\n",
      "      total_loss: 22.835481643676758\n",
      "      vf_explained_var: 0.9926146268844604\n",
      "      vf_loss: 22.83425521850586\n",
      "    grad_time_ms: 1564.238\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 8030000\n",
      "    num_steps_trained: 8030000\n",
      "    sample_time_ms: 15895.664\n",
      "    update_time_ms: 4.289\n",
      "  iterations_since_restore: 803\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14185.633599996567\n",
      "  time_this_iter_s: 17.63849449157715\n",
      "  time_total_s: 14185.633599996567\n",
      "  timestamp: 1550630632\n",
      "  timesteps_since_restore: 8030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8030000\n",
      "  training_iteration: 803\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14185 s, 803 iter, 8030000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-44-10\n",
      "  done: false\n",
      "  episode_len_mean: 137.91\n",
      "  episode_reward_max: 217.68144155208884\n",
      "  episode_reward_mean: 178.2012669422663\n",
      "  episode_reward_min: 85.76711902059245\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 61096\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.32931649684906\n",
      "      kl: 0.015663892030715942\n",
      "      policy_loss: -0.0019347280031070113\n",
      "      total_loss: 30.429847717285156\n",
      "      vf_explained_var: 0.9900987148284912\n",
      "      vf_loss: 30.431777954101562\n",
      "    grad_time_ms: 1566.291\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 8040000\n",
      "    num_steps_trained: 8040000\n",
      "    sample_time_ms: 15975.061\n",
      "    update_time_ms: 4.289\n",
      "  iterations_since_restore: 804\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14203.48500418663\n",
      "  time_this_iter_s: 17.851404190063477\n",
      "  time_total_s: 14203.48500418663\n",
      "  timestamp: 1550630650\n",
      "  timesteps_since_restore: 8040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8040000\n",
      "  training_iteration: 804\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14203 s, 804 iter, 8040000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-44-28\n",
      "  done: false\n",
      "  episode_len_mean: 136.17\n",
      "  episode_reward_max: 220.3221597498892\n",
      "  episode_reward_mean: 176.547840002965\n",
      "  episode_reward_min: 80.80935817115963\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 61170\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1523553133010864\n",
      "      kl: 0.017722198739647865\n",
      "      policy_loss: -0.001510858302935958\n",
      "      total_loss: 26.760604858398438\n",
      "      vf_explained_var: 0.9913487434387207\n",
      "      vf_loss: 26.762113571166992\n",
      "    grad_time_ms: 1566.217\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 8050000\n",
      "    num_steps_trained: 8050000\n",
      "    sample_time_ms: 16000.577\n",
      "    update_time_ms: 4.471\n",
      "  iterations_since_restore: 805\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14221.18124127388\n",
      "  time_this_iter_s: 17.696237087249756\n",
      "  time_total_s: 14221.18124127388\n",
      "  timestamp: 1550630668\n",
      "  timesteps_since_restore: 8050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8050000\n",
      "  training_iteration: 805\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14221 s, 805 iter, 8050000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-44-45\n",
      "  done: false\n",
      "  episode_len_mean: 135.4\n",
      "  episode_reward_max: 225.07910687749327\n",
      "  episode_reward_mean: 177.91696679779056\n",
      "  episode_reward_min: 82.06373717001466\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 61244\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0779664516448975\n",
      "      kl: 0.02139311470091343\n",
      "      policy_loss: 0.00014866945275571197\n",
      "      total_loss: 27.618793487548828\n",
      "      vf_explained_var: 0.9913825988769531\n",
      "      vf_loss: 27.6186466217041\n",
      "    grad_time_ms: 1565.419\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 8060000\n",
      "    num_steps_trained: 8060000\n",
      "    sample_time_ms: 15940.884\n",
      "    update_time_ms: 4.465\n",
      "  iterations_since_restore: 806\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14237.982031345367\n",
      "  time_this_iter_s: 16.800790071487427\n",
      "  time_total_s: 14237.982031345367\n",
      "  timestamp: 1550630685\n",
      "  timesteps_since_restore: 8060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8060000\n",
      "  training_iteration: 806\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14237 s, 806 iter, 8060000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-45-02\n",
      "  done: false\n",
      "  episode_len_mean: 135.7\n",
      "  episode_reward_max: 224.9835041287807\n",
      "  episode_reward_mean: 177.5024084991293\n",
      "  episode_reward_min: 82.06373717001466\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 61318\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0403684377670288\n",
      "      kl: 0.021687006577849388\n",
      "      policy_loss: -0.00018035725224763155\n",
      "      total_loss: 43.88492965698242\n",
      "      vf_explained_var: 0.9866116046905518\n",
      "      vf_loss: 43.885108947753906\n",
      "    grad_time_ms: 1568.203\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 8070000\n",
      "    num_steps_trained: 8070000\n",
      "    sample_time_ms: 15879.949\n",
      "    update_time_ms: 4.526\n",
      "  iterations_since_restore: 807\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14254.851627111435\n",
      "  time_this_iter_s: 16.869595766067505\n",
      "  time_total_s: 14254.851627111435\n",
      "  timestamp: 1550630702\n",
      "  timesteps_since_restore: 8070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8070000\n",
      "  training_iteration: 807\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14254 s, 807 iter, 8070000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-45-19\n",
      "  done: false\n",
      "  episode_len_mean: 135.52\n",
      "  episode_reward_max: 226.74085132991618\n",
      "  episode_reward_mean: 182.2499955276032\n",
      "  episode_reward_min: 98.62271858559973\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 61391\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9959887862205505\n",
      "      kl: 0.017171591520309448\n",
      "      policy_loss: -0.0004818551242351532\n",
      "      total_loss: 19.985607147216797\n",
      "      vf_explained_var: 0.993685781955719\n",
      "      vf_loss: 19.986087799072266\n",
      "    grad_time_ms: 1552.36\n",
      "    load_time_ms: 1.402\n",
      "    num_steps_sampled: 8080000\n",
      "    num_steps_trained: 8080000\n",
      "    sample_time_ms: 15922.475\n",
      "    update_time_ms: 4.559\n",
      "  iterations_since_restore: 808\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14272.374274969101\n",
      "  time_this_iter_s: 17.522647857666016\n",
      "  time_total_s: 14272.374274969101\n",
      "  timestamp: 1550630719\n",
      "  timesteps_since_restore: 8080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8080000\n",
      "  training_iteration: 808\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14272 s, 808 iter, 8080000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-45-36\n",
      "  done: false\n",
      "  episode_len_mean: 135.83\n",
      "  episode_reward_max: 221.19525245355788\n",
      "  episode_reward_mean: 179.750985963193\n",
      "  episode_reward_min: 103.14567186428911\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 61465\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1994524002075195\n",
      "      kl: 0.017534907907247543\n",
      "      policy_loss: 0.00013730961654800922\n",
      "      total_loss: 20.274715423583984\n",
      "      vf_explained_var: 0.9932856559753418\n",
      "      vf_loss: 20.27457618713379\n",
      "    grad_time_ms: 1553.206\n",
      "    load_time_ms: 1.369\n",
      "    num_steps_sampled: 8090000\n",
      "    num_steps_trained: 8090000\n",
      "    sample_time_ms: 15842.012\n",
      "    update_time_ms: 4.437\n",
      "  iterations_since_restore: 809\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14289.024908304214\n",
      "  time_this_iter_s: 16.650633335113525\n",
      "  time_total_s: 14289.024908304214\n",
      "  timestamp: 1550630736\n",
      "  timesteps_since_restore: 8090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8090000\n",
      "  training_iteration: 809\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14289 s, 809 iter, 8090000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-45-53\n",
      "  done: false\n",
      "  episode_len_mean: 135.34\n",
      "  episode_reward_max: 225.36443892770473\n",
      "  episode_reward_mean: 179.95698395566805\n",
      "  episode_reward_min: 103.14567186428911\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 61538\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9827897548675537\n",
      "      kl: 0.03296513855457306\n",
      "      policy_loss: 0.0011395049514248967\n",
      "      total_loss: 20.737668991088867\n",
      "      vf_explained_var: 0.9933198094367981\n",
      "      vf_loss: 20.73653221130371\n",
      "    grad_time_ms: 1572.098\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 8100000\n",
      "    num_steps_trained: 8100000\n",
      "    sample_time_ms: 15848.666\n",
      "    update_time_ms: 4.4\n",
      "  iterations_since_restore: 810\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14306.522827863693\n",
      "  time_this_iter_s: 17.49791955947876\n",
      "  time_total_s: 14306.522827863693\n",
      "  timestamp: 1550630753\n",
      "  timesteps_since_restore: 8100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8100000\n",
      "  training_iteration: 810\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14306 s, 810 iter, 8100000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-46-10\n",
      "  done: false\n",
      "  episode_len_mean: 135.56\n",
      "  episode_reward_max: 224.19107298641518\n",
      "  episode_reward_mean: 182.95038677955145\n",
      "  episode_reward_min: 80.31008959908314\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 61613\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9972792267799377\n",
      "      kl: 0.017142118886113167\n",
      "      policy_loss: -0.0005930598126724362\n",
      "      total_loss: 27.069786071777344\n",
      "      vf_explained_var: 0.9913181662559509\n",
      "      vf_loss: 27.07038116455078\n",
      "    grad_time_ms: 1572.761\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 8110000\n",
      "    num_steps_trained: 8110000\n",
      "    sample_time_ms: 15777.392\n",
      "    update_time_ms: 4.573\n",
      "  iterations_since_restore: 811\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14323.528196811676\n",
      "  time_this_iter_s: 17.005368947982788\n",
      "  time_total_s: 14323.528196811676\n",
      "  timestamp: 1550630770\n",
      "  timesteps_since_restore: 8110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8110000\n",
      "  training_iteration: 811\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14323 s, 811 iter, 8110000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-46-27\n",
      "  done: false\n",
      "  episode_len_mean: 136.83\n",
      "  episode_reward_max: 225.7282253929809\n",
      "  episode_reward_mean: 176.2944958838358\n",
      "  episode_reward_min: 46.906413655989894\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 61685\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3257904052734375\n",
      "      kl: 0.023296555504202843\n",
      "      policy_loss: 0.001473930198699236\n",
      "      total_loss: 34.346588134765625\n",
      "      vf_explained_var: 0.9904749989509583\n",
      "      vf_loss: 34.34511947631836\n",
      "    grad_time_ms: 1572.921\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 8120000\n",
      "    num_steps_trained: 8120000\n",
      "    sample_time_ms: 15668.685\n",
      "    update_time_ms: 4.496\n",
      "  iterations_since_restore: 812\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14340.59720826149\n",
      "  time_this_iter_s: 17.069011449813843\n",
      "  time_total_s: 14340.59720826149\n",
      "  timestamp: 1550630787\n",
      "  timesteps_since_restore: 8120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8120000\n",
      "  training_iteration: 812\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14340 s, 812 iter, 8120000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-46-44\n",
      "  done: false\n",
      "  episode_len_mean: 137.71\n",
      "  episode_reward_max: 230.06095159894764\n",
      "  episode_reward_mean: 175.6393728294446\n",
      "  episode_reward_min: 73.23010519818206\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 61758\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3928009271621704\n",
      "      kl: 0.02458752505481243\n",
      "      policy_loss: 0.00010124130494659767\n",
      "      total_loss: 30.805150985717773\n",
      "      vf_explained_var: 0.9899859428405762\n",
      "      vf_loss: 30.805049896240234\n",
      "    grad_time_ms: 1573.074\n",
      "    load_time_ms: 1.347\n",
      "    num_steps_sampled: 8130000\n",
      "    num_steps_trained: 8130000\n",
      "    sample_time_ms: 15598.857\n",
      "    update_time_ms: 4.4\n",
      "  iterations_since_restore: 813\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14357.538391590118\n",
      "  time_this_iter_s: 16.94118332862854\n",
      "  time_total_s: 14357.538391590118\n",
      "  timestamp: 1550630804\n",
      "  timesteps_since_restore: 8130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8130000\n",
      "  training_iteration: 813\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14357 s, 813 iter, 8130000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-47-02\n",
      "  done: false\n",
      "  episode_len_mean: 136.93\n",
      "  episode_reward_max: 221.75723136968838\n",
      "  episode_reward_mean: 180.68714927811834\n",
      "  episode_reward_min: 96.61081669936962\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 61831\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1099789142608643\n",
      "      kl: 0.023789621889591217\n",
      "      policy_loss: 0.0010277500841766596\n",
      "      total_loss: 26.93776512145996\n",
      "      vf_explained_var: 0.9914360046386719\n",
      "      vf_loss: 26.936737060546875\n",
      "    grad_time_ms: 1573.057\n",
      "    load_time_ms: 1.313\n",
      "    num_steps_sampled: 8140000\n",
      "    num_steps_trained: 8140000\n",
      "    sample_time_ms: 15597.314\n",
      "    update_time_ms: 4.488\n",
      "  iterations_since_restore: 814\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14375.37531876564\n",
      "  time_this_iter_s: 17.83692717552185\n",
      "  time_total_s: 14375.37531876564\n",
      "  timestamp: 1550630822\n",
      "  timesteps_since_restore: 8140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8140000\n",
      "  training_iteration: 814\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14375 s, 814 iter, 8140000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 136.11\n",
      "  episode_reward_max: 225.61163121764307\n",
      "  episode_reward_mean: 182.53653996187018\n",
      "  episode_reward_min: 123.03385733663666\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 61904\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0712627172470093\n",
      "      kl: 0.028023365885019302\n",
      "      policy_loss: 0.004179635550826788\n",
      "      total_loss: 14.1318359375\n",
      "      vf_explained_var: 0.9955935478210449\n",
      "      vf_loss: 14.127655982971191\n",
      "    grad_time_ms: 1574.169\n",
      "    load_time_ms: 1.302\n",
      "    num_steps_sampled: 8150000\n",
      "    num_steps_trained: 8150000\n",
      "    sample_time_ms: 15567.567\n",
      "    update_time_ms: 4.321\n",
      "  iterations_since_restore: 815\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14392.783720254898\n",
      "  time_this_iter_s: 17.408401489257812\n",
      "  time_total_s: 14392.783720254898\n",
      "  timestamp: 1550630840\n",
      "  timesteps_since_restore: 8150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8150000\n",
      "  training_iteration: 815\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14392 s, 815 iter, 8150000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-47-37\n",
      "  done: false\n",
      "  episode_len_mean: 136.08\n",
      "  episode_reward_max: 225.61163121764307\n",
      "  episode_reward_mean: 176.57429062769594\n",
      "  episode_reward_min: 99.67385307286335\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 61978\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1962838172912598\n",
      "      kl: 0.02094743587076664\n",
      "      policy_loss: -0.0005669546080753207\n",
      "      total_loss: 31.44664192199707\n",
      "      vf_explained_var: 0.9897809028625488\n",
      "      vf_loss: 31.447208404541016\n",
      "    grad_time_ms: 1575.794\n",
      "    load_time_ms: 1.258\n",
      "    num_steps_sampled: 8160000\n",
      "    num_steps_trained: 8160000\n",
      "    sample_time_ms: 15637.123\n",
      "    update_time_ms: 4.442\n",
      "  iterations_since_restore: 816\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14410.297804355621\n",
      "  time_this_iter_s: 17.514084100723267\n",
      "  time_total_s: 14410.297804355621\n",
      "  timestamp: 1550630857\n",
      "  timesteps_since_restore: 8160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8160000\n",
      "  training_iteration: 816\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14410 s, 816 iter, 8160000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-47-55\n",
      "  done: false\n",
      "  episode_len_mean: 137.17\n",
      "  episode_reward_max: 223.34702350811497\n",
      "  episode_reward_mean: 178.5644041143495\n",
      "  episode_reward_min: 114.8662116948036\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 62051\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1193585395812988\n",
      "      kl: 0.023142490535974503\n",
      "      policy_loss: -0.00127975398208946\n",
      "      total_loss: 14.128145217895508\n",
      "      vf_explained_var: 0.9951776266098022\n",
      "      vf_loss: 14.129426002502441\n",
      "    grad_time_ms: 1580.314\n",
      "    load_time_ms: 1.248\n",
      "    num_steps_sampled: 8170000\n",
      "    num_steps_trained: 8170000\n",
      "    sample_time_ms: 15671.453\n",
      "    update_time_ms: 4.413\n",
      "  iterations_since_restore: 817\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14427.554503679276\n",
      "  time_this_iter_s: 17.256699323654175\n",
      "  time_total_s: 14427.554503679276\n",
      "  timestamp: 1550630875\n",
      "  timesteps_since_restore: 8170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8170000\n",
      "  training_iteration: 817\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14427 s, 817 iter, 8170000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-48-11\n",
      "  done: false\n",
      "  episode_len_mean: 136.51\n",
      "  episode_reward_max: 223.34702350811497\n",
      "  episode_reward_mean: 177.7220019031867\n",
      "  episode_reward_min: -40.3708386686769\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 62125\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0689116716384888\n",
      "      kl: 0.027906080707907677\n",
      "      policy_loss: -0.004060165025293827\n",
      "      total_loss: 94.86995697021484\n",
      "      vf_explained_var: 0.9736944437026978\n",
      "      vf_loss: 94.87400817871094\n",
      "    grad_time_ms: 1573.571\n",
      "    load_time_ms: 1.244\n",
      "    num_steps_sampled: 8180000\n",
      "    num_steps_trained: 8180000\n",
      "    sample_time_ms: 15610.332\n",
      "    update_time_ms: 4.435\n",
      "  iterations_since_restore: 818\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14444.399727344513\n",
      "  time_this_iter_s: 16.845223665237427\n",
      "  time_total_s: 14444.399727344513\n",
      "  timestamp: 1550630891\n",
      "  timesteps_since_restore: 8180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8180000\n",
      "  training_iteration: 818\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14444 s, 818 iter, 8180000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-48-29\n",
      "  done: false\n",
      "  episode_len_mean: 136.76\n",
      "  episode_reward_max: 222.33799385198262\n",
      "  episode_reward_mean: 179.3813596024875\n",
      "  episode_reward_min: -31.379254820028123\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 62198\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0541787147521973\n",
      "      kl: 0.020185736939311028\n",
      "      policy_loss: -0.0004775496490765363\n",
      "      total_loss: 80.28936004638672\n",
      "      vf_explained_var: 0.9761196970939636\n",
      "      vf_loss: 80.28982543945312\n",
      "    grad_time_ms: 1574.307\n",
      "    load_time_ms: 1.246\n",
      "    num_steps_sampled: 8190000\n",
      "    num_steps_trained: 8190000\n",
      "    sample_time_ms: 15680.892\n",
      "    update_time_ms: 4.387\n",
      "  iterations_since_restore: 819\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14461.76373410225\n",
      "  time_this_iter_s: 17.364006757736206\n",
      "  time_total_s: 14461.76373410225\n",
      "  timestamp: 1550630909\n",
      "  timesteps_since_restore: 8190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8190000\n",
      "  training_iteration: 819\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14461 s, 819 iter, 8190000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-48-46\n",
      "  done: false\n",
      "  episode_len_mean: 135.34\n",
      "  episode_reward_max: 227.6806024523213\n",
      "  episode_reward_mean: 179.02640183342572\n",
      "  episode_reward_min: -31.379254820028123\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 62272\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.12490713596344\n",
      "      kl: 0.02446792647242546\n",
      "      policy_loss: 0.000319645885610953\n",
      "      total_loss: 21.045122146606445\n",
      "      vf_explained_var: 0.9930775761604309\n",
      "      vf_loss: 21.044801712036133\n",
      "    grad_time_ms: 1556.183\n",
      "    load_time_ms: 1.223\n",
      "    num_steps_sampled: 8200000\n",
      "    num_steps_trained: 8200000\n",
      "    sample_time_ms: 15647.185\n",
      "    update_time_ms: 4.414\n",
      "  iterations_since_restore: 820\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14478.742255926132\n",
      "  time_this_iter_s: 16.978521823883057\n",
      "  time_total_s: 14478.742255926132\n",
      "  timestamp: 1550630926\n",
      "  timesteps_since_restore: 8200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8200000\n",
      "  training_iteration: 820\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14478 s, 820 iter, 8200000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-49-04\n",
      "  done: false\n",
      "  episode_len_mean: 134.82\n",
      "  episode_reward_max: 221.09029384654505\n",
      "  episode_reward_mean: 180.2989641627709\n",
      "  episode_reward_min: 106.51018832646096\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 62346\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.029736876487732\n",
      "      kl: 0.0194636732339859\n",
      "      policy_loss: 5.8621740208764095e-06\n",
      "      total_loss: 18.900537490844727\n",
      "      vf_explained_var: 0.9938128590583801\n",
      "      vf_loss: 18.900529861450195\n",
      "    grad_time_ms: 1555.951\n",
      "    load_time_ms: 1.193\n",
      "    num_steps_sampled: 8210000\n",
      "    num_steps_trained: 8210000\n",
      "    sample_time_ms: 15713.965\n",
      "    update_time_ms: 4.263\n",
      "  iterations_since_restore: 821\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14496.411358594894\n",
      "  time_this_iter_s: 17.669102668762207\n",
      "  time_total_s: 14496.411358594894\n",
      "  timestamp: 1550630944\n",
      "  timesteps_since_restore: 8210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8210000\n",
      "  training_iteration: 821\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14496 s, 821 iter, 8210000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-49-21\n",
      "  done: false\n",
      "  episode_len_mean: 137.31\n",
      "  episode_reward_max: 229.45085766134167\n",
      "  episode_reward_mean: 179.08872644126194\n",
      "  episode_reward_min: 116.70796398145359\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 62418\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1680330038070679\n",
      "      kl: 0.02118759974837303\n",
      "      policy_loss: 0.000340902479365468\n",
      "      total_loss: 32.93540954589844\n",
      "      vf_explained_var: 0.9898727536201477\n",
      "      vf_loss: 32.9350700378418\n",
      "    grad_time_ms: 1555.658\n",
      "    load_time_ms: 1.221\n",
      "    num_steps_sampled: 8220000\n",
      "    num_steps_trained: 8220000\n",
      "    sample_time_ms: 15745.369\n",
      "    update_time_ms: 4.281\n",
      "  iterations_since_restore: 822\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14513.79223370552\n",
      "  time_this_iter_s: 17.38087511062622\n",
      "  time_total_s: 14513.79223370552\n",
      "  timestamp: 1550630961\n",
      "  timesteps_since_restore: 8220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8220000\n",
      "  training_iteration: 822\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14513 s, 822 iter, 8220000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-49-39\n",
      "  done: false\n",
      "  episode_len_mean: 136.31\n",
      "  episode_reward_max: 229.45085766134167\n",
      "  episode_reward_mean: 180.91125053349919\n",
      "  episode_reward_min: 105.36520040241794\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 62492\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9727717638015747\n",
      "      kl: 0.02600697986781597\n",
      "      policy_loss: 0.002470768289640546\n",
      "      total_loss: 24.27611541748047\n",
      "      vf_explained_var: 0.992224395275116\n",
      "      vf_loss: 24.27364158630371\n",
      "    grad_time_ms: 1553.514\n",
      "    load_time_ms: 1.203\n",
      "    num_steps_sampled: 8230000\n",
      "    num_steps_trained: 8230000\n",
      "    sample_time_ms: 15828.334\n",
      "    update_time_ms: 4.278\n",
      "  iterations_since_restore: 823\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14531.539379119873\n",
      "  time_this_iter_s: 17.747145414352417\n",
      "  time_total_s: 14531.539379119873\n",
      "  timestamp: 1550630979\n",
      "  timesteps_since_restore: 8230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8230000\n",
      "  training_iteration: 823\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14531 s, 823 iter, 8230000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-49-56\n",
      "  done: false\n",
      "  episode_len_mean: 136.45\n",
      "  episode_reward_max: 225.0942907172928\n",
      "  episode_reward_mean: 174.75303930897445\n",
      "  episode_reward_min: -40.5778243538767\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 62565\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.189094066619873\n",
      "      kl: 0.03413057327270508\n",
      "      policy_loss: -0.00178879767190665\n",
      "      total_loss: 140.9020233154297\n",
      "      vf_explained_var: 0.9573851227760315\n",
      "      vf_loss: 140.90383911132812\n",
      "    grad_time_ms: 1550.742\n",
      "    load_time_ms: 1.232\n",
      "    num_steps_sampled: 8240000\n",
      "    num_steps_trained: 8240000\n",
      "    sample_time_ms: 15795.219\n",
      "    update_time_ms: 4.299\n",
      "  iterations_since_restore: 824\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14549.018273830414\n",
      "  time_this_iter_s: 17.47889471054077\n",
      "  time_total_s: 14549.018273830414\n",
      "  timestamp: 1550630996\n",
      "  timesteps_since_restore: 8240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8240000\n",
      "  training_iteration: 824\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14549 s, 824 iter, 8240000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-50-14\n",
      "  done: false\n",
      "  episode_len_mean: 137.54\n",
      "  episode_reward_max: 223.476537765511\n",
      "  episode_reward_mean: 179.00057634697302\n",
      "  episode_reward_min: 91.33376443865583\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 62638\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0207430124282837\n",
      "      kl: 0.01955670490860939\n",
      "      policy_loss: -0.002431400353088975\n",
      "      total_loss: 42.2896728515625\n",
      "      vf_explained_var: 0.9868339896202087\n",
      "      vf_loss: 42.292110443115234\n",
      "    grad_time_ms: 1549.594\n",
      "    load_time_ms: 1.286\n",
      "    num_steps_sampled: 8250000\n",
      "    num_steps_trained: 8250000\n",
      "    sample_time_ms: 15785.741\n",
      "    update_time_ms: 4.311\n",
      "  iterations_since_restore: 825\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14566.320876121521\n",
      "  time_this_iter_s: 17.302602291107178\n",
      "  time_total_s: 14566.320876121521\n",
      "  timestamp: 1550631014\n",
      "  timesteps_since_restore: 8250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8250000\n",
      "  training_iteration: 825\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14566 s, 825 iter, 8250000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-50-31\n",
      "  done: false\n",
      "  episode_len_mean: 137.3\n",
      "  episode_reward_max: 227.96824930447823\n",
      "  episode_reward_mean: 177.82627808992243\n",
      "  episode_reward_min: -39.71731468223701\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 62712\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.158438801765442\n",
      "      kl: 0.018878761678934097\n",
      "      policy_loss: -0.0022382496390491724\n",
      "      total_loss: 49.6904182434082\n",
      "      vf_explained_var: 0.9851998686790466\n",
      "      vf_loss: 49.69266128540039\n",
      "    grad_time_ms: 1548.99\n",
      "    load_time_ms: 1.297\n",
      "    num_steps_sampled: 8260000\n",
      "    num_steps_trained: 8260000\n",
      "    sample_time_ms: 15786.805\n",
      "    update_time_ms: 4.258\n",
      "  iterations_since_restore: 826\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14583.83693909645\n",
      "  time_this_iter_s: 17.51606297492981\n",
      "  time_total_s: 14583.83693909645\n",
      "  timestamp: 1550631031\n",
      "  timesteps_since_restore: 8260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8260000\n",
      "  training_iteration: 826\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14583 s, 826 iter, 8260000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-50-48\n",
      "  done: false\n",
      "  episode_len_mean: 136.31\n",
      "  episode_reward_max: 228.3815823982259\n",
      "  episode_reward_mean: 180.525415384069\n",
      "  episode_reward_min: -35.443495623914885\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 62785\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.1758367733783904e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9795231223106384\n",
      "      kl: 0.05259855464100838\n",
      "      policy_loss: 0.0014236351707950234\n",
      "      total_loss: 62.5527458190918\n",
      "      vf_explained_var: 0.9793188571929932\n",
      "      vf_loss: 62.55133819580078\n",
      "    grad_time_ms: 1542.404\n",
      "    load_time_ms: 1.287\n",
      "    num_steps_sampled: 8270000\n",
      "    num_steps_trained: 8270000\n",
      "    sample_time_ms: 15786.696\n",
      "    update_time_ms: 4.259\n",
      "  iterations_since_restore: 827\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14601.025232553482\n",
      "  time_this_iter_s: 17.18829345703125\n",
      "  time_total_s: 14601.025232553482\n",
      "  timestamp: 1550631048\n",
      "  timesteps_since_restore: 8270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8270000\n",
      "  training_iteration: 827\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14601 s, 827 iter, 8270000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-51-06\n",
      "  done: false\n",
      "  episode_len_mean: 135.59\n",
      "  episode_reward_max: 228.3815823982259\n",
      "  episode_reward_mean: 178.63958640683018\n",
      "  episode_reward_min: -37.729550904271605\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 62859\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.763756169809544e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9864877462387085\n",
      "      kl: 0.029382091015577316\n",
      "      policy_loss: -0.0005253723356872797\n",
      "      total_loss: 52.47783279418945\n",
      "      vf_explained_var: 0.9848139882087708\n",
      "      vf_loss: 52.47834777832031\n",
      "    grad_time_ms: 1543.124\n",
      "    load_time_ms: 1.354\n",
      "    num_steps_sampled: 8280000\n",
      "    num_steps_trained: 8280000\n",
      "    sample_time_ms: 15828.135\n",
      "    update_time_ms: 4.226\n",
      "  iterations_since_restore: 828\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14618.293717622757\n",
      "  time_this_iter_s: 17.268485069274902\n",
      "  time_total_s: 14618.293717622757\n",
      "  timestamp: 1550631066\n",
      "  timesteps_since_restore: 8280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8280000\n",
      "  training_iteration: 828\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14618 s, 828 iter, 8280000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-51-23\n",
      "  done: false\n",
      "  episode_len_mean: 137.61\n",
      "  episode_reward_max: 227.51640783110193\n",
      "  episode_reward_mean: 175.5702099411222\n",
      "  episode_reward_min: -37.729550904271605\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 62931\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.763756169809544e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.208178997039795\n",
      "      kl: 0.018758030608296394\n",
      "      policy_loss: -0.001830049091950059\n",
      "      total_loss: 21.241201400756836\n",
      "      vf_explained_var: 0.9930989146232605\n",
      "      vf_loss: 21.243032455444336\n",
      "    grad_time_ms: 1557.305\n",
      "    load_time_ms: 1.346\n",
      "    num_steps_sampled: 8290000\n",
      "    num_steps_trained: 8290000\n",
      "    sample_time_ms: 15844.611\n",
      "    update_time_ms: 4.211\n",
      "  iterations_since_restore: 829\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14635.962182760239\n",
      "  time_this_iter_s: 17.66846513748169\n",
      "  time_total_s: 14635.962182760239\n",
      "  timestamp: 1550631083\n",
      "  timesteps_since_restore: 8290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8290000\n",
      "  training_iteration: 829\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14635 s, 829 iter, 8290000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-51-40\n",
      "  done: false\n",
      "  episode_len_mean: 138.69\n",
      "  episode_reward_max: 226.74690140920245\n",
      "  episode_reward_mean: 177.79688866511168\n",
      "  episode_reward_min: 83.8296020104745\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 63003\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.763756169809544e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0764702558517456\n",
      "      kl: 0.11976230889558792\n",
      "      policy_loss: 0.007823650725185871\n",
      "      total_loss: 42.5330810546875\n",
      "      vf_explained_var: 0.9867781400680542\n",
      "      vf_loss: 42.52526092529297\n",
      "    grad_time_ms: 1558.698\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 8300000\n",
      "    num_steps_trained: 8300000\n",
      "    sample_time_ms: 15813.285\n",
      "    update_time_ms: 4.357\n",
      "  iterations_since_restore: 830\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14652.643953561783\n",
      "  time_this_iter_s: 16.68177080154419\n",
      "  time_total_s: 14652.643953561783\n",
      "  timestamp: 1550631100\n",
      "  timesteps_since_restore: 8300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8300000\n",
      "  training_iteration: 830\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14652 s, 830 iter, 8300000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-51-57\n",
      "  done: false\n",
      "  episode_len_mean: 135.89\n",
      "  episode_reward_max: 230.33074595967284\n",
      "  episode_reward_mean: 182.59897095078134\n",
      "  episode_reward_min: 99.78437884933876\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 63077\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.145634456662708e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.081770658493042\n",
      "      kl: 0.035642359405756\n",
      "      policy_loss: 0.0018617268651723862\n",
      "      total_loss: 23.63206672668457\n",
      "      vf_explained_var: 0.9925819039344788\n",
      "      vf_loss: 23.630205154418945\n",
      "    grad_time_ms: 1558.313\n",
      "    load_time_ms: 1.346\n",
      "    num_steps_sampled: 8310000\n",
      "    num_steps_trained: 8310000\n",
      "    sample_time_ms: 15732.081\n",
      "    update_time_ms: 4.357\n",
      "  iterations_since_restore: 831\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14669.496638536453\n",
      "  time_this_iter_s: 16.85268497467041\n",
      "  time_total_s: 14669.496638536453\n",
      "  timestamp: 1550631117\n",
      "  timesteps_since_restore: 8310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8310000\n",
      "  training_iteration: 831\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14669 s, 831 iter, 8310000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-52-14\n",
      "  done: false\n",
      "  episode_len_mean: 134.27\n",
      "  episode_reward_max: 223.12049411816338\n",
      "  episode_reward_mean: 179.47215431171452\n",
      "  episode_reward_min: -39.51120113511336\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 63152\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.145634456662708e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0097793340682983\n",
      "      kl: 0.032200492918491364\n",
      "      policy_loss: 0.0009381423587910831\n",
      "      total_loss: 61.52080154418945\n",
      "      vf_explained_var: 0.9806304574012756\n",
      "      vf_loss: 61.51986312866211\n",
      "    grad_time_ms: 1558.808\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 8320000\n",
      "    num_steps_trained: 8320000\n",
      "    sample_time_ms: 15693.321\n",
      "    update_time_ms: 4.44\n",
      "  iterations_since_restore: 832\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14686.494958400726\n",
      "  time_this_iter_s: 16.99831986427307\n",
      "  time_total_s: 14686.494958400726\n",
      "  timestamp: 1550631134\n",
      "  timesteps_since_restore: 8320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8320000\n",
      "  training_iteration: 832\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14686 s, 832 iter, 8320000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-52-32\n",
      "  done: false\n",
      "  episode_len_mean: 135.46\n",
      "  episode_reward_max: 224.2789151070289\n",
      "  episode_reward_mean: 183.17294141100356\n",
      "  episode_reward_min: 126.73110020750826\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 63225\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.145634456662708e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.025113582611084\n",
      "      kl: 0.02581121027469635\n",
      "      policy_loss: -0.0016163036925718188\n",
      "      total_loss: 9.423721313476562\n",
      "      vf_explained_var: 0.9968467354774475\n",
      "      vf_loss: 9.425338745117188\n",
      "    grad_time_ms: 1559.905\n",
      "    load_time_ms: 1.381\n",
      "    num_steps_sampled: 8330000\n",
      "    num_steps_trained: 8330000\n",
      "    sample_time_ms: 15660.88\n",
      "    update_time_ms: 4.554\n",
      "  iterations_since_restore: 833\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14703.934099674225\n",
      "  time_this_iter_s: 17.439141273498535\n",
      "  time_total_s: 14703.934099674225\n",
      "  timestamp: 1550631152\n",
      "  timesteps_since_restore: 8330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8330000\n",
      "  training_iteration: 833\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14703 s, 833 iter, 8330000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-52-49\n",
      "  done: false\n",
      "  episode_len_mean: 135.67\n",
      "  episode_reward_max: 224.2789151070289\n",
      "  episode_reward_mean: 176.78106529784378\n",
      "  episode_reward_min: -40.221283334685424\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 63299\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.145634456662708e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0098159313201904\n",
      "      kl: 0.016026712954044342\n",
      "      policy_loss: -7.364139310084283e-05\n",
      "      total_loss: 99.66194915771484\n",
      "      vf_explained_var: 0.9741052389144897\n",
      "      vf_loss: 99.6620101928711\n",
      "    grad_time_ms: 1561.523\n",
      "    load_time_ms: 1.393\n",
      "    num_steps_sampled: 8340000\n",
      "    num_steps_trained: 8340000\n",
      "    sample_time_ms: 15642.228\n",
      "    update_time_ms: 4.482\n",
      "  iterations_since_restore: 834\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14721.242596387863\n",
      "  time_this_iter_s: 17.308496713638306\n",
      "  time_total_s: 14721.242596387863\n",
      "  timestamp: 1550631169\n",
      "  timesteps_since_restore: 8340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8340000\n",
      "  training_iteration: 834\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14721 s, 834 iter, 8340000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-53-06\n",
      "  done: false\n",
      "  episode_len_mean: 134.74\n",
      "  episode_reward_max: 217.82912859755862\n",
      "  episode_reward_mean: 175.88085407581156\n",
      "  episode_reward_min: -40.18990227668594\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 63374\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.145634456662708e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9577834010124207\n",
      "      kl: 0.04275978356599808\n",
      "      policy_loss: -0.007660584524273872\n",
      "      total_loss: 126.98947143554688\n",
      "      vf_explained_var: 0.9623768925666809\n",
      "      vf_loss: 126.99714660644531\n",
      "    grad_time_ms: 1560.679\n",
      "    load_time_ms: 1.348\n",
      "    num_steps_sampled: 8350000\n",
      "    num_steps_trained: 8350000\n",
      "    sample_time_ms: 15632.107\n",
      "    update_time_ms: 4.555\n",
      "  iterations_since_restore: 835\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14738.43423962593\n",
      "  time_this_iter_s: 17.191643238067627\n",
      "  time_total_s: 14738.43423962593\n",
      "  timestamp: 1550631186\n",
      "  timesteps_since_restore: 8350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8350000\n",
      "  training_iteration: 835\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14738 s, 835 iter, 8350000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-53-24\n",
      "  done: false\n",
      "  episode_len_mean: 135.86\n",
      "  episode_reward_max: 225.0044895609344\n",
      "  episode_reward_mean: 175.05742678657325\n",
      "  episode_reward_min: -38.524171698801624\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 63447\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0718450473303712e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.134758472442627\n",
      "      kl: 0.017594918608665466\n",
      "      policy_loss: 0.0005744416848756373\n",
      "      total_loss: 91.37255859375\n",
      "      vf_explained_var: 0.9724326729774475\n",
      "      vf_loss: 91.37199401855469\n",
      "    grad_time_ms: 1579.478\n",
      "    load_time_ms: 1.341\n",
      "    num_steps_sampled: 8360000\n",
      "    num_steps_trained: 8360000\n",
      "    sample_time_ms: 15641.587\n",
      "    update_time_ms: 4.412\n",
      "  iterations_since_restore: 836\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14756.232675552368\n",
      "  time_this_iter_s: 17.798435926437378\n",
      "  time_total_s: 14756.232675552368\n",
      "  timestamp: 1550631204\n",
      "  timesteps_since_restore: 8360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8360000\n",
      "  training_iteration: 836\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14756 s, 836 iter, 8360000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-53-41\n",
      "  done: false\n",
      "  episode_len_mean: 136.38\n",
      "  episode_reward_max: 224.91709314275636\n",
      "  episode_reward_mean: 177.58201359673575\n",
      "  episode_reward_min: 95.91337049280367\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 63521\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0718450473303712e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1681268215179443\n",
      "      kl: 0.025059135630726814\n",
      "      policy_loss: -0.001182605279609561\n",
      "      total_loss: 24.887981414794922\n",
      "      vf_explained_var: 0.9922192692756653\n",
      "      vf_loss: 24.8891658782959\n",
      "    grad_time_ms: 1585.462\n",
      "    load_time_ms: 1.398\n",
      "    num_steps_sampled: 8370000\n",
      "    num_steps_trained: 8370000\n",
      "    sample_time_ms: 15651.868\n",
      "    update_time_ms: 4.388\n",
      "  iterations_since_restore: 837\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14773.586366415024\n",
      "  time_this_iter_s: 17.35369086265564\n",
      "  time_total_s: 14773.586366415024\n",
      "  timestamp: 1550631221\n",
      "  timesteps_since_restore: 8370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8370000\n",
      "  training_iteration: 837\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14773 s, 837 iter, 8370000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-53-59\n",
      "  done: false\n",
      "  episode_len_mean: 135.12\n",
      "  episode_reward_max: 224.91709314275636\n",
      "  episode_reward_mean: 175.65173730472827\n",
      "  episode_reward_min: 73.30025385084124\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 63595\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0718450473303712e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9760768413543701\n",
      "      kl: 0.023662375286221504\n",
      "      policy_loss: -0.002345802029594779\n",
      "      total_loss: 53.99697494506836\n",
      "      vf_explained_var: 0.9831230044364929\n",
      "      vf_loss: 53.99931716918945\n",
      "    grad_time_ms: 1585.862\n",
      "    load_time_ms: 1.332\n",
      "    num_steps_sampled: 8380000\n",
      "    num_steps_trained: 8380000\n",
      "    sample_time_ms: 15656.834\n",
      "    update_time_ms: 4.429\n",
      "  iterations_since_restore: 838\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14790.9066593647\n",
      "  time_this_iter_s: 17.320292949676514\n",
      "  time_total_s: 14790.9066593647\n",
      "  timestamp: 1550631239\n",
      "  timesteps_since_restore: 8380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8380000\n",
      "  training_iteration: 838\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14790 s, 838 iter, 8380000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-54-16\n",
      "  done: false\n",
      "  episode_len_mean: 135.4\n",
      "  episode_reward_max: 223.70376173876647\n",
      "  episode_reward_mean: 177.29495279806156\n",
      "  episode_reward_min: 76.18090294072829\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 63668\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0718450473303712e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1671221256256104\n",
      "      kl: 0.022947095334529877\n",
      "      policy_loss: 0.0003741015389095992\n",
      "      total_loss: 31.767459869384766\n",
      "      vf_explained_var: 0.9900934100151062\n",
      "      vf_loss: 31.767080307006836\n",
      "    grad_time_ms: 1570.904\n",
      "    load_time_ms: 1.396\n",
      "    num_steps_sampled: 8390000\n",
      "    num_steps_trained: 8390000\n",
      "    sample_time_ms: 15584.719\n",
      "    update_time_ms: 4.604\n",
      "  iterations_since_restore: 839\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14807.708648443222\n",
      "  time_this_iter_s: 16.80198907852173\n",
      "  time_total_s: 14807.708648443222\n",
      "  timestamp: 1550631256\n",
      "  timesteps_since_restore: 8390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8390000\n",
      "  training_iteration: 839\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14807 s, 839 iter, 8390000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-54-33\n",
      "  done: false\n",
      "  episode_len_mean: 137.98\n",
      "  episode_reward_max: 230.17670971752696\n",
      "  episode_reward_mean: 180.9647684446284\n",
      "  episode_reward_min: 110.19350476231305\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 63740\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0718450473303712e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.340127944946289\n",
      "      kl: 0.034110136330127716\n",
      "      policy_loss: 0.0012771314941346645\n",
      "      total_loss: 15.65902328491211\n",
      "      vf_explained_var: 0.9952374696731567\n",
      "      vf_loss: 15.657747268676758\n",
      "    grad_time_ms: 1570.945\n",
      "    load_time_ms: 1.388\n",
      "    num_steps_sampled: 8400000\n",
      "    num_steps_trained: 8400000\n",
      "    sample_time_ms: 15660.724\n",
      "    update_time_ms: 4.493\n",
      "  iterations_since_restore: 840\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14825.149071216583\n",
      "  time_this_iter_s: 17.440422773361206\n",
      "  time_total_s: 14825.149071216583\n",
      "  timestamp: 1550631273\n",
      "  timesteps_since_restore: 8400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8400000\n",
      "  training_iteration: 840\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14825 s, 840 iter, 8400000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-54-51\n",
      "  done: false\n",
      "  episode_len_mean: 138.96\n",
      "  episode_reward_max: 230.17670971752696\n",
      "  episode_reward_mean: 177.68288639464242\n",
      "  episode_reward_min: 81.0462438441298\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 63813\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0718450473303712e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2531054019927979\n",
      "      kl: 0.016221610829234123\n",
      "      policy_loss: -0.0007242989377118647\n",
      "      total_loss: 35.06412887573242\n",
      "      vf_explained_var: 0.9887191653251648\n",
      "      vf_loss: 35.06485366821289\n",
      "    grad_time_ms: 1570.166\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 8410000\n",
      "    num_steps_trained: 8410000\n",
      "    sample_time_ms: 15738.577\n",
      "    update_time_ms: 4.462\n",
      "  iterations_since_restore: 841\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14842.771772623062\n",
      "  time_this_iter_s: 17.622701406478882\n",
      "  time_total_s: 14842.771772623062\n",
      "  timestamp: 1550631291\n",
      "  timesteps_since_restore: 8410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8410000\n",
      "  training_iteration: 841\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14842 s, 841 iter, 8410000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-55-08\n",
      "  done: false\n",
      "  episode_len_mean: 133.97\n",
      "  episode_reward_max: 219.26181979427614\n",
      "  episode_reward_mean: 178.0057938200668\n",
      "  episode_reward_min: -32.986756850513515\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 63888\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.0718450473303712e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0274324417114258\n",
      "      kl: 11.329802513122559\n",
      "      policy_loss: 0.03579995781183243\n",
      "      total_loss: 73.86573028564453\n",
      "      vf_explained_var: 0.9779983758926392\n",
      "      vf_loss: 73.82991790771484\n",
      "    grad_time_ms: 1567.344\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 8420000\n",
      "    num_steps_trained: 8420000\n",
      "    sample_time_ms: 15769.52\n",
      "    update_time_ms: 4.367\n",
      "  iterations_since_restore: 842\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14860.051230669022\n",
      "  time_this_iter_s: 17.279458045959473\n",
      "  time_total_s: 14860.051230669022\n",
      "  timestamp: 1550631308\n",
      "  timesteps_since_restore: 8420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8420000\n",
      "  training_iteration: 842\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14860 s, 842 iter, 8420000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-55-25\n",
      "  done: false\n",
      "  episode_len_mean: 134.41\n",
      "  episode_reward_max: 222.7506132181181\n",
      "  episode_reward_mean: 176.66198213446322\n",
      "  episode_reward_min: -38.30459661003534\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 63961\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.6077676921645918e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1383229494094849\n",
      "      kl: 29.262592315673828\n",
      "      policy_loss: 0.037028104066848755\n",
      "      total_loss: 133.3053436279297\n",
      "      vf_explained_var: 0.9647697806358337\n",
      "      vf_loss: 133.268310546875\n",
      "    grad_time_ms: 1564.737\n",
      "    load_time_ms: 1.386\n",
      "    num_steps_sampled: 8430000\n",
      "    num_steps_trained: 8430000\n",
      "    sample_time_ms: 15748.34\n",
      "    update_time_ms: 4.205\n",
      "  iterations_since_restore: 843\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14877.248421669006\n",
      "  time_this_iter_s: 17.19719099998474\n",
      "  time_total_s: 14877.248421669006\n",
      "  timestamp: 1550631325\n",
      "  timesteps_since_restore: 8430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8430000\n",
      "  training_iteration: 843\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14877 s, 843 iter, 8430000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 135.13\n",
      "  episode_reward_max: 231.06786053882226\n",
      "  episode_reward_mean: 165.80180284632794\n",
      "  episode_reward_min: -43.40902962251614\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 64036\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4116508920120342e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1710278987884521\n",
      "      kl: 0.03351948410272598\n",
      "      policy_loss: 0.0006092606927268207\n",
      "      total_loss: 332.2042236328125\n",
      "      vf_explained_var: 0.9257946610450745\n",
      "      vf_loss: 332.2036437988281\n",
      "    grad_time_ms: 1562.977\n",
      "    load_time_ms: 1.406\n",
      "    num_steps_sampled: 8440000\n",
      "    num_steps_trained: 8440000\n",
      "    sample_time_ms: 15805.275\n",
      "    update_time_ms: 4.263\n",
      "  iterations_since_restore: 844\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14895.108849287033\n",
      "  time_this_iter_s: 17.860427618026733\n",
      "  time_total_s: 14895.108849287033\n",
      "  timestamp: 1550631343\n",
      "  timesteps_since_restore: 8440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8440000\n",
      "  training_iteration: 844\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14895 s, 844 iter, 8440000 ts, 166 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-56-01\n",
      "  done: false\n",
      "  episode_len_mean: 133.88\n",
      "  episode_reward_max: 226.37152377803744\n",
      "  episode_reward_mean: 164.78550265744352\n",
      "  episode_reward_min: -43.40902962251614\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 64110\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4116508920120342e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0989841222763062\n",
      "      kl: 0.023196114227175713\n",
      "      policy_loss: -0.0005053695640526712\n",
      "      total_loss: 151.77879333496094\n",
      "      vf_explained_var: 0.9572866559028625\n",
      "      vf_loss: 151.77932739257812\n",
      "    grad_time_ms: 1561.392\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 8450000\n",
      "    num_steps_trained: 8450000\n",
      "    sample_time_ms: 15833.732\n",
      "    update_time_ms: 4.222\n",
      "  iterations_since_restore: 845\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14912.570730686188\n",
      "  time_this_iter_s: 17.461881399154663\n",
      "  time_total_s: 14912.570730686188\n",
      "  timestamp: 1550631361\n",
      "  timesteps_since_restore: 8450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8450000\n",
      "  training_iteration: 845\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14912 s, 845 iter, 8450000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-56-18\n",
      "  done: false\n",
      "  episode_len_mean: 134.21\n",
      "  episode_reward_max: 227.79713206461605\n",
      "  episode_reward_mean: 164.1942677430462\n",
      "  episode_reward_min: -46.11407820056055\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 64184\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4116508920120342e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1987813711166382\n",
      "      kl: 0.02444835752248764\n",
      "      policy_loss: -0.002451955573633313\n",
      "      total_loss: 154.33792114257812\n",
      "      vf_explained_var: 0.9583096504211426\n",
      "      vf_loss: 154.34034729003906\n",
      "    grad_time_ms: 1540.768\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 8460000\n",
      "    num_steps_trained: 8460000\n",
      "    sample_time_ms: 15812.229\n",
      "    update_time_ms: 4.275\n",
      "  iterations_since_restore: 846\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14929.948306322098\n",
      "  time_this_iter_s: 17.377575635910034\n",
      "  time_total_s: 14929.948306322098\n",
      "  timestamp: 1550631378\n",
      "  timesteps_since_restore: 8460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8460000\n",
      "  training_iteration: 846\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14929 s, 846 iter, 8460000 ts, 164 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-56-35\n",
      "  done: false\n",
      "  episode_len_mean: 135.78\n",
      "  episode_reward_max: 227.79713206461605\n",
      "  episode_reward_mean: 174.0240723677073\n",
      "  episode_reward_min: -45.36487045873067\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 64258\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.4116508920120342e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0726059675216675\n",
      "      kl: 0.047539275139570236\n",
      "      policy_loss: 0.003180114086717367\n",
      "      total_loss: 131.94357299804688\n",
      "      vf_explained_var: 0.9626429677009583\n",
      "      vf_loss: 131.94036865234375\n",
      "    grad_time_ms: 1535.038\n",
      "    load_time_ms: 1.405\n",
      "    num_steps_sampled: 8470000\n",
      "    num_steps_trained: 8470000\n",
      "    sample_time_ms: 15815.882\n",
      "    update_time_ms: 4.253\n",
      "  iterations_since_restore: 847\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14947.279947757721\n",
      "  time_this_iter_s: 17.33164143562317\n",
      "  time_total_s: 14947.279947757721\n",
      "  timestamp: 1550631395\n",
      "  timesteps_since_restore: 8470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8470000\n",
      "  training_iteration: 847\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14947 s, 847 iter, 8470000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-56-52\n",
      "  done: false\n",
      "  episode_len_mean: 135.77\n",
      "  episode_reward_max: 227.6664169289098\n",
      "  episode_reward_mean: 169.16236890871588\n",
      "  episode_reward_min: -45.36487045873067\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 64332\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.617476661135478e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0239547491073608\n",
      "      kl: 0.041683584451675415\n",
      "      policy_loss: 0.00024276554177049547\n",
      "      total_loss: 218.7832489013672\n",
      "      vf_explained_var: 0.9424771070480347\n",
      "      vf_loss: 218.7830352783203\n",
      "    grad_time_ms: 1533.55\n",
      "    load_time_ms: 1.422\n",
      "    num_steps_sampled: 8480000\n",
      "    num_steps_trained: 8480000\n",
      "    sample_time_ms: 15769.711\n",
      "    update_time_ms: 4.171\n",
      "  iterations_since_restore: 848\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14964.124701976776\n",
      "  time_this_iter_s: 16.844754219055176\n",
      "  time_total_s: 14964.124701976776\n",
      "  timestamp: 1550631412\n",
      "  timesteps_since_restore: 8480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8480000\n",
      "  training_iteration: 848\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14964 s, 848 iter, 8480000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-57-09\n",
      "  done: false\n",
      "  episode_len_mean: 134.72\n",
      "  episode_reward_max: 227.0375861339272\n",
      "  episode_reward_mean: 171.83266538738744\n",
      "  episode_reward_min: -43.24612180637841\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 64406\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.426216930407778e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1289037466049194\n",
      "      kl: 2.4717953205108643\n",
      "      policy_loss: 0.03374891355633736\n",
      "      total_loss: 137.9558868408203\n",
      "      vf_explained_var: 0.9608471989631653\n",
      "      vf_loss: 137.92213439941406\n",
      "    grad_time_ms: 1534.272\n",
      "    load_time_ms: 1.358\n",
      "    num_steps_sampled: 8490000\n",
      "    num_steps_trained: 8490000\n",
      "    sample_time_ms: 15789.505\n",
      "    update_time_ms: 4.159\n",
      "  iterations_since_restore: 849\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14981.13066482544\n",
      "  time_this_iter_s: 17.00596284866333\n",
      "  time_total_s: 14981.13066482544\n",
      "  timestamp: 1550631429\n",
      "  timesteps_since_restore: 8490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8490000\n",
      "  training_iteration: 849\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14981 s, 849 iter, 8490000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-57-27\n",
      "  done: false\n",
      "  episode_len_mean: 134.54\n",
      "  episode_reward_max: 225.51946002687552\n",
      "  episode_reward_mean: 173.45403791726494\n",
      "  episode_reward_min: -44.50501452910135\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 64481\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0306164026260376\n",
      "      kl: 0.029356833547353745\n",
      "      policy_loss: 0.0020645803306251764\n",
      "      total_loss: 69.31761169433594\n",
      "      vf_explained_var: 0.9809482097625732\n",
      "      vf_loss: 69.31554412841797\n",
      "    grad_time_ms: 1532.834\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 8500000\n",
      "    num_steps_trained: 8500000\n",
      "    sample_time_ms: 15762.908\n",
      "    update_time_ms: 4.148\n",
      "  iterations_since_restore: 850\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 14998.29326915741\n",
      "  time_this_iter_s: 17.162604331970215\n",
      "  time_total_s: 14998.29326915741\n",
      "  timestamp: 1550631447\n",
      "  timesteps_since_restore: 8500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8500000\n",
      "  training_iteration: 850\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 14998 s, 850 iter, 8500000 ts, 173 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-57-44\n",
      "  done: false\n",
      "  episode_len_mean: 137.74\n",
      "  episode_reward_max: 229.1537094258952\n",
      "  episode_reward_mean: 175.49127194837155\n",
      "  episode_reward_min: -44.50501452910135\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 64553\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.170112133026123\n",
      "      kl: 0.01611938886344433\n",
      "      policy_loss: -0.0010456268209964037\n",
      "      total_loss: 78.82391357421875\n",
      "      vf_explained_var: 0.9793727397918701\n",
      "      vf_loss: 78.82496643066406\n",
      "    grad_time_ms: 1534.748\n",
      "    load_time_ms: 1.398\n",
      "    num_steps_sampled: 8510000\n",
      "    num_steps_trained: 8510000\n",
      "    sample_time_ms: 15754.779\n",
      "    update_time_ms: 4.13\n",
      "  iterations_since_restore: 851\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15015.855076551437\n",
      "  time_this_iter_s: 17.56180739402771\n",
      "  time_total_s: 15015.855076551437\n",
      "  timestamp: 1550631464\n",
      "  timesteps_since_restore: 8510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8510000\n",
      "  training_iteration: 851\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15015 s, 851 iter, 8510000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-58-02\n",
      "  done: false\n",
      "  episode_len_mean: 136.48\n",
      "  episode_reward_max: 224.24887279823116\n",
      "  episode_reward_mean: 175.94089742781372\n",
      "  episode_reward_min: -39.77118238596488\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 64627\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0855475664138794\n",
      "      kl: 0.020240291953086853\n",
      "      policy_loss: 0.0021648299880325794\n",
      "      total_loss: 94.28472137451172\n",
      "      vf_explained_var: 0.9747346043586731\n",
      "      vf_loss: 94.28256225585938\n",
      "    grad_time_ms: 1536.011\n",
      "    load_time_ms: 1.376\n",
      "    num_steps_sampled: 8520000\n",
      "    num_steps_trained: 8520000\n",
      "    sample_time_ms: 15784.122\n",
      "    update_time_ms: 4.129\n",
      "  iterations_since_restore: 852\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15033.441231966019\n",
      "  time_this_iter_s: 17.5861554145813\n",
      "  time_total_s: 15033.441231966019\n",
      "  timestamp: 1550631482\n",
      "  timesteps_since_restore: 8520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8520000\n",
      "  training_iteration: 852\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15033 s, 852 iter, 8520000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-58-19\n",
      "  done: false\n",
      "  episode_len_mean: 134.45\n",
      "  episode_reward_max: 223.57320901205645\n",
      "  episode_reward_mean: 167.5341109008512\n",
      "  episode_reward_min: -41.823216182023\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 64700\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2956452369689941\n",
      "      kl: 0.03506099432706833\n",
      "      policy_loss: -0.001687822863459587\n",
      "      total_loss: 116.84357452392578\n",
      "      vf_explained_var: 0.9669603109359741\n",
      "      vf_loss: 116.84526824951172\n",
      "    grad_time_ms: 1539.577\n",
      "    load_time_ms: 1.34\n",
      "    num_steps_sampled: 8530000\n",
      "    num_steps_trained: 8530000\n",
      "    sample_time_ms: 15816.431\n",
      "    update_time_ms: 4.134\n",
      "  iterations_since_restore: 853\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15050.996166467667\n",
      "  time_this_iter_s: 17.55493450164795\n",
      "  time_total_s: 15050.996166467667\n",
      "  timestamp: 1550631499\n",
      "  timesteps_since_restore: 8530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8530000\n",
      "  training_iteration: 853\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15050 s, 853 iter, 8530000 ts, 168 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-58-37\n",
      "  done: false\n",
      "  episode_len_mean: 135.92\n",
      "  episode_reward_max: 224.44821640839896\n",
      "  episode_reward_mean: 165.4996700550973\n",
      "  episode_reward_min: -41.823216182023\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 64773\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.449662208557129\n",
      "      kl: 0.03227972239255905\n",
      "      policy_loss: -0.0011226400965824723\n",
      "      total_loss: 89.35102081298828\n",
      "      vf_explained_var: 0.973694920539856\n",
      "      vf_loss: 89.35214233398438\n",
      "    grad_time_ms: 1540.823\n",
      "    load_time_ms: 1.278\n",
      "    num_steps_sampled: 8540000\n",
      "    num_steps_trained: 8540000\n",
      "    sample_time_ms: 15779.78\n",
      "    update_time_ms: 4.068\n",
      "  iterations_since_restore: 854\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15068.500413894653\n",
      "  time_this_iter_s: 17.504247426986694\n",
      "  time_total_s: 15068.500413894653\n",
      "  timestamp: 1550631517\n",
      "  timesteps_since_restore: 8540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8540000\n",
      "  training_iteration: 854\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15068 s, 854 iter, 8540000 ts, 165 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-58-54\n",
      "  done: false\n",
      "  episode_len_mean: 137.36\n",
      "  episode_reward_max: 227.2220087142866\n",
      "  episode_reward_mean: 171.92159526331292\n",
      "  episode_reward_min: -34.16333477560542\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 64847\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.108562707901001\n",
      "      kl: 0.017909420654177666\n",
      "      policy_loss: -0.000893457094207406\n",
      "      total_loss: 56.0339241027832\n",
      "      vf_explained_var: 0.9843922257423401\n",
      "      vf_loss: 56.03481674194336\n",
      "    grad_time_ms: 1556.851\n",
      "    load_time_ms: 1.214\n",
      "    num_steps_sampled: 8550000\n",
      "    num_steps_trained: 8550000\n",
      "    sample_time_ms: 15765.382\n",
      "    update_time_ms: 4.124\n",
      "  iterations_since_restore: 855\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15085.977218151093\n",
      "  time_this_iter_s: 17.47680425643921\n",
      "  time_total_s: 15085.977218151093\n",
      "  timestamp: 1550631534\n",
      "  timesteps_since_restore: 8550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8550000\n",
      "  training_iteration: 855\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15085 s, 855 iter, 8550000 ts, 172 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-59-11\n",
      "  done: false\n",
      "  episode_len_mean: 135.17\n",
      "  episode_reward_max: 220.88255927143712\n",
      "  episode_reward_mean: 171.32429993868368\n",
      "  episode_reward_min: -42.49145631462632\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 64920\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1471517086029053\n",
      "      kl: 0.029926475137472153\n",
      "      policy_loss: -0.005434074904769659\n",
      "      total_loss: 82.55104064941406\n",
      "      vf_explained_var: 0.9746479988098145\n",
      "      vf_loss: 82.55648040771484\n",
      "    grad_time_ms: 1556.982\n",
      "    load_time_ms: 1.221\n",
      "    num_steps_sampled: 8560000\n",
      "    num_steps_trained: 8560000\n",
      "    sample_time_ms: 15733.758\n",
      "    update_time_ms: 4.117\n",
      "  iterations_since_restore: 856\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15103.03866648674\n",
      "  time_this_iter_s: 17.061448335647583\n",
      "  time_total_s: 15103.03866648674\n",
      "  timestamp: 1550631551\n",
      "  timesteps_since_restore: 8560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8560000\n",
      "  training_iteration: 856\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15103 s, 856 iter, 8560000 ts, 171 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-59-29\n",
      "  done: false\n",
      "  episode_len_mean: 135.91\n",
      "  episode_reward_max: 224.05440215275857\n",
      "  episode_reward_mean: 169.58666835664593\n",
      "  episode_reward_min: -42.49145631462632\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 64993\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2178843021392822\n",
      "      kl: 0.015820620581507683\n",
      "      policy_loss: -0.0006676596822217107\n",
      "      total_loss: 72.49614715576172\n",
      "      vf_explained_var: 0.9792866706848145\n",
      "      vf_loss: 72.49681091308594\n",
      "    grad_time_ms: 1556.266\n",
      "    load_time_ms: 1.227\n",
      "    num_steps_sampled: 8570000\n",
      "    num_steps_trained: 8570000\n",
      "    sample_time_ms: 15729.121\n",
      "    update_time_ms: 4.21\n",
      "  iterations_since_restore: 857\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15120.315637588501\n",
      "  time_this_iter_s: 17.276971101760864\n",
      "  time_total_s: 15120.315637588501\n",
      "  timestamp: 1550631569\n",
      "  timesteps_since_restore: 8570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8570000\n",
      "  training_iteration: 857\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15120 s, 857 iter, 8570000 ts, 170 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_03-59-46\n",
      "  done: false\n",
      "  episode_len_mean: 137.62\n",
      "  episode_reward_max: 223.07002534097683\n",
      "  episode_reward_mean: 180.456666342528\n",
      "  episode_reward_min: 77.04777116365364\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 65065\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 8.13932410314196e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3262072801589966\n",
      "      kl: 0.08104013651609421\n",
      "      policy_loss: 0.0045095873065292835\n",
      "      total_loss: 49.22229766845703\n",
      "      vf_explained_var: 0.9848458766937256\n",
      "      vf_loss: 49.21778869628906\n",
      "    grad_time_ms: 1557.551\n",
      "    load_time_ms: 1.262\n",
      "    num_steps_sampled: 8580000\n",
      "    num_steps_trained: 8580000\n",
      "    sample_time_ms: 15799.746\n",
      "    update_time_ms: 4.357\n",
      "  iterations_since_restore: 858\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15137.881727218628\n",
      "  time_this_iter_s: 17.566089630126953\n",
      "  time_total_s: 15137.881727218628\n",
      "  timestamp: 1550631586\n",
      "  timesteps_since_restore: 8580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8580000\n",
      "  training_iteration: 858\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15137 s, 858 iter, 8580000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-00-04\n",
      "  done: false\n",
      "  episode_len_mean: 136.3\n",
      "  episode_reward_max: 228.08458698526175\n",
      "  episode_reward_mean: 175.96843751428796\n",
      "  episode_reward_min: -39.36557574275105\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 65140\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0663822889328003\n",
      "      kl: 0.03269342705607414\n",
      "      policy_loss: 0.0007705578464083374\n",
      "      total_loss: 131.5550537109375\n",
      "      vf_explained_var: 0.962295413017273\n",
      "      vf_loss: 131.55426025390625\n",
      "    grad_time_ms: 1556.364\n",
      "    load_time_ms: 1.387\n",
      "    num_steps_sampled: 8590000\n",
      "    num_steps_trained: 8590000\n",
      "    sample_time_ms: 15808.704\n",
      "    update_time_ms: 4.283\n",
      "  iterations_since_restore: 859\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15154.966688394547\n",
      "  time_this_iter_s: 17.08496117591858\n",
      "  time_total_s: 15154.966688394547\n",
      "  timestamp: 1550631604\n",
      "  timesteps_since_restore: 8590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8590000\n",
      "  training_iteration: 859\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15154 s, 859 iter, 8590000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-00-21\n",
      "  done: false\n",
      "  episode_len_mean: 134.65\n",
      "  episode_reward_max: 228.20334765547432\n",
      "  episode_reward_mean: 168.96126818521293\n",
      "  episode_reward_min: -42.62827089388327\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 65214\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1422207355499268\n",
      "      kl: 0.017626235261559486\n",
      "      policy_loss: -0.001743842731229961\n",
      "      total_loss: 94.51156616210938\n",
      "      vf_explained_var: 0.9738081693649292\n",
      "      vf_loss: 94.51331329345703\n",
      "    grad_time_ms: 1556.549\n",
      "    load_time_ms: 1.325\n",
      "    num_steps_sampled: 8600000\n",
      "    num_steps_trained: 8600000\n",
      "    sample_time_ms: 15822.271\n",
      "    update_time_ms: 4.309\n",
      "  iterations_since_restore: 860\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15172.26375746727\n",
      "  time_this_iter_s: 17.29706907272339\n",
      "  time_total_s: 15172.26375746727\n",
      "  timestamp: 1550631621\n",
      "  timesteps_since_restore: 8600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8600000\n",
      "  training_iteration: 860\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15172 s, 860 iter, 8600000 ts, 169 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-00-38\n",
      "  done: false\n",
      "  episode_len_mean: 137.97\n",
      "  episode_reward_max: 228.20334765547432\n",
      "  episode_reward_mean: 176.75178576872287\n",
      "  episode_reward_min: -41.689907832310915\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 65286\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3050317764282227\n",
      "      kl: 0.030424203723669052\n",
      "      policy_loss: 0.0006822274881415069\n",
      "      total_loss: 84.61141204833984\n",
      "      vf_explained_var: 0.97451251745224\n",
      "      vf_loss: 84.61073303222656\n",
      "    grad_time_ms: 1555.387\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 8610000\n",
      "    num_steps_trained: 8610000\n",
      "    sample_time_ms: 15818.029\n",
      "    update_time_ms: 4.263\n",
      "  iterations_since_restore: 861\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15189.771013975143\n",
      "  time_this_iter_s: 17.507256507873535\n",
      "  time_total_s: 15189.771013975143\n",
      "  timestamp: 1550631638\n",
      "  timesteps_since_restore: 8610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8610000\n",
      "  training_iteration: 861\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15189 s, 861 iter, 8610000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-00-56\n",
      "  done: false\n",
      "  episode_len_mean: 136.33\n",
      "  episode_reward_max: 227.34222573307468\n",
      "  episode_reward_mean: 176.49312401010113\n",
      "  episode_reward_min: -41.20661559954541\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 65360\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2379672527313232\n",
      "      kl: 0.02625848352909088\n",
      "      policy_loss: -0.0010877499589696527\n",
      "      total_loss: 62.17558670043945\n",
      "      vf_explained_var: 0.9826791286468506\n",
      "      vf_loss: 62.176658630371094\n",
      "    grad_time_ms: 1553.992\n",
      "    load_time_ms: 1.349\n",
      "    num_steps_sampled: 8620000\n",
      "    num_steps_trained: 8620000\n",
      "    sample_time_ms: 15850.688\n",
      "    update_time_ms: 4.354\n",
      "  iterations_since_restore: 862\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15207.670077323914\n",
      "  time_this_iter_s: 17.89906334877014\n",
      "  time_total_s: 15207.670077323914\n",
      "  timestamp: 1550631656\n",
      "  timesteps_since_restore: 8620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8620000\n",
      "  training_iteration: 862\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15207 s, 862 iter, 8620000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-01-13\n",
      "  done: false\n",
      "  episode_len_mean: 136.83\n",
      "  episode_reward_max: 225.53648045511525\n",
      "  episode_reward_mean: 175.3423512152706\n",
      "  episode_reward_min: -41.20661559954541\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 65432\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.310755729675293\n",
      "      kl: 0.018382307142019272\n",
      "      policy_loss: -0.0004069093556609005\n",
      "      total_loss: 57.46431350708008\n",
      "      vf_explained_var: 0.9837353229522705\n",
      "      vf_loss: 57.464725494384766\n",
      "    grad_time_ms: 1552.629\n",
      "    load_time_ms: 1.345\n",
      "    num_steps_sampled: 8630000\n",
      "    num_steps_trained: 8630000\n",
      "    sample_time_ms: 15805.282\n",
      "    update_time_ms: 4.504\n",
      "  iterations_since_restore: 863\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15224.758159160614\n",
      "  time_this_iter_s: 17.08808183670044\n",
      "  time_total_s: 15224.758159160614\n",
      "  timestamp: 1550631673\n",
      "  timesteps_since_restore: 8630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8630000\n",
      "  training_iteration: 863\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15224 s, 863 iter, 8630000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-01-31\n",
      "  done: false\n",
      "  episode_len_mean: 136.71\n",
      "  episode_reward_max: 223.7290953675858\n",
      "  episode_reward_mean: 174.64669127222632\n",
      "  episode_reward_min: -42.83755243798294\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 65506\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0617796182632446\n",
      "      kl: 0.03873008117079735\n",
      "      policy_loss: 0.0017135298112407327\n",
      "      total_loss: 112.85123443603516\n",
      "      vf_explained_var: 0.9725642800331116\n",
      "      vf_loss: 112.84954833984375\n",
      "    grad_time_ms: 1551.852\n",
      "    load_time_ms: 1.347\n",
      "    num_steps_sampled: 8640000\n",
      "    num_steps_trained: 8640000\n",
      "    sample_time_ms: 15767.176\n",
      "    update_time_ms: 4.646\n",
      "  iterations_since_restore: 864\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15241.875480651855\n",
      "  time_this_iter_s: 17.117321491241455\n",
      "  time_total_s: 15241.875480651855\n",
      "  timestamp: 1550631691\n",
      "  timesteps_since_restore: 8640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8640000\n",
      "  training_iteration: 864\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15241 s, 864 iter, 8640000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-01-48\n",
      "  done: false\n",
      "  episode_len_mean: 136.8\n",
      "  episode_reward_max: 226.48849973348104\n",
      "  episode_reward_mean: 181.13306977701458\n",
      "  episode_reward_min: -41.885345657346846\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 65578\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1468290090560913\n",
      "      kl: 0.02355124056339264\n",
      "      policy_loss: 0.0003403817827347666\n",
      "      total_loss: 70.2598876953125\n",
      "      vf_explained_var: 0.9795385599136353\n",
      "      vf_loss: 70.2595443725586\n",
      "    grad_time_ms: 1537.493\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 8650000\n",
      "    num_steps_trained: 8650000\n",
      "    sample_time_ms: 15799.337\n",
      "    update_time_ms: 4.617\n",
      "  iterations_since_restore: 865\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15259.532578229904\n",
      "  time_this_iter_s: 17.657097578048706\n",
      "  time_total_s: 15259.532578229904\n",
      "  timestamp: 1550631708\n",
      "  timesteps_since_restore: 8650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8650000\n",
      "  training_iteration: 865\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15259 s, 865 iter, 8650000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-02-06\n",
      "  done: false\n",
      "  episode_len_mean: 138.21\n",
      "  episode_reward_max: 229.68372464194744\n",
      "  episode_reward_mean: 178.32734069554576\n",
      "  episode_reward_min: -41.42570354206727\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 65650\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1850968599319458\n",
      "      kl: 0.01944284327328205\n",
      "      policy_loss: -0.001400513225235045\n",
      "      total_loss: 107.40570068359375\n",
      "      vf_explained_var: 0.9714758396148682\n",
      "      vf_loss: 107.40711212158203\n",
      "    grad_time_ms: 1536.283\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 8660000\n",
      "    num_steps_trained: 8660000\n",
      "    sample_time_ms: 15838.76\n",
      "    update_time_ms: 4.733\n",
      "  iterations_since_restore: 866\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15276.976731777191\n",
      "  time_this_iter_s: 17.444153547286987\n",
      "  time_total_s: 15276.976731777191\n",
      "  timestamp: 1550631726\n",
      "  timesteps_since_restore: 8660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8660000\n",
      "  training_iteration: 866\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15276 s, 866 iter, 8660000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-02-23\n",
      "  done: false\n",
      "  episode_len_mean: 137.01\n",
      "  episode_reward_max: 227.48495211551813\n",
      "  episode_reward_mean: 173.58776643585446\n",
      "  episode_reward_min: -39.92767944931984\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 65723\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.182145357131958\n",
      "      kl: 0.018571170046925545\n",
      "      policy_loss: -0.0008153002127073705\n",
      "      total_loss: 90.2524185180664\n",
      "      vf_explained_var: 0.9736027717590332\n",
      "      vf_loss: 90.25323486328125\n",
      "    grad_time_ms: 1554.497\n",
      "    load_time_ms: 1.342\n",
      "    num_steps_sampled: 8670000\n",
      "    num_steps_trained: 8670000\n",
      "    sample_time_ms: 15822.033\n",
      "    update_time_ms: 4.662\n",
      "  iterations_since_restore: 867\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15294.26906633377\n",
      "  time_this_iter_s: 17.29233455657959\n",
      "  time_total_s: 15294.26906633377\n",
      "  timestamp: 1550631743\n",
      "  timesteps_since_restore: 8670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8670000\n",
      "  training_iteration: 867\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15294 s, 867 iter, 8670000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-02-40\n",
      "  done: false\n",
      "  episode_len_mean: 135.24\n",
      "  episode_reward_max: 228.85572070425542\n",
      "  episode_reward_mean: 174.11421958917626\n",
      "  episode_reward_min: -37.99278012338545\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 65798\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.2208986800947793e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0048264265060425\n",
      "      kl: 13.110721588134766\n",
      "      policy_loss: 0.04213905334472656\n",
      "      total_loss: 83.28031158447266\n",
      "      vf_explained_var: 0.9788073897361755\n",
      "      vf_loss: 83.2381591796875\n",
      "    grad_time_ms: 1552.09\n",
      "    load_time_ms: 1.342\n",
      "    num_steps_sampled: 8680000\n",
      "    num_steps_trained: 8680000\n",
      "    sample_time_ms: 15792.507\n",
      "    update_time_ms: 4.602\n",
      "  iterations_since_restore: 868\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15311.514949321747\n",
      "  time_this_iter_s: 17.245882987976074\n",
      "  time_total_s: 15311.514949321747\n",
      "  timestamp: 1550631760\n",
      "  timesteps_since_restore: 8680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8680000\n",
      "  training_iteration: 868\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15311 s, 868 iter, 8680000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-02-58\n",
      "  done: false\n",
      "  episode_len_mean: 137.18\n",
      "  episode_reward_max: 228.85572070425542\n",
      "  episode_reward_mean: 178.9926012097725\n",
      "  episode_reward_min: -37.99278012338545\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 65871\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.831347503154286e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1245393753051758\n",
      "      kl: 0.024833794683218002\n",
      "      policy_loss: -0.0013863419881090522\n",
      "      total_loss: 20.74773597717285\n",
      "      vf_explained_var: 0.9938850402832031\n",
      "      vf_loss: 20.74912452697754\n",
      "    grad_time_ms: 1551.966\n",
      "    load_time_ms: 1.285\n",
      "    num_steps_sampled: 8690000\n",
      "    num_steps_trained: 8690000\n",
      "    sample_time_ms: 15816.269\n",
      "    update_time_ms: 4.556\n",
      "  iterations_since_restore: 869\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15328.83445572853\n",
      "  time_this_iter_s: 17.319506406784058\n",
      "  time_total_s: 15328.83445572853\n",
      "  timestamp: 1550631778\n",
      "  timesteps_since_restore: 8690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8690000\n",
      "  training_iteration: 869\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15328 s, 869 iter, 8690000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-03-15\n",
      "  done: false\n",
      "  episode_len_mean: 138.4\n",
      "  episode_reward_max: 224.13809560700375\n",
      "  episode_reward_mean: 177.47894195204114\n",
      "  episode_reward_min: 89.31516429833556\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 65942\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.831347503154286e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1471892595291138\n",
      "      kl: 0.03106982819736004\n",
      "      policy_loss: 0.0012987013906240463\n",
      "      total_loss: 105.20346069335938\n",
      "      vf_explained_var: 0.9727004766464233\n",
      "      vf_loss: 105.20216369628906\n",
      "    grad_time_ms: 1550.953\n",
      "    load_time_ms: 1.294\n",
      "    num_steps_sampled: 8700000\n",
      "    num_steps_trained: 8700000\n",
      "    sample_time_ms: 15772.992\n",
      "    update_time_ms: 4.553\n",
      "  iterations_since_restore: 870\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15345.688003540039\n",
      "  time_this_iter_s: 16.85354781150818\n",
      "  time_total_s: 15345.688003540039\n",
      "  timestamp: 1550631795\n",
      "  timesteps_since_restore: 8700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8700000\n",
      "  training_iteration: 870\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15345 s, 870 iter, 8700000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-03-32\n",
      "  done: false\n",
      "  episode_len_mean: 139.02\n",
      "  episode_reward_max: 224.0563519270262\n",
      "  episode_reward_mean: 181.09153127430997\n",
      "  episode_reward_min: 85.23114450939804\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66015\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.831347503154286e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.127624750137329\n",
      "      kl: 0.013546385802328587\n",
      "      policy_loss: 6.387105531757697e-05\n",
      "      total_loss: 30.76508331298828\n",
      "      vf_explained_var: 0.9906805753707886\n",
      "      vf_loss: 30.7650146484375\n",
      "    grad_time_ms: 1550.958\n",
      "    load_time_ms: 1.267\n",
      "    num_steps_sampled: 8710000\n",
      "    num_steps_trained: 8710000\n",
      "    sample_time_ms: 15779.689\n",
      "    update_time_ms: 4.678\n",
      "  iterations_since_restore: 871\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15363.263483047485\n",
      "  time_this_iter_s: 17.57547950744629\n",
      "  time_total_s: 15363.263483047485\n",
      "  timestamp: 1550631812\n",
      "  timesteps_since_restore: 8710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8710000\n",
      "  training_iteration: 871\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15363 s, 871 iter, 8710000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-03-50\n",
      "  done: false\n",
      "  episode_len_mean: 136.12\n",
      "  episode_reward_max: 222.21466663221616\n",
      "  episode_reward_mean: 183.61932423598577\n",
      "  episode_reward_min: 96.73184402895575\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66088\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.831347503154286e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9566531181335449\n",
      "      kl: 0.029965877532958984\n",
      "      policy_loss: 0.004241931717842817\n",
      "      total_loss: 32.87688446044922\n",
      "      vf_explained_var: 0.9904597401618958\n",
      "      vf_loss: 32.872650146484375\n",
      "    grad_time_ms: 1552.685\n",
      "    load_time_ms: 1.314\n",
      "    num_steps_sampled: 8720000\n",
      "    num_steps_trained: 8720000\n",
      "    sample_time_ms: 15741.496\n",
      "    update_time_ms: 4.829\n",
      "  iterations_since_restore: 872\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15380.800426006317\n",
      "  time_this_iter_s: 17.536942958831787\n",
      "  time_total_s: 15380.800426006317\n",
      "  timestamp: 1550631830\n",
      "  timesteps_since_restore: 8720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8720000\n",
      "  training_iteration: 872\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15380 s, 872 iter, 8720000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-04-07\n",
      "  done: false\n",
      "  episode_len_mean: 138.48\n",
      "  episode_reward_max: 225.37416683718354\n",
      "  episode_reward_mean: 178.6594732870775\n",
      "  episode_reward_min: 82.4647221018624\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 66160\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.831347503154286e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.252458095550537\n",
      "      kl: 0.02764355204999447\n",
      "      policy_loss: 0.00037236674688756466\n",
      "      total_loss: 55.70250701904297\n",
      "      vf_explained_var: 0.9847140908241272\n",
      "      vf_loss: 55.70212173461914\n",
      "    grad_time_ms: 1554.187\n",
      "    load_time_ms: 1.346\n",
      "    num_steps_sampled: 8730000\n",
      "    num_steps_trained: 8730000\n",
      "    sample_time_ms: 15753.072\n",
      "    update_time_ms: 4.749\n",
      "  iterations_since_restore: 873\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15398.01950263977\n",
      "  time_this_iter_s: 17.21907663345337\n",
      "  time_total_s: 15398.01950263977\n",
      "  timestamp: 1550631847\n",
      "  timesteps_since_restore: 8730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8730000\n",
      "  training_iteration: 873\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15398 s, 873 iter, 8730000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-04-25\n",
      "  done: false\n",
      "  episode_len_mean: 138.33\n",
      "  episode_reward_max: 232.17142954833898\n",
      "  episode_reward_mean: 177.9206173126232\n",
      "  episode_reward_min: 81.23378626485857\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66233\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.831347503154286e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0644855499267578\n",
      "      kl: 0.01792370155453682\n",
      "      policy_loss: -0.0022688943427056074\n",
      "      total_loss: 46.23807907104492\n",
      "      vf_explained_var: 0.9868375062942505\n",
      "      vf_loss: 46.240352630615234\n",
      "    grad_time_ms: 1556.347\n",
      "    load_time_ms: 1.388\n",
      "    num_steps_sampled: 8740000\n",
      "    num_steps_trained: 8740000\n",
      "    sample_time_ms: 15797.98\n",
      "    update_time_ms: 4.681\n",
      "  iterations_since_restore: 874\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15415.607498168945\n",
      "  time_this_iter_s: 17.587995529174805\n",
      "  time_total_s: 15415.607498168945\n",
      "  timestamp: 1550631865\n",
      "  timesteps_since_restore: 8740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8740000\n",
      "  training_iteration: 874\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15415 s, 874 iter, 8740000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-04-42\n",
      "  done: false\n",
      "  episode_len_mean: 136.81\n",
      "  episode_reward_max: 224.26204389676724\n",
      "  episode_reward_mean: 177.3485120575282\n",
      "  episode_reward_min: -37.349600803143915\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66306\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.831347503154286e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.093835711479187\n",
      "      kl: 0.042222484946250916\n",
      "      policy_loss: 0.0013624413404613733\n",
      "      total_loss: 96.52171325683594\n",
      "      vf_explained_var: 0.9726887941360474\n",
      "      vf_loss: 96.52035522460938\n",
      "    grad_time_ms: 1555.785\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 8750000\n",
      "    num_steps_trained: 8750000\n",
      "    sample_time_ms: 15762.882\n",
      "    update_time_ms: 4.636\n",
      "  iterations_since_restore: 875\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15432.908993721008\n",
      "  time_this_iter_s: 17.30149555206299\n",
      "  time_total_s: 15432.908993721008\n",
      "  timestamp: 1550631882\n",
      "  timesteps_since_restore: 8750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8750000\n",
      "  training_iteration: 875\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15432 s, 875 iter, 8750000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-04-59\n",
      "  done: false\n",
      "  episode_len_mean: 137.81\n",
      "  episode_reward_max: 224.26204389676724\n",
      "  episode_reward_mean: 179.57067166550314\n",
      "  episode_reward_min: -37.349600803143915\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 66378\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1812396049499512\n",
      "      kl: 0.02244052104651928\n",
      "      policy_loss: 0.001347821205854416\n",
      "      total_loss: 21.842857360839844\n",
      "      vf_explained_var: 0.9928691387176514\n",
      "      vf_loss: 21.841510772705078\n",
      "    grad_time_ms: 1558.621\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 8760000\n",
      "    num_steps_trained: 8760000\n",
      "    sample_time_ms: 15744.112\n",
      "    update_time_ms: 4.596\n",
      "  iterations_since_restore: 876\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15450.19571352005\n",
      "  time_this_iter_s: 17.286719799041748\n",
      "  time_total_s: 15450.19571352005\n",
      "  timestamp: 1550631899\n",
      "  timesteps_since_restore: 8760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8760000\n",
      "  training_iteration: 876\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15450 s, 876 iter, 8760000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-05-16\n",
      "  done: false\n",
      "  episode_len_mean: 137.65\n",
      "  episode_reward_max: 221.6999153004829\n",
      "  episode_reward_mean: 176.82077306176768\n",
      "  episode_reward_min: 64.74683960600947\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66451\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1374733448028564\n",
      "      kl: 0.016307605430483818\n",
      "      policy_loss: 0.001160254469141364\n",
      "      total_loss: 36.959922790527344\n",
      "      vf_explained_var: 0.9885879755020142\n",
      "      vf_loss: 36.958770751953125\n",
      "    grad_time_ms: 1540.815\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 8770000\n",
      "    num_steps_trained: 8770000\n",
      "    sample_time_ms: 15726.995\n",
      "    update_time_ms: 4.621\n",
      "  iterations_since_restore: 877\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15467.139265298843\n",
      "  time_this_iter_s: 16.943551778793335\n",
      "  time_total_s: 15467.139265298843\n",
      "  timestamp: 1550631916\n",
      "  timesteps_since_restore: 8770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8770000\n",
      "  training_iteration: 877\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15467 s, 877 iter, 8770000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-05-34\n",
      "  done: false\n",
      "  episode_len_mean: 137.41\n",
      "  episode_reward_max: 229.6710301870757\n",
      "  episode_reward_mean: 177.82612249295252\n",
      "  episode_reward_min: -37.50783256729048\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 66523\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1575266122817993\n",
      "      kl: 0.03210305795073509\n",
      "      policy_loss: 0.0011978260008618236\n",
      "      total_loss: 63.85070037841797\n",
      "      vf_explained_var: 0.9818452596664429\n",
      "      vf_loss: 63.84950256347656\n",
      "    grad_time_ms: 1542.192\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 8780000\n",
      "    num_steps_trained: 8780000\n",
      "    sample_time_ms: 15746.981\n",
      "    update_time_ms: 4.666\n",
      "  iterations_since_restore: 878\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15484.598903894424\n",
      "  time_this_iter_s: 17.459638595581055\n",
      "  time_total_s: 15484.598903894424\n",
      "  timestamp: 1550631934\n",
      "  timesteps_since_restore: 8780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8780000\n",
      "  training_iteration: 878\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15484 s, 878 iter, 8780000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-05-51\n",
      "  done: false\n",
      "  episode_len_mean: 138.07\n",
      "  episode_reward_max: 220.82375160014578\n",
      "  episode_reward_mean: 178.97323587375038\n",
      "  episode_reward_min: 85.51490473636602\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 66597\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0316401720046997\n",
      "      kl: 0.027896765619516373\n",
      "      policy_loss: -0.00032564287539571524\n",
      "      total_loss: 38.99850845336914\n",
      "      vf_explained_var: 0.9881805181503296\n",
      "      vf_loss: 38.998836517333984\n",
      "    grad_time_ms: 1543.192\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 8790000\n",
      "    num_steps_trained: 8790000\n",
      "    sample_time_ms: 15741.174\n",
      "    update_time_ms: 4.746\n",
      "  iterations_since_restore: 879\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15501.871381998062\n",
      "  time_this_iter_s: 17.272478103637695\n",
      "  time_total_s: 15501.871381998062\n",
      "  timestamp: 1550631951\n",
      "  timesteps_since_restore: 8790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8790000\n",
      "  training_iteration: 879\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15501 s, 879 iter, 8790000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-06-09\n",
      "  done: false\n",
      "  episode_len_mean: 137.58\n",
      "  episode_reward_max: 221.3631039324152\n",
      "  episode_reward_mean: 181.087268270989\n",
      "  episode_reward_min: 85.51490473636602\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66670\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0816341638565063\n",
      "      kl: 0.021076027303934097\n",
      "      policy_loss: 0.0020436663180589676\n",
      "      total_loss: 15.76992130279541\n",
      "      vf_explained_var: 0.995088517665863\n",
      "      vf_loss: 15.767878532409668\n",
      "    grad_time_ms: 1545.748\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 8800000\n",
      "    num_steps_trained: 8800000\n",
      "    sample_time_ms: 15839.126\n",
      "    update_time_ms: 4.761\n",
      "  iterations_since_restore: 880\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15519.731835126877\n",
      "  time_this_iter_s: 17.860453128814697\n",
      "  time_total_s: 15519.731835126877\n",
      "  timestamp: 1550631969\n",
      "  timesteps_since_restore: 8800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8800000\n",
      "  training_iteration: 880\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15519 s, 880 iter, 8800000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-06-26\n",
      "  done: false\n",
      "  episode_len_mean: 136.75\n",
      "  episode_reward_max: 227.03877880560725\n",
      "  episode_reward_mean: 180.61981987581555\n",
      "  episode_reward_min: -32.30568041482776\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66743\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8553271889686584\n",
      "      kl: 0.022857127711176872\n",
      "      policy_loss: -0.0016475599259138107\n",
      "      total_loss: 76.90555572509766\n",
      "      vf_explained_var: 0.9773977398872375\n",
      "      vf_loss: 76.9072036743164\n",
      "    grad_time_ms: 1545.0\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 8810000\n",
      "    num_steps_trained: 8810000\n",
      "    sample_time_ms: 15783.348\n",
      "    update_time_ms: 4.71\n",
      "  iterations_since_restore: 881\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15536.742806196213\n",
      "  time_this_iter_s: 17.010971069335938\n",
      "  time_total_s: 15536.742806196213\n",
      "  timestamp: 1550631986\n",
      "  timesteps_since_restore: 8810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8810000\n",
      "  training_iteration: 881\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15536 s, 881 iter, 8810000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-06-43\n",
      "  done: false\n",
      "  episode_len_mean: 136.04\n",
      "  episode_reward_max: 227.09771297665515\n",
      "  episode_reward_mean: 173.63780620439357\n",
      "  episode_reward_min: -32.30568041482776\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66816\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1637908220291138\n",
      "      kl: 0.02192017436027527\n",
      "      policy_loss: -0.0018502912716940045\n",
      "      total_loss: 38.0733757019043\n",
      "      vf_explained_var: 0.9877704977989197\n",
      "      vf_loss: 38.07522201538086\n",
      "    grad_time_ms: 1545.424\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 8820000\n",
      "    num_steps_trained: 8820000\n",
      "    sample_time_ms: 15737.623\n",
      "    update_time_ms: 4.472\n",
      "  iterations_since_restore: 882\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15553.821786880493\n",
      "  time_this_iter_s: 17.078980684280396\n",
      "  time_total_s: 15553.821786880493\n",
      "  timestamp: 1550632003\n",
      "  timesteps_since_restore: 8820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8820000\n",
      "  training_iteration: 882\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15553 s, 882 iter, 8820000 ts, 174 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-07-01\n",
      "  done: false\n",
      "  episode_len_mean: 138.0\n",
      "  episode_reward_max: 224.21683647616376\n",
      "  episode_reward_mean: 181.98916475481525\n",
      "  episode_reward_min: 75.37541892364763\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 66888\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1417324542999268\n",
      "      kl: 0.023861965164542198\n",
      "      policy_loss: -0.00044173808419145644\n",
      "      total_loss: 34.51702117919922\n",
      "      vf_explained_var: 0.9893770217895508\n",
      "      vf_loss: 34.51746368408203\n",
      "    grad_time_ms: 1546.791\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 8830000\n",
      "    num_steps_trained: 8830000\n",
      "    sample_time_ms: 15760.824\n",
      "    update_time_ms: 4.524\n",
      "  iterations_since_restore: 883\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15571.288043737411\n",
      "  time_this_iter_s: 17.466256856918335\n",
      "  time_total_s: 15571.288043737411\n",
      "  timestamp: 1550632021\n",
      "  timesteps_since_restore: 8830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8830000\n",
      "  training_iteration: 883\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15571 s, 883 iter, 8830000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-07-18\n",
      "  done: false\n",
      "  episode_len_mean: 139.76\n",
      "  episode_reward_max: 227.24406057013448\n",
      "  episode_reward_mean: 182.45625460609855\n",
      "  episode_reward_min: 94.43471218380009\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 66960\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.275029182434082\n",
      "      kl: 0.017168546095490456\n",
      "      policy_loss: -0.0014054663479328156\n",
      "      total_loss: 18.0104923248291\n",
      "      vf_explained_var: 0.9939898252487183\n",
      "      vf_loss: 18.011899948120117\n",
      "    grad_time_ms: 1546.81\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 8840000\n",
      "    num_steps_trained: 8840000\n",
      "    sample_time_ms: 15769.881\n",
      "    update_time_ms: 4.471\n",
      "  iterations_since_restore: 884\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15588.964053630829\n",
      "  time_this_iter_s: 17.67600989341736\n",
      "  time_total_s: 15588.964053630829\n",
      "  timestamp: 1550632038\n",
      "  timesteps_since_restore: 8840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8840000\n",
      "  training_iteration: 884\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15588 s, 884 iter, 8840000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-07-36\n",
      "  done: false\n",
      "  episode_len_mean: 137.64\n",
      "  episode_reward_max: 229.97638392042703\n",
      "  episode_reward_mean: 181.2424884699834\n",
      "  episode_reward_min: 119.33883230775442\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 67033\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0385297536849976\n",
      "      kl: 0.023568592965602875\n",
      "      policy_loss: 0.0013584031257778406\n",
      "      total_loss: 23.517995834350586\n",
      "      vf_explained_var: 0.9925567507743835\n",
      "      vf_loss: 23.516639709472656\n",
      "    grad_time_ms: 1546.923\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 8850000\n",
      "    num_steps_trained: 8850000\n",
      "    sample_time_ms: 15806.985\n",
      "    update_time_ms: 4.41\n",
      "  iterations_since_restore: 885\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15606.637871980667\n",
      "  time_this_iter_s: 17.673818349838257\n",
      "  time_total_s: 15606.637871980667\n",
      "  timestamp: 1550632056\n",
      "  timesteps_since_restore: 8850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8850000\n",
      "  training_iteration: 885\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15606 s, 885 iter, 8850000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-07-54\n",
      "  done: false\n",
      "  episode_len_mean: 137.64\n",
      "  episode_reward_max: 229.97638392042703\n",
      "  episode_reward_mean: 179.20364607357243\n",
      "  episode_reward_min: 60.07509535558464\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 67105\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2150540351867676\n",
      "      kl: 0.015178067609667778\n",
      "      policy_loss: -0.003260080236941576\n",
      "      total_loss: 43.289466857910156\n",
      "      vf_explained_var: 0.9864524602890015\n",
      "      vf_loss: 43.292724609375\n",
      "    grad_time_ms: 1564.115\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 8860000\n",
      "    num_steps_trained: 8860000\n",
      "    sample_time_ms: 15875.768\n",
      "    update_time_ms: 4.365\n",
      "  iterations_since_restore: 886\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15624.783856630325\n",
      "  time_this_iter_s: 18.145984649658203\n",
      "  time_total_s: 15624.783856630325\n",
      "  timestamp: 1550632074\n",
      "  timesteps_since_restore: 8860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8860000\n",
      "  training_iteration: 886\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15624 s, 886 iter, 8860000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-08-12\n",
      "  done: false\n",
      "  episode_len_mean: 137.2\n",
      "  episode_reward_max: 229.9769614148554\n",
      "  episode_reward_mean: 179.78548355779273\n",
      "  episode_reward_min: -41.28209953910054\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 67178\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.09735107421875\n",
      "      kl: 0.034344322979450226\n",
      "      policy_loss: -0.0016152157913893461\n",
      "      total_loss: 64.44929504394531\n",
      "      vf_explained_var: 0.979729175567627\n",
      "      vf_loss: 64.45091247558594\n",
      "    grad_time_ms: 1564.324\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 8870000\n",
      "    num_steps_trained: 8870000\n",
      "    sample_time_ms: 15940.477\n",
      "    update_time_ms: 4.422\n",
      "  iterations_since_restore: 887\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15642.378254652023\n",
      "  time_this_iter_s: 17.594398021697998\n",
      "  time_total_s: 15642.378254652023\n",
      "  timestamp: 1550632092\n",
      "  timesteps_since_restore: 8870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8870000\n",
      "  training_iteration: 887\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15642 s, 887 iter, 8870000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-08-29\n",
      "  done: false\n",
      "  episode_len_mean: 140.71\n",
      "  episode_reward_max: 229.9769614148554\n",
      "  episode_reward_mean: 179.80585929817505\n",
      "  episode_reward_min: -41.28209953910054\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 67249\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1400105953216553\n",
      "      kl: 0.018140627071261406\n",
      "      policy_loss: -0.00138817576225847\n",
      "      total_loss: 44.104618072509766\n",
      "      vf_explained_var: 0.9872349500656128\n",
      "      vf_loss: 44.10600280761719\n",
      "    grad_time_ms: 1565.407\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 8880000\n",
      "    num_steps_trained: 8880000\n",
      "    sample_time_ms: 15929.738\n",
      "    update_time_ms: 4.415\n",
      "  iterations_since_restore: 888\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15659.740054368973\n",
      "  time_this_iter_s: 17.361799716949463\n",
      "  time_total_s: 15659.740054368973\n",
      "  timestamp: 1550632109\n",
      "  timesteps_since_restore: 8880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8880000\n",
      "  training_iteration: 888\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15659 s, 888 iter, 8880000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-08-47\n",
      "  done: false\n",
      "  episode_len_mean: 137.75\n",
      "  episode_reward_max: 224.4633824756314\n",
      "  episode_reward_mean: 179.8671729455466\n",
      "  episode_reward_min: 76.99582650991943\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 67322\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0180606842041016\n",
      "      kl: 0.020218154415488243\n",
      "      policy_loss: -0.0007106910343281925\n",
      "      total_loss: 9.456083297729492\n",
      "      vf_explained_var: 0.996933102607727\n",
      "      vf_loss: 9.456794738769531\n",
      "    grad_time_ms: 1564.016\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 8890000\n",
      "    num_steps_trained: 8890000\n",
      "    sample_time_ms: 15943.543\n",
      "    update_time_ms: 4.334\n",
      "  iterations_since_restore: 889\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15677.133152723312\n",
      "  time_this_iter_s: 17.3930983543396\n",
      "  time_total_s: 15677.133152723312\n",
      "  timestamp: 1550632127\n",
      "  timesteps_since_restore: 8890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8890000\n",
      "  training_iteration: 889\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15677 s, 889 iter, 8890000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-09-04\n",
      "  done: false\n",
      "  episode_len_mean: 138.54\n",
      "  episode_reward_max: 225.97456000535053\n",
      "  episode_reward_mean: 182.72095475252416\n",
      "  episode_reward_min: 74.41982930618346\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 67394\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0234912633895874\n",
      "      kl: 0.016355276107788086\n",
      "      policy_loss: -0.0007242629071697593\n",
      "      total_loss: 44.67317581176758\n",
      "      vf_explained_var: 0.9861364960670471\n",
      "      vf_loss: 44.67390441894531\n",
      "    grad_time_ms: 1559.844\n",
      "    load_time_ms: 1.406\n",
      "    num_steps_sampled: 8900000\n",
      "    num_steps_trained: 8900000\n",
      "    sample_time_ms: 15912.376\n",
      "    update_time_ms: 4.183\n",
      "  iterations_since_restore: 890\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15694.638127088547\n",
      "  time_this_iter_s: 17.504974365234375\n",
      "  time_total_s: 15694.638127088547\n",
      "  timestamp: 1550632144\n",
      "  timesteps_since_restore: 8900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8900000\n",
      "  training_iteration: 890\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15694 s, 890 iter, 8900000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-09-22\n",
      "  done: false\n",
      "  episode_len_mean: 138.15\n",
      "  episode_reward_max: 225.92880026015018\n",
      "  episode_reward_mean: 179.10784900503498\n",
      "  episode_reward_min: 74.41982930618346\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 67466\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0543166399002075\n",
      "      kl: 0.01539622526615858\n",
      "      policy_loss: -0.0004371795803308487\n",
      "      total_loss: 38.75164794921875\n",
      "      vf_explained_var: 0.9883022904396057\n",
      "      vf_loss: 38.752079010009766\n",
      "    grad_time_ms: 1560.043\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 8910000\n",
      "    num_steps_trained: 8910000\n",
      "    sample_time_ms: 15938.608\n",
      "    update_time_ms: 4.335\n",
      "  iterations_since_restore: 891\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15711.913303136826\n",
      "  time_this_iter_s: 17.27517604827881\n",
      "  time_total_s: 15711.913303136826\n",
      "  timestamp: 1550632162\n",
      "  timesteps_since_restore: 8910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8910000\n",
      "  training_iteration: 891\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15711 s, 891 iter, 8910000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-09-39\n",
      "  done: false\n",
      "  episode_len_mean: 138.47\n",
      "  episode_reward_max: 226.2134891329426\n",
      "  episode_reward_mean: 182.6878251839774\n",
      "  episode_reward_min: 93.59841101083649\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 67539\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.942664623260498\n",
      "      kl: 0.028422731906175613\n",
      "      policy_loss: 0.0018395871156826615\n",
      "      total_loss: 24.574615478515625\n",
      "      vf_explained_var: 0.9922230839729309\n",
      "      vf_loss: 24.572776794433594\n",
      "    grad_time_ms: 1557.841\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 8920000\n",
      "    num_steps_trained: 8920000\n",
      "    sample_time_ms: 15964.028\n",
      "    update_time_ms: 4.492\n",
      "  iterations_since_restore: 892\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15729.227228879929\n",
      "  time_this_iter_s: 17.313925743103027\n",
      "  time_total_s: 15729.227228879929\n",
      "  timestamp: 1550632179\n",
      "  timesteps_since_restore: 8920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8920000\n",
      "  training_iteration: 892\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15729 s, 892 iter, 8920000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-09-57\n",
      "  done: false\n",
      "  episode_len_mean: 139.35\n",
      "  episode_reward_max: 226.2134891329426\n",
      "  episode_reward_mean: 183.07895620667787\n",
      "  episode_reward_min: 92.34412143143399\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 67610\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.019295573234558\n",
      "      kl: 0.02409430779516697\n",
      "      policy_loss: -0.0018477272242307663\n",
      "      total_loss: 28.1355037689209\n",
      "      vf_explained_var: 0.9911012053489685\n",
      "      vf_loss: 28.137344360351562\n",
      "    grad_time_ms: 1553.524\n",
      "    load_time_ms: 1.319\n",
      "    num_steps_sampled: 8930000\n",
      "    num_steps_trained: 8930000\n",
      "    sample_time_ms: 16040.926\n",
      "    update_time_ms: 4.594\n",
      "  iterations_since_restore: 893\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15747.417763233185\n",
      "  time_this_iter_s: 18.190534353256226\n",
      "  time_total_s: 15747.417763233185\n",
      "  timestamp: 1550632197\n",
      "  timesteps_since_restore: 8930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8930000\n",
      "  training_iteration: 893\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15747 s, 893 iter, 8930000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-10-14\n",
      "  done: false\n",
      "  episode_len_mean: 138.75\n",
      "  episode_reward_max: 222.54809235150714\n",
      "  episode_reward_mean: 179.515859647418\n",
      "  episode_reward_min: 92.34412143143399\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 67683\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9549316763877869\n",
      "      kl: 0.026047345250844955\n",
      "      policy_loss: 0.00015765332500450313\n",
      "      total_loss: 48.979549407958984\n",
      "      vf_explained_var: 0.9851881861686707\n",
      "      vf_loss: 48.979393005371094\n",
      "    grad_time_ms: 1551.468\n",
      "    load_time_ms: 1.374\n",
      "    num_steps_sampled: 8940000\n",
      "    num_steps_trained: 8940000\n",
      "    sample_time_ms: 15964.818\n",
      "    update_time_ms: 4.586\n",
      "  iterations_since_restore: 894\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15764.314777135849\n",
      "  time_this_iter_s: 16.897013902664185\n",
      "  time_total_s: 15764.314777135849\n",
      "  timestamp: 1550632214\n",
      "  timesteps_since_restore: 8940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8940000\n",
      "  training_iteration: 894\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15764 s, 894 iter, 8940000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-10-32\n",
      "  done: false\n",
      "  episode_len_mean: 137.94\n",
      "  episode_reward_max: 219.03141650288268\n",
      "  episode_reward_mean: 181.33378288203377\n",
      "  episode_reward_min: 102.07051708984494\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 67755\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0821083784103394\n",
      "      kl: 0.0286728348582983\n",
      "      policy_loss: 0.00029547445592470467\n",
      "      total_loss: 8.894444465637207\n",
      "      vf_explained_var: 0.9970599412918091\n",
      "      vf_loss: 8.894149780273438\n",
      "    grad_time_ms: 1551.074\n",
      "    load_time_ms: 1.348\n",
      "    num_steps_sampled: 8950000\n",
      "    num_steps_trained: 8950000\n",
      "    sample_time_ms: 15958.146\n",
      "    update_time_ms: 4.617\n",
      "  iterations_since_restore: 895\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15781.916975975037\n",
      "  time_this_iter_s: 17.602198839187622\n",
      "  time_total_s: 15781.916975975037\n",
      "  timestamp: 1550632232\n",
      "  timesteps_since_restore: 8950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8950000\n",
      "  training_iteration: 895\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15781 s, 895 iter, 8950000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-10-49\n",
      "  done: false\n",
      "  episode_len_mean: 138.99\n",
      "  episode_reward_max: 224.51607409329853\n",
      "  episode_reward_mean: 179.89900379706526\n",
      "  episode_reward_min: 67.8086505246414\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 67827\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9297156929969788\n",
      "      kl: 0.019419485703110695\n",
      "      policy_loss: -0.0009530639508739114\n",
      "      total_loss: 37.33074951171875\n",
      "      vf_explained_var: 0.9889578223228455\n",
      "      vf_loss: 37.331703186035156\n",
      "    grad_time_ms: 1532.982\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 8960000\n",
      "    num_steps_trained: 8960000\n",
      "    sample_time_ms: 15896.727\n",
      "    update_time_ms: 4.646\n",
      "  iterations_since_restore: 896\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15799.26777434349\n",
      "  time_this_iter_s: 17.35079836845398\n",
      "  time_total_s: 15799.26777434349\n",
      "  timestamp: 1550632249\n",
      "  timesteps_since_restore: 8960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8960000\n",
      "  training_iteration: 896\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15799 s, 896 iter, 8960000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 139.12\n",
      "  episode_reward_max: 225.52345885461807\n",
      "  episode_reward_mean: 182.91585632389112\n",
      "  episode_reward_min: 94.10016549658945\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 67899\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8001816868782043\n",
      "      kl: 0.017430976033210754\n",
      "      policy_loss: 0.0007908252300694585\n",
      "      total_loss: 22.796812057495117\n",
      "      vf_explained_var: 0.9932520985603333\n",
      "      vf_loss: 22.7960262298584\n",
      "    grad_time_ms: 1531.647\n",
      "    load_time_ms: 1.37\n",
      "    num_steps_sampled: 8970000\n",
      "    num_steps_trained: 8970000\n",
      "    sample_time_ms: 15885.418\n",
      "    update_time_ms: 4.623\n",
      "  iterations_since_restore: 897\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15816.73381471634\n",
      "  time_this_iter_s: 17.46604037284851\n",
      "  time_total_s: 15816.73381471634\n",
      "  timestamp: 1550632267\n",
      "  timesteps_since_restore: 8970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8970000\n",
      "  training_iteration: 897\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15816 s, 897 iter, 8970000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-11-24\n",
      "  done: false\n",
      "  episode_len_mean: 138.84\n",
      "  episode_reward_max: 227.86728482663915\n",
      "  episode_reward_mean: 184.3188469714808\n",
      "  episode_reward_min: 73.19598264903718\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 67971\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8784165978431702\n",
      "      kl: 0.0155152827501297\n",
      "      policy_loss: -0.0006440929719246924\n",
      "      total_loss: 39.712520599365234\n",
      "      vf_explained_var: 0.9883337616920471\n",
      "      vf_loss: 39.71316146850586\n",
      "    grad_time_ms: 1549.686\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 8980000\n",
      "    num_steps_trained: 8980000\n",
      "    sample_time_ms: 15863.497\n",
      "    update_time_ms: 4.582\n",
      "  iterations_since_restore: 898\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15834.055661678314\n",
      "  time_this_iter_s: 17.321846961975098\n",
      "  time_total_s: 15834.055661678314\n",
      "  timestamp: 1550632284\n",
      "  timesteps_since_restore: 8980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8980000\n",
      "  training_iteration: 898\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15834 s, 898 iter, 8980000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-11-41\n",
      "  done: false\n",
      "  episode_len_mean: 137.38\n",
      "  episode_reward_max: 227.86728482663915\n",
      "  episode_reward_mean: 184.70210113984274\n",
      "  episode_reward_min: 86.1884558456074\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 68044\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7579354643821716\n",
      "      kl: 0.0204923152923584\n",
      "      policy_loss: -0.0001324669283349067\n",
      "      total_loss: 26.681488037109375\n",
      "      vf_explained_var: 0.9917761087417603\n",
      "      vf_loss: 26.68161964416504\n",
      "    grad_time_ms: 1549.533\n",
      "    load_time_ms: 1.359\n",
      "    num_steps_sampled: 8990000\n",
      "    num_steps_trained: 8990000\n",
      "    sample_time_ms: 15822.317\n",
      "    update_time_ms: 4.541\n",
      "  iterations_since_restore: 899\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15851.03586602211\n",
      "  time_this_iter_s: 16.980204343795776\n",
      "  time_total_s: 15851.03586602211\n",
      "  timestamp: 1550632301\n",
      "  timesteps_since_restore: 8990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8990000\n",
      "  training_iteration: 899\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15851 s, 899 iter, 8990000 ts, 185 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-11-59\n",
      "  done: false\n",
      "  episode_len_mean: 138.21\n",
      "  episode_reward_max: 223.89317611936883\n",
      "  episode_reward_mean: 180.74854324909552\n",
      "  episode_reward_min: -39.57296760040934\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 68115\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.7470213193549145e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0232303142547607\n",
      "      kl: 0.041052449494600296\n",
      "      policy_loss: -0.0008745959494262934\n",
      "      total_loss: 129.35067749023438\n",
      "      vf_explained_var: 0.964601457118988\n",
      "      vf_loss: 129.35153198242188\n",
      "    grad_time_ms: 1553.64\n",
      "    load_time_ms: 1.358\n",
      "    num_steps_sampled: 9000000\n",
      "    num_steps_trained: 9000000\n",
      "    sample_time_ms: 15860.145\n",
      "    update_time_ms: 4.702\n",
      "  iterations_since_restore: 900\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15868.960942268372\n",
      "  time_this_iter_s: 17.925076246261597\n",
      "  time_total_s: 15868.960942268372\n",
      "  timestamp: 1550632319\n",
      "  timesteps_since_restore: 9000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9000000\n",
      "  training_iteration: 900\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15868 s, 900 iter, 9000000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-12-16\n",
      "  done: false\n",
      "  episode_len_mean: 139.67\n",
      "  episode_reward_max: 223.61348656107583\n",
      "  episode_reward_mean: 185.05706830708723\n",
      "  episode_reward_min: 96.23428090160132\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 68188\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9042773246765137\n",
      "      kl: 0.033278509974479675\n",
      "      policy_loss: 0.001152863958850503\n",
      "      total_loss: 19.88512420654297\n",
      "      vf_explained_var: 0.993772566318512\n",
      "      vf_loss: 19.883968353271484\n",
      "    grad_time_ms: 1553.845\n",
      "    load_time_ms: 1.389\n",
      "    num_steps_sampled: 9010000\n",
      "    num_steps_trained: 9010000\n",
      "    sample_time_ms: 15855.481\n",
      "    update_time_ms: 4.526\n",
      "  iterations_since_restore: 901\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15886.190084934235\n",
      "  time_this_iter_s: 17.229142665863037\n",
      "  time_total_s: 15886.190084934235\n",
      "  timestamp: 1550632336\n",
      "  timesteps_since_restore: 9010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9010000\n",
      "  training_iteration: 901\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15886 s, 901 iter, 9010000 ts, 185 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-12-33\n",
      "  done: false\n",
      "  episode_len_mean: 137.56\n",
      "  episode_reward_max: 224.31167768576356\n",
      "  episode_reward_mean: 186.58462995440354\n",
      "  episode_reward_min: 98.90554664453651\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68260\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6060064435005188\n",
      "      kl: 0.014103097841143608\n",
      "      policy_loss: 0.0009994521969929338\n",
      "      total_loss: 36.11745834350586\n",
      "      vf_explained_var: 0.9896820187568665\n",
      "      vf_loss: 36.11646270751953\n",
      "    grad_time_ms: 1554.46\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 9020000\n",
      "    num_steps_trained: 9020000\n",
      "    sample_time_ms: 15816.571\n",
      "    update_time_ms: 4.496\n",
      "  iterations_since_restore: 902\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15903.120147705078\n",
      "  time_this_iter_s: 16.930062770843506\n",
      "  time_total_s: 15903.120147705078\n",
      "  timestamp: 1550632353\n",
      "  timesteps_since_restore: 9020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9020000\n",
      "  training_iteration: 902\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15903 s, 902 iter, 9020000 ts, 187 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-12-50\n",
      "  done: false\n",
      "  episode_len_mean: 139.03\n",
      "  episode_reward_max: 223.70006561876824\n",
      "  episode_reward_mean: 184.46807048614667\n",
      "  episode_reward_min: 87.21716721704016\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68332\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9456678628921509\n",
      "      kl: 0.017430776730179787\n",
      "      policy_loss: -0.0007872350397519767\n",
      "      total_loss: 43.82168197631836\n",
      "      vf_explained_var: 0.9868133664131165\n",
      "      vf_loss: 43.822471618652344\n",
      "    grad_time_ms: 1556.174\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 9030000\n",
      "    num_steps_trained: 9030000\n",
      "    sample_time_ms: 15713.154\n",
      "    update_time_ms: 4.346\n",
      "  iterations_since_restore: 903\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15920.292702913284\n",
      "  time_this_iter_s: 17.172555208206177\n",
      "  time_total_s: 15920.292702913284\n",
      "  timestamp: 1550632370\n",
      "  timesteps_since_restore: 9030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9030000\n",
      "  training_iteration: 903\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15920 s, 903 iter, 9030000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-13-08\n",
      "  done: false\n",
      "  episode_len_mean: 138.57\n",
      "  episode_reward_max: 228.43257800603996\n",
      "  episode_reward_mean: 179.00840084035784\n",
      "  episode_reward_min: 87.21716721704016\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68404\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8779943585395813\n",
      "      kl: 0.026245923712849617\n",
      "      policy_loss: -0.0012784225400537252\n",
      "      total_loss: 35.722076416015625\n",
      "      vf_explained_var: 0.9900467991828918\n",
      "      vf_loss: 35.72336196899414\n",
      "    grad_time_ms: 1556.865\n",
      "    load_time_ms: 1.302\n",
      "    num_steps_sampled: 9040000\n",
      "    num_steps_trained: 9040000\n",
      "    sample_time_ms: 15762.364\n",
      "    update_time_ms: 4.428\n",
      "  iterations_since_restore: 904\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15937.686926841736\n",
      "  time_this_iter_s: 17.394223928451538\n",
      "  time_total_s: 15937.686926841736\n",
      "  timestamp: 1550632388\n",
      "  timesteps_since_restore: 9040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9040000\n",
      "  training_iteration: 904\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15937 s, 904 iter, 9040000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-13-25\n",
      "  done: false\n",
      "  episode_len_mean: 138.59\n",
      "  episode_reward_max: 228.43257800603996\n",
      "  episode_reward_mean: 180.89897304956213\n",
      "  episode_reward_min: 91.65308669799637\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68476\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7735496163368225\n",
      "      kl: 0.03219220042228699\n",
      "      policy_loss: 0.0006825763266533613\n",
      "      total_loss: 19.358434677124023\n",
      "      vf_explained_var: 0.9940031170845032\n",
      "      vf_loss: 19.357749938964844\n",
      "    grad_time_ms: 1558.645\n",
      "    load_time_ms: 1.306\n",
      "    num_steps_sampled: 9050000\n",
      "    num_steps_trained: 9050000\n",
      "    sample_time_ms: 15737.071\n",
      "    update_time_ms: 4.449\n",
      "  iterations_since_restore: 905\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15955.054491519928\n",
      "  time_this_iter_s: 17.36756467819214\n",
      "  time_total_s: 15955.054491519928\n",
      "  timestamp: 1550632405\n",
      "  timesteps_since_restore: 9050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9050000\n",
      "  training_iteration: 905\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15955 s, 905 iter, 9050000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-13-43\n",
      "  done: false\n",
      "  episode_len_mean: 139.02\n",
      "  episode_reward_max: 231.10436975424835\n",
      "  episode_reward_mean: 180.34366208195033\n",
      "  episode_reward_min: -32.521568894976426\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68548\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.058213233947754\n",
      "      kl: 0.024696379899978638\n",
      "      policy_loss: -0.004104774910956621\n",
      "      total_loss: 89.01084899902344\n",
      "      vf_explained_var: 0.9735727310180664\n",
      "      vf_loss: 89.01496887207031\n",
      "    grad_time_ms: 1564.383\n",
      "    load_time_ms: 1.306\n",
      "    num_steps_sampled: 9060000\n",
      "    num_steps_trained: 9060000\n",
      "    sample_time_ms: 15714.153\n",
      "    update_time_ms: 4.438\n",
      "  iterations_since_restore: 906\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15972.23482298851\n",
      "  time_this_iter_s: 17.180331468582153\n",
      "  time_total_s: 15972.23482298851\n",
      "  timestamp: 1550632423\n",
      "  timesteps_since_restore: 9060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9060000\n",
      "  training_iteration: 906\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15972 s, 906 iter, 9060000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-14-00\n",
      "  done: false\n",
      "  episode_len_mean: 138.41\n",
      "  episode_reward_max: 224.40292142125062\n",
      "  episode_reward_mean: 178.77251847255616\n",
      "  episode_reward_min: -32.521568894976426\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68620\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.752766489982605\n",
      "      kl: 0.023372933268547058\n",
      "      policy_loss: 0.0005975595558993518\n",
      "      total_loss: 28.114219665527344\n",
      "      vf_explained_var: 0.9914196729660034\n",
      "      vf_loss: 28.11362648010254\n",
      "    grad_time_ms: 1565.939\n",
      "    load_time_ms: 1.324\n",
      "    num_steps_sampled: 9070000\n",
      "    num_steps_trained: 9070000\n",
      "    sample_time_ms: 15722.377\n",
      "    update_time_ms: 4.456\n",
      "  iterations_since_restore: 907\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 15989.801711559296\n",
      "  time_this_iter_s: 17.566888570785522\n",
      "  time_total_s: 15989.801711559296\n",
      "  timestamp: 1550632440\n",
      "  timesteps_since_restore: 9070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9070000\n",
      "  training_iteration: 907\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 15989 s, 907 iter, 9070000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-14-17\n",
      "  done: false\n",
      "  episode_len_mean: 139.03\n",
      "  episode_reward_max: 220.05969772502624\n",
      "  episode_reward_mean: 180.13763185518192\n",
      "  episode_reward_min: 99.89769877663048\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68692\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9971030950546265\n",
      "      kl: 0.017153015360236168\n",
      "      policy_loss: -0.0006535100401379168\n",
      "      total_loss: 40.30537796020508\n",
      "      vf_explained_var: 0.9877663850784302\n",
      "      vf_loss: 40.306034088134766\n",
      "    grad_time_ms: 1546.205\n",
      "    load_time_ms: 1.286\n",
      "    num_steps_sampled: 9080000\n",
      "    num_steps_trained: 9080000\n",
      "    sample_time_ms: 15699.009\n",
      "    update_time_ms: 4.476\n",
      "  iterations_since_restore: 908\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16006.694366693497\n",
      "  time_this_iter_s: 16.89265513420105\n",
      "  time_total_s: 16006.694366693497\n",
      "  timestamp: 1550632457\n",
      "  timesteps_since_restore: 9080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9080000\n",
      "  training_iteration: 908\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16006 s, 908 iter, 9080000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-14-34\n",
      "  done: false\n",
      "  episode_len_mean: 140.06\n",
      "  episode_reward_max: 226.45965359979644\n",
      "  episode_reward_mean: 179.34425798848883\n",
      "  episode_reward_min: 84.81227909407974\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 68763\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0783292055130005\n",
      "      kl: 0.025864392518997192\n",
      "      policy_loss: -0.0001965780829777941\n",
      "      total_loss: 21.362106323242188\n",
      "      vf_explained_var: 0.993381917476654\n",
      "      vf_loss: 21.362300872802734\n",
      "    grad_time_ms: 1546.393\n",
      "    load_time_ms: 1.285\n",
      "    num_steps_sampled: 9090000\n",
      "    num_steps_trained: 9090000\n",
      "    sample_time_ms: 15721.141\n",
      "    update_time_ms: 4.556\n",
      "  iterations_since_restore: 909\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16023.899236440659\n",
      "  time_this_iter_s: 17.204869747161865\n",
      "  time_total_s: 16023.899236440659\n",
      "  timestamp: 1550632474\n",
      "  timesteps_since_restore: 9090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9090000\n",
      "  training_iteration: 909\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16023 s, 909 iter, 9090000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-14-52\n",
      "  done: false\n",
      "  episode_len_mean: 138.41\n",
      "  episode_reward_max: 222.65368376196463\n",
      "  episode_reward_mean: 179.30430114518987\n",
      "  episode_reward_min: -39.797660565612325\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 68836\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8894675970077515\n",
      "      kl: 0.02457127720117569\n",
      "      policy_loss: -0.0041321939788758755\n",
      "      total_loss: 69.35420989990234\n",
      "      vf_explained_var: 0.9803795218467712\n",
      "      vf_loss: 69.35834503173828\n",
      "    grad_time_ms: 1544.359\n",
      "    load_time_ms: 1.287\n",
      "    num_steps_sampled: 9100000\n",
      "    num_steps_trained: 9100000\n",
      "    sample_time_ms: 15712.269\n",
      "    update_time_ms: 4.517\n",
      "  iterations_since_restore: 910\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16041.714348554611\n",
      "  time_this_iter_s: 17.815112113952637\n",
      "  time_total_s: 16041.714348554611\n",
      "  timestamp: 1550632492\n",
      "  timesteps_since_restore: 9100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9100000\n",
      "  training_iteration: 910\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16041 s, 910 iter, 9100000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-15-09\n",
      "  done: false\n",
      "  episode_len_mean: 137.04\n",
      "  episode_reward_max: 220.97394457437318\n",
      "  episode_reward_mean: 177.88486717722893\n",
      "  episode_reward_min: -39.797660565612325\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 68909\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9181381464004517\n",
      "      kl: 0.02722802758216858\n",
      "      policy_loss: 0.0010811944957822561\n",
      "      total_loss: 22.45013427734375\n",
      "      vf_explained_var: 0.9928416013717651\n",
      "      vf_loss: 22.449052810668945\n",
      "    grad_time_ms: 1544.498\n",
      "    load_time_ms: 1.248\n",
      "    num_steps_sampled: 9110000\n",
      "    num_steps_trained: 9110000\n",
      "    sample_time_ms: 15707.027\n",
      "    update_time_ms: 4.663\n",
      "  iterations_since_restore: 911\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16058.894577264786\n",
      "  time_this_iter_s: 17.18022871017456\n",
      "  time_total_s: 16058.894577264786\n",
      "  timestamp: 1550632509\n",
      "  timesteps_since_restore: 9110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9110000\n",
      "  training_iteration: 911\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16058 s, 911 iter, 9110000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-15-27\n",
      "  done: false\n",
      "  episode_len_mean: 138.52\n",
      "  episode_reward_max: 223.42729328082194\n",
      "  episode_reward_mean: 178.82829534939458\n",
      "  episode_reward_min: 97.88753356732929\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68981\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9375614523887634\n",
      "      kl: 0.026504607871174812\n",
      "      policy_loss: 9.178191248793155e-05\n",
      "      total_loss: 43.806243896484375\n",
      "      vf_explained_var: 0.9869123697280884\n",
      "      vf_loss: 43.80615234375\n",
      "    grad_time_ms: 1545.966\n",
      "    load_time_ms: 1.294\n",
      "    num_steps_sampled: 9120000\n",
      "    num_steps_trained: 9120000\n",
      "    sample_time_ms: 15791.218\n",
      "    update_time_ms: 4.565\n",
      "  iterations_since_restore: 912\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16076.683388471603\n",
      "  time_this_iter_s: 17.788811206817627\n",
      "  time_total_s: 16076.683388471603\n",
      "  timestamp: 1550632527\n",
      "  timesteps_since_restore: 9120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9120000\n",
      "  training_iteration: 912\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16076 s, 912 iter, 9120000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-15-46\n",
      "  done: false\n",
      "  episode_len_mean: 137.75\n",
      "  episode_reward_max: 225.99322526923868\n",
      "  episode_reward_mean: 181.94087244845804\n",
      "  episode_reward_min: 97.88753356732929\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 69053\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7430503368377686\n",
      "      kl: 0.028649428859353065\n",
      "      policy_loss: 0.00021841864509042352\n",
      "      total_loss: 18.42901039123535\n",
      "      vf_explained_var: 0.9942348003387451\n",
      "      vf_loss: 18.42879295349121\n",
      "    grad_time_ms: 1546.433\n",
      "    load_time_ms: 1.383\n",
      "    num_steps_sampled: 9130000\n",
      "    num_steps_trained: 9130000\n",
      "    sample_time_ms: 15907.48\n",
      "    update_time_ms: 4.649\n",
      "  iterations_since_restore: 913\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16095.027136802673\n",
      "  time_this_iter_s: 18.343748331069946\n",
      "  time_total_s: 16095.027136802673\n",
      "  timestamp: 1550632546\n",
      "  timesteps_since_restore: 9130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9130000\n",
      "  training_iteration: 913\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16095 s, 913 iter, 9130000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-16-03\n",
      "  done: false\n",
      "  episode_len_mean: 138.97\n",
      "  episode_reward_max: 223.89727142040087\n",
      "  episode_reward_mean: 179.06497644790264\n",
      "  episode_reward_min: 85.94403432914518\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 69125\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9804633855819702\n",
      "      kl: 0.019008178263902664\n",
      "      policy_loss: -0.002492231549695134\n",
      "      total_loss: 52.127525329589844\n",
      "      vf_explained_var: 0.9849483966827393\n",
      "      vf_loss: 52.13002395629883\n",
      "    grad_time_ms: 1547.233\n",
      "    load_time_ms: 1.374\n",
      "    num_steps_sampled: 9140000\n",
      "    num_steps_trained: 9140000\n",
      "    sample_time_ms: 15933.787\n",
      "    update_time_ms: 4.629\n",
      "  iterations_since_restore: 914\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16112.69280576706\n",
      "  time_this_iter_s: 17.665668964385986\n",
      "  time_total_s: 16112.69280576706\n",
      "  timestamp: 1550632563\n",
      "  timesteps_since_restore: 9140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9140000\n",
      "  training_iteration: 914\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16112 s, 914 iter, 9140000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-16-20\n",
      "  done: false\n",
      "  episode_len_mean: 138.43\n",
      "  episode_reward_max: 223.00131033703985\n",
      "  episode_reward_mean: 181.0363193953079\n",
      "  episode_reward_min: 85.94403432914518\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 69198\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8579142689704895\n",
      "      kl: 0.02491345815360546\n",
      "      policy_loss: 0.0005582303856499493\n",
      "      total_loss: 14.805888175964355\n",
      "      vf_explained_var: 0.9953227043151855\n",
      "      vf_loss: 14.805330276489258\n",
      "    grad_time_ms: 1546.796\n",
      "    load_time_ms: 1.322\n",
      "    num_steps_sampled: 9150000\n",
      "    num_steps_trained: 9150000\n",
      "    sample_time_ms: 15892.522\n",
      "    update_time_ms: 4.627\n",
      "  iterations_since_restore: 915\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16129.640671491623\n",
      "  time_this_iter_s: 16.9478657245636\n",
      "  time_total_s: 16129.640671491623\n",
      "  timestamp: 1550632580\n",
      "  timesteps_since_restore: 9150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9150000\n",
      "  training_iteration: 915\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16129 s, 915 iter, 9150000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-16-37\n",
      "  done: false\n",
      "  episode_len_mean: 137.62\n",
      "  episode_reward_max: 223.00131033703985\n",
      "  episode_reward_mean: 182.03280843189768\n",
      "  episode_reward_min: -39.5800245289165\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 69270\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8993107676506042\n",
      "      kl: 0.02644057758152485\n",
      "      policy_loss: -0.00428971741348505\n",
      "      total_loss: 60.46413803100586\n",
      "      vf_explained_var: 0.981212317943573\n",
      "      vf_loss: 60.46841812133789\n",
      "    grad_time_ms: 1539.879\n",
      "    load_time_ms: 1.284\n",
      "    num_steps_sampled: 9160000\n",
      "    num_steps_trained: 9160000\n",
      "    sample_time_ms: 15864.915\n",
      "    update_time_ms: 4.662\n",
      "  iterations_since_restore: 916\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16146.473535776138\n",
      "  time_this_iter_s: 16.83286428451538\n",
      "  time_total_s: 16146.473535776138\n",
      "  timestamp: 1550632597\n",
      "  timesteps_since_restore: 9160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9160000\n",
      "  training_iteration: 916\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16146 s, 916 iter, 9160000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-16-55\n",
      "  done: false\n",
      "  episode_len_mean: 141.17\n",
      "  episode_reward_max: 229.51912987280153\n",
      "  episode_reward_mean: 179.0210070690472\n",
      "  episode_reward_min: -37.77522130354797\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 69341\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1124979257583618\n",
      "      kl: 0.03235558047890663\n",
      "      policy_loss: 0.0020089817699044943\n",
      "      total_loss: 95.47437286376953\n",
      "      vf_explained_var: 0.9737074375152588\n",
      "      vf_loss: 95.47235870361328\n",
      "    grad_time_ms: 1543.274\n",
      "    load_time_ms: 1.281\n",
      "    num_steps_sampled: 9170000\n",
      "    num_steps_trained: 9170000\n",
      "    sample_time_ms: 15845.71\n",
      "    update_time_ms: 4.649\n",
      "  iterations_since_restore: 917\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16163.881710290909\n",
      "  time_this_iter_s: 17.408174514770508\n",
      "  time_total_s: 16163.881710290909\n",
      "  timestamp: 1550632615\n",
      "  timesteps_since_restore: 9170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9170000\n",
      "  training_iteration: 917\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16163 s, 917 iter, 9170000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-17-12\n",
      "  done: false\n",
      "  episode_len_mean: 138.15\n",
      "  episode_reward_max: 223.00915236435478\n",
      "  episode_reward_mean: 183.22614433946833\n",
      "  episode_reward_min: 76.71462881684951\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 69413\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9336918592453003\n",
      "      kl: 0.01783883199095726\n",
      "      policy_loss: -0.0006200140342116356\n",
      "      total_loss: 22.648956298828125\n",
      "      vf_explained_var: 0.9927579164505005\n",
      "      vf_loss: 22.649578094482422\n",
      "    grad_time_ms: 1543.382\n",
      "    load_time_ms: 1.324\n",
      "    num_steps_sampled: 9180000\n",
      "    num_steps_trained: 9180000\n",
      "    sample_time_ms: 15866.402\n",
      "    update_time_ms: 4.572\n",
      "  iterations_since_restore: 918\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16180.981981277466\n",
      "  time_this_iter_s: 17.100270986557007\n",
      "  time_total_s: 16180.981981277466\n",
      "  timestamp: 1550632632\n",
      "  timesteps_since_restore: 9180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9180000\n",
      "  training_iteration: 918\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16180 s, 918 iter, 9180000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 137.45\n",
      "  episode_reward_max: 224.92712043727383\n",
      "  episode_reward_mean: 174.69159568027914\n",
      "  episode_reward_min: -39.50874748353909\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 69486\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9963855147361755\n",
      "      kl: 0.02526458166539669\n",
      "      policy_loss: -0.0040777274407446384\n",
      "      total_loss: 86.69205474853516\n",
      "      vf_explained_var: 0.9758729934692383\n",
      "      vf_loss: 86.69612884521484\n",
      "    grad_time_ms: 1543.219\n",
      "    load_time_ms: 1.359\n",
      "    num_steps_sampled: 9190000\n",
      "    num_steps_trained: 9190000\n",
      "    sample_time_ms: 15850.476\n",
      "    update_time_ms: 4.709\n",
      "  iterations_since_restore: 919\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16198.028982400894\n",
      "  time_this_iter_s: 17.047001123428345\n",
      "  time_total_s: 16198.028982400894\n",
      "  timestamp: 1550632649\n",
      "  timesteps_since_restore: 9190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9190000\n",
      "  training_iteration: 919\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16198 s, 919 iter, 9190000 ts, 175 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-17-46\n",
      "  done: false\n",
      "  episode_len_mean: 136.61\n",
      "  episode_reward_max: 224.92712043727383\n",
      "  episode_reward_mean: 179.164386030961\n",
      "  episode_reward_min: -39.50874748353909\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 69559\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7924855947494507\n",
      "      kl: 0.02142948843538761\n",
      "      policy_loss: -0.00034524520742706954\n",
      "      total_loss: 16.584135055541992\n",
      "      vf_explained_var: 0.9947628974914551\n",
      "      vf_loss: 16.5844783782959\n",
      "    grad_time_ms: 1544.346\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 9200000\n",
      "    num_steps_trained: 9200000\n",
      "    sample_time_ms: 15784.662\n",
      "    update_time_ms: 4.754\n",
      "  iterations_since_restore: 920\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16215.201918840408\n",
      "  time_this_iter_s: 17.17293643951416\n",
      "  time_total_s: 16215.201918840408\n",
      "  timestamp: 1550632666\n",
      "  timesteps_since_restore: 9200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9200000\n",
      "  training_iteration: 920\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16215 s, 920 iter, 9200000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-18-03\n",
      "  done: false\n",
      "  episode_len_mean: 137.37\n",
      "  episode_reward_max: 225.02807471034407\n",
      "  episode_reward_mean: 179.80789156517505\n",
      "  episode_reward_min: -41.602452589143624\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 69632\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9009935259819031\n",
      "      kl: 0.03046141192317009\n",
      "      policy_loss: -0.00029111557523719966\n",
      "      total_loss: 72.16993713378906\n",
      "      vf_explained_var: 0.9788865447044373\n",
      "      vf_loss: 72.17023468017578\n",
      "    grad_time_ms: 1544.419\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 9210000\n",
      "    num_steps_trained: 9210000\n",
      "    sample_time_ms: 15774.808\n",
      "    update_time_ms: 4.715\n",
      "  iterations_since_restore: 921\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16232.28494644165\n",
      "  time_this_iter_s: 17.083027601242065\n",
      "  time_total_s: 16232.28494644165\n",
      "  timestamp: 1550632683\n",
      "  timesteps_since_restore: 9210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9210000\n",
      "  training_iteration: 921\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16232 s, 921 iter, 9210000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-18-20\n",
      "  done: false\n",
      "  episode_len_mean: 137.27\n",
      "  episode_reward_max: 225.02807471034407\n",
      "  episode_reward_mean: 179.7130330091387\n",
      "  episode_reward_min: -41.602452589143624\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 69705\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8810495138168335\n",
      "      kl: 0.023769047111272812\n",
      "      policy_loss: -0.0014579376438632607\n",
      "      total_loss: 11.933173179626465\n",
      "      vf_explained_var: 0.9963966608047485\n",
      "      vf_loss: 11.93463134765625\n",
      "    grad_time_ms: 1545.699\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 9220000\n",
      "    num_steps_trained: 9220000\n",
      "    sample_time_ms: 15717.071\n",
      "    update_time_ms: 4.695\n",
      "  iterations_since_restore: 922\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16249.505569696426\n",
      "  time_this_iter_s: 17.220623254776\n",
      "  time_total_s: 16249.505569696426\n",
      "  timestamp: 1550632700\n",
      "  timesteps_since_restore: 9220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9220000\n",
      "  training_iteration: 922\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16249 s, 922 iter, 9220000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-18-38\n",
      "  done: false\n",
      "  episode_len_mean: 138.02\n",
      "  episode_reward_max: 225.12367360876652\n",
      "  episode_reward_mean: 181.77879000116033\n",
      "  episode_reward_min: -40.038955175640545\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 69777\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.999799370765686\n",
      "      kl: 0.026573823764920235\n",
      "      policy_loss: -0.004359876736998558\n",
      "      total_loss: 63.949012756347656\n",
      "      vf_explained_var: 0.9809519648551941\n",
      "      vf_loss: 63.95337677001953\n",
      "    grad_time_ms: 1545.606\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 9230000\n",
      "    num_steps_trained: 9230000\n",
      "    sample_time_ms: 15595.134\n",
      "    update_time_ms: 4.699\n",
      "  iterations_since_restore: 923\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16266.627233505249\n",
      "  time_this_iter_s: 17.121663808822632\n",
      "  time_total_s: 16266.627233505249\n",
      "  timestamp: 1550632718\n",
      "  timesteps_since_restore: 9230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9230000\n",
      "  training_iteration: 923\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16266 s, 923 iter, 9230000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 138.2\n",
      "  episode_reward_max: 217.782618480375\n",
      "  episode_reward_mean: 179.50999778393506\n",
      "  episode_reward_min: -40.038955175640545\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 69848\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9750749468803406\n",
      "      kl: 0.020177576690912247\n",
      "      policy_loss: 0.0011761134956032038\n",
      "      total_loss: 16.2374324798584\n",
      "      vf_explained_var: 0.994793713092804\n",
      "      vf_loss: 16.23625373840332\n",
      "    grad_time_ms: 1544.493\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 9240000\n",
      "    num_steps_trained: 9240000\n",
      "    sample_time_ms: 15568.494\n",
      "    update_time_ms: 4.701\n",
      "  iterations_since_restore: 924\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16284.015537977219\n",
      "  time_this_iter_s: 17.388304471969604\n",
      "  time_total_s: 16284.015537977219\n",
      "  timestamp: 1550632735\n",
      "  timesteps_since_restore: 9240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9240000\n",
      "  training_iteration: 924\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16284 s, 924 iter, 9240000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-19-12\n",
      "  done: false\n",
      "  episode_len_mean: 138.96\n",
      "  episode_reward_max: 214.73101958949678\n",
      "  episode_reward_mean: 178.13995131337583\n",
      "  episode_reward_min: 83.99345456926838\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 69921\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0442086458206177\n",
      "      kl: 0.017288943752646446\n",
      "      policy_loss: -0.0004928983398713171\n",
      "      total_loss: 22.8843936920166\n",
      "      vf_explained_var: 0.99261873960495\n",
      "      vf_loss: 22.88488006591797\n",
      "    grad_time_ms: 1545.09\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 9250000\n",
      "    num_steps_trained: 9250000\n",
      "    sample_time_ms: 15585.536\n",
      "    update_time_ms: 4.786\n",
      "  iterations_since_restore: 925\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16301.142084598541\n",
      "  time_this_iter_s: 17.126546621322632\n",
      "  time_total_s: 16301.142084598541\n",
      "  timestamp: 1550632752\n",
      "  timesteps_since_restore: 9250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9250000\n",
      "  training_iteration: 925\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16301 s, 925 iter, 9250000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-19-30\n",
      "  done: false\n",
      "  episode_len_mean: 138.16\n",
      "  episode_reward_max: 222.3403875159728\n",
      "  episode_reward_mean: 183.86464869711165\n",
      "  episode_reward_min: 109.65674781677603\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 69993\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6570644974708557\n",
      "      kl: 0.023593934252858162\n",
      "      policy_loss: 0.001232260256074369\n",
      "      total_loss: 17.70894432067871\n",
      "      vf_explained_var: 0.9945693612098694\n",
      "      vf_loss: 17.707712173461914\n",
      "    grad_time_ms: 1546.38\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 9260000\n",
      "    num_steps_trained: 9260000\n",
      "    sample_time_ms: 15679.048\n",
      "    update_time_ms: 4.81\n",
      "  iterations_since_restore: 926\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16318.925040721893\n",
      "  time_this_iter_s: 17.78295612335205\n",
      "  time_total_s: 16318.925040721893\n",
      "  timestamp: 1550632770\n",
      "  timesteps_since_restore: 9260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9260000\n",
      "  training_iteration: 926\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16318 s, 926 iter, 9260000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-19-47\n",
      "  done: false\n",
      "  episode_len_mean: 137.48\n",
      "  episode_reward_max: 222.3403875159728\n",
      "  episode_reward_mean: 183.1338166275136\n",
      "  episode_reward_min: 104.10687104501937\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 70066\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7937678098678589\n",
      "      kl: 0.02335614152252674\n",
      "      policy_loss: 0.0010000342736020684\n",
      "      total_loss: 28.970937728881836\n",
      "      vf_explained_var: 0.9908881783485413\n",
      "      vf_loss: 28.96993637084961\n",
      "    grad_time_ms: 1545.314\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 9270000\n",
      "    num_steps_trained: 9270000\n",
      "    sample_time_ms: 15659.157\n",
      "    update_time_ms: 4.757\n",
      "  iterations_since_restore: 927\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16336.121667146683\n",
      "  time_this_iter_s: 17.19662642478943\n",
      "  time_total_s: 16336.121667146683\n",
      "  timestamp: 1550632787\n",
      "  timesteps_since_restore: 9270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9270000\n",
      "  training_iteration: 927\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16336 s, 927 iter, 9270000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-20-04\n",
      "  done: false\n",
      "  episode_len_mean: 137.0\n",
      "  episode_reward_max: 222.4885809686553\n",
      "  episode_reward_mean: 180.80830717184188\n",
      "  episode_reward_min: -38.042482549601274\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 70139\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7587688565254211\n",
      "      kl: 0.03289433941245079\n",
      "      policy_loss: -0.0010488481493666768\n",
      "      total_loss: 67.85897064208984\n",
      "      vf_explained_var: 0.9807589650154114\n",
      "      vf_loss: 67.86003112792969\n",
      "    grad_time_ms: 1544.946\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 9280000\n",
      "    num_steps_trained: 9280000\n",
      "    sample_time_ms: 15654.447\n",
      "    update_time_ms: 4.803\n",
      "  iterations_since_restore: 928\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16353.170491933823\n",
      "  time_this_iter_s: 17.048824787139893\n",
      "  time_total_s: 16353.170491933823\n",
      "  timestamp: 1550632804\n",
      "  timesteps_since_restore: 9280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9280000\n",
      "  training_iteration: 928\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16353 s, 928 iter, 9280000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-20-22\n",
      "  done: false\n",
      "  episode_len_mean: 138.58\n",
      "  episode_reward_max: 219.04489276613498\n",
      "  episode_reward_mean: 184.38279222274335\n",
      "  episode_reward_min: 86.99746601512237\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 70211\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9489306211471558\n",
      "      kl: 0.029922157526016235\n",
      "      policy_loss: -0.0007223359425552189\n",
      "      total_loss: 16.027599334716797\n",
      "      vf_explained_var: 0.995046079158783\n",
      "      vf_loss: 16.028324127197266\n",
      "    grad_time_ms: 1547.393\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 9290000\n",
      "    num_steps_trained: 9290000\n",
      "    sample_time_ms: 15681.555\n",
      "    update_time_ms: 4.571\n",
      "  iterations_since_restore: 929\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16370.509137630463\n",
      "  time_this_iter_s: 17.338645696640015\n",
      "  time_total_s: 16370.509137630463\n",
      "  timestamp: 1550632822\n",
      "  timesteps_since_restore: 9290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9290000\n",
      "  training_iteration: 929\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16370 s, 929 iter, 9290000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-20-39\n",
      "  done: false\n",
      "  episode_len_mean: 138.01\n",
      "  episode_reward_max: 225.1573354391253\n",
      "  episode_reward_mean: 181.55977951355854\n",
      "  episode_reward_min: -37.74257057078993\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 70284\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7845743894577026\n",
      "      kl: 0.018280386924743652\n",
      "      policy_loss: -0.0035863297525793314\n",
      "      total_loss: 48.48941421508789\n",
      "      vf_explained_var: 0.9859125018119812\n",
      "      vf_loss: 48.49300003051758\n",
      "    grad_time_ms: 1545.917\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 9300000\n",
      "    num_steps_trained: 9300000\n",
      "    sample_time_ms: 15694.063\n",
      "    update_time_ms: 4.511\n",
      "  iterations_since_restore: 930\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16387.788999319077\n",
      "  time_this_iter_s: 17.27986168861389\n",
      "  time_total_s: 16387.788999319077\n",
      "  timestamp: 1550632839\n",
      "  timesteps_since_restore: 9300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9300000\n",
      "  training_iteration: 930\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16387 s, 930 iter, 9300000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 137.4\n",
      "  episode_reward_max: 218.5133683608826\n",
      "  episode_reward_mean: 181.8579624373491\n",
      "  episode_reward_min: 116.37419129855452\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 70356\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9094381928443909\n",
      "      kl: 0.01578555628657341\n",
      "      policy_loss: -0.002036670921370387\n",
      "      total_loss: 8.64760684967041\n",
      "      vf_explained_var: 0.9971064925193787\n",
      "      vf_loss: 8.649643898010254\n",
      "    grad_time_ms: 1545.101\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 9310000\n",
      "    num_steps_trained: 9310000\n",
      "    sample_time_ms: 15689.189\n",
      "    update_time_ms: 4.34\n",
      "  iterations_since_restore: 931\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16404.811869621277\n",
      "  time_this_iter_s: 17.022870302200317\n",
      "  time_total_s: 16404.811869621277\n",
      "  timestamp: 1550632856\n",
      "  timesteps_since_restore: 9310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9310000\n",
      "  training_iteration: 931\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16404 s, 931 iter, 9310000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-21-13\n",
      "  done: false\n",
      "  episode_len_mean: 139.28\n",
      "  episode_reward_max: 227.4108657911052\n",
      "  episode_reward_mean: 182.56643608918904\n",
      "  episode_reward_min: 96.2434959963405\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 70428\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0240819454193115\n",
      "      kl: 0.018488124012947083\n",
      "      policy_loss: -0.00256770639680326\n",
      "      total_loss: 20.950672149658203\n",
      "      vf_explained_var: 0.9934821724891663\n",
      "      vf_loss: 20.9532413482666\n",
      "    grad_time_ms: 1543.005\n",
      "    load_time_ms: 1.473\n",
      "    num_steps_sampled: 9320000\n",
      "    num_steps_trained: 9320000\n",
      "    sample_time_ms: 15649.2\n",
      "    update_time_ms: 4.388\n",
      "  iterations_since_restore: 932\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16421.613624811172\n",
      "  time_this_iter_s: 16.80175518989563\n",
      "  time_total_s: 16421.613624811172\n",
      "  timestamp: 1550632873\n",
      "  timesteps_since_restore: 9320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9320000\n",
      "  training_iteration: 932\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16421 s, 932 iter, 9320000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-21-30\n",
      "  done: false\n",
      "  episode_len_mean: 138.39\n",
      "  episode_reward_max: 221.8052814779527\n",
      "  episode_reward_mean: 180.293667153786\n",
      "  episode_reward_min: 74.1013103182807\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 70500\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.925204336643219\n",
      "      kl: 0.023425940424203873\n",
      "      policy_loss: -0.0026795128360390663\n",
      "      total_loss: 21.359495162963867\n",
      "      vf_explained_var: 0.9931091070175171\n",
      "      vf_loss: 21.36217498779297\n",
      "    grad_time_ms: 1544.444\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 9330000\n",
      "    num_steps_trained: 9330000\n",
      "    sample_time_ms: 15641.309\n",
      "    update_time_ms: 4.225\n",
      "  iterations_since_restore: 933\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16438.67028236389\n",
      "  time_this_iter_s: 17.056657552719116\n",
      "  time_total_s: 16438.67028236389\n",
      "  timestamp: 1550632890\n",
      "  timesteps_since_restore: 9330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9330000\n",
      "  training_iteration: 933\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16438 s, 933 iter, 9330000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-21-47\n",
      "  done: false\n",
      "  episode_len_mean: 138.56\n",
      "  episode_reward_max: 228.40172514638473\n",
      "  episode_reward_mean: 180.35344561693012\n",
      "  episode_reward_min: 98.90656586057776\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 70573\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.895239531993866\n",
      "      kl: 0.030878014862537384\n",
      "      policy_loss: 0.0024094898253679276\n",
      "      total_loss: 28.15565299987793\n",
      "      vf_explained_var: 0.9915985465049744\n",
      "      vf_loss: 28.153242111206055\n",
      "    grad_time_ms: 1547.561\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 9340000\n",
      "    num_steps_trained: 9340000\n",
      "    sample_time_ms: 15640.466\n",
      "    update_time_ms: 4.149\n",
      "  iterations_since_restore: 934\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16456.081616163254\n",
      "  time_this_iter_s: 17.411333799362183\n",
      "  time_total_s: 16456.081616163254\n",
      "  timestamp: 1550632907\n",
      "  timesteps_since_restore: 9340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9340000\n",
      "  training_iteration: 934\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16456 s, 934 iter, 9340000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-22-05\n",
      "  done: false\n",
      "  episode_len_mean: 137.85\n",
      "  episode_reward_max: 220.65475230621587\n",
      "  episode_reward_mean: 184.08392447026293\n",
      "  episode_reward_min: 106.70767240809027\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 70646\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7647795677185059\n",
      "      kl: 0.028378477320075035\n",
      "      policy_loss: 0.002334963995963335\n",
      "      total_loss: 7.031138896942139\n",
      "      vf_explained_var: 0.9977652430534363\n",
      "      vf_loss: 7.02880334854126\n",
      "    grad_time_ms: 1547.307\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 9350000\n",
      "    num_steps_trained: 9350000\n",
      "    sample_time_ms: 15676.825\n",
      "    update_time_ms: 4.162\n",
      "  iterations_since_restore: 935\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16473.568819522858\n",
      "  time_this_iter_s: 17.487203359603882\n",
      "  time_total_s: 16473.568819522858\n",
      "  timestamp: 1550632925\n",
      "  timesteps_since_restore: 9350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9350000\n",
      "  training_iteration: 935\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16473 s, 935 iter, 9350000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-22-22\n",
      "  done: false\n",
      "  episode_len_mean: 137.69\n",
      "  episode_reward_max: 220.56199556707148\n",
      "  episode_reward_mean: 180.5521101873019\n",
      "  episode_reward_min: 72.07913461464025\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 70718\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8090339303016663\n",
      "      kl: 0.016264673322439194\n",
      "      policy_loss: -0.00196880754083395\n",
      "      total_loss: 58.64593505859375\n",
      "      vf_explained_var: 0.9837625026702881\n",
      "      vf_loss: 58.64790725708008\n",
      "    grad_time_ms: 1548.331\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 9360000\n",
      "    num_steps_trained: 9360000\n",
      "    sample_time_ms: 15602.847\n",
      "    update_time_ms: 4.079\n",
      "  iterations_since_restore: 936\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16490.618876218796\n",
      "  time_this_iter_s: 17.05005669593811\n",
      "  time_total_s: 16490.618876218796\n",
      "  timestamp: 1550632942\n",
      "  timesteps_since_restore: 9360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9360000\n",
      "  training_iteration: 936\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16490 s, 936 iter, 9360000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-22-40\n",
      "  done: false\n",
      "  episode_len_mean: 137.36\n",
      "  episode_reward_max: 219.80745324743256\n",
      "  episode_reward_mean: 180.03725724747005\n",
      "  episode_reward_min: 72.07913461464025\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 70791\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7912558317184448\n",
      "      kl: 0.036465227603912354\n",
      "      policy_loss: 0.006564991548657417\n",
      "      total_loss: 5.951451778411865\n",
      "      vf_explained_var: 0.9979913234710693\n",
      "      vf_loss: 5.944886207580566\n",
      "    grad_time_ms: 1546.742\n",
      "    load_time_ms: 1.373\n",
      "    num_steps_sampled: 9370000\n",
      "    num_steps_trained: 9370000\n",
      "    sample_time_ms: 15645.468\n",
      "    update_time_ms: 4.194\n",
      "  iterations_since_restore: 937\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16508.2275762558\n",
      "  time_this_iter_s: 17.608700037002563\n",
      "  time_total_s: 16508.2275762558\n",
      "  timestamp: 1550632960\n",
      "  timesteps_since_restore: 9370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9370000\n",
      "  training_iteration: 937\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16508 s, 937 iter, 9370000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-22-57\n",
      "  done: false\n",
      "  episode_len_mean: 137.57\n",
      "  episode_reward_max: 224.48005605470576\n",
      "  episode_reward_mean: 181.8250583802961\n",
      "  episode_reward_min: 88.20248800973474\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 70864\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7561725974082947\n",
      "      kl: 0.013101453892886639\n",
      "      policy_loss: -0.002106329193338752\n",
      "      total_loss: 32.57019805908203\n",
      "      vf_explained_var: 0.9905184507369995\n",
      "      vf_loss: 32.57230758666992\n",
      "    grad_time_ms: 1549.983\n",
      "    load_time_ms: 1.329\n",
      "    num_steps_sampled: 9380000\n",
      "    num_steps_trained: 9380000\n",
      "    sample_time_ms: 15686.139\n",
      "    update_time_ms: 4.149\n",
      "  iterations_since_restore: 938\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16525.715904712677\n",
      "  time_this_iter_s: 17.488328456878662\n",
      "  time_total_s: 16525.715904712677\n",
      "  timestamp: 1550632977\n",
      "  timesteps_since_restore: 9380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9380000\n",
      "  training_iteration: 938\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16525 s, 938 iter, 9380000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-23-14\n",
      "  done: false\n",
      "  episode_len_mean: 136.38\n",
      "  episode_reward_max: 222.26526207170716\n",
      "  episode_reward_mean: 176.07568135171567\n",
      "  episode_reward_min: -38.16306958104124\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 70938\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8532400727272034\n",
      "      kl: 0.027663808315992355\n",
      "      policy_loss: 0.0009366264566779137\n",
      "      total_loss: 56.16643524169922\n",
      "      vf_explained_var: 0.9828855991363525\n",
      "      vf_loss: 56.165496826171875\n",
      "    grad_time_ms: 1547.43\n",
      "    load_time_ms: 1.379\n",
      "    num_steps_sampled: 9390000\n",
      "    num_steps_trained: 9390000\n",
      "    sample_time_ms: 15636.575\n",
      "    update_time_ms: 4.186\n",
      "  iterations_since_restore: 939\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16542.53517818451\n",
      "  time_this_iter_s: 16.819273471832275\n",
      "  time_total_s: 16542.53517818451\n",
      "  timestamp: 1550632994\n",
      "  timesteps_since_restore: 9390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9390000\n",
      "  training_iteration: 939\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16542 s, 939 iter, 9390000 ts, 176 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-23-32\n",
      "  done: false\n",
      "  episode_len_mean: 137.72\n",
      "  episode_reward_max: 216.0000714603259\n",
      "  episode_reward_mean: 183.45005807264715\n",
      "  episode_reward_min: 105.24477923432792\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 71010\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8720095753669739\n",
      "      kl: 0.03981800377368927\n",
      "      policy_loss: 0.0021103559993207455\n",
      "      total_loss: 24.850242614746094\n",
      "      vf_explained_var: 0.9923946857452393\n",
      "      vf_loss: 24.848133087158203\n",
      "    grad_time_ms: 1550.433\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 9400000\n",
      "    num_steps_trained: 9400000\n",
      "    sample_time_ms: 15684.826\n",
      "    update_time_ms: 4.152\n",
      "  iterations_since_restore: 940\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16560.329151153564\n",
      "  time_this_iter_s: 17.793972969055176\n",
      "  time_total_s: 16560.329151153564\n",
      "  timestamp: 1550633012\n",
      "  timesteps_since_restore: 9400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9400000\n",
      "  training_iteration: 940\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16560 s, 940 iter, 9400000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-23-49\n",
      "  done: false\n",
      "  episode_len_mean: 139.94\n",
      "  episode_reward_max: 221.2100515095056\n",
      "  episode_reward_mean: 183.4793689821246\n",
      "  episode_reward_min: 99.26240297145031\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 71081\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7608166933059692\n",
      "      kl: 0.026060152798891068\n",
      "      policy_loss: -0.0017489301972091198\n",
      "      total_loss: 17.05260467529297\n",
      "      vf_explained_var: 0.9946779012680054\n",
      "      vf_loss: 17.054353713989258\n",
      "    grad_time_ms: 1551.184\n",
      "    load_time_ms: 1.407\n",
      "    num_steps_sampled: 9410000\n",
      "    num_steps_trained: 9410000\n",
      "    sample_time_ms: 15722.483\n",
      "    update_time_ms: 4.338\n",
      "  iterations_since_restore: 941\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16577.736428022385\n",
      "  time_this_iter_s: 17.40727686882019\n",
      "  time_total_s: 16577.736428022385\n",
      "  timestamp: 1550633029\n",
      "  timesteps_since_restore: 9410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9410000\n",
      "  training_iteration: 941\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16577 s, 941 iter, 9410000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-24-07\n",
      "  done: false\n",
      "  episode_len_mean: 138.41\n",
      "  episode_reward_max: 221.2100515095056\n",
      "  episode_reward_mean: 178.73657391814507\n",
      "  episode_reward_min: -35.02495899280106\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 71154\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7412680387496948\n",
      "      kl: 0.024404514580965042\n",
      "      policy_loss: -0.004640198312699795\n",
      "      total_loss: 81.58086395263672\n",
      "      vf_explained_var: 0.9766852259635925\n",
      "      vf_loss: 81.58549499511719\n",
      "    grad_time_ms: 1551.079\n",
      "    load_time_ms: 1.405\n",
      "    num_steps_sampled: 9420000\n",
      "    num_steps_trained: 9420000\n",
      "    sample_time_ms: 15767.462\n",
      "    update_time_ms: 4.365\n",
      "  iterations_since_restore: 942\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16594.987795352936\n",
      "  time_this_iter_s: 17.251367330551147\n",
      "  time_total_s: 16594.987795352936\n",
      "  timestamp: 1550633047\n",
      "  timesteps_since_restore: 9420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9420000\n",
      "  training_iteration: 942\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16594 s, 942 iter, 9420000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-24-24\n",
      "  done: false\n",
      "  episode_len_mean: 136.4\n",
      "  episode_reward_max: 221.3418033249526\n",
      "  episode_reward_mean: 177.1658532609789\n",
      "  episode_reward_min: -35.02495899280106\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 71227\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6502846479415894\n",
      "      kl: 0.02320467121899128\n",
      "      policy_loss: 0.00048232977860607207\n",
      "      total_loss: 18.06758689880371\n",
      "      vf_explained_var: 0.9941813349723816\n",
      "      vf_loss: 18.067102432250977\n",
      "    grad_time_ms: 1567.945\n",
      "    load_time_ms: 1.384\n",
      "    num_steps_sampled: 9430000\n",
      "    num_steps_trained: 9430000\n",
      "    sample_time_ms: 15782.229\n",
      "    update_time_ms: 4.395\n",
      "  iterations_since_restore: 943\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16612.35898590088\n",
      "  time_this_iter_s: 17.371190547943115\n",
      "  time_total_s: 16612.35898590088\n",
      "  timestamp: 1550633064\n",
      "  timesteps_since_restore: 9430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9430000\n",
      "  training_iteration: 943\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16612 s, 943 iter, 9430000 ts, 177 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-24-41\n",
      "  done: false\n",
      "  episode_len_mean: 138.65\n",
      "  episode_reward_max: 225.21234072371408\n",
      "  episode_reward_mean: 181.47393730810845\n",
      "  episode_reward_min: 80.75035257305532\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 71299\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9108743667602539\n",
      "      kl: 0.01915888860821724\n",
      "      policy_loss: -0.002087533473968506\n",
      "      total_loss: 41.769813537597656\n",
      "      vf_explained_var: 0.9883103966712952\n",
      "      vf_loss: 41.77190399169922\n",
      "    grad_time_ms: 1565.251\n",
      "    load_time_ms: 1.317\n",
      "    num_steps_sampled: 9440000\n",
      "    num_steps_trained: 9440000\n",
      "    sample_time_ms: 15782.901\n",
      "    update_time_ms: 4.401\n",
      "  iterations_since_restore: 944\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16629.749663352966\n",
      "  time_this_iter_s: 17.390677452087402\n",
      "  time_total_s: 16629.749663352966\n",
      "  timestamp: 1550633081\n",
      "  timesteps_since_restore: 9440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9440000\n",
      "  training_iteration: 944\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16629 s, 944 iter, 9440000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-24-58\n",
      "  done: false\n",
      "  episode_len_mean: 138.56\n",
      "  episode_reward_max: 221.2555984654785\n",
      "  episode_reward_mean: 185.00895947577334\n",
      "  episode_reward_min: 120.2120690011595\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 71371\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 4.1205312035505475e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8306912183761597\n",
      "      kl: 48.34384536743164\n",
      "      policy_loss: 0.035946860909461975\n",
      "      total_loss: 15.6405029296875\n",
      "      vf_explained_var: 0.9949398636817932\n",
      "      vf_loss: 15.6045560836792\n",
      "    grad_time_ms: 1565.765\n",
      "    load_time_ms: 1.31\n",
      "    num_steps_sampled: 9450000\n",
      "    num_steps_trained: 9450000\n",
      "    sample_time_ms: 15727.883\n",
      "    update_time_ms: 4.422\n",
      "  iterations_since_restore: 945\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16646.690753221512\n",
      "  time_this_iter_s: 16.941089868545532\n",
      "  time_total_s: 16646.690753221512\n",
      "  timestamp: 1550633098\n",
      "  timesteps_since_restore: 9450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9450000\n",
      "  training_iteration: 945\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16646 s, 945 iter, 9450000 ts, 185 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 135.35\n",
      "  episode_reward_max: 210.84701047262357\n",
      "  episode_reward_mean: 179.18403815898938\n",
      "  episode_reward_min: 76.24046189758471\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 71445\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 6.180797451560675e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9101542234420776\n",
      "      kl: 0.009782693348824978\n",
      "      policy_loss: -0.0019294137600809336\n",
      "      total_loss: 33.91514587402344\n",
      "      vf_explained_var: 0.9896519184112549\n",
      "      vf_loss: 33.91707229614258\n",
      "    grad_time_ms: 1566.412\n",
      "    load_time_ms: 1.296\n",
      "    num_steps_sampled: 9460000\n",
      "    num_steps_trained: 9460000\n",
      "    sample_time_ms: 15709.333\n",
      "    update_time_ms: 4.406\n",
      "  iterations_since_restore: 946\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16663.56261587143\n",
      "  time_this_iter_s: 16.871862649917603\n",
      "  time_total_s: 16663.56261587143\n",
      "  timestamp: 1550633115\n",
      "  timesteps_since_restore: 9460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9460000\n",
      "  training_iteration: 946\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16663 s, 946 iter, 9460000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-25-33\n",
      "  done: false\n",
      "  episode_len_mean: 136.91\n",
      "  episode_reward_max: 220.7062727575845\n",
      "  episode_reward_mean: 178.19734667182414\n",
      "  episode_reward_min: -34.139978637199576\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 71518\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.0903987257803374e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9062443971633911\n",
      "      kl: 0.008501498959958553\n",
      "      policy_loss: -0.0021408344618976116\n",
      "      total_loss: 86.07730102539062\n",
      "      vf_explained_var: 0.9774807691574097\n",
      "      vf_loss: 86.07942962646484\n",
      "    grad_time_ms: 1566.223\n",
      "    load_time_ms: 1.295\n",
      "    num_steps_sampled: 9470000\n",
      "    num_steps_trained: 9470000\n",
      "    sample_time_ms: 15681.501\n",
      "    update_time_ms: 4.299\n",
      "  iterations_since_restore: 947\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16680.890643119812\n",
      "  time_this_iter_s: 17.32802724838257\n",
      "  time_total_s: 16680.890643119812\n",
      "  timestamp: 1550633133\n",
      "  timesteps_since_restore: 9470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9470000\n",
      "  training_iteration: 947\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16680 s, 947 iter, 9470000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-25-50\n",
      "  done: false\n",
      "  episode_len_mean: 135.86\n",
      "  episode_reward_max: 223.72965989516376\n",
      "  episode_reward_mean: 181.81696083258342\n",
      "  episode_reward_min: 99.65799424575991\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 71591\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5451993628901687e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8188883662223816\n",
      "      kl: 0.016770798712968826\n",
      "      policy_loss: 0.0012230194406583905\n",
      "      total_loss: 20.29718017578125\n",
      "      vf_explained_var: 0.9934549331665039\n",
      "      vf_loss: 20.295957565307617\n",
      "    grad_time_ms: 1565.285\n",
      "    load_time_ms: 1.347\n",
      "    num_steps_sampled: 9480000\n",
      "    num_steps_trained: 9480000\n",
      "    sample_time_ms: 15627.817\n",
      "    update_time_ms: 4.367\n",
      "  iterations_since_restore: 948\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16697.83400630951\n",
      "  time_this_iter_s: 16.943363189697266\n",
      "  time_total_s: 16697.83400630951\n",
      "  timestamp: 1550633150\n",
      "  timesteps_since_restore: 9480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9480000\n",
      "  training_iteration: 948\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16697 s, 948 iter, 9480000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-26-07\n",
      "  done: false\n",
      "  episode_len_mean: 137.15\n",
      "  episode_reward_max: 223.72965989516376\n",
      "  episode_reward_mean: 183.62544825227013\n",
      "  episode_reward_min: 84.0471640671833\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 71664\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5451993628901687e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9526393413543701\n",
      "      kl: 0.019089702516794205\n",
      "      policy_loss: -0.0029169719200581312\n",
      "      total_loss: 28.13706398010254\n",
      "      vf_explained_var: 0.9910012483596802\n",
      "      vf_loss: 28.139984130859375\n",
      "    grad_time_ms: 1565.428\n",
      "    load_time_ms: 1.275\n",
      "    num_steps_sampled: 9490000\n",
      "    num_steps_trained: 9490000\n",
      "    sample_time_ms: 15686.686\n",
      "    update_time_ms: 4.413\n",
      "  iterations_since_restore: 949\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16715.242668390274\n",
      "  time_this_iter_s: 17.40866208076477\n",
      "  time_total_s: 16715.242668390274\n",
      "  timestamp: 1550633167\n",
      "  timesteps_since_restore: 9490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9490000\n",
      "  training_iteration: 949\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16715 s, 949 iter, 9490000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-26-24\n",
      "  done: false\n",
      "  episode_len_mean: 136.27\n",
      "  episode_reward_max: 220.01185225984918\n",
      "  episode_reward_mean: 183.82663826356296\n",
      "  episode_reward_min: 78.54848223876692\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 71738\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5451993628901687e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8405379056930542\n",
      "      kl: 0.01721968688070774\n",
      "      policy_loss: -0.0003815490927081555\n",
      "      total_loss: 25.471099853515625\n",
      "      vf_explained_var: 0.9919799566268921\n",
      "      vf_loss: 25.47148323059082\n",
      "    grad_time_ms: 1584.424\n",
      "    load_time_ms: 1.244\n",
      "    num_steps_sampled: 9500000\n",
      "    num_steps_trained: 9500000\n",
      "    sample_time_ms: 15595.48\n",
      "    update_time_ms: 4.444\n",
      "  iterations_since_restore: 950\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16732.31356239319\n",
      "  time_this_iter_s: 17.07089400291443\n",
      "  time_total_s: 16732.31356239319\n",
      "  timestamp: 1550633184\n",
      "  timesteps_since_restore: 9500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9500000\n",
      "  training_iteration: 950\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16732 s, 950 iter, 9500000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-26-41\n",
      "  done: false\n",
      "  episode_len_mean: 136.17\n",
      "  episode_reward_max: 225.0795102979951\n",
      "  episode_reward_mean: 184.76457776534335\n",
      "  episode_reward_min: 96.0408090434156\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 71810\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5451993628901687e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.947080671787262\n",
      "      kl: 0.023027518764138222\n",
      "      policy_loss: -0.001167537528090179\n",
      "      total_loss: 24.5760440826416\n",
      "      vf_explained_var: 0.9923039078712463\n",
      "      vf_loss: 24.577211380004883\n",
      "    grad_time_ms: 1582.331\n",
      "    load_time_ms: 1.278\n",
      "    num_steps_sampled: 9510000\n",
      "    num_steps_trained: 9510000\n",
      "    sample_time_ms: 15542.188\n",
      "    update_time_ms: 4.349\n",
      "  iterations_since_restore: 951\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16749.16831445694\n",
      "  time_this_iter_s: 16.85475206375122\n",
      "  time_total_s: 16749.16831445694\n",
      "  timestamp: 1550633201\n",
      "  timesteps_since_restore: 9510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9510000\n",
      "  training_iteration: 951\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16749 s, 951 iter, 9510000 ts, 185 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-26-58\n",
      "  done: false\n",
      "  episode_len_mean: 137.91\n",
      "  episode_reward_max: 221.96337561394176\n",
      "  episode_reward_mean: 178.29032231268104\n",
      "  episode_reward_min: -39.13306388347454\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 71883\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.5451993628901687e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0576915740966797\n",
      "      kl: 0.37630733847618103\n",
      "      policy_loss: 0.0136322733014822\n",
      "      total_loss: 118.18413543701172\n",
      "      vf_explained_var: 0.9663078188896179\n",
      "      vf_loss: 118.17052459716797\n",
      "    grad_time_ms: 1582.845\n",
      "    load_time_ms: 1.243\n",
      "    num_steps_sampled: 9520000\n",
      "    num_steps_trained: 9520000\n",
      "    sample_time_ms: 15556.199\n",
      "    update_time_ms: 4.312\n",
      "  iterations_since_restore: 952\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16766.562375307083\n",
      "  time_this_iter_s: 17.394060850143433\n",
      "  time_total_s: 16766.562375307083\n",
      "  timestamp: 1550633218\n",
      "  timesteps_since_restore: 9520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9520000\n",
      "  training_iteration: 952\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16766 s, 952 iter, 9520000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-27-16\n",
      "  done: false\n",
      "  episode_len_mean: 136.25\n",
      "  episode_reward_max: 219.99530554931656\n",
      "  episode_reward_mean: 179.0758923085327\n",
      "  episode_reward_min: -39.13306388347454\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 71955\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.317798850464797e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9224088788032532\n",
      "      kl: 0.02115049958229065\n",
      "      policy_loss: 0.0008477969677187502\n",
      "      total_loss: 62.10841751098633\n",
      "      vf_explained_var: 0.9825255274772644\n",
      "      vf_loss: 62.107566833496094\n",
      "    grad_time_ms: 1563.859\n",
      "    load_time_ms: 1.244\n",
      "    num_steps_sampled: 9530000\n",
      "    num_steps_trained: 9530000\n",
      "    sample_time_ms: 15575.105\n",
      "    update_time_ms: 4.311\n",
      "  iterations_since_restore: 953\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16783.931708574295\n",
      "  time_this_iter_s: 17.369333267211914\n",
      "  time_total_s: 16783.931708574295\n",
      "  timestamp: 1550633236\n",
      "  timesteps_since_restore: 9530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9530000\n",
      "  training_iteration: 953\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16783 s, 953 iter, 9530000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-27-33\n",
      "  done: false\n",
      "  episode_len_mean: 136.95\n",
      "  episode_reward_max: 224.70680951127915\n",
      "  episode_reward_mean: 181.39463687799665\n",
      "  episode_reward_min: -39.0300820151178\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 72029\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 2.317798850464797e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9394741654396057\n",
      "      kl: 0.050650037825107574\n",
      "      policy_loss: 0.0017001295927911997\n",
      "      total_loss: 65.12969207763672\n",
      "      vf_explained_var: 0.9816803336143494\n",
      "      vf_loss: 65.12799072265625\n",
      "    grad_time_ms: 1565.841\n",
      "    load_time_ms: 1.304\n",
      "    num_steps_sampled: 9540000\n",
      "    num_steps_trained: 9540000\n",
      "    sample_time_ms: 15576.861\n",
      "    update_time_ms: 4.391\n",
      "  iterations_since_restore: 954\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16801.361956357956\n",
      "  time_this_iter_s: 17.43024778366089\n",
      "  time_total_s: 16801.361956357956\n",
      "  timestamp: 1550633253\n",
      "  timesteps_since_restore: 9540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9540000\n",
      "  training_iteration: 954\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16801 s, 954 iter, 9540000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-27-51\n",
      "  done: false\n",
      "  episode_len_mean: 136.99\n",
      "  episode_reward_max: 225.7622333865354\n",
      "  episode_reward_mean: 182.91951256716766\n",
      "  episode_reward_min: -39.0300820151178\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 72101\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.4767000851547854e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9899880886077881\n",
      "      kl: 0.037877604365348816\n",
      "      policy_loss: 0.0008336239843629301\n",
      "      total_loss: 31.493194580078125\n",
      "      vf_explained_var: 0.9907568693161011\n",
      "      vf_loss: 31.492368698120117\n",
      "    grad_time_ms: 1565.095\n",
      "    load_time_ms: 1.304\n",
      "    num_steps_sampled: 9550000\n",
      "    num_steps_trained: 9550000\n",
      "    sample_time_ms: 15637.887\n",
      "    update_time_ms: 4.295\n",
      "  iterations_since_restore: 955\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16818.90457868576\n",
      "  time_this_iter_s: 17.542622327804565\n",
      "  time_total_s: 16818.90457868576\n",
      "  timestamp: 1550633271\n",
      "  timesteps_since_restore: 9550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9550000\n",
      "  training_iteration: 955\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16818 s, 955 iter, 9550000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-28-08\n",
      "  done: false\n",
      "  episode_len_mean: 136.44\n",
      "  episode_reward_max: 225.7622333865354\n",
      "  episode_reward_mean: 183.11860411202818\n",
      "  episode_reward_min: 82.1917461250899\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 72175\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.4767000851547854e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9633104205131531\n",
      "      kl: 0.021091613918542862\n",
      "      policy_loss: -1.2827797945647035e-05\n",
      "      total_loss: 19.757713317871094\n",
      "      vf_explained_var: 0.9942329525947571\n",
      "      vf_loss: 19.75773048400879\n",
      "    grad_time_ms: 1561.162\n",
      "    load_time_ms: 1.359\n",
      "    num_steps_sampled: 9560000\n",
      "    num_steps_trained: 9560000\n",
      "    sample_time_ms: 15669.807\n",
      "    update_time_ms: 4.383\n",
      "  iterations_since_restore: 956\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16836.05959868431\n",
      "  time_this_iter_s: 17.155019998550415\n",
      "  time_total_s: 16836.05959868431\n",
      "  timestamp: 1550633288\n",
      "  timesteps_since_restore: 9560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9560000\n",
      "  training_iteration: 956\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16836 s, 956 iter, 9560000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-28-25\n",
      "  done: false\n",
      "  episode_len_mean: 136.5\n",
      "  episode_reward_max: 220.2943127657665\n",
      "  episode_reward_mean: 178.61921096573712\n",
      "  episode_reward_min: 82.1917461250899\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 72248\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.4767000851547854e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.970019519329071\n",
      "      kl: 0.02057281881570816\n",
      "      policy_loss: -0.00023011289886198938\n",
      "      total_loss: 29.79267692565918\n",
      "      vf_explained_var: 0.9913336634635925\n",
      "      vf_loss: 29.792905807495117\n",
      "    grad_time_ms: 1559.809\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 9570000\n",
      "    num_steps_trained: 9570000\n",
      "    sample_time_ms: 15643.715\n",
      "    update_time_ms: 4.399\n",
      "  iterations_since_restore: 957\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16853.113243103027\n",
      "  time_this_iter_s: 17.05364441871643\n",
      "  time_total_s: 16853.113243103027\n",
      "  timestamp: 1550633305\n",
      "  timesteps_since_restore: 9570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9570000\n",
      "  training_iteration: 957\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16853 s, 957 iter, 9570000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-28-43\n",
      "  done: false\n",
      "  episode_len_mean: 137.93\n",
      "  episode_reward_max: 222.8754839964285\n",
      "  episode_reward_mean: 178.3606090465325\n",
      "  episode_reward_min: 84.18556652944704\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 72320\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.4767000851547854e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0206636190414429\n",
      "      kl: 0.03071802668273449\n",
      "      policy_loss: 0.0025898220483213663\n",
      "      total_loss: 49.278438568115234\n",
      "      vf_explained_var: 0.9870520234107971\n",
      "      vf_loss: 49.27585220336914\n",
      "    grad_time_ms: 1556.932\n",
      "    load_time_ms: 1.394\n",
      "    num_steps_sampled: 9580000\n",
      "    num_steps_trained: 9580000\n",
      "    sample_time_ms: 15685.248\n",
      "    update_time_ms: 4.389\n",
      "  iterations_since_restore: 958\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16870.44261956215\n",
      "  time_this_iter_s: 17.329376459121704\n",
      "  time_total_s: 16870.44261956215\n",
      "  timestamp: 1550633323\n",
      "  timesteps_since_restore: 9580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9580000\n",
      "  training_iteration: 958\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16870 s, 958 iter, 9580000 ts, 178 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-29-00\n",
      "  done: false\n",
      "  episode_len_mean: 136.46\n",
      "  episode_reward_max: 227.47403775741992\n",
      "  episode_reward_mean: 179.3068029670841\n",
      "  episode_reward_min: 84.18556652944704\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 72394\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 3.4767000851547854e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8100573420524597\n",
      "      kl: 0.05868446081876755\n",
      "      policy_loss: 0.006682651117444038\n",
      "      total_loss: 29.838031768798828\n",
      "      vf_explained_var: 0.9908990859985352\n",
      "      vf_loss: 29.831342697143555\n",
      "    grad_time_ms: 1558.212\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 9590000\n",
      "    num_steps_trained: 9590000\n",
      "    sample_time_ms: 15661.151\n",
      "    update_time_ms: 4.51\n",
      "  iterations_since_restore: 959\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16887.62389922142\n",
      "  time_this_iter_s: 17.18127965927124\n",
      "  time_total_s: 16887.62389922142\n",
      "  timestamp: 1550633340\n",
      "  timesteps_since_restore: 9590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9590000\n",
      "  training_iteration: 959\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16887 s, 959 iter, 9590000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-29-17\n",
      "  done: false\n",
      "  episode_len_mean: 136.82\n",
      "  episode_reward_max: 227.47403775741992\n",
      "  episode_reward_mean: 184.88744021895934\n",
      "  episode_reward_min: 112.43596895430034\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 72468\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 5.215048059780647e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9988459944725037\n",
      "      kl: 7.380523681640625\n",
      "      policy_loss: 0.026843657717108727\n",
      "      total_loss: 7.482356071472168\n",
      "      vf_explained_var: 0.997541069984436\n",
      "      vf_loss: 7.455513000488281\n",
      "    grad_time_ms: 1536.251\n",
      "    load_time_ms: 1.4\n",
      "    num_steps_sampled: 9600000\n",
      "    num_steps_trained: 9600000\n",
      "    sample_time_ms: 15653.248\n",
      "    update_time_ms: 4.595\n",
      "  iterations_since_restore: 960\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16904.397079229355\n",
      "  time_this_iter_s: 16.77318000793457\n",
      "  time_total_s: 16904.397079229355\n",
      "  timestamp: 1550633357\n",
      "  timesteps_since_restore: 9600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9600000\n",
      "  training_iteration: 960\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16904 s, 960 iter, 9600000 ts, 185 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-29-34\n",
      "  done: false\n",
      "  episode_len_mean: 136.24\n",
      "  episode_reward_max: 213.93983896851242\n",
      "  episode_reward_mean: 182.3821960771832\n",
      "  episode_reward_min: 123.76581658028277\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 72541\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9190191626548767\n",
      "      kl: 0.02189849503338337\n",
      "      policy_loss: 0.002175647532567382\n",
      "      total_loss: 16.43922233581543\n",
      "      vf_explained_var: 0.9945786595344543\n",
      "      vf_loss: 16.437042236328125\n",
      "    grad_time_ms: 1537.232\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 9610000\n",
      "    num_steps_trained: 9610000\n",
      "    sample_time_ms: 15698.859\n",
      "    update_time_ms: 4.654\n",
      "  iterations_since_restore: 961\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16921.717507362366\n",
      "  time_this_iter_s: 17.320428133010864\n",
      "  time_total_s: 16921.717507362366\n",
      "  timestamp: 1550633374\n",
      "  timesteps_since_restore: 9610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9610000\n",
      "  training_iteration: 961\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16921 s, 961 iter, 9610000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-29-51\n",
      "  done: false\n",
      "  episode_len_mean: 134.46\n",
      "  episode_reward_max: 226.2004106444593\n",
      "  episode_reward_mean: 180.2245423547619\n",
      "  episode_reward_min: 119.7432839523757\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 72615\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7984064221382141\n",
      "      kl: 0.020308038219809532\n",
      "      policy_loss: 5.562240403378382e-05\n",
      "      total_loss: 13.762250900268555\n",
      "      vf_explained_var: 0.9957246780395508\n",
      "      vf_loss: 13.762194633483887\n",
      "    grad_time_ms: 1536.325\n",
      "    load_time_ms: 1.414\n",
      "    num_steps_sampled: 9620000\n",
      "    num_steps_trained: 9620000\n",
      "    sample_time_ms: 15696.11\n",
      "    update_time_ms: 4.674\n",
      "  iterations_since_restore: 962\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16939.076285600662\n",
      "  time_this_iter_s: 17.35877823829651\n",
      "  time_total_s: 16939.076285600662\n",
      "  timestamp: 1550633391\n",
      "  timesteps_since_restore: 9620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9620000\n",
      "  training_iteration: 962\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16939 s, 962 iter, 9620000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-30-09\n",
      "  done: false\n",
      "  episode_len_mean: 137.51\n",
      "  episode_reward_max: 226.2004106444593\n",
      "  episode_reward_mean: 182.6729272687179\n",
      "  episode_reward_min: 113.31740454635997\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 72687\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0730475187301636\n",
      "      kl: 0.02819989249110222\n",
      "      policy_loss: -0.0002752360887825489\n",
      "      total_loss: 20.144662857055664\n",
      "      vf_explained_var: 0.9938367009162903\n",
      "      vf_loss: 20.144939422607422\n",
      "    grad_time_ms: 1536.493\n",
      "    load_time_ms: 1.435\n",
      "    num_steps_sampled: 9630000\n",
      "    num_steps_trained: 9630000\n",
      "    sample_time_ms: 15695.512\n",
      "    update_time_ms: 4.74\n",
      "  iterations_since_restore: 963\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16956.44543361664\n",
      "  time_this_iter_s: 17.369148015975952\n",
      "  time_total_s: 16956.44543361664\n",
      "  timestamp: 1550633409\n",
      "  timesteps_since_restore: 9630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9630000\n",
      "  training_iteration: 963\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16956 s, 963 iter, 9630000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-30-26\n",
      "  done: false\n",
      "  episode_len_mean: 136.76\n",
      "  episode_reward_max: 221.95327562311348\n",
      "  episode_reward_mean: 181.79008697503005\n",
      "  episode_reward_min: 93.2540940421051\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 72760\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7333246469497681\n",
      "      kl: 0.022513827309012413\n",
      "      policy_loss: -0.0009609797270968556\n",
      "      total_loss: 32.865447998046875\n",
      "      vf_explained_var: 0.9903477430343628\n",
      "      vf_loss: 32.86641311645508\n",
      "    grad_time_ms: 1534.544\n",
      "    load_time_ms: 1.4\n",
      "    num_steps_sampled: 9640000\n",
      "    num_steps_trained: 9640000\n",
      "    sample_time_ms: 15687.53\n",
      "    update_time_ms: 4.68\n",
      "  iterations_since_restore: 964\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16973.773408651352\n",
      "  time_this_iter_s: 17.327975034713745\n",
      "  time_total_s: 16973.773408651352\n",
      "  timestamp: 1550633426\n",
      "  timesteps_since_restore: 9640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9640000\n",
      "  training_iteration: 964\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16973 s, 964 iter, 9640000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-30-43\n",
      "  done: false\n",
      "  episode_len_mean: 135.89\n",
      "  episode_reward_max: 227.91122153836605\n",
      "  episode_reward_mean: 180.2646375454848\n",
      "  episode_reward_min: 93.2540940421051\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 72834\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7930477857589722\n",
      "      kl: 0.025699038058519363\n",
      "      policy_loss: 0.002128289546817541\n",
      "      total_loss: 31.706172943115234\n",
      "      vf_explained_var: 0.9904524087905884\n",
      "      vf_loss: 31.70405387878418\n",
      "    grad_time_ms: 1533.735\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 9650000\n",
      "    num_steps_trained: 9650000\n",
      "    sample_time_ms: 15660.724\n",
      "    update_time_ms: 4.67\n",
      "  iterations_since_restore: 965\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 16991.04096841812\n",
      "  time_this_iter_s: 17.26755976676941\n",
      "  time_total_s: 16991.04096841812\n",
      "  timestamp: 1550633443\n",
      "  timesteps_since_restore: 9650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9650000\n",
      "  training_iteration: 965\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 16991 s, 965 iter, 9650000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-31-01\n",
      "  done: false\n",
      "  episode_len_mean: 134.08\n",
      "  episode_reward_max: 221.9073141305202\n",
      "  episode_reward_mean: 180.14109828816444\n",
      "  episode_reward_min: 93.38123551464756\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 72909\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7322168946266174\n",
      "      kl: 0.025711331516504288\n",
      "      policy_loss: -0.0009680892690084875\n",
      "      total_loss: 6.986952781677246\n",
      "      vf_explained_var: 0.997670590877533\n",
      "      vf_loss: 6.987918853759766\n",
      "    grad_time_ms: 1537.012\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 9660000\n",
      "    num_steps_trained: 9660000\n",
      "    sample_time_ms: 15696.496\n",
      "    update_time_ms: 4.645\n",
      "  iterations_since_restore: 966\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17008.58496785164\n",
      "  time_this_iter_s: 17.543999433517456\n",
      "  time_total_s: 17008.58496785164\n",
      "  timestamp: 1550633461\n",
      "  timesteps_since_restore: 9660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9660000\n",
      "  training_iteration: 966\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17008 s, 966 iter, 9660000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-31-18\n",
      "  done: false\n",
      "  episode_len_mean: 135.06\n",
      "  episode_reward_max: 224.66281063773545\n",
      "  episode_reward_mean: 183.93836014958327\n",
      "  episode_reward_min: 143.10620534313057\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 72983\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7468838691711426\n",
      "      kl: 0.03572629764676094\n",
      "      policy_loss: 0.0038128250744193792\n",
      "      total_loss: 5.58898401260376\n",
      "      vf_explained_var: 0.9981474280357361\n",
      "      vf_loss: 5.585170745849609\n",
      "    grad_time_ms: 1537.202\n",
      "    load_time_ms: 1.376\n",
      "    num_steps_sampled: 9670000\n",
      "    num_steps_trained: 9670000\n",
      "    sample_time_ms: 15717.634\n",
      "    update_time_ms: 4.849\n",
      "  iterations_since_restore: 967\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17025.8518345356\n",
      "  time_this_iter_s: 17.26686668395996\n",
      "  time_total_s: 17025.8518345356\n",
      "  timestamp: 1550633478\n",
      "  timesteps_since_restore: 9670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9670000\n",
      "  training_iteration: 967\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17025 s, 967 iter, 9670000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-31-36\n",
      "  done: false\n",
      "  episode_len_mean: 136.29\n",
      "  episode_reward_max: 214.54635685781875\n",
      "  episode_reward_mean: 180.8267413790327\n",
      "  episode_reward_min: 99.97453554771329\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 73056\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9771366715431213\n",
      "      kl: 0.01750982739031315\n",
      "      policy_loss: -0.00024123623734340072\n",
      "      total_loss: 22.1321964263916\n",
      "      vf_explained_var: 0.9931974411010742\n",
      "      vf_loss: 22.132434844970703\n",
      "    grad_time_ms: 1537.253\n",
      "    load_time_ms: 1.341\n",
      "    num_steps_sampled: 9680000\n",
      "    num_steps_trained: 9680000\n",
      "    sample_time_ms: 15711.091\n",
      "    update_time_ms: 4.884\n",
      "  iterations_since_restore: 968\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17043.11654472351\n",
      "  time_this_iter_s: 17.264710187911987\n",
      "  time_total_s: 17043.11654472351\n",
      "  timestamp: 1550633496\n",
      "  timesteps_since_restore: 9680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9680000\n",
      "  training_iteration: 968\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17043 s, 968 iter, 9680000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-31-53\n",
      "  done: false\n",
      "  episode_len_mean: 135.89\n",
      "  episode_reward_max: 226.47918361499177\n",
      "  episode_reward_mean: 182.03622414422952\n",
      "  episode_reward_min: 99.97453554771329\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 73130\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.669122040271759\n",
      "      kl: 0.022873321548104286\n",
      "      policy_loss: 0.0019742469303309917\n",
      "      total_loss: 15.244791984558105\n",
      "      vf_explained_var: 0.9952213764190674\n",
      "      vf_loss: 15.242816925048828\n",
      "    grad_time_ms: 1554.959\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 9690000\n",
      "    num_steps_trained: 9690000\n",
      "    sample_time_ms: 15736.186\n",
      "    update_time_ms: 4.764\n",
      "  iterations_since_restore: 969\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17060.725158929825\n",
      "  time_this_iter_s: 17.608614206314087\n",
      "  time_total_s: 17060.725158929825\n",
      "  timestamp: 1550633513\n",
      "  timesteps_since_restore: 9690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9690000\n",
      "  training_iteration: 969\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17060 s, 969 iter, 9690000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-32-10\n",
      "  done: false\n",
      "  episode_len_mean: 136.28\n",
      "  episode_reward_max: 221.0717979923333\n",
      "  episode_reward_mean: 182.39079063186128\n",
      "  episode_reward_min: 98.46262357037256\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 73204\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7874771356582642\n",
      "      kl: 0.02066153846681118\n",
      "      policy_loss: -9.380710980622098e-05\n",
      "      total_loss: 14.266266822814941\n",
      "      vf_explained_var: 0.9954490661621094\n",
      "      vf_loss: 14.26636028289795\n",
      "    grad_time_ms: 1554.57\n",
      "    load_time_ms: 1.321\n",
      "    num_steps_sampled: 9700000\n",
      "    num_steps_trained: 9700000\n",
      "    sample_time_ms: 15763.437\n",
      "    update_time_ms: 4.741\n",
      "  iterations_since_restore: 970\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17077.765734672546\n",
      "  time_this_iter_s: 17.040575742721558\n",
      "  time_total_s: 17077.765734672546\n",
      "  timestamp: 1550633530\n",
      "  timesteps_since_restore: 9700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9700000\n",
      "  training_iteration: 970\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17077 s, 970 iter, 9700000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-32-28\n",
      "  done: false\n",
      "  episode_len_mean: 137.18\n",
      "  episode_reward_max: 222.33583466232864\n",
      "  episode_reward_mean: 183.35941496426275\n",
      "  episode_reward_min: 98.46262357037256\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 73277\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7353572249412537\n",
      "      kl: 0.018756594508886337\n",
      "      policy_loss: -0.0017399608623236418\n",
      "      total_loss: 22.39391326904297\n",
      "      vf_explained_var: 0.9935978651046753\n",
      "      vf_loss: 22.39565086364746\n",
      "    grad_time_ms: 1554.791\n",
      "    load_time_ms: 1.33\n",
      "    num_steps_sampled: 9710000\n",
      "    num_steps_trained: 9710000\n",
      "    sample_time_ms: 15750.469\n",
      "    update_time_ms: 4.62\n",
      "  iterations_since_restore: 971\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17094.95712161064\n",
      "  time_this_iter_s: 17.191386938095093\n",
      "  time_total_s: 17094.95712161064\n",
      "  timestamp: 1550633548\n",
      "  timesteps_since_restore: 9710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9710000\n",
      "  training_iteration: 971\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17094 s, 971 iter, 9710000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-32-45\n",
      "  done: false\n",
      "  episode_len_mean: 137.82\n",
      "  episode_reward_max: 227.8751797902554\n",
      "  episode_reward_mean: 183.96192709367767\n",
      "  episode_reward_min: 95.05173100228629\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 73349\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8304821848869324\n",
      "      kl: 0.017482489347457886\n",
      "      policy_loss: -0.00020747641974594444\n",
      "      total_loss: 33.349266052246094\n",
      "      vf_explained_var: 0.9903824925422668\n",
      "      vf_loss: 33.34947204589844\n",
      "    grad_time_ms: 1558.955\n",
      "    load_time_ms: 1.271\n",
      "    num_steps_sampled: 9720000\n",
      "    num_steps_trained: 9720000\n",
      "    sample_time_ms: 15759.588\n",
      "    update_time_ms: 4.645\n",
      "  iterations_since_restore: 972\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17112.448033571243\n",
      "  time_this_iter_s: 17.490911960601807\n",
      "  time_total_s: 17112.448033571243\n",
      "  timestamp: 1550633565\n",
      "  timesteps_since_restore: 9720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9720000\n",
      "  training_iteration: 972\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17112 s, 972 iter, 9720000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-33-03\n",
      "  done: false\n",
      "  episode_len_mean: 137.06\n",
      "  episode_reward_max: 224.43945981462542\n",
      "  episode_reward_mean: 184.64403816480507\n",
      "  episode_reward_min: 95.6359946443007\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 73423\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7021815180778503\n",
      "      kl: 0.031148601323366165\n",
      "      policy_loss: 0.003287645522505045\n",
      "      total_loss: 5.456977844238281\n",
      "      vf_explained_var: 0.998306155204773\n",
      "      vf_loss: 5.453690052032471\n",
      "    grad_time_ms: 1560.695\n",
      "    load_time_ms: 1.302\n",
      "    num_steps_sampled: 9730000\n",
      "    num_steps_trained: 9730000\n",
      "    sample_time_ms: 15797.632\n",
      "    update_time_ms: 4.563\n",
      "  iterations_since_restore: 973\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17130.212431192398\n",
      "  time_this_iter_s: 17.764397621154785\n",
      "  time_total_s: 17130.212431192398\n",
      "  timestamp: 1550633583\n",
      "  timesteps_since_restore: 9730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9730000\n",
      "  training_iteration: 973\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17130 s, 973 iter, 9730000 ts, 185 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-33-20\n",
      "  done: false\n",
      "  episode_len_mean: 136.16\n",
      "  episode_reward_max: 224.43945981462542\n",
      "  episode_reward_mean: 181.73875281058486\n",
      "  episode_reward_min: 93.94445722203434\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 73496\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.766737163066864\n",
      "      kl: 0.01614784635603428\n",
      "      policy_loss: -0.0005431046010926366\n",
      "      total_loss: 42.32971954345703\n",
      "      vf_explained_var: 0.9878865480422974\n",
      "      vf_loss: 42.33026885986328\n",
      "    grad_time_ms: 1560.907\n",
      "    load_time_ms: 1.278\n",
      "    num_steps_sampled: 9740000\n",
      "    num_steps_trained: 9740000\n",
      "    sample_time_ms: 15760.64\n",
      "    update_time_ms: 4.479\n",
      "  iterations_since_restore: 974\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17147.17279958725\n",
      "  time_this_iter_s: 16.960368394851685\n",
      "  time_total_s: 17147.17279958725\n",
      "  timestamp: 1550633600\n",
      "  timesteps_since_restore: 9740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9740000\n",
      "  training_iteration: 974\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17147 s, 974 iter, 9740000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-33-37\n",
      "  done: false\n",
      "  episode_len_mean: 136.58\n",
      "  episode_reward_max: 219.30402781415984\n",
      "  episode_reward_mean: 184.0409830877883\n",
      "  episode_reward_min: 103.72992557279835\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 73569\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7437368035316467\n",
      "      kl: 0.030699625611305237\n",
      "      policy_loss: 0.0027052604127675295\n",
      "      total_loss: 6.213042259216309\n",
      "      vf_explained_var: 0.9980276823043823\n",
      "      vf_loss: 6.210337162017822\n",
      "    grad_time_ms: 1559.688\n",
      "    load_time_ms: 1.283\n",
      "    num_steps_sampled: 9750000\n",
      "    num_steps_trained: 9750000\n",
      "    sample_time_ms: 15753.965\n",
      "    update_time_ms: 4.476\n",
      "  iterations_since_restore: 975\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17164.36170244217\n",
      "  time_this_iter_s: 17.188902854919434\n",
      "  time_total_s: 17164.36170244217\n",
      "  timestamp: 1550633617\n",
      "  timesteps_since_restore: 9750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9750000\n",
      "  training_iteration: 975\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17164 s, 975 iter, 9750000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-33-54\n",
      "  done: false\n",
      "  episode_len_mean: 136.16\n",
      "  episode_reward_max: 219.30402781415984\n",
      "  episode_reward_mean: 186.08094982682096\n",
      "  episode_reward_min: 143.50002100237515\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 73642\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7777591943740845\n",
      "      kl: 0.020153643563389778\n",
      "      policy_loss: -0.0006964863860048354\n",
      "      total_loss: 6.194509029388428\n",
      "      vf_explained_var: 0.9979565143585205\n",
      "      vf_loss: 6.195204734802246\n",
      "    grad_time_ms: 1576.938\n",
      "    load_time_ms: 1.278\n",
      "    num_steps_sampled: 9760000\n",
      "    num_steps_trained: 9760000\n",
      "    sample_time_ms: 15695.316\n",
      "    update_time_ms: 4.401\n",
      "  iterations_since_restore: 976\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17181.49075770378\n",
      "  time_this_iter_s: 17.12905526161194\n",
      "  time_total_s: 17181.49075770378\n",
      "  timestamp: 1550633634\n",
      "  timesteps_since_restore: 9760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9760000\n",
      "  training_iteration: 976\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17181 s, 976 iter, 9760000 ts, 186 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-34-11\n",
      "  done: false\n",
      "  episode_len_mean: 136.95\n",
      "  episode_reward_max: 217.65106553270812\n",
      "  episode_reward_mean: 187.2951446885128\n",
      "  episode_reward_min: 143.50002100237515\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 73715\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8165924549102783\n",
      "      kl: 0.020356597378849983\n",
      "      policy_loss: -0.0018167999805882573\n",
      "      total_loss: 7.893710613250732\n",
      "      vf_explained_var: 0.9975044131278992\n",
      "      vf_loss: 7.895528316497803\n",
      "    grad_time_ms: 1578.201\n",
      "    load_time_ms: 1.339\n",
      "    num_steps_sampled: 9770000\n",
      "    num_steps_trained: 9770000\n",
      "    sample_time_ms: 15684.239\n",
      "    update_time_ms: 4.154\n",
      "  iterations_since_restore: 977\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17198.66071152687\n",
      "  time_this_iter_s: 17.1699538230896\n",
      "  time_total_s: 17198.66071152687\n",
      "  timestamp: 1550633651\n",
      "  timesteps_since_restore: 9770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9770000\n",
      "  training_iteration: 977\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17198 s, 977 iter, 9770000 ts, 187 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-34-29\n",
      "  done: false\n",
      "  episode_len_mean: 138.14\n",
      "  episode_reward_max: 224.44246293353558\n",
      "  episode_reward_mean: 188.9338141929252\n",
      "  episode_reward_min: 106.8151467145965\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 73787\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7929177284240723\n",
      "      kl: 0.014582864940166473\n",
      "      policy_loss: -0.0002753693552222103\n",
      "      total_loss: 15.553244590759277\n",
      "      vf_explained_var: 0.9957686066627502\n",
      "      vf_loss: 15.553520202636719\n",
      "    grad_time_ms: 1577.929\n",
      "    load_time_ms: 1.394\n",
      "    num_steps_sampled: 9780000\n",
      "    num_steps_trained: 9780000\n",
      "    sample_time_ms: 15686.337\n",
      "    update_time_ms: 4.018\n",
      "  iterations_since_restore: 978\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17215.942237377167\n",
      "  time_this_iter_s: 17.28152585029602\n",
      "  time_total_s: 17215.942237377167\n",
      "  timestamp: 1550633669\n",
      "  timesteps_since_restore: 9780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9780000\n",
      "  training_iteration: 978\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17215 s, 978 iter, 9780000 ts, 189 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-34-46\n",
      "  done: false\n",
      "  episode_len_mean: 138.57\n",
      "  episode_reward_max: 224.44246293353558\n",
      "  episode_reward_mean: 182.34419397365855\n",
      "  episode_reward_min: 67.99244964963736\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 73860\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8439425826072693\n",
      "      kl: 0.012609871104359627\n",
      "      policy_loss: -0.0018842276185750961\n",
      "      total_loss: 37.14928436279297\n",
      "      vf_explained_var: 0.989680826663971\n",
      "      vf_loss: 37.15116882324219\n",
      "    grad_time_ms: 1559.259\n",
      "    load_time_ms: 1.395\n",
      "    num_steps_sampled: 9790000\n",
      "    num_steps_trained: 9790000\n",
      "    sample_time_ms: 15675.522\n",
      "    update_time_ms: 4.007\n",
      "  iterations_since_restore: 979\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17233.255442142487\n",
      "  time_this_iter_s: 17.313204765319824\n",
      "  time_total_s: 17233.255442142487\n",
      "  timestamp: 1550633686\n",
      "  timesteps_since_restore: 9790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9790000\n",
      "  training_iteration: 979\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17233 s, 979 iter, 9790000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-35-03\n",
      "  done: false\n",
      "  episode_len_mean: 138.09\n",
      "  episode_reward_max: 219.7168109654864\n",
      "  episode_reward_mean: 181.50177886835883\n",
      "  episode_reward_min: 67.99244964963736\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 73933\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7479416131973267\n",
      "      kl: 0.02002030424773693\n",
      "      policy_loss: 0.00034669539309106767\n",
      "      total_loss: 16.064239501953125\n",
      "      vf_explained_var: 0.9952051043510437\n",
      "      vf_loss: 16.06389045715332\n",
      "    grad_time_ms: 1558.888\n",
      "    load_time_ms: 1.398\n",
      "    num_steps_sampled: 9800000\n",
      "    num_steps_trained: 9800000\n",
      "    sample_time_ms: 15685.569\n",
      "    update_time_ms: 3.932\n",
      "  iterations_since_restore: 980\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17250.39217233658\n",
      "  time_this_iter_s: 17.136730194091797\n",
      "  time_total_s: 17250.39217233658\n",
      "  timestamp: 1550633703\n",
      "  timesteps_since_restore: 9800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9800000\n",
      "  training_iteration: 980\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17250 s, 980 iter, 9800000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-35-21\n",
      "  done: false\n",
      "  episode_len_mean: 140.21\n",
      "  episode_reward_max: 219.37599894847017\n",
      "  episode_reward_mean: 181.61579857624915\n",
      "  episode_reward_min: 82.70361650891448\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 74003\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.202473759651184\n",
      "      kl: 0.013685569167137146\n",
      "      policy_loss: -0.00012183206126792356\n",
      "      total_loss: 41.719215393066406\n",
      "      vf_explained_var: 0.9880845546722412\n",
      "      vf_loss: 41.719337463378906\n",
      "    grad_time_ms: 1559.547\n",
      "    load_time_ms: 1.392\n",
      "    num_steps_sampled: 9810000\n",
      "    num_steps_trained: 9810000\n",
      "    sample_time_ms: 15710.29\n",
      "    update_time_ms: 3.986\n",
      "  iterations_since_restore: 981\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17267.836965084076\n",
      "  time_this_iter_s: 17.44479274749756\n",
      "  time_total_s: 17267.836965084076\n",
      "  timestamp: 1550633721\n",
      "  timesteps_since_restore: 9810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9810000\n",
      "  training_iteration: 981\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17267 s, 981 iter, 9810000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-35-38\n",
      "  done: false\n",
      "  episode_len_mean: 138.73\n",
      "  episode_reward_max: 221.43835344163725\n",
      "  episode_reward_mean: 180.97484192413955\n",
      "  episode_reward_min: 95.27145781463915\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 74075\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8720832467079163\n",
      "      kl: 0.019477354362607002\n",
      "      policy_loss: -0.0013097742339596152\n",
      "      total_loss: 21.287776947021484\n",
      "      vf_explained_var: 0.9935908317565918\n",
      "      vf_loss: 21.289085388183594\n",
      "    grad_time_ms: 1555.901\n",
      "    load_time_ms: 1.414\n",
      "    num_steps_sampled: 9820000\n",
      "    num_steps_trained: 9820000\n",
      "    sample_time_ms: 15730.377\n",
      "    update_time_ms: 3.918\n",
      "  iterations_since_restore: 982\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17285.495622873306\n",
      "  time_this_iter_s: 17.658657789230347\n",
      "  time_total_s: 17285.495622873306\n",
      "  timestamp: 1550633738\n",
      "  timesteps_since_restore: 9820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9820000\n",
      "  training_iteration: 982\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17285 s, 982 iter, 9820000 ts, 181 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-35-56\n",
      "  done: false\n",
      "  episode_len_mean: 139.09\n",
      "  episode_reward_max: 224.33940751122134\n",
      "  episode_reward_mean: 184.31024738529788\n",
      "  episode_reward_min: 86.28956522364714\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 74147\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9766778349876404\n",
      "      kl: 0.020818082615733147\n",
      "      policy_loss: -0.001661797403357923\n",
      "      total_loss: 15.535380363464355\n",
      "      vf_explained_var: 0.995347261428833\n",
      "      vf_loss: 15.537040710449219\n",
      "    grad_time_ms: 1553.49\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 9830000\n",
      "    num_steps_trained: 9830000\n",
      "    sample_time_ms: 15730.941\n",
      "    update_time_ms: 4.001\n",
      "  iterations_since_restore: 983\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17303.24228000641\n",
      "  time_this_iter_s: 17.746657133102417\n",
      "  time_total_s: 17303.24228000641\n",
      "  timestamp: 1550633756\n",
      "  timesteps_since_restore: 9830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9830000\n",
      "  training_iteration: 983\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17303 s, 983 iter, 9830000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-36-14\n",
      "  done: false\n",
      "  episode_len_mean: 141.59\n",
      "  episode_reward_max: 223.8390949090369\n",
      "  episode_reward_mean: 187.84845409561066\n",
      "  episode_reward_min: 94.38358086399217\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 74218\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0516375303268433\n",
      "      kl: 0.03262455016374588\n",
      "      policy_loss: -0.0008421232923865318\n",
      "      total_loss: 28.633121490478516\n",
      "      vf_explained_var: 0.9918522834777832\n",
      "      vf_loss: 28.63396453857422\n",
      "    grad_time_ms: 1554.539\n",
      "    load_time_ms: 1.39\n",
      "    num_steps_sampled: 9840000\n",
      "    num_steps_trained: 9840000\n",
      "    sample_time_ms: 15796.213\n",
      "    update_time_ms: 4.052\n",
      "  iterations_since_restore: 984\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17320.86873626709\n",
      "  time_this_iter_s: 17.626456260681152\n",
      "  time_total_s: 17320.86873626709\n",
      "  timestamp: 1550633774\n",
      "  timesteps_since_restore: 9840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9840000\n",
      "  training_iteration: 984\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17320 s, 984 iter, 9840000 ts, 188 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-36-32\n",
      "  done: false\n",
      "  episode_len_mean: 139.14\n",
      "  episode_reward_max: 224.88901873799685\n",
      "  episode_reward_mean: 188.03874313036198\n",
      "  episode_reward_min: 100.33296690379643\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 74290\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7464337348937988\n",
      "      kl: 0.023264002054929733\n",
      "      policy_loss: -0.0005469695897772908\n",
      "      total_loss: 17.144025802612305\n",
      "      vf_explained_var: 0.9949612617492676\n",
      "      vf_loss: 17.144569396972656\n",
      "    grad_time_ms: 1558.031\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 9850000\n",
      "    num_steps_trained: 9850000\n",
      "    sample_time_ms: 15840.158\n",
      "    update_time_ms: 4.059\n",
      "  iterations_since_restore: 985\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17338.533415317535\n",
      "  time_this_iter_s: 17.664679050445557\n",
      "  time_total_s: 17338.533415317535\n",
      "  timestamp: 1550633792\n",
      "  timesteps_since_restore: 9850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9850000\n",
      "  training_iteration: 985\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17338 s, 985 iter, 9850000 ts, 188 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-36-48\n",
      "  done: false\n",
      "  episode_len_mean: 139.12\n",
      "  episode_reward_max: 223.7467601130726\n",
      "  episode_reward_mean: 188.16178288751064\n",
      "  episode_reward_min: 94.90563204863145\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 74361\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6202595233917236\n",
      "      kl: 0.023412605747580528\n",
      "      policy_loss: -0.0014168221969157457\n",
      "      total_loss: 15.829509735107422\n",
      "      vf_explained_var: 0.9956265687942505\n",
      "      vf_loss: 15.8309326171875\n",
      "    grad_time_ms: 1539.865\n",
      "    load_time_ms: 1.389\n",
      "    num_steps_sampled: 9860000\n",
      "    num_steps_trained: 9860000\n",
      "    sample_time_ms: 15822.951\n",
      "    update_time_ms: 4.166\n",
      "  iterations_since_restore: 986\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17355.30761051178\n",
      "  time_this_iter_s: 16.774195194244385\n",
      "  time_total_s: 17355.30761051178\n",
      "  timestamp: 1550633808\n",
      "  timesteps_since_restore: 9860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9860000\n",
      "  training_iteration: 986\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17355 s, 986 iter, 9860000 ts, 188 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-37-06\n",
      "  done: false\n",
      "  episode_len_mean: 139.07\n",
      "  episode_reward_max: 223.7467601130726\n",
      "  episode_reward_mean: 186.76691048991478\n",
      "  episode_reward_min: 96.04561715727152\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 74434\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7550634145736694\n",
      "      kl: 0.016629131510853767\n",
      "      policy_loss: -0.0005187359056435525\n",
      "      total_loss: 26.76740837097168\n",
      "      vf_explained_var: 0.9923635721206665\n",
      "      vf_loss: 26.767925262451172\n",
      "    grad_time_ms: 1537.525\n",
      "    load_time_ms: 1.324\n",
      "    num_steps_sampled: 9870000\n",
      "    num_steps_trained: 9870000\n",
      "    sample_time_ms: 15833.027\n",
      "    update_time_ms: 4.213\n",
      "  iterations_since_restore: 987\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17372.553245067596\n",
      "  time_this_iter_s: 17.24563455581665\n",
      "  time_total_s: 17372.553245067596\n",
      "  timestamp: 1550633826\n",
      "  timesteps_since_restore: 9870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9870000\n",
      "  training_iteration: 987\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17372 s, 987 iter, 9870000 ts, 187 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-37-23\n",
      "  done: false\n",
      "  episode_len_mean: 138.37\n",
      "  episode_reward_max: 218.04763584982328\n",
      "  episode_reward_mean: 184.99763031475257\n",
      "  episode_reward_min: 98.79688689732308\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 74506\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8192660808563232\n",
      "      kl: 0.020324958488345146\n",
      "      policy_loss: -0.002686668187379837\n",
      "      total_loss: 25.526208877563477\n",
      "      vf_explained_var: 0.992505669593811\n",
      "      vf_loss: 25.52889633178711\n",
      "    grad_time_ms: 1555.903\n",
      "    load_time_ms: 1.265\n",
      "    num_steps_sampled: 9880000\n",
      "    num_steps_trained: 9880000\n",
      "    sample_time_ms: 15833.197\n",
      "    update_time_ms: 4.352\n",
      "  iterations_since_restore: 988\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17390.022455215454\n",
      "  time_this_iter_s: 17.469210147857666\n",
      "  time_total_s: 17390.022455215454\n",
      "  timestamp: 1550633843\n",
      "  timesteps_since_restore: 9880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9880000\n",
      "  training_iteration: 988\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17390 s, 988 iter, 9880000 ts, 185 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-37-41\n",
      "  done: false\n",
      "  episode_len_mean: 138.17\n",
      "  episode_reward_max: 229.97942278622696\n",
      "  episode_reward_mean: 183.82657590937708\n",
      "  episode_reward_min: 106.8243500560448\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 74579\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8389074802398682\n",
      "      kl: 0.018782582134008408\n",
      "      policy_loss: 0.00014202800230123103\n",
      "      total_loss: 16.679073333740234\n",
      "      vf_explained_var: 0.9947080612182617\n",
      "      vf_loss: 16.67893409729004\n",
      "    grad_time_ms: 1556.036\n",
      "    load_time_ms: 1.274\n",
      "    num_steps_sampled: 9890000\n",
      "    num_steps_trained: 9890000\n",
      "    sample_time_ms: 15828.612\n",
      "    update_time_ms: 4.443\n",
      "  iterations_since_restore: 989\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17407.29502606392\n",
      "  time_this_iter_s: 17.272570848464966\n",
      "  time_total_s: 17407.29502606392\n",
      "  timestamp: 1550633861\n",
      "  timesteps_since_restore: 9890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9890000\n",
      "  training_iteration: 989\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17407 s, 989 iter, 9890000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-37-58\n",
      "  done: false\n",
      "  episode_len_mean: 139.02\n",
      "  episode_reward_max: 219.04355241745571\n",
      "  episode_reward_mean: 185.4095485199528\n",
      "  episode_reward_min: 95.97080146602474\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 74651\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7158054709434509\n",
      "      kl: 0.020975185558199883\n",
      "      policy_loss: 0.0011273418786004186\n",
      "      total_loss: 20.575063705444336\n",
      "      vf_explained_var: 0.9937517046928406\n",
      "      vf_loss: 20.57393455505371\n",
      "    grad_time_ms: 1558.209\n",
      "    load_time_ms: 1.316\n",
      "    num_steps_sampled: 9900000\n",
      "    num_steps_trained: 9900000\n",
      "    sample_time_ms: 15870.161\n",
      "    update_time_ms: 4.602\n",
      "  iterations_since_restore: 990\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17424.871388673782\n",
      "  time_this_iter_s: 17.57636260986328\n",
      "  time_total_s: 17424.871388673782\n",
      "  timestamp: 1550633878\n",
      "  timesteps_since_restore: 9900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9900000\n",
      "  training_iteration: 990\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17424 s, 990 iter, 9900000 ts, 185 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-38-16\n",
      "  done: false\n",
      "  episode_len_mean: 140.05\n",
      "  episode_reward_max: 223.88216065726056\n",
      "  episode_reward_mean: 185.59784112372373\n",
      "  episode_reward_min: 67.10253205408563\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 74721\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9590182304382324\n",
      "      kl: 0.01851075328886509\n",
      "      policy_loss: -0.0018294703913852572\n",
      "      total_loss: 43.55040740966797\n",
      "      vf_explained_var: 0.9872342348098755\n",
      "      vf_loss: 43.55223846435547\n",
      "    grad_time_ms: 1558.89\n",
      "    load_time_ms: 1.314\n",
      "    num_steps_sampled: 9910000\n",
      "    num_steps_trained: 9910000\n",
      "    sample_time_ms: 15891.889\n",
      "    update_time_ms: 4.64\n",
      "  iterations_since_restore: 991\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17442.540298461914\n",
      "  time_this_iter_s: 17.668909788131714\n",
      "  time_total_s: 17442.540298461914\n",
      "  timestamp: 1550633896\n",
      "  timesteps_since_restore: 9910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9910000\n",
      "  training_iteration: 991\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17442 s, 991 iter, 9910000 ts, 186 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-38-33\n",
      "  done: false\n",
      "  episode_len_mean: 139.57\n",
      "  episode_reward_max: 222.51798440781562\n",
      "  episode_reward_mean: 183.46271541757426\n",
      "  episode_reward_min: 67.10253205408563\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 74794\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5768851637840271\n",
      "      kl: 0.01960967667400837\n",
      "      policy_loss: -0.0014868176076561213\n",
      "      total_loss: 31.761947631835938\n",
      "      vf_explained_var: 0.9908790588378906\n",
      "      vf_loss: 31.763431549072266\n",
      "    grad_time_ms: 1559.329\n",
      "    load_time_ms: 1.334\n",
      "    num_steps_sampled: 9920000\n",
      "    num_steps_trained: 9920000\n",
      "    sample_time_ms: 15852.122\n",
      "    update_time_ms: 4.702\n",
      "  iterations_since_restore: 992\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17459.803182840347\n",
      "  time_this_iter_s: 17.262884378433228\n",
      "  time_total_s: 17459.803182840347\n",
      "  timestamp: 1550633913\n",
      "  timesteps_since_restore: 9920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9920000\n",
      "  training_iteration: 992\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17459 s, 992 iter, 9920000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-38-51\n",
      "  done: false\n",
      "  episode_len_mean: 137.6\n",
      "  episode_reward_max: 218.64263625079664\n",
      "  episode_reward_mean: 183.96068211156074\n",
      "  episode_reward_min: 100.93338448026844\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 74866\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7991044521331787\n",
      "      kl: 0.026053424924612045\n",
      "      policy_loss: -0.0015982295153662562\n",
      "      total_loss: 20.24595069885254\n",
      "      vf_explained_var: 0.9936627149581909\n",
      "      vf_loss: 20.24755096435547\n",
      "    grad_time_ms: 1559.966\n",
      "    load_time_ms: 1.327\n",
      "    num_steps_sampled: 9930000\n",
      "    num_steps_trained: 9930000\n",
      "    sample_time_ms: 15821.447\n",
      "    update_time_ms: 4.708\n",
      "  iterations_since_restore: 993\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17477.249185800552\n",
      "  time_this_iter_s: 17.446002960205078\n",
      "  time_total_s: 17477.249185800552\n",
      "  timestamp: 1550633931\n",
      "  timesteps_since_restore: 9930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9930000\n",
      "  training_iteration: 993\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17477 s, 993 iter, 9930000 ts, 184 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-39-08\n",
      "  done: false\n",
      "  episode_len_mean: 137.26\n",
      "  episode_reward_max: 221.76272301700436\n",
      "  episode_reward_mean: 181.99067571176528\n",
      "  episode_reward_min: 94.49710506388905\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 74940\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5966701507568359\n",
      "      kl: 0.03773609921336174\n",
      "      policy_loss: -0.0035884410608559847\n",
      "      total_loss: 38.81904983520508\n",
      "      vf_explained_var: 0.9891122579574585\n",
      "      vf_loss: 38.82263946533203\n",
      "    grad_time_ms: 1557.443\n",
      "    load_time_ms: 1.339\n",
      "    num_steps_sampled: 9940000\n",
      "    num_steps_trained: 9940000\n",
      "    sample_time_ms: 15784.139\n",
      "    update_time_ms: 4.637\n",
      "  iterations_since_restore: 994\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17494.475570440292\n",
      "  time_this_iter_s: 17.22638463973999\n",
      "  time_total_s: 17494.475570440292\n",
      "  timestamp: 1550633948\n",
      "  timesteps_since_restore: 9940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9940000\n",
      "  training_iteration: 994\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17494 s, 994 iter, 9940000 ts, 182 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-39-25\n",
      "  done: false\n",
      "  episode_len_mean: 138.54\n",
      "  episode_reward_max: 221.76272301700436\n",
      "  episode_reward_mean: 183.38006990306843\n",
      "  episode_reward_min: 79.40359455398692\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 75011\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6506057381629944\n",
      "      kl: 0.023643195629119873\n",
      "      policy_loss: -0.0026253978721797466\n",
      "      total_loss: 37.74233627319336\n",
      "      vf_explained_var: 0.989445149898529\n",
      "      vf_loss: 37.74496841430664\n",
      "    grad_time_ms: 1554.692\n",
      "    load_time_ms: 1.32\n",
      "    num_steps_sampled: 9950000\n",
      "    num_steps_trained: 9950000\n",
      "    sample_time_ms: 15751.1\n",
      "    update_time_ms: 4.712\n",
      "  iterations_since_restore: 995\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17511.783388614655\n",
      "  time_this_iter_s: 17.307818174362183\n",
      "  time_total_s: 17511.783388614655\n",
      "  timestamp: 1550633965\n",
      "  timesteps_since_restore: 9950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9950000\n",
      "  training_iteration: 995\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17511 s, 995 iter, 9950000 ts, 183 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-39-43\n",
      "  done: false\n",
      "  episode_len_mean: 141.4\n",
      "  episode_reward_max: 224.6802843379059\n",
      "  episode_reward_mean: 185.8964425861441\n",
      "  episode_reward_min: 92.1411522958254\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 75081\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 7.822571572683087e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9852824807167053\n",
      "      kl: 33.08645248413086\n",
      "      policy_loss: 0.03139563277363777\n",
      "      total_loss: 28.06214714050293\n",
      "      vf_explained_var: 0.9923104643821716\n",
      "      vf_loss: 28.030752182006836\n",
      "    grad_time_ms: 1562.339\n",
      "    load_time_ms: 1.318\n",
      "    num_steps_sampled: 9960000\n",
      "    num_steps_trained: 9960000\n",
      "    sample_time_ms: 15840.101\n",
      "    update_time_ms: 4.69\n",
      "  iterations_since_restore: 996\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17529.524015665054\n",
      "  time_this_iter_s: 17.74062705039978\n",
      "  time_total_s: 17529.524015665054\n",
      "  timestamp: 1550633983\n",
      "  timesteps_since_restore: 9960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9960000\n",
      "  training_iteration: 996\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17529 s, 996 iter, 9960000 ts, 186 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-40-01\n",
      "  done: false\n",
      "  episode_len_mean: 136.5\n",
      "  episode_reward_max: 217.1559557459586\n",
      "  episode_reward_mean: 180.06198064715102\n",
      "  episode_reward_min: 104.74594083140695\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 75155\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.173386097793981e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5226399898529053\n",
      "      kl: 0.033098723739385605\n",
      "      policy_loss: 0.0003526665095705539\n",
      "      total_loss: 12.71113395690918\n",
      "      vf_explained_var: 0.9959396123886108\n",
      "      vf_loss: 12.710780143737793\n",
      "    grad_time_ms: 1566.601\n",
      "    load_time_ms: 1.354\n",
      "    num_steps_sampled: 9970000\n",
      "    num_steps_trained: 9970000\n",
      "    sample_time_ms: 15865.824\n",
      "    update_time_ms: 4.73\n",
      "  iterations_since_restore: 997\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17547.071156978607\n",
      "  time_this_iter_s: 17.547141313552856\n",
      "  time_total_s: 17547.071156978607\n",
      "  timestamp: 1550634001\n",
      "  timesteps_since_restore: 9970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9970000\n",
      "  training_iteration: 997\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17547 s, 997 iter, 9970000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-40-18\n",
      "  done: false\n",
      "  episode_len_mean: 135.06\n",
      "  episode_reward_max: 211.5953194776384\n",
      "  episode_reward_mean: 179.53091875647843\n",
      "  episode_reward_min: 139.62859382225886\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 75230\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.173386097793981e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5296717286109924\n",
      "      kl: 0.04450012743473053\n",
      "      policy_loss: 0.005739503540098667\n",
      "      total_loss: 4.711845397949219\n",
      "      vf_explained_var: 0.9983935356140137\n",
      "      vf_loss: 4.706105709075928\n",
      "    grad_time_ms: 1550.533\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 9980000\n",
      "    num_steps_trained: 9980000\n",
      "    sample_time_ms: 15875.624\n",
      "    update_time_ms: 4.718\n",
      "  iterations_since_restore: 998\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17564.47622036934\n",
      "  time_this_iter_s: 17.40506339073181\n",
      "  time_total_s: 17564.47622036934\n",
      "  timestamp: 1550634018\n",
      "  timesteps_since_restore: 9980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9980000\n",
      "  training_iteration: 998\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17564 s, 998 iter, 9980000 ts, 180 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-40-36\n",
      "  done: false\n",
      "  episode_len_mean: 136.06\n",
      "  episode_reward_max: 217.6849885867299\n",
      "  episode_reward_mean: 178.79000033398745\n",
      "  episode_reward_min: 105.614347272407\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 75303\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.760079250088548e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5611960291862488\n",
      "      kl: 0.02137773111462593\n",
      "      policy_loss: 0.0015367850428447127\n",
      "      total_loss: 8.734923362731934\n",
      "      vf_explained_var: 0.9972985982894897\n",
      "      vf_loss: 8.73338794708252\n",
      "    grad_time_ms: 1552.813\n",
      "    load_time_ms: 1.405\n",
      "    num_steps_sampled: 9990000\n",
      "    num_steps_trained: 9990000\n",
      "    sample_time_ms: 15919.306\n",
      "    update_time_ms: 4.652\n",
      "  iterations_since_restore: 999\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17582.206612110138\n",
      "  time_this_iter_s: 17.73039174079895\n",
      "  time_total_s: 17582.206612110138\n",
      "  timestamp: 1550634036\n",
      "  timesteps_since_restore: 9990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9990000\n",
      "  training_iteration: 999\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tRUNNING [pid=11085], 17582 s, 999 iter, 9990000 ts, 179 rew\n",
      "\n",
      "Result for PPO_IntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-20_04-40-53\n",
      "  done: true\n",
      "  episode_len_mean: 135.5\n",
      "  episode_reward_max: 211.2145107924052\n",
      "  episode_reward_mean: 181.59267295914935\n",
      "  episode_reward_min: 140.22116787892082\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 75377\n",
      "  experiment_id: 9d2cfd4ba2f7483a838320c419e6817d\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    default:\n",
      "      cur_kl_coeff: 1.760079250088548e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.467109739780426\n",
      "      kl: 0.031539496034383774\n",
      "      policy_loss: 0.0014065781142562628\n",
      "      total_loss: 4.43518590927124\n",
      "      vf_explained_var: 0.9985412359237671\n",
      "      vf_loss: 4.433780193328857\n",
      "    grad_time_ms: 1572.003\n",
      "    load_time_ms: 1.359\n",
      "    num_steps_sampled: 10000000\n",
      "    num_steps_trained: 10000000\n",
      "    sample_time_ms: 15888.3\n",
      "    update_time_ms: 4.586\n",
      "  iterations_since_restore: 1000\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 11085\n",
      "  policy_reward_mean: {}\n",
      "  time_since_restore: 17599.663439512253\n",
      "  time_this_iter_s: 17.456827402114868\n",
      "  time_total_s: 17599.663439512253\n",
      "  timestamp: 1550634053\n",
      "  timesteps_since_restore: 10000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000000\n",
      "  training_iteration: 1000\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tTERMINATED [pid=11085], 17599 s, 1000 iter, 10000000 ts, 182 rew\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_IntersectionEnv-v0_0:\tTERMINATED [pid=11085], 17599 s, 1000 iter, 10000000 ts, 182 rew\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,  # RL algorithm to run\n",
    "        \"env\": gym_name,  # environment name generated earlier\n",
    "        \"config\": {  # configuration params (must match \"run\" value)\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 1,  # number of iterations between checkpoints\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 1000,  # number of iterations to stop after\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flow_2)",
   "language": "python",
   "name": "flow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
