{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING I3W\n",
    "\n",
    "\n",
    "# A) Create Envorinment, Vehicles etc\n",
    "\n",
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scenarios:\n",
      "['Scenario', 'BayBridgeScenario', 'BayBridgeTollScenario', 'BottleneckScenario', 'Figure8Scenario', 'SimpleGridScenario', 'HighwayScenario', 'LoopScenario', 'MergeScenario', 'TwoLoopsOneMergingScenario', 'MultiLoopScenario', 'IntersectionScenarioTW']\n",
      "\n",
      "Available environments:\n",
      "['MultiEnv', 'MultiAgentAccelEnv', 'MultiWaveAttenuationPOEnv', 'MultiAgentIntersectionEnv', 'MultiAgentTeamSpiritIntersectionEnv', 'MultiAgentIntersectionEnv_baseline_1', 'MultiAgentIntersectionEnv_baseline_2', 'MultiAgentIntersectionEnv_baseline_3']\n"
     ]
    }
   ],
   "source": [
    "# Define horizon as a variable to ensure consistent use across notebook (length of one rollout)\n",
    "HORIZON=500                                 #103 max Horizon, wenn es vor verlassen abbrechen soll!, default war 500\n",
    "\n",
    "# name of the experiment\n",
    "experiment_name = \"IntersectionExample\"\n",
    "\n",
    "# scenario class\n",
    "import flow.scenarios as scenarios\n",
    "print(\"Available scenarios:\")\n",
    "print(scenarios.__all__)\n",
    "scenario_name = \"IntersectionTWScenario\"\n",
    "\n",
    "# environment class\n",
    "import flow.multiagent_envs as flowenvs\n",
    "print(\"\\nAvailable environments:\")\n",
    "print(flowenvs.__all__)\n",
    "env_name = \"MultiAgentIntersectionEnv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import NetParams\n",
    "from flow.scenarios.intersection import ADDITIONAL_NET_PARAMS\n",
    "\n",
    "additionalNetParams = {\n",
    "            \"edge_length\": 40,\n",
    "            \"lanes\": 1,\n",
    "            \"speed_limit\": 30\n",
    "        }\n",
    "\n",
    "net_params = NetParams( no_internal_links=False,                  #default: True   !! damit Kreuzungen nicht Ã¼berspr. werden\n",
    "                        inflows=None,                             #default: None\n",
    "                        osm_path=None,                            #default: None\n",
    "                        netfile=None,                             #default: None\n",
    "                        additional_params=additionalNetParams     #default: None   !!\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitialConfig Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import InitialConfig\n",
    "\n",
    "initial_config = InitialConfig( shuffle=True,                            #default: False         !!\n",
    "                                spacing=\"custom\",                        #default: \"uniform\"     !!\n",
    "                                min_gap=10,                              #default: 0\n",
    "                                perturbation=29.99,                      #default: 0.0            !!        \n",
    "                                x0=0,                                    #default: 0\n",
    "                                bunching=0,                              #default: 0\n",
    "                                lanes_distribution=float(\"inf\"),         #default: float(\"inf\")\n",
    "                                edges_distribution=\"all\",                #default: \"all\"\n",
    "                                additional_params=None )                 #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMO Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sumo_params = SumoParams( port = None,                  #default: None\n",
    "                          sim_step=0.1,                 #default: 0.1\n",
    "                          emission_path=None,           #default: None\n",
    "                          lateral_resolution=None,      #default: None\n",
    "                          no_step_log=True,             #default: True\n",
    "                          render=False,                 #default: False\n",
    "                          save_render=False,            #default: False\n",
    "                          sight_radius=25,              #default: 25\n",
    "                          show_radius=False,            #default: False\n",
    "                          pxpm=2,                       #default: 2\n",
    "                          overtake_right=False,         #default: False    \n",
    "                          seed=None,                    #default: None\n",
    "                          restart_instance=False,       #default: False\n",
    "                          print_warnings=True,          #default: True\n",
    "                          teleport_time=-1,             #default: -1\n",
    "                          num_clients=1,                #default: 1\n",
    "                          sumo_binary=None )            #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "additionalEnvParams = {\n",
    "        # maximum acceleration of autonomous vehicles\n",
    "        \"max_accel\": 3,\n",
    "        # maximum deceleration of autonomous vehicles\n",
    "        \"max_decel\": 3,\n",
    "        \"target_velocity\": 30\n",
    "    }\n",
    "\n",
    "env_params = EnvParams( additional_params=additionalEnvParams, #default: None    !!\n",
    "                        horizon=HORIZON,                       #default: 500     !!\n",
    "                        warmup_steps=0,                        #default: 0       \n",
    "                        sims_per_step=1,                       #default: 1\n",
    "                        evaluate=False )                       #default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import VehicleParams\n",
    "\n",
    "# import vehicles dynamics models\n",
    "#from flow.controllers import SumoCarFollowingController\n",
    "from flow.controllers import ContinuousRouter\n",
    "#from flow.controllers.lane_change_controllers import SumoLaneChangeController\n",
    "from flow.controllers.lane_change_controllers import StaticLaneChanger\n",
    "from flow.controllers import RLController\n",
    "from flow.core.params import SumoLaneChangeParams\n",
    "from flow.core.params import SumoCarFollowingParams\n",
    "from random import *\n",
    "\n",
    "vehicles = VehicleParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add RL-Agent controlled vehicles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car following parameters, default: None\n",
    "cf_parameter = SumoCarFollowingParams(\n",
    "                speed_mode=\"aggressive\")\n",
    "# lane change parameters, default: None\n",
    "lc_parameter =  None\n",
    "\n",
    "vehicles.add( # name of the vehicle\n",
    "                veh_id = \"rl\",\n",
    "              # acceleration controller, default: (SumoCarFollowingController, {})\n",
    "                acceleration_controller=(RLController, {}),\n",
    "              # lane_change_controller, default: (SumoLaneChangeController, {})\n",
    "                lane_change_controller=(StaticLaneChanger,{}),\n",
    "              # routing controller, default: None\n",
    "                routing_controller=(ContinuousRouter, {}),\n",
    "              # initial speed, default: 0\n",
    "                initial_speed=0,\n",
    "              # number of vehicles, default: 1 \n",
    "                num_vehicles=2,\n",
    "                \n",
    "                car_following_params=cf_parameter\n",
    "              # speed mode, default: \"right_of_way\"\n",
    "                #speed_mode=\"aggressive\",\n",
    "              # lane change mode, default: \"no_lat_collide\"\n",
    "                #lane_change_mode=\"aggressive\", \n",
    "              # car following parameter, default: None\n",
    "                #sumo_car_following_params=cf_parameter,\n",
    "              # lane change parameter, default: None\n",
    "                #sumo_lc_params=lc_parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict( # name of the experiment\n",
    "                      exp_tag=experiment_name,\n",
    "                    # name of the flow environment the experiment is running on\n",
    "                      env_name=env_name,\n",
    "                    # name of the scenario class the experiment uses\n",
    "                      scenario=scenario_name,\n",
    "                    # simulator that is used by the experiment\n",
    "                      simulator='traci',\n",
    "                    # sumo-related parameters (see flow.core.params.SumoParams)\n",
    "                      sim=sumo_params,\n",
    "                    # environment related parameters (see flow.core.params.EnvParams)\n",
    "                      env=env_params,\n",
    "                    # network-related parameters (see flow.core.params.NetParams and\n",
    "                    # the scenario's documentation or ADDITIONAL_NET_PARAMS component)\n",
    "                      net=net_params,\n",
    "                    # vehicles to be placed in the network at the start of a rollout \n",
    "                    # (see flow.core.vehicles.Vehicles)\n",
    "                      veh=vehicles,\n",
    "                   # (optional) parameters affecting the positioning of vehicles upon \n",
    "                   # initialization/reset (see flow.core.params.InitialConfig)\n",
    "                      initial=initial_config\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo.ppo_policy_graph import PPOPolicyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-03-20_23-42-41_12635/logs.\n",
      "Waiting for redis server at 127.0.0.1:53923 to respond...\n",
      "Waiting for redis server at 127.0.0.1:47681 to respond...\n",
      "Starting the Plasma object store with 6.554658406 GB memory using /dev/shm.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=a0a144a5bab3e38edf499afd28254d461f3b525382fe70af\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.2.102',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-03-20_23-42-41_12635/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-03-20_23-42-41_12635/sockets/raylet'],\n",
       " 'redis_address': '192.168.2.102:53923',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui.ipynb?token=a0a144a5bab3e38edf499afd28254d461f3b525382fe70af'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "N_CPUS = 2\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 20\n",
    "\n",
    "ray.init(redirect_output=True, num_cpus=N_CPUS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm or model to train. This may refer to \"\n",
    "#      \"the name of a built-on algorithm (e.g. RLLib's DQN \"\n",
    "#      \"or PPO), or a user-defined trainable function or \"\n",
    "#      \"class registered in the tune registry.\")\n",
    "alg_run = \"PPO\"\n",
    "\n",
    "agent_cls = get_agent_class(alg_run)\n",
    "config = agent_cls._default_config.copy()\n",
    "config[\"num_workers\"] = N_CPUS  # number of parallel workers\n",
    "config[\"train_batch_size\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.9  # discount rate default 0.999\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [100, 50, 25]})  # size of hidden layers in network defaule 64 32\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "#config[\"sgd_minibatch_size\"] = min(16 * 1024, config[\"train_batch_size\"])  # stochastic gradient descent\n",
    "#config[\"sample_batch_size\"] = config[\"train_batch_size\"]/config[\"num_workers\"] # 200 default, trotzdem zu hoch?\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "config['env_config']['run'] = alg_run\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, gym_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(gym_name, create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Starting SUMO on port 35979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.810823812562866\n",
      "19.209701566894147\n"
     ]
    }
   ],
   "source": [
    "# multi agent policy mapping\n",
    "test_env = create_env()\n",
    "obs_space = test_env.observation_space\n",
    "act_space = test_env.action_space\n",
    "\n",
    "def gen_policy():\n",
    "    return (PPOPolicyGraph, obs_space, act_space, {})\n",
    "\n",
    "# Setup PG with an ensemble of `num_policies` different policy graphs\n",
    "policy_graphs = {'rl_0': gen_policy()}\n",
    "    \n",
    "def policy_mapping_fn(agent_id):\n",
    "    return 'rl_0'\n",
    "\n",
    "config.update({\n",
    "        'multiagent': {\n",
    "            'policy_graphs': policy_graphs,\n",
    "            'policy_mapping_fn': tune.function(policy_mapping_fn),\n",
    "            'policies_to_train': ['rl_0']\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "\n",
      "Created LogSyncer for /home/thorsten/ray_results/IntersectionExample/PPO_MultiAgentIntersectionEnv-v0_0_2019-03-20_23-42-430ht1kvt9 -> \n",
      "WARNING: Falling back to serializing objects of type <class 'numpy.dtype'> by using pickle. This may be inefficient.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-43-47\n",
      "  done: false\n",
      "  episode_len_mean: 485.3\n",
      "  episode_reward_max: 260.1386717794316\n",
      "  episode_reward_mean: 104.50339380636703\n",
      "  episode_reward_min: -135.2918705150996\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 20\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4752.245\n",
      "    load_time_ms: 46.154\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20000004768371582\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4239012002944946\n",
      "      kl: 0.0009658889030106366\n",
      "      policy_loss: -0.0011507364688441157\n",
      "      total_loss: 12.931821823120117\n",
      "      vf_explained_var: 0.26930326223373413\n",
      "      vf_loss: 12.932780265808105\n",
      "    sample_time_ms: 26837.489\n",
      "    update_time_ms: 690.881\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.25169690318351\n",
      "  time_since_restore: 32.388999223709106\n",
      "  time_this_iter_s: 32.388999223709106\n",
      "  time_total_s: 32.388999223709106\n",
      "  timestamp: 1553121827\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 32 s, 1 iter, 10000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-44-14\n",
      "  done: false\n",
      "  episode_len_mean: 486.1\n",
      "  episode_reward_max: 260.1386717794316\n",
      "  episode_reward_mean: 109.85212787809901\n",
      "  episode_reward_min: -146.50245955118586\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 40\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4710.214\n",
      "    load_time_ms: 23.996\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10000002384185791\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4247936010360718\n",
      "      kl: 0.008725888095796108\n",
      "      policy_loss: -0.0044606220908463\n",
      "      total_loss: 4.425405502319336\n",
      "      vf_explained_var: 0.6462365388870239\n",
      "      vf_loss: 4.4289937019348145\n",
      "    sample_time_ms: 24238.721\n",
      "    update_time_ms: 347.66\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.926063939049506\n",
      "  time_since_restore: 58.72147274017334\n",
      "  time_this_iter_s: 26.332473516464233\n",
      "  time_total_s: 58.72147274017334\n",
      "  timestamp: 1553121854\n",
      "  timesteps_since_restore: 20000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 58 s, 2 iter, 20000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-44-39\n",
      "  done: false\n",
      "  episode_len_mean: 441.85074626865674\n",
      "  episode_reward_max: 334.794740554014\n",
      "  episode_reward_mean: 133.01480349710286\n",
      "  episode_reward_min: -147.94627834608596\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 67\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4577.558\n",
      "    load_time_ms: 16.673\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.050000011920928955\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.424507975578308\n",
      "      kl: 0.008257962763309479\n",
      "      policy_loss: -0.0031524519436061382\n",
      "      total_loss: 24.02385902404785\n",
      "      vf_explained_var: 0.3766806125640869\n",
      "      vf_loss: 24.02659797668457\n",
      "    sample_time_ms: 23086.615\n",
      "    update_time_ms: 233.666\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.50740174855143\n",
      "  time_since_restore: 83.84197092056274\n",
      "  time_this_iter_s: 25.120498180389404\n",
      "  time_total_s: 83.84197092056274\n",
      "  timestamp: 1553121879\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 3\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 83 s, 3 iter, 30000 ts, 133 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-45-03\n",
      "  done: false\n",
      "  episode_len_mean: 380.02\n",
      "  episode_reward_max: 373.18104676121624\n",
      "  episode_reward_mean: 140.37801861862596\n",
      "  episode_reward_min: -165.7508589951873\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 103\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4435.897\n",
      "    load_time_ms: 12.92\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025000005960464478\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4250863790512085\n",
      "      kl: 0.003855158109217882\n",
      "      policy_loss: -0.0015971993561834097\n",
      "      total_loss: 43.118858337402344\n",
      "      vf_explained_var: 0.31909164786338806\n",
      "      vf_loss: 43.120361328125\n",
      "    sample_time_ms: 22214.616\n",
      "    update_time_ms: 176.619\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.18900930931297\n",
      "  time_since_restore: 107.47531414031982\n",
      "  time_this_iter_s: 23.63334321975708\n",
      "  time_total_s: 107.47531414031982\n",
      "  timestamp: 1553121903\n",
      "  timesteps_since_restore: 40000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 4\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 107 s, 4 iter, 40000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-45-26\n",
      "  done: false\n",
      "  episode_len_mean: 290.14\n",
      "  episode_reward_max: 376.0977609287789\n",
      "  episode_reward_mean: 120.70649965241505\n",
      "  episode_reward_min: -165.7508589951873\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 143\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4353.407\n",
      "    load_time_ms: 10.741\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 50000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.012500002980232239\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4198254346847534\n",
      "      kl: 0.0042443908751010895\n",
      "      policy_loss: -0.0010774750262498856\n",
      "      total_loss: 79.33080291748047\n",
      "      vf_explained_var: 0.25362688302993774\n",
      "      vf_loss: 79.33183288574219\n",
      "    sample_time_ms: 21536.342\n",
      "    update_time_ms: 142.151\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.3532498262075\n",
      "  time_since_restore: 130.34523630142212\n",
      "  time_this_iter_s: 22.869922161102295\n",
      "  time_total_s: 130.34523630142212\n",
      "  timestamp: 1553121926\n",
      "  timesteps_since_restore: 50000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 5\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 130 s, 5 iter, 50000 ts, 121 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-45-49\n",
      "  done: false\n",
      "  episode_len_mean: 276.81\n",
      "  episode_reward_max: 376.0977609287789\n",
      "  episode_reward_mean: 113.25592566381307\n",
      "  episode_reward_min: -165.7508589951873\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 175\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4293.955\n",
      "    load_time_ms: 9.186\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.006250001490116119\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.413277268409729\n",
      "      kl: 0.0043801916763186455\n",
      "      policy_loss: -0.0019741083960980177\n",
      "      total_loss: 34.99400329589844\n",
      "      vf_explained_var: 0.4350240230560303\n",
      "      vf_loss: 34.995948791503906\n",
      "    sample_time_ms: 21132.968\n",
      "    update_time_ms: 119.305\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.62796283190654\n",
      "  time_since_restore: 153.4823043346405\n",
      "  time_this_iter_s: 23.137068033218384\n",
      "  time_total_s: 153.4823043346405\n",
      "  timestamp: 1553121949\n",
      "  timesteps_since_restore: 60000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 6\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 153 s, 6 iter, 60000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-46-12\n",
      "  done: false\n",
      "  episode_len_mean: 283.74\n",
      "  episode_reward_max: 376.0977609287789\n",
      "  episode_reward_mean: 132.45476586390274\n",
      "  episode_reward_min: -164.3419347970346\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 211\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4251.187\n",
      "    load_time_ms: 8.066\n",
      "    num_steps_sampled: 70000\n",
      "    num_steps_trained: 70000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0031250007450580597\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3912400007247925\n",
      "      kl: 0.015042350627481937\n",
      "      policy_loss: -0.0034391896333545446\n",
      "      total_loss: 28.573238372802734\n",
      "      vf_explained_var: 0.5588495135307312\n",
      "      vf_loss: 28.576629638671875\n",
      "    sample_time_ms: 20779.021\n",
      "    update_time_ms: 102.941\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.22738293195138\n",
      "  time_since_restore: 176.1543333530426\n",
      "  time_this_iter_s: 22.6720290184021\n",
      "  time_total_s: 176.1543333530426\n",
      "  timestamp: 1553121972\n",
      "  timesteps_since_restore: 70000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 70000\n",
      "  training_iteration: 7\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 176 s, 7 iter, 70000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 234.52\n",
      "  episode_reward_max: 338.73420231446346\n",
      "  episode_reward_mean: 67.26340440038535\n",
      "  episode_reward_min: -167.23664898893117\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 263\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4221.167\n",
      "    load_time_ms: 7.294\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0031250007450580597\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3912105560302734\n",
      "      kl: 0.0031794647220522165\n",
      "      policy_loss: -0.001288066734559834\n",
      "      total_loss: 114.75067901611328\n",
      "      vf_explained_var: 0.35158655047416687\n",
      "      vf_loss: 114.751953125\n",
      "    sample_time_ms: 20596.516\n",
      "    update_time_ms: 90.955\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.63170220019268\n",
      "  time_since_restore: 199.51230597496033\n",
      "  time_this_iter_s: 23.357972621917725\n",
      "  time_total_s: 199.51230597496033\n",
      "  timestamp: 1553121995\n",
      "  timesteps_since_restore: 80000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 8\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 199 s, 8 iter, 80000 ts, 67.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-46-58\n",
      "  done: false\n",
      "  episode_len_mean: 219.44\n",
      "  episode_reward_max: 338.73420231446346\n",
      "  episode_reward_mean: 43.98716925147809\n",
      "  episode_reward_min: -167.23664898893117\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 303\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4198.24\n",
      "    load_time_ms: 6.632\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0015625003725290298\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.395527958869934\n",
      "      kl: 0.008238587528467178\n",
      "      policy_loss: -0.0025338041596114635\n",
      "      total_loss: 62.95335006713867\n",
      "      vf_explained_var: 0.38528570532798767\n",
      "      vf_loss: 62.955867767333984\n",
      "    sample_time_ms: 20466.679\n",
      "    update_time_ms: 81.42\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.99358462573902\n",
      "  time_since_restore: 222.97829461097717\n",
      "  time_this_iter_s: 23.465988636016846\n",
      "  time_total_s: 222.97829461097717\n",
      "  timestamp: 1553122018\n",
      "  timesteps_since_restore: 90000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 9\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 222 s, 9 iter, 90000 ts, 44 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-47-21\n",
      "  done: false\n",
      "  episode_len_mean: 220.29\n",
      "  episode_reward_max: 333.62192275961087\n",
      "  episode_reward_mean: 92.31789958763173\n",
      "  episode_reward_min: -164.04719547446646\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 351\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4179.327\n",
      "    load_time_ms: 6.102\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0007812501862645149\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3951315879821777\n",
      "      kl: 0.0032516615465283394\n",
      "      policy_loss: -0.0020518286619335413\n",
      "      total_loss: 56.6030387878418\n",
      "      vf_explained_var: 0.4838414192199707\n",
      "      vf_loss: 56.60509490966797\n",
      "    sample_time_ms: 20273.977\n",
      "    update_time_ms: 73.798\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.158949793815864\n",
      "  time_since_restore: 245.5502028465271\n",
      "  time_this_iter_s: 22.571908235549927\n",
      "  time_total_s: 245.5502028465271\n",
      "  timestamp: 1553122041\n",
      "  timesteps_since_restore: 100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 10\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 245 s, 10 iter, 100000 ts, 92.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-47-44\n",
      "  done: false\n",
      "  episode_len_mean: 202.86\n",
      "  episode_reward_max: 347.43331604544795\n",
      "  episode_reward_mean: 113.81289716383532\n",
      "  episode_reward_min: -165.23983642176515\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 402\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4107.179\n",
      "    load_time_ms: 1.687\n",
      "    num_steps_sampled: 110000\n",
      "    num_steps_trained: 110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00039062509313225746\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3788506984710693\n",
      "      kl: 0.007192404009401798\n",
      "      policy_loss: -0.0013622737023979425\n",
      "      total_loss: 61.0984001159668\n",
      "      vf_explained_var: 0.4990145266056061\n",
      "      vf_loss: 61.09976577758789\n",
      "    sample_time_ms: 19429.14\n",
      "    update_time_ms: 5.765\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.906448581917665\n",
      "  time_since_restore: 267.9991443157196\n",
      "  time_this_iter_s: 22.448941469192505\n",
      "  time_total_s: 267.9991443157196\n",
      "  timestamp: 1553122064\n",
      "  timesteps_since_restore: 110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 110000\n",
      "  training_iteration: 11\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 267 s, 11 iter, 110000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-48-07\n",
      "  done: false\n",
      "  episode_len_mean: 190.76\n",
      "  episode_reward_max: 347.43331604544795\n",
      "  episode_reward_mean: 111.15970060103659\n",
      "  episode_reward_min: -165.23983642176515\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 456\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4039.984\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00019531254656612873\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3768444061279297\n",
      "      kl: 0.002570231445133686\n",
      "      policy_loss: -0.0011611907975748181\n",
      "      total_loss: 55.73411178588867\n",
      "      vf_explained_var: 0.5541653633117676\n",
      "      vf_loss: 55.73526382446289\n",
      "    sample_time_ms: 19173.284\n",
      "    update_time_ms: 5.938\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.579850300518274\n",
      "  time_since_restore: 291.10135412216187\n",
      "  time_this_iter_s: 23.10220980644226\n",
      "  time_total_s: 291.10135412216187\n",
      "  timestamp: 1553122087\n",
      "  timesteps_since_restore: 120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 12\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 291 s, 12 iter, 120000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-48-30\n",
      "  done: false\n",
      "  episode_len_mean: 182.29\n",
      "  episode_reward_max: 340.7791013084583\n",
      "  episode_reward_mean: 127.46185197909948\n",
      "  episode_reward_min: -163.22759503901096\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 509\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4010.761\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 130000\n",
      "    num_steps_trained: 130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.765627328306437e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.368786096572876\n",
      "      kl: 0.009946336038410664\n",
      "      policy_loss: -0.0022107139229774475\n",
      "      total_loss: 48.603065490722656\n",
      "      vf_explained_var: 0.5642716884613037\n",
      "      vf_loss: 48.60527420043945\n",
      "    sample_time_ms: 18998.138\n",
      "    update_time_ms: 5.85\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.73092598954974\n",
      "  time_since_restore: 314.17530035972595\n",
      "  time_this_iter_s: 23.073946237564087\n",
      "  time_total_s: 314.17530035972595\n",
      "  timestamp: 1553122110\n",
      "  timesteps_since_restore: 130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 130000\n",
      "  training_iteration: 13\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 314 s, 13 iter, 130000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-48-53\n",
      "  done: false\n",
      "  episode_len_mean: 177.13\n",
      "  episode_reward_max: 342.1725654365512\n",
      "  episode_reward_mean: 163.09705674481842\n",
      "  episode_reward_min: -165.33531693416003\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 569\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4011.588\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.882813664153218e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3574455976486206\n",
      "      kl: 0.00876773614436388\n",
      "      policy_loss: -0.001028513885103166\n",
      "      total_loss: 46.785438537597656\n",
      "      vf_explained_var: 0.6312237977981567\n",
      "      vf_loss: 46.78646469116211\n",
      "    sample_time_ms: 18952.651\n",
      "    update_time_ms: 5.828\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.54852837240922\n",
      "  time_since_restore: 337.36209297180176\n",
      "  time_this_iter_s: 23.186792612075806\n",
      "  time_total_s: 337.36209297180176\n",
      "  timestamp: 1553122133\n",
      "  timesteps_since_restore: 140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 14\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 337 s, 14 iter, 140000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-49-17\n",
      "  done: false\n",
      "  episode_len_mean: 166.0\n",
      "  episode_reward_max: 347.35764486996044\n",
      "  episode_reward_mean: 182.29916291858547\n",
      "  episode_reward_min: -166.63994464536927\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 629\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4014.425\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.344896912574768\n",
      "      kl: 0.01466930378228426\n",
      "      policy_loss: -0.0023177003022283316\n",
      "      total_loss: 34.09196090698242\n",
      "      vf_explained_var: 0.6522161960601807\n",
      "      vf_loss: 34.09428024291992\n",
      "    sample_time_ms: 19027.542\n",
      "    update_time_ms: 5.914\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.14958145929273\n",
      "  time_since_restore: 361.00758123397827\n",
      "  time_this_iter_s: 23.645488262176514\n",
      "  time_total_s: 361.00758123397827\n",
      "  timestamp: 1553122157\n",
      "  timesteps_since_restore: 150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 15\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 361 s, 15 iter, 150000 ts, 182 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-49-40\n",
      "  done: false\n",
      "  episode_len_mean: 151.56\n",
      "  episode_reward_max: 347.35764486996044\n",
      "  episode_reward_mean: 166.9695248521467\n",
      "  episode_reward_min: -159.2262381426296\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 697\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4023.657\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3272013664245605\n",
      "      kl: 0.010907316580414772\n",
      "      policy_loss: -0.0018141336040571332\n",
      "      total_loss: 49.46728515625\n",
      "      vf_explained_var: 0.6672075986862183\n",
      "      vf_loss: 49.469093322753906\n",
      "    sample_time_ms: 19058.841\n",
      "    update_time_ms: 5.912\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.48476242607336\n",
      "  time_since_restore: 384.5516731739044\n",
      "  time_this_iter_s: 23.544091939926147\n",
      "  time_total_s: 384.5516731739044\n",
      "  timestamp: 1553122180\n",
      "  timesteps_since_restore: 160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 16\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 384 s, 16 iter, 160000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-50-04\n",
      "  done: false\n",
      "  episode_len_mean: 141.7\n",
      "  episode_reward_max: 345.1066996727621\n",
      "  episode_reward_mean: 162.0879519548365\n",
      "  episode_reward_min: -162.30746363164786\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 768\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4018.755\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 170000\n",
      "    num_steps_trained: 170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.326639175415039\n",
      "      kl: 0.01316413376480341\n",
      "      policy_loss: -0.0019187197322025895\n",
      "      total_loss: 45.49076461791992\n",
      "      vf_explained_var: 0.7005592584609985\n",
      "      vf_loss: 45.49268341064453\n",
      "    sample_time_ms: 19136.583\n",
      "    update_time_ms: 5.893\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.04397597741826\n",
      "  time_since_restore: 407.9532108306885\n",
      "  time_this_iter_s: 23.401537656784058\n",
      "  time_total_s: 407.9532108306885\n",
      "  timestamp: 1553122204\n",
      "  timesteps_since_restore: 170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 170000\n",
      "  training_iteration: 17\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 407 s, 17 iter, 170000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-50-27\n",
      "  done: false\n",
      "  episode_len_mean: 138.9\n",
      "  episode_reward_max: 332.6232781298981\n",
      "  episode_reward_mean: 185.5375352776726\n",
      "  episode_reward_min: -163.5594249847785\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 842\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4010.697\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3100078105926514\n",
      "      kl: 0.010581749491393566\n",
      "      policy_loss: -0.0021600350737571716\n",
      "      total_loss: 42.818721771240234\n",
      "      vf_explained_var: 0.689116358757019\n",
      "      vf_loss: 42.82088088989258\n",
      "    sample_time_ms: 19127.119\n",
      "    update_time_ms: 5.643\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.7687676388363\n",
      "  time_since_restore: 431.13296699523926\n",
      "  time_this_iter_s: 23.17975616455078\n",
      "  time_total_s: 431.13296699523926\n",
      "  timestamp: 1553122227\n",
      "  timesteps_since_restore: 180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 18\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 431 s, 18 iter, 180000 ts, 186 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-50-49\n",
      "  done: false\n",
      "  episode_len_mean: 133.17\n",
      "  episode_reward_max: 346.87007572630455\n",
      "  episode_reward_mean: 180.58113130499814\n",
      "  episode_reward_min: -162.80136851707184\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 915\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3997.757\n",
      "    load_time_ms: 1.663\n",
      "    num_steps_sampled: 190000\n",
      "    num_steps_trained: 190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2834655046463013\n",
      "      kl: 0.013892128132283688\n",
      "      policy_loss: -0.0027400210965424776\n",
      "      total_loss: 36.80851364135742\n",
      "      vf_explained_var: 0.7029890418052673\n",
      "      vf_loss: 36.811248779296875\n",
      "    sample_time_ms: 19032.682\n",
      "    update_time_ms: 5.994\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.29056565249908\n",
      "  time_since_restore: 453.52839493751526\n",
      "  time_this_iter_s: 22.395427942276\n",
      "  time_total_s: 453.52839493751526\n",
      "  timestamp: 1553122249\n",
      "  timesteps_since_restore: 190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 190000\n",
      "  training_iteration: 19\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 453 s, 19 iter, 190000 ts, 181 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-51-12\n",
      "  done: false\n",
      "  episode_len_mean: 129.16\n",
      "  episode_reward_max: 348.95599359065784\n",
      "  episode_reward_mean: 178.72180110828347\n",
      "  episode_reward_min: -164.63760295427312\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 991\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3985.19\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2757773399353027\n",
      "      kl: 0.012794454582035542\n",
      "      policy_loss: -0.0018955558771267533\n",
      "      total_loss: 45.70710754394531\n",
      "      vf_explained_var: 0.6780186295509338\n",
      "      vf_loss: 45.70899963378906\n",
      "    sample_time_ms: 19065.863\n",
      "    update_time_ms: 6.121\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.36090055414174\n",
      "  time_since_restore: 476.30826115608215\n",
      "  time_this_iter_s: 22.779866218566895\n",
      "  time_total_s: 476.30826115608215\n",
      "  timestamp: 1553122272\n",
      "  timesteps_since_restore: 200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 20\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 476 s, 20 iter, 200000 ts, 179 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-51-35\n",
      "  done: false\n",
      "  episode_len_mean: 117.0\n",
      "  episode_reward_max: 352.00045062324256\n",
      "  episode_reward_mean: 143.67434556588725\n",
      "  episode_reward_min: -165.65268429345082\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 1079\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3969.126\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2633678913116455\n",
      "      kl: 0.009589622728526592\n",
      "      policy_loss: -0.0017927682492882013\n",
      "      total_loss: 66.75460052490234\n",
      "      vf_explained_var: 0.6955236792564392\n",
      "      vf_loss: 66.75638580322266\n",
      "    sample_time_ms: 19118.212\n",
      "    update_time_ms: 5.621\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.83717278294364\n",
      "  time_since_restore: 499.1163411140442\n",
      "  time_this_iter_s: 22.808079957962036\n",
      "  time_total_s: 499.1163411140442\n",
      "  timestamp: 1553122295\n",
      "  timesteps_since_restore: 210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 21\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 499 s, 21 iter, 210000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-51-58\n",
      "  done: false\n",
      "  episode_len_mean: 121.86\n",
      "  episode_reward_max: 363.24956746004307\n",
      "  episode_reward_mean: 183.59468261061895\n",
      "  episode_reward_min: -163.82870737065957\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 1160\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3958.995\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2207034160383046e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2619595527648926\n",
      "      kl: 0.009431789629161358\n",
      "      policy_loss: -0.0025422878097742796\n",
      "      total_loss: 41.54372787475586\n",
      "      vf_explained_var: 0.7147093415260315\n",
      "      vf_loss: 41.546268463134766\n",
      "    sample_time_ms: 19084.613\n",
      "    update_time_ms: 5.472\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.79734130530947\n",
      "  time_since_restore: 521.7808442115784\n",
      "  time_this_iter_s: 22.66450309753418\n",
      "  time_total_s: 521.7808442115784\n",
      "  timestamp: 1553122318\n",
      "  timesteps_since_restore: 220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 22\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 521 s, 22 iter, 220000 ts, 184 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-52-21\n",
      "  done: false\n",
      "  episode_len_mean: 113.58\n",
      "  episode_reward_max: 341.73194565746996\n",
      "  episode_reward_mean: 160.42716508320424\n",
      "  episode_reward_min: -164.85335221449174\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 1248\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3943.912\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 230000\n",
      "    num_steps_trained: 230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.103517080191523e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2203000783920288\n",
      "      kl: 0.023801201954483986\n",
      "      policy_loss: -0.002081636106595397\n",
      "      total_loss: 48.48579025268555\n",
      "      vf_explained_var: 0.7635899782180786\n",
      "      vf_loss: 48.48786926269531\n",
      "    sample_time_ms: 19085.619\n",
      "    update_time_ms: 5.497\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.21358254160214\n",
      "  time_since_restore: 544.716025352478\n",
      "  time_this_iter_s: 22.935181140899658\n",
      "  time_total_s: 544.716025352478\n",
      "  timestamp: 1553122341\n",
      "  timesteps_since_restore: 230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 230000\n",
      "  training_iteration: 23\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 544 s, 23 iter, 230000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-52-44\n",
      "  done: false\n",
      "  episode_len_mean: 118.07\n",
      "  episode_reward_max: 348.85261408596284\n",
      "  episode_reward_mean: 206.35341746696548\n",
      "  episode_reward_min: -162.05121677224912\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 1331\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3947.411\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.103517080191523e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2192636728286743\n",
      "      kl: 0.011002766899764538\n",
      "      policy_loss: -0.0031391833908855915\n",
      "      total_loss: 32.69710922241211\n",
      "      vf_explained_var: 0.7625241875648499\n",
      "      vf_loss: 32.700252532958984\n",
      "    sample_time_ms: 19093.596\n",
      "    update_time_ms: 5.472\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 103.17670873348276\n",
      "  time_since_restore: 568.0168714523315\n",
      "  time_this_iter_s: 23.300846099853516\n",
      "  time_total_s: 568.0168714523315\n",
      "  timestamp: 1553122364\n",
      "  timesteps_since_restore: 240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 24\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 568 s, 24 iter, 240000 ts, 206 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-53-07\n",
      "  done: false\n",
      "  episode_len_mean: 115.93\n",
      "  episode_reward_max: 360.0278075031341\n",
      "  episode_reward_mean: 207.64258703468494\n",
      "  episode_reward_min: -157.62787404511343\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 1418\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3929.302\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 250000\n",
      "    num_steps_trained: 250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.103517080191523e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.204020619392395\n",
      "      kl: 0.014120597392320633\n",
      "      policy_loss: -0.0018834865186363459\n",
      "      total_loss: 41.09770584106445\n",
      "      vf_explained_var: 0.7288042306900024\n",
      "      vf_loss: 41.099586486816406\n",
      "    sample_time_ms: 19005.997\n",
      "    update_time_ms: 5.585\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 103.82129351734245\n",
      "  time_since_restore: 590.6087698936462\n",
      "  time_this_iter_s: 22.591898441314697\n",
      "  time_total_s: 590.6087698936462\n",
      "  timestamp: 1553122387\n",
      "  timesteps_since_restore: 250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 250000\n",
      "  training_iteration: 25\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 590 s, 25 iter, 250000 ts, 208 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-53-29\n",
      "  done: false\n",
      "  episode_len_mean: 113.27\n",
      "  episode_reward_max: 350.8612918782706\n",
      "  episode_reward_mean: 203.7878082557959\n",
      "  episode_reward_min: -166.29925744998178\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 1507\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.164\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.103517080191523e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1806013584136963\n",
      "      kl: 0.018331259489059448\n",
      "      policy_loss: -0.0018636506283655763\n",
      "      total_loss: 36.22712707519531\n",
      "      vf_explained_var: 0.7835078835487366\n",
      "      vf_loss: 36.22899627685547\n",
      "    sample_time_ms: 18930.583\n",
      "    update_time_ms: 5.581\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 101.89390412789797\n",
      "  time_since_restore: 613.185430765152\n",
      "  time_this_iter_s: 22.576660871505737\n",
      "  time_total_s: 613.185430765152\n",
      "  timestamp: 1553122409\n",
      "  timesteps_since_restore: 260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 26\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 613 s, 26 iter, 260000 ts, 204 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-53-52\n",
      "  done: false\n",
      "  episode_len_mean: 113.91\n",
      "  episode_reward_max: 355.24421321495265\n",
      "  episode_reward_mean: 222.05191825324908\n",
      "  episode_reward_min: -166.79934529934857\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 1594\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.489\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.103517080191523e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.168764591217041\n",
      "      kl: 0.007846617139875889\n",
      "      policy_loss: -0.0009109163656830788\n",
      "      total_loss: 34.059852600097656\n",
      "      vf_explained_var: 0.757789134979248\n",
      "      vf_loss: 34.06076431274414\n",
      "    sample_time_ms: 18834.567\n",
      "    update_time_ms: 5.644\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 111.02595912662454\n",
      "  time_since_restore: 635.5603532791138\n",
      "  time_this_iter_s: 22.374922513961792\n",
      "  time_total_s: 635.5603532791138\n",
      "  timestamp: 1553122432\n",
      "  timesteps_since_restore: 270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 27\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 635 s, 27 iter, 270000 ts, 222 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-54-14\n",
      "  done: false\n",
      "  episode_len_mean: 107.34\n",
      "  episode_reward_max: 346.9071778378108\n",
      "  episode_reward_mean: 194.99467228154532\n",
      "  episode_reward_min: -168.57867494149684\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 1688\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.03\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1607513427734375\n",
      "      kl: 0.012953290715813637\n",
      "      policy_loss: -0.0012498883297666907\n",
      "      total_loss: 40.13066482543945\n",
      "      vf_explained_var: 0.7845975160598755\n",
      "      vf_loss: 40.13191604614258\n",
      "    sample_time_ms: 18780.411\n",
      "    update_time_ms: 5.883\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.49733614077265\n",
      "  time_since_restore: 658.1553444862366\n",
      "  time_this_iter_s: 22.594991207122803\n",
      "  time_total_s: 658.1553444862366\n",
      "  timestamp: 1553122454\n",
      "  timesteps_since_restore: 280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 28\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 658 s, 28 iter, 280000 ts, 195 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-54-37\n",
      "  done: false\n",
      "  episode_len_mean: 108.7\n",
      "  episode_reward_max: 351.71971478425246\n",
      "  episode_reward_mean: 211.8194667744625\n",
      "  episode_reward_min: -163.62217632809669\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 1779\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.299\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 290000\n",
      "    num_steps_trained: 290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.16123366355896\n",
      "      kl: 0.01044413074851036\n",
      "      policy_loss: -0.0018840684788301587\n",
      "      total_loss: 37.45917892456055\n",
      "      vf_explained_var: 0.771216094493866\n",
      "      vf_loss: 37.461063385009766\n",
      "    sample_time_ms: 18775.067\n",
      "    update_time_ms: 5.525\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 105.90973338723124\n",
      "  time_since_restore: 680.466591835022\n",
      "  time_this_iter_s: 22.3112473487854\n",
      "  time_total_s: 680.466591835022\n",
      "  timestamp: 1553122477\n",
      "  timesteps_since_restore: 290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 290000\n",
      "  training_iteration: 29\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 680 s, 29 iter, 290000 ts, 212 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-54-59\n",
      "  done: false\n",
      "  episode_len_mean: 114.14\n",
      "  episode_reward_max: 349.0498943026712\n",
      "  episode_reward_mean: 254.22445241957195\n",
      "  episode_reward_min: -164.18026480315373\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 1869\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.18\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1543614864349365\n",
      "      kl: 0.011303003877401352\n",
      "      policy_loss: -0.001411590026691556\n",
      "      total_loss: 25.008750915527344\n",
      "      vf_explained_var: 0.8094885349273682\n",
      "      vf_loss: 25.010162353515625\n",
      "    sample_time_ms: 18739.937\n",
      "    update_time_ms: 5.406\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 127.11222620978599\n",
      "  time_since_restore: 702.911425113678\n",
      "  time_this_iter_s: 22.444833278656006\n",
      "  time_total_s: 702.911425113678\n",
      "  timestamp: 1553122499\n",
      "  timesteps_since_restore: 300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 30\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 702 s, 30 iter, 300000 ts, 254 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-55-22\n",
      "  done: false\n",
      "  episode_len_mean: 107.88\n",
      "  episode_reward_max: 354.3255055628232\n",
      "  episode_reward_mean: 227.13139654840737\n",
      "  episode_reward_min: -165.26077191843655\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 1961\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.547\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 310000\n",
      "    num_steps_trained: 310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.145662784576416\n",
      "      kl: 0.012109516188502312\n",
      "      policy_loss: -0.0011034271446987987\n",
      "      total_loss: 31.116962432861328\n",
      "      vf_explained_var: 0.8124998807907104\n",
      "      vf_loss: 31.118070602416992\n",
      "    sample_time_ms: 18692.217\n",
      "    update_time_ms: 5.427\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 113.56569827420364\n",
      "  time_since_restore: 725.2645628452301\n",
      "  time_this_iter_s: 22.353137731552124\n",
      "  time_total_s: 725.2645628452301\n",
      "  timestamp: 1553122522\n",
      "  timesteps_since_restore: 310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 310000\n",
      "  training_iteration: 31\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 725 s, 31 iter, 310000 ts, 227 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 109.36\n",
      "  episode_reward_max: 349.8000401850466\n",
      "  episode_reward_mean: 242.9405776038207\n",
      "  episode_reward_min: -167.4819228817186\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 2053\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.466\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1148340702056885\n",
      "      kl: 0.01777203194797039\n",
      "      policy_loss: -0.0022307648323476315\n",
      "      total_loss: 31.221229553222656\n",
      "      vf_explained_var: 0.7740465998649597\n",
      "      vf_loss: 31.223461151123047\n",
      "    sample_time_ms: 18682.167\n",
      "    update_time_ms: 6.329\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 121.47028880191036\n",
      "  time_since_restore: 747.8164713382721\n",
      "  time_this_iter_s: 22.551908493041992\n",
      "  time_total_s: 747.8164713382721\n",
      "  timestamp: 1553122544\n",
      "  timesteps_since_restore: 320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 32\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 747 s, 32 iter, 320000 ts, 243 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-56-07\n",
      "  done: false\n",
      "  episode_len_mean: 99.46\n",
      "  episode_reward_max: 346.92259945344745\n",
      "  episode_reward_mean: 190.9304187309142\n",
      "  episode_reward_min: -167.4819228817186\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 2152\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.141\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0870996713638306\n",
      "      kl: 0.013204568065702915\n",
      "      policy_loss: -0.00233089504763484\n",
      "      total_loss: 39.25497055053711\n",
      "      vf_explained_var: 0.8116950988769531\n",
      "      vf_loss: 39.25729751586914\n",
      "    sample_time_ms: 18628.065\n",
      "    update_time_ms: 6.341\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.4652093654571\n",
      "  time_since_restore: 770.1453280448914\n",
      "  time_this_iter_s: 22.328856706619263\n",
      "  time_total_s: 770.1453280448914\n",
      "  timestamp: 1553122567\n",
      "  timesteps_since_restore: 330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 33\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 770 s, 33 iter, 330000 ts, 191 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 103.99\n",
      "  episode_reward_max: 339.71444678686294\n",
      "  episode_reward_mean: 228.01377573925367\n",
      "  episode_reward_min: -166.98164880618222\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 2248\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3859.283\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0720329284667969\n",
      "      kl: 0.01149587333202362\n",
      "      policy_loss: -0.0011520045809447765\n",
      "      total_loss: 30.6010799407959\n",
      "      vf_explained_var: 0.7908065319061279\n",
      "      vf_loss: 30.602231979370117\n",
      "    sample_time_ms: 18599.006\n",
      "    update_time_ms: 6.418\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 114.00688786962684\n",
      "  time_since_restore: 792.8505811691284\n",
      "  time_this_iter_s: 22.70525312423706\n",
      "  time_total_s: 792.8505811691284\n",
      "  timestamp: 1553122589\n",
      "  timesteps_since_restore: 340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 34\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 792 s, 34 iter, 340000 ts, 228 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-56-52\n",
      "  done: false\n",
      "  episode_len_mean: 105.95\n",
      "  episode_reward_max: 353.0373319031127\n",
      "  episode_reward_mean: 248.1143969835995\n",
      "  episode_reward_min: -168.95856772248726\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 2342\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3846.649\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 350000\n",
      "    num_steps_trained: 350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0667541027069092\n",
      "      kl: 0.014020657166838646\n",
      "      policy_loss: -0.0031370949000120163\n",
      "      total_loss: 20.90496253967285\n",
      "      vf_explained_var: 0.8557152152061462\n",
      "      vf_loss: 20.908100128173828\n",
      "    sample_time_ms: 18654.518\n",
      "    update_time_ms: 6.239\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 124.05719849179974\n",
      "  time_since_restore: 815.8695254325867\n",
      "  time_this_iter_s: 23.018944263458252\n",
      "  time_total_s: 815.8695254325867\n",
      "  timestamp: 1553122612\n",
      "  timesteps_since_restore: 350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 350000\n",
      "  training_iteration: 35\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 815 s, 35 iter, 350000 ts, 248 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 97.04807692307692\n",
      "  episode_reward_max: 347.90038462804955\n",
      "  episode_reward_mean: 195.06250771873505\n",
      "  episode_reward_min: -167.75556487239226\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 2446\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3834.76\n",
      "    load_time_ms: 1.646\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0547690391540527\n",
      "      kl: 0.007706933189183474\n",
      "      policy_loss: -0.0019315817626193166\n",
      "      total_loss: 37.32810974121094\n",
      "      vf_explained_var: 0.8362945914268494\n",
      "      vf_loss: 37.330047607421875\n",
      "    sample_time_ms: 18696.397\n",
      "    update_time_ms: 6.308\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.53125385936752\n",
      "  time_since_restore: 838.7489967346191\n",
      "  time_this_iter_s: 22.87947130203247\n",
      "  time_total_s: 838.7489967346191\n",
      "  timestamp: 1553122635\n",
      "  timesteps_since_restore: 360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 36\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 838 s, 36 iter, 360000 ts, 195 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-57-38\n",
      "  done: false\n",
      "  episode_len_mean: 96.51456310679612\n",
      "  episode_reward_max: 355.9338677387009\n",
      "  episode_reward_mean: 194.5491447048255\n",
      "  episode_reward_min: -166.85277395807063\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 2549\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3826.983\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 370000\n",
      "    num_steps_trained: 370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5258792700478807e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0552822351455688\n",
      "      kl: 0.007823791354894638\n",
      "      policy_loss: -0.0010267657926306129\n",
      "      total_loss: 43.74095916748047\n",
      "      vf_explained_var: 0.7987105250358582\n",
      "      vf_loss: 43.74198532104492\n",
      "    sample_time_ms: 18702.489\n",
      "    update_time_ms: 6.296\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.27457235241278\n",
      "  time_since_restore: 861.1096222400665\n",
      "  time_this_iter_s: 22.360625505447388\n",
      "  time_total_s: 861.1096222400665\n",
      "  timestamp: 1553122658\n",
      "  timesteps_since_restore: 370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 370000\n",
      "  training_iteration: 37\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 861 s, 37 iter, 370000 ts, 195 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-58-00\n",
      "  done: false\n",
      "  episode_len_mean: 97.22330097087378\n",
      "  episode_reward_max: 350.1366835338737\n",
      "  episode_reward_mean: 202.25541111539974\n",
      "  episode_reward_min: -167.49068182351363\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 2652\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3811.214\n",
      "    load_time_ms: 1.722\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.629396350239404e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.050508975982666\n",
      "      kl: 0.01064337883144617\n",
      "      policy_loss: -0.0031006550416350365\n",
      "      total_loss: 41.26887512207031\n",
      "      vf_explained_var: 0.7971975803375244\n",
      "      vf_loss: 41.27197265625\n",
      "    sample_time_ms: 18719.107\n",
      "    update_time_ms: 6.206\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 101.12770555769988\n",
      "  time_since_restore: 883.7122101783752\n",
      "  time_this_iter_s: 22.602587938308716\n",
      "  time_total_s: 883.7122101783752\n",
      "  timestamp: 1553122680\n",
      "  timesteps_since_restore: 380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 38\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 883 s, 38 iter, 380000 ts, 202 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-58-23\n",
      "  done: false\n",
      "  episode_len_mean: 99.16831683168317\n",
      "  episode_reward_max: 354.63338034620284\n",
      "  episode_reward_mean: 219.38808234048435\n",
      "  episode_reward_min: -165.53780516503167\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 2753\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3797.599\n",
      "    load_time_ms: 1.718\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.629396350239404e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0343953371047974\n",
      "      kl: 0.00807190127670765\n",
      "      policy_loss: -0.0014015763299539685\n",
      "      total_loss: 26.72119140625\n",
      "      vf_explained_var: 0.8576327562332153\n",
      "      vf_loss: 26.722593307495117\n",
      "    sample_time_ms: 18742.289\n",
      "    update_time_ms: 6.185\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 109.69404117024217\n",
      "  time_since_restore: 906.1178753376007\n",
      "  time_this_iter_s: 22.405665159225464\n",
      "  time_total_s: 906.1178753376007\n",
      "  timestamp: 1553122703\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 39\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 906 s, 39 iter, 390000 ts, 219 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-58-45\n",
      "  done: false\n",
      "  episode_len_mean: 100.04\n",
      "  episode_reward_max: 350.4456403004047\n",
      "  episode_reward_mean: 225.18254329538675\n",
      "  episode_reward_min: -163.78008171882263\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2853\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3780.162\n",
      "    load_time_ms: 1.793\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.814698175119702e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0348095893859863\n",
      "      kl: 0.00962854828685522\n",
      "      policy_loss: -0.001146734575740993\n",
      "      total_loss: 35.92604446411133\n",
      "      vf_explained_var: 0.7971490621566772\n",
      "      vf_loss: 35.927188873291016\n",
      "    sample_time_ms: 18739.274\n",
      "    update_time_ms: 6.236\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 112.59127164769339\n",
      "  time_since_restore: 928.3649518489838\n",
      "  time_this_iter_s: 22.247076511383057\n",
      "  time_total_s: 928.3649518489838\n",
      "  timestamp: 1553122725\n",
      "  timesteps_since_restore: 400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 40\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 928 s, 40 iter, 400000 ts, 225 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-59-07\n",
      "  done: false\n",
      "  episode_len_mean: 97.68932038834951\n",
      "  episode_reward_max: 354.455942219033\n",
      "  episode_reward_mean: 204.8881955186276\n",
      "  episode_reward_min: -159.94317955975546\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 2956\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3775.164\n",
      "    load_time_ms: 1.768\n",
      "    num_steps_sampled: 410000\n",
      "    num_steps_trained: 410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.907349087559851e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0393081903457642\n",
      "      kl: 0.009383324533700943\n",
      "      policy_loss: -0.00042080230196006596\n",
      "      total_loss: 35.48716735839844\n",
      "      vf_explained_var: 0.833685040473938\n",
      "      vf_loss: 35.48759078979492\n",
      "    sample_time_ms: 18736.009\n",
      "    update_time_ms: 6.105\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 102.4440977593138\n",
      "  time_since_restore: 950.63441157341\n",
      "  time_this_iter_s: 22.26945972442627\n",
      "  time_total_s: 950.63441157341\n",
      "  timestamp: 1553122747\n",
      "  timesteps_since_restore: 410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 410000\n",
      "  training_iteration: 41\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 950 s, 41 iter, 410000 ts, 205 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-59-30\n",
      "  done: false\n",
      "  episode_len_mean: 105.92\n",
      "  episode_reward_max: 356.0690031691619\n",
      "  episode_reward_mean: 266.8658425775039\n",
      "  episode_reward_min: -165.3052517755343\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 3050\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3772.268\n",
      "    load_time_ms: 1.798\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.536745437799254e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0423498153686523\n",
      "      kl: 0.007540990132838488\n",
      "      policy_loss: -0.001626848359592259\n",
      "      total_loss: 31.375728607177734\n",
      "      vf_explained_var: 0.7513500452041626\n",
      "      vf_loss: 31.377357482910156\n",
      "    sample_time_ms: 18715.902\n",
      "    update_time_ms: 5.274\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 133.43292128875194\n",
      "  time_since_restore: 972.9475679397583\n",
      "  time_this_iter_s: 22.313156366348267\n",
      "  time_total_s: 972.9475679397583\n",
      "  timestamp: 1553122770\n",
      "  timesteps_since_restore: 420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 42\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 972 s, 42 iter, 420000 ts, 267 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-20_23-59-52\n",
      "  done: false\n",
      "  episode_len_mean: 99.43\n",
      "  episode_reward_max: 354.4982489392003\n",
      "  episode_reward_mean: 226.62025207815432\n",
      "  episode_reward_min: -163.023928503717\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 3150\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3772.133\n",
      "    load_time_ms: 1.917\n",
      "    num_steps_sampled: 430000\n",
      "    num_steps_trained: 430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.768372718899627e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0281308889389038\n",
      "      kl: 0.011862890794873238\n",
      "      policy_loss: -0.0003319378010928631\n",
      "      total_loss: 28.329336166381836\n",
      "      vf_explained_var: 0.8535316586494446\n",
      "      vf_loss: 28.329668045043945\n",
      "    sample_time_ms: 18727.143\n",
      "    update_time_ms: 5.216\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 113.31012603907715\n",
      "  time_since_restore: 995.3903820514679\n",
      "  time_this_iter_s: 22.442814111709595\n",
      "  time_total_s: 995.3903820514679\n",
      "  timestamp: 1553122792\n",
      "  timesteps_since_restore: 430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 430000\n",
      "  training_iteration: 43\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 995 s, 43 iter, 430000 ts, 227 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-00-14\n",
      "  done: false\n",
      "  episode_len_mean: 99.5049504950495\n",
      "  episode_reward_max: 355.96665953669844\n",
      "  episode_reward_mean: 229.78585206281707\n",
      "  episode_reward_min: -163.31030300145414\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 3251\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3777.213\n",
      "    load_time_ms: 1.836\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.768372718899627e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0114656686782837\n",
      "      kl: 0.01248528528958559\n",
      "      policy_loss: -0.0010373031254857779\n",
      "      total_loss: 35.811058044433594\n",
      "      vf_explained_var: 0.8165785074234009\n",
      "      vf_loss: 35.812095642089844\n",
      "    sample_time_ms: 18664.191\n",
      "    update_time_ms: 5.632\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 114.89292603140855\n",
      "  time_since_restore: 1017.516699552536\n",
      "  time_this_iter_s: 22.126317501068115\n",
      "  time_total_s: 1017.516699552536\n",
      "  timestamp: 1553122814\n",
      "  timesteps_since_restore: 440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 44\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1017 s, 44 iter, 440000 ts, 230 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-00-37\n",
      "  done: false\n",
      "  episode_len_mean: 94.25471698113208\n",
      "  episode_reward_max: 366.3417035503182\n",
      "  episode_reward_mean: 194.60622196269927\n",
      "  episode_reward_min: -167.00411927733575\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 3357\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3781.28\n",
      "    load_time_ms: 1.784\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.768372718899627e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.013231873512268\n",
      "      kl: 0.008675219491124153\n",
      "      policy_loss: -0.0013115627225488424\n",
      "      total_loss: 45.360557556152344\n",
      "      vf_explained_var: 0.8058549165725708\n",
      "      vf_loss: 45.361873626708984\n",
      "    sample_time_ms: 18616.51\n",
      "    update_time_ms: 5.659\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.30311098134963\n",
      "  time_since_restore: 1040.0988125801086\n",
      "  time_this_iter_s: 22.582113027572632\n",
      "  time_total_s: 1040.0988125801086\n",
      "  timestamp: 1553122837\n",
      "  timesteps_since_restore: 450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 45\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1040 s, 45 iter, 450000 ts, 195 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-00-59\n",
      "  done: false\n",
      "  episode_len_mean: 90.17117117117117\n",
      "  episode_reward_max: 360.18606599111234\n",
      "  episode_reward_mean: 170.45395733456735\n",
      "  episode_reward_min: -168.797272564902\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 3468\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3787.343\n",
      "    load_time_ms: 1.804\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3841863594498136e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9738229513168335\n",
      "      kl: 0.01028019841760397\n",
      "      policy_loss: -0.0012584453215822577\n",
      "      total_loss: 46.51641845703125\n",
      "      vf_explained_var: 0.8379026651382446\n",
      "      vf_loss: 46.51767349243164\n",
      "    sample_time_ms: 18540.828\n",
      "    update_time_ms: 5.583\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.22697866728369\n",
      "  time_since_restore: 1062.282152414322\n",
      "  time_this_iter_s: 22.183339834213257\n",
      "  time_total_s: 1062.282152414322\n",
      "  timestamp: 1553122859\n",
      "  timesteps_since_restore: 460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 46\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1062 s, 46 iter, 460000 ts, 170 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-01-21\n",
      "  done: false\n",
      "  episode_len_mean: 100.6\n",
      "  episode_reward_max: 360.30534985776546\n",
      "  episode_reward_mean: 238.28113785963396\n",
      "  episode_reward_min: -161.12789599816344\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 3566\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3789.132\n",
      "    load_time_ms: 1.77\n",
      "    num_steps_sampled: 470000\n",
      "    num_steps_trained: 470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3841863594498136e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9870672225952148\n",
      "      kl: 0.011840893886983395\n",
      "      policy_loss: -0.0025972239673137665\n",
      "      total_loss: 30.47923469543457\n",
      "      vf_explained_var: 0.8265643119812012\n",
      "      vf_loss: 30.481830596923828\n",
      "    sample_time_ms: 18517.056\n",
      "    update_time_ms: 5.522\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 119.14056892981698\n",
      "  time_since_restore: 1084.4195082187653\n",
      "  time_this_iter_s: 22.13735580444336\n",
      "  time_total_s: 1084.4195082187653\n",
      "  timestamp: 1553122881\n",
      "  timesteps_since_restore: 470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 470000\n",
      "  training_iteration: 47\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1084 s, 47 iter, 470000 ts, 238 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-01-44\n",
      "  done: false\n",
      "  episode_len_mean: 97.55339805825243\n",
      "  episode_reward_max: 356.0303020303263\n",
      "  episode_reward_mean: 221.52283873166442\n",
      "  episode_reward_min: -168.86524149170523\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 3669\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.487\n",
      "    load_time_ms: 1.728\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3841863594498136e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.978024423122406\n",
      "      kl: 0.009058812633156776\n",
      "      policy_loss: -0.0003158324980176985\n",
      "      total_loss: 41.04219436645508\n",
      "      vf_explained_var: 0.7998108267784119\n",
      "      vf_loss: 41.042510986328125\n",
      "    sample_time_ms: 18499.989\n",
      "    update_time_ms: 5.603\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 110.76141936583221\n",
      "  time_since_restore: 1106.9254925251007\n",
      "  time_this_iter_s: 22.50598430633545\n",
      "  time_total_s: 1106.9254925251007\n",
      "  timestamp: 1553122904\n",
      "  timesteps_since_restore: 480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 48\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1106 s, 48 iter, 480000 ts, 222 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-02-07\n",
      "  done: false\n",
      "  episode_len_mean: 101.1\n",
      "  episode_reward_max: 357.1924497871046\n",
      "  episode_reward_mean: 244.86469970962204\n",
      "  episode_reward_min: -164.99077383431398\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 3768\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3806.296\n",
      "    load_time_ms: 1.73\n",
      "    num_steps_sampled: 490000\n",
      "    num_steps_trained: 490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1920931797249068e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9656460285186768\n",
      "      kl: 0.018384087830781937\n",
      "      policy_loss: -0.0018532028188928962\n",
      "      total_loss: 30.643428802490234\n",
      "      vf_explained_var: 0.8252395391464233\n",
      "      vf_loss: 30.645282745361328\n",
      "    sample_time_ms: 18508.15\n",
      "    update_time_ms: 5.728\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 122.43234985481104\n",
      "  time_since_restore: 1129.51722073555\n",
      "  time_this_iter_s: 22.59172821044922\n",
      "  time_total_s: 1129.51722073555\n",
      "  timestamp: 1553122927\n",
      "  timesteps_since_restore: 490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 490000\n",
      "  training_iteration: 49\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1129 s, 49 iter, 490000 ts, 245 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-02-29\n",
      "  done: false\n",
      "  episode_len_mean: 91.65137614678899\n",
      "  episode_reward_max: 370.0755009609315\n",
      "  episode_reward_mean: 176.20246194761074\n",
      "  episode_reward_min: -165.0279196988679\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 3877\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3817.036\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1920931797249068e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9607219099998474\n",
      "      kl: 0.010801474563777447\n",
      "      policy_loss: -0.0009061128948815167\n",
      "      total_loss: 50.82457733154297\n",
      "      vf_explained_var: 0.82234126329422\n",
      "      vf_loss: 50.82547378540039\n",
      "    sample_time_ms: 18551.377\n",
      "    update_time_ms: 5.611\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.10123097380537\n",
      "  time_since_restore: 1152.2986526489258\n",
      "  time_this_iter_s: 22.781431913375854\n",
      "  time_total_s: 1152.2986526489258\n",
      "  timestamp: 1553122949\n",
      "  timesteps_since_restore: 500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 50\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1152 s, 50 iter, 500000 ts, 176 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-02-53\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_reward_max: 366.1939971385491\n",
      "  episode_reward_mean: 235.38838552934513\n",
      "  episode_reward_min: -163.00327355278455\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 3978\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.659\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1920931797249068e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9594302773475647\n",
      "      kl: 0.009261096827685833\n",
      "      policy_loss: -0.001739975530654192\n",
      "      total_loss: 26.2724609375\n",
      "      vf_explained_var: 0.8657296895980835\n",
      "      vf_loss: 26.274200439453125\n",
      "    sample_time_ms: 18634.207\n",
      "    update_time_ms: 5.873\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 117.69419276467256\n",
      "  time_since_restore: 1175.3844480514526\n",
      "  time_this_iter_s: 23.085795402526855\n",
      "  time_total_s: 1175.3844480514526\n",
      "  timestamp: 1553122973\n",
      "  timesteps_since_restore: 510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 51\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1175 s, 51 iter, 510000 ts, 235 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-03-15\n",
      "  done: false\n",
      "  episode_len_mean: 90.41441441441441\n",
      "  episode_reward_max: 363.3133231252419\n",
      "  episode_reward_mean: 173.21169580335982\n",
      "  episode_reward_min: -167.08318612759453\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 4089\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3810.82\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.960465898624534e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9390104413032532\n",
      "      kl: 0.012951407581567764\n",
      "      policy_loss: -0.0015066079795360565\n",
      "      total_loss: 47.95857620239258\n",
      "      vf_explained_var: 0.8306251764297485\n",
      "      vf_loss: 47.960079193115234\n",
      "    sample_time_ms: 18629.078\n",
      "    update_time_ms: 5.878\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.6058479016799\n",
      "  time_since_restore: 1197.5977153778076\n",
      "  time_this_iter_s: 22.21326732635498\n",
      "  time_total_s: 1197.5977153778076\n",
      "  timestamp: 1553122995\n",
      "  timesteps_since_restore: 520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 52\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1197 s, 52 iter, 520000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-03-37\n",
      "  done: false\n",
      "  episode_len_mean: 103.91\n",
      "  episode_reward_max: 367.8146282296059\n",
      "  episode_reward_mean: 264.8078195761559\n",
      "  episode_reward_min: -166.81762996976016\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 4185\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3812.293\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 530000\n",
      "    num_steps_trained: 530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.960465898624534e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9565524458885193\n",
      "      kl: 0.010055161081254482\n",
      "      policy_loss: -0.0015199682675302029\n",
      "      total_loss: 30.619203567504883\n",
      "      vf_explained_var: 0.80494624376297\n",
      "      vf_loss: 30.6207218170166\n",
      "    sample_time_ms: 18636.068\n",
      "    update_time_ms: 6.077\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 132.4039097880779\n",
      "  time_since_restore: 1220.1253471374512\n",
      "  time_this_iter_s: 22.527631759643555\n",
      "  time_total_s: 1220.1253471374512\n",
      "  timestamp: 1553123017\n",
      "  timesteps_since_restore: 530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 530000\n",
      "  training_iteration: 53\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1220 s, 53 iter, 530000 ts, 265 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-04-00\n",
      "  done: false\n",
      "  episode_len_mean: 91.80733944954129\n",
      "  episode_reward_max: 368.8005954326782\n",
      "  episode_reward_mean: 178.94063641551597\n",
      "  episode_reward_min: -164.96462651821128\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 4294\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3810.918\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.960465898624534e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9549636840820312\n",
      "      kl: 0.007019325625151396\n",
      "      policy_loss: -0.0017663160106167197\n",
      "      total_loss: 64.83072662353516\n",
      "      vf_explained_var: 0.7622035145759583\n",
      "      vf_loss: 64.8324966430664\n",
      "    sample_time_ms: 18676.047\n",
      "    update_time_ms: 5.548\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.47031820775797\n",
      "  time_since_restore: 1242.6373054981232\n",
      "  time_this_iter_s: 22.511958360671997\n",
      "  time_total_s: 1242.6373054981232\n",
      "  timestamp: 1553123040\n",
      "  timesteps_since_restore: 540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 54\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1242 s, 54 iter, 540000 ts, 179 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 97.00970873786407\n",
      "  episode_reward_max: 364.6053236918946\n",
      "  episode_reward_mean: 220.27771886532165\n",
      "  episode_reward_min: -165.17539805779717\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4397\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3811.344\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 550000\n",
      "    num_steps_trained: 550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.980232949312267e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9311047792434692\n",
      "      kl: 0.00924201961606741\n",
      "      policy_loss: -0.0004051759315188974\n",
      "      total_loss: 39.40431594848633\n",
      "      vf_explained_var: 0.8190565705299377\n",
      "      vf_loss: 39.40472412109375\n",
      "    sample_time_ms: 18653.43\n",
      "    update_time_ms: 5.747\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 110.13885943266081\n",
      "  time_since_restore: 1265.0039517879486\n",
      "  time_this_iter_s: 22.36664628982544\n",
      "  time_total_s: 1265.0039517879486\n",
      "  timestamp: 1553123062\n",
      "  timesteps_since_restore: 550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 550000\n",
      "  training_iteration: 55\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1265 s, 55 iter, 550000 ts, 220 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-04-46\n",
      "  done: false\n",
      "  episode_len_mean: 94.33333333333333\n",
      "  episode_reward_max: 367.5077279565222\n",
      "  episode_reward_mean: 200.3260194806394\n",
      "  episode_reward_min: -160.86730498474338\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 4502\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3813.557\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4901164746561335e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9473223686218262\n",
      "      kl: 0.008721577934920788\n",
      "      policy_loss: -0.0010214479407295585\n",
      "      total_loss: 38.896820068359375\n",
      "      vf_explained_var: 0.8458071947097778\n",
      "      vf_loss: 38.89784240722656\n",
      "    sample_time_ms: 18771.829\n",
      "    update_time_ms: 5.96\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 100.1630097403197\n",
      "  time_since_restore: 1288.3938462734222\n",
      "  time_this_iter_s: 23.389894485473633\n",
      "  time_total_s: 1288.3938462734222\n",
      "  timestamp: 1553123086\n",
      "  timesteps_since_restore: 560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 56\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1288 s, 56 iter, 560000 ts, 200 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-05-09\n",
      "  done: false\n",
      "  episode_len_mean: 89.07964601769912\n",
      "  episode_reward_max: 365.8339963264031\n",
      "  episode_reward_mean: 165.41201310778857\n",
      "  episode_reward_min: -166.81466983473484\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 4615\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3813.384\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.450582373280668e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9353787302970886\n",
      "      kl: 0.011563431471586227\n",
      "      policy_loss: -0.0007547284476459026\n",
      "      total_loss: 62.3432502746582\n",
      "      vf_explained_var: 0.7939439415931702\n",
      "      vf_loss: 62.3440055847168\n",
      "    sample_time_ms: 18833.462\n",
      "    update_time_ms: 5.908\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.70600655389433\n",
      "  time_since_restore: 1311.1434943675995\n",
      "  time_this_iter_s: 22.749648094177246\n",
      "  time_total_s: 1311.1434943675995\n",
      "  timestamp: 1553123109\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 57\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1311 s, 57 iter, 570000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-05-32\n",
      "  done: false\n",
      "  episode_len_mean: 92.31481481481481\n",
      "  episode_reward_max: 367.60565117838865\n",
      "  episode_reward_mean: 182.31932281212727\n",
      "  episode_reward_min: -166.93826372229142\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 4723\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3817.73\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.450582373280668e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9479886293411255\n",
      "      kl: 0.008707270957529545\n",
      "      policy_loss: -0.0005700884503312409\n",
      "      total_loss: 41.591365814208984\n",
      "      vf_explained_var: 0.8481228351593018\n",
      "      vf_loss: 41.59193420410156\n",
      "    sample_time_ms: 18885.159\n",
      "    update_time_ms: 5.651\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.15966140606363\n",
      "  time_since_restore: 1334.2052266597748\n",
      "  time_this_iter_s: 23.061732292175293\n",
      "  time_total_s: 1334.2052266597748\n",
      "  timestamp: 1553123132\n",
      "  timesteps_since_restore: 580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 58\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1334 s, 58 iter, 580000 ts, 182 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-05-54\n",
      "  done: false\n",
      "  episode_len_mean: 99.92079207920793\n",
      "  episode_reward_max: 366.32415971063983\n",
      "  episode_reward_mean: 239.75528653553664\n",
      "  episode_reward_min: -162.89857786818177\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 4824\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.155\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 590000\n",
      "    num_steps_trained: 590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.725291186640334e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9256489872932434\n",
      "      kl: 0.011978253722190857\n",
      "      policy_loss: -0.0018100675661116838\n",
      "      total_loss: 28.875537872314453\n",
      "      vf_explained_var: 0.8543603420257568\n",
      "      vf_loss: 28.877347946166992\n",
      "    sample_time_ms: 18890.461\n",
      "    update_time_ms: 5.553\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 119.87764326776828\n",
      "  time_since_restore: 1356.8203430175781\n",
      "  time_this_iter_s: 22.615116357803345\n",
      "  time_total_s: 1356.8203430175781\n",
      "  timestamp: 1553123154\n",
      "  timesteps_since_restore: 590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 590000\n",
      "  training_iteration: 59\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1356 s, 59 iter, 590000 ts, 240 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-06-17\n",
      "  done: false\n",
      "  episode_len_mean: 93.87735849056604\n",
      "  episode_reward_max: 373.17349065943716\n",
      "  episode_reward_mean: 198.85910622596546\n",
      "  episode_reward_min: -168.73635808341214\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 4930\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3817.963\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.725291186640334e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9180608987808228\n",
      "      kl: 0.007151428610086441\n",
      "      policy_loss: -1.9104052171314834e-06\n",
      "      total_loss: 40.00026321411133\n",
      "      vf_explained_var: 0.8443370461463928\n",
      "      vf_loss: 40.00026321411133\n",
      "    sample_time_ms: 18904.719\n",
      "    update_time_ms: 5.727\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 99.42955311298273\n",
      "  time_since_restore: 1379.7735450267792\n",
      "  time_this_iter_s: 22.95320200920105\n",
      "  time_total_s: 1379.7735450267792\n",
      "  timestamp: 1553123177\n",
      "  timesteps_since_restore: 600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 60\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1379 s, 60 iter, 600000 ts, 199 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-06-39\n",
      "  done: false\n",
      "  episode_len_mean: 96.02912621359224\n",
      "  episode_reward_max: 368.4593352020463\n",
      "  episode_reward_mean: 213.62574786200898\n",
      "  episode_reward_min: -162.83679772590796\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 5033\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3817.641\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 610000\n",
      "    num_steps_trained: 610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.862645593320167e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9233036637306213\n",
      "      kl: 0.012586543336510658\n",
      "      policy_loss: -0.0030820041429251432\n",
      "      total_loss: 31.19327163696289\n",
      "      vf_explained_var: 0.8618911504745483\n",
      "      vf_loss: 31.196348190307617\n",
      "    sample_time_ms: 18776.428\n",
      "    update_time_ms: 5.486\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 106.81287393100452\n",
      "  time_since_restore: 1401.5709080696106\n",
      "  time_this_iter_s: 21.79736304283142\n",
      "  time_total_s: 1401.5709080696106\n",
      "  timestamp: 1553123199\n",
      "  timesteps_since_restore: 610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 610000\n",
      "  training_iteration: 61\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1401 s, 61 iter, 610000 ts, 214 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-07-02\n",
      "  done: false\n",
      "  episode_len_mean: 97.59615384615384\n",
      "  episode_reward_max: 371.46720300342037\n",
      "  episode_reward_mean: 226.8362553691108\n",
      "  episode_reward_min: -164.75042982420365\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5137\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3817.278\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.862645593320167e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9260668754577637\n",
      "      kl: 0.008840633556246758\n",
      "      policy_loss: -0.0005387600976973772\n",
      "      total_loss: 50.05404281616211\n",
      "      vf_explained_var: 0.7728291749954224\n",
      "      vf_loss: 50.05458068847656\n",
      "    sample_time_ms: 18842.369\n",
      "    update_time_ms: 5.408\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 113.41812768455537\n",
      "  time_since_restore: 1424.4384140968323\n",
      "  time_this_iter_s: 22.86750602722168\n",
      "  time_total_s: 1424.4384140968323\n",
      "  timestamp: 1553123222\n",
      "  timesteps_since_restore: 620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 62\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1424 s, 62 iter, 620000 ts, 227 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-07-24\n",
      "  done: false\n",
      "  episode_len_mean: 97.00980392156863\n",
      "  episode_reward_max: 376.1876317032308\n",
      "  episode_reward_mean: 220.91581667947855\n",
      "  episode_reward_min: -164.77629606161238\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 5239\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3817.03\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.313227966600834e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8993154764175415\n",
      "      kl: 0.009094463661313057\n",
      "      policy_loss: -0.0005572147783823311\n",
      "      total_loss: 42.79899215698242\n",
      "      vf_explained_var: 0.8058410882949829\n",
      "      vf_loss: 42.7995491027832\n",
      "    sample_time_ms: 18791.309\n",
      "    update_time_ms: 5.234\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 110.45790833973928\n",
      "  time_since_restore: 1446.4525609016418\n",
      "  time_this_iter_s: 22.01414680480957\n",
      "  time_total_s: 1446.4525609016418\n",
      "  timestamp: 1553123244\n",
      "  timesteps_since_restore: 630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 63\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1446 s, 63 iter, 630000 ts, 221 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-07-46\n",
      "  done: false\n",
      "  episode_len_mean: 97.3076923076923\n",
      "  episode_reward_max: 381.64303877992756\n",
      "  episode_reward_mean: 222.37842501174322\n",
      "  episode_reward_min: -164.86888508817816\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5343\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3818.854\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 640000\n",
      "    num_steps_trained: 640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.656613983300417e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8782569766044617\n",
      "      kl: 0.01634020358324051\n",
      "      policy_loss: -0.001857950002886355\n",
      "      total_loss: 37.10343551635742\n",
      "      vf_explained_var: 0.8305776715278625\n",
      "      vf_loss: 37.105289459228516\n",
      "    sample_time_ms: 18754.914\n",
      "    update_time_ms: 5.356\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 111.18921250587161\n",
      "  time_since_restore: 1468.6157257556915\n",
      "  time_this_iter_s: 22.163164854049683\n",
      "  time_total_s: 1468.6157257556915\n",
      "  timestamp: 1553123266\n",
      "  timesteps_since_restore: 640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 640000\n",
      "  training_iteration: 64\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1468 s, 64 iter, 640000 ts, 222 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-08-08\n",
      "  done: false\n",
      "  episode_len_mean: 90.22018348623853\n",
      "  episode_reward_max: 373.8288486956689\n",
      "  episode_reward_mean: 174.96251300541934\n",
      "  episode_reward_min: -162.7067869632834\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 5452\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3818.165\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 650000\n",
      "    num_steps_trained: 650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.656613983300417e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8496705889701843\n",
      "      kl: 0.008864302188158035\n",
      "      policy_loss: -0.0013261521235108376\n",
      "      total_loss: 54.494815826416016\n",
      "      vf_explained_var: 0.8147764801979065\n",
      "      vf_loss: 54.49614334106445\n",
      "    sample_time_ms: 18703.032\n",
      "    update_time_ms: 5.17\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.48125650270968\n",
      "  time_since_restore: 1490.4505405426025\n",
      "  time_this_iter_s: 21.83481478691101\n",
      "  time_total_s: 1490.4505405426025\n",
      "  timestamp: 1553123288\n",
      "  timesteps_since_restore: 650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 650000\n",
      "  training_iteration: 65\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1490 s, 65 iter, 650000 ts, 175 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-08-31\n",
      "  done: false\n",
      "  episode_len_mean: 93.25925925925925\n",
      "  episode_reward_max: 377.41498198665045\n",
      "  episode_reward_mean: 202.8301792490296\n",
      "  episode_reward_min: -162.70837900471366\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 5560\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3819.488\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3283069916502086e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8525030612945557\n",
      "      kl: 0.005652618128806353\n",
      "      policy_loss: -0.0002611447707749903\n",
      "      total_loss: 33.69969940185547\n",
      "      vf_explained_var: 0.8662145733833313\n",
      "      vf_loss: 33.69995880126953\n",
      "    sample_time_ms: 18655.707\n",
      "    update_time_ms: 4.996\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 101.4150896245148\n",
      "  time_since_restore: 1513.3809230327606\n",
      "  time_this_iter_s: 22.93038249015808\n",
      "  time_total_s: 1513.3809230327606\n",
      "  timestamp: 1553123311\n",
      "  timesteps_since_restore: 660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 66\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1513 s, 66 iter, 660000 ts, 203 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-08-53\n",
      "  done: false\n",
      "  episode_len_mean: 89.58558558558559\n",
      "  episode_reward_max: 372.2925184765669\n",
      "  episode_reward_mean: 176.76361888660364\n",
      "  episode_reward_min: -164.7160722138961\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 5671\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3810.043\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 670000\n",
      "    num_steps_trained: 670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1641534958251043e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.841458261013031\n",
      "      kl: 0.0065884361974895\n",
      "      policy_loss: -0.0002992370864376426\n",
      "      total_loss: 47.65017318725586\n",
      "      vf_explained_var: 0.8380762934684753\n",
      "      vf_loss: 47.65047073364258\n",
      "    sample_time_ms: 18584.456\n",
      "    update_time_ms: 4.998\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.38180944330182\n",
      "  time_since_restore: 1535.3274216651917\n",
      "  time_this_iter_s: 21.94649863243103\n",
      "  time_total_s: 1535.3274216651917\n",
      "  timestamp: 1553123333\n",
      "  timesteps_since_restore: 670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 670000\n",
      "  training_iteration: 67\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1535 s, 67 iter, 670000 ts, 177 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-09-15\n",
      "  done: false\n",
      "  episode_len_mean: 91.29729729729729\n",
      "  episode_reward_max: 376.18609182922177\n",
      "  episode_reward_mean: 190.83646620962853\n",
      "  episode_reward_min: -166.6997356155361\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 5782\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.194\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.8207674791255215e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8150619864463806\n",
      "      kl: 0.010547320358455181\n",
      "      policy_loss: -0.0013965758262202144\n",
      "      total_loss: 37.37533187866211\n",
      "      vf_explained_var: 0.862927258014679\n",
      "      vf_loss: 37.37673568725586\n",
      "    sample_time_ms: 18508.189\n",
      "    update_time_ms: 5.284\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.41823310481428\n",
      "  time_since_restore: 1557.5247588157654\n",
      "  time_this_iter_s: 22.19733715057373\n",
      "  time_total_s: 1557.5247588157654\n",
      "  timestamp: 1553123355\n",
      "  timesteps_since_restore: 680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 68\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1557 s, 68 iter, 680000 ts, 191 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-09-38\n",
      "  done: false\n",
      "  episode_len_mean: 92.0925925925926\n",
      "  episode_reward_max: 375.7397123210589\n",
      "  episode_reward_mean: 198.09834758706924\n",
      "  episode_reward_min: -166.69339057514767\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 5890\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.355\n",
      "    load_time_ms: 1.638\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.8207674791255215e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.822489321231842\n",
      "      kl: 0.0057703363709151745\n",
      "      policy_loss: -0.00026983977295458317\n",
      "      total_loss: 40.05389404296875\n",
      "      vf_explained_var: 0.8528618216514587\n",
      "      vf_loss: 40.054168701171875\n",
      "    sample_time_ms: 18494.514\n",
      "    update_time_ms: 5.265\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 99.04917379353458\n",
      "  time_since_restore: 1579.9755086898804\n",
      "  time_this_iter_s: 22.45074987411499\n",
      "  time_total_s: 1579.9755086898804\n",
      "  timestamp: 1553123378\n",
      "  timesteps_since_restore: 690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 69\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1579 s, 69 iter, 690000 ts, 198 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-10-00\n",
      "  done: false\n",
      "  episode_len_mean: 89.16071428571429\n",
      "  episode_reward_max: 374.26953628274447\n",
      "  episode_reward_mean: 177.26507084652516\n",
      "  episode_reward_min: -166.7338405505734\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 6002\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3783.799\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9103837395627608e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8224360346794128\n",
      "      kl: 0.004068627022206783\n",
      "      policy_loss: -0.0004347738577052951\n",
      "      total_loss: 49.66274642944336\n",
      "      vf_explained_var: 0.8271943926811218\n",
      "      vf_loss: 49.66318130493164\n",
      "    sample_time_ms: 18412.704\n",
      "    update_time_ms: 5.13\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.63253542326257\n",
      "  time_since_restore: 1601.9842162132263\n",
      "  time_this_iter_s: 22.008707523345947\n",
      "  time_total_s: 1601.9842162132263\n",
      "  timestamp: 1553123400\n",
      "  timesteps_since_restore: 700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 70\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1601 s, 70 iter, 700000 ts, 177 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-10-23\n",
      "  done: false\n",
      "  episode_len_mean: 91.14678899082568\n",
      "  episode_reward_max: 374.04094129053533\n",
      "  episode_reward_mean: 190.49829161088547\n",
      "  episode_reward_min: -166.6927230340843\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 6111\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3775.245\n",
      "    load_time_ms: 1.625\n",
      "    num_steps_sampled: 710000\n",
      "    num_steps_trained: 710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4551918697813804e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8145811557769775\n",
      "      kl: 0.00784702692180872\n",
      "      policy_loss: -0.0006563476053997874\n",
      "      total_loss: 40.364383697509766\n",
      "      vf_explained_var: 0.8585337400436401\n",
      "      vf_loss: 40.36503982543945\n",
      "    sample_time_ms: 18513.735\n",
      "    update_time_ms: 5.395\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.24914580544275\n",
      "  time_since_restore: 1624.7090532779694\n",
      "  time_this_iter_s: 22.724837064743042\n",
      "  time_total_s: 1624.7090532779694\n",
      "  timestamp: 1553123423\n",
      "  timesteps_since_restore: 710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 710000\n",
      "  training_iteration: 71\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1624 s, 71 iter, 710000 ts, 190 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-10-45\n",
      "  done: false\n",
      "  episode_len_mean: 95.1214953271028\n",
      "  episode_reward_max: 377.85019731747485\n",
      "  episode_reward_mean: 217.3242594867541\n",
      "  episode_reward_min: -168.65489664573795\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 6218\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.384\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.275959348906902e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8011705875396729\n",
      "      kl: 0.011446778662502766\n",
      "      policy_loss: -0.000996773480437696\n",
      "      total_loss: 43.16511917114258\n",
      "      vf_explained_var: 0.8180934190750122\n",
      "      vf_loss: 43.166114807128906\n",
      "    sample_time_ms: 18459.578\n",
      "    update_time_ms: 5.828\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 108.66212974337705\n",
      "  time_since_restore: 1646.9598696231842\n",
      "  time_this_iter_s: 22.250816345214844\n",
      "  time_total_s: 1646.9598696231842\n",
      "  timestamp: 1553123445\n",
      "  timesteps_since_restore: 720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 72\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1646 s, 72 iter, 720000 ts, 217 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 90.94495412844037\n",
      "  episode_reward_max: 375.908370689137\n",
      "  episode_reward_mean: 188.38752873255444\n",
      "  episode_reward_min: -164.82387318953394\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 6327\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3758.527\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 730000\n",
      "    num_steps_trained: 730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.275959348906902e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8065603971481323\n",
      "      kl: 0.00741160660982132\n",
      "      policy_loss: -0.0002935241209343076\n",
      "      total_loss: 44.537864685058594\n",
      "      vf_explained_var: 0.8381485342979431\n",
      "      vf_loss: 44.53815460205078\n",
      "    sample_time_ms: 18422.521\n",
      "    update_time_ms: 5.869\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.19376436627722\n",
      "  time_since_restore: 1668.5128390789032\n",
      "  time_this_iter_s: 21.552969455718994\n",
      "  time_total_s: 1668.5128390789032\n",
      "  timestamp: 1553123467\n",
      "  timesteps_since_restore: 730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 730000\n",
      "  training_iteration: 73\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1668 s, 73 iter, 730000 ts, 188 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-11-29\n",
      "  done: false\n",
      "  episode_len_mean: 89.10714285714286\n",
      "  episode_reward_max: 374.8446999889488\n",
      "  episode_reward_mean: 172.46879428623075\n",
      "  episode_reward_min: -164.82365053440995\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 6439\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3747.453\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.637979674453451e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7859329581260681\n",
      "      kl: 0.012231891974806786\n",
      "      policy_loss: -0.0021214596927165985\n",
      "      total_loss: 35.48634338378906\n",
      "      vf_explained_var: 0.8875454664230347\n",
      "      vf_loss: 35.48846435546875\n",
      "    sample_time_ms: 18457.225\n",
      "    update_time_ms: 5.799\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.23439714311537\n",
      "  time_since_restore: 1690.911925315857\n",
      "  time_this_iter_s: 22.399086236953735\n",
      "  time_total_s: 1690.911925315857\n",
      "  timestamp: 1553123489\n",
      "  timesteps_since_restore: 740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 74\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1690 s, 74 iter, 740000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-11-51\n",
      "  done: false\n",
      "  episode_len_mean: 91.36697247706422\n",
      "  episode_reward_max: 374.06888840917225\n",
      "  episode_reward_mean: 192.97613269084908\n",
      "  episode_reward_min: -164.84089817193745\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 6548\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3741.212\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.637979674453451e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7774588465690613\n",
      "      kl: 0.007122081704437733\n",
      "      policy_loss: 0.0008997782715596259\n",
      "      total_loss: 49.30787658691406\n",
      "      vf_explained_var: 0.8214755058288574\n",
      "      vf_loss: 49.30698013305664\n",
      "    sample_time_ms: 18457.979\n",
      "    update_time_ms: 5.81\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.48806634542454\n",
      "  time_since_restore: 1712.6931431293488\n",
      "  time_this_iter_s: 21.78121781349182\n",
      "  time_total_s: 1712.6931431293488\n",
      "  timestamp: 1553123511\n",
      "  timesteps_since_restore: 750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 75\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1712 s, 75 iter, 750000 ts, 193 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-12-13\n",
      "  done: false\n",
      "  episode_len_mean: 84.52100840336135\n",
      "  episode_reward_max: 377.0388349101445\n",
      "  episode_reward_mean: 143.89533144795533\n",
      "  episode_reward_min: -166.68072005971086\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 6667\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.521\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 760000\n",
      "    num_steps_trained: 760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8189898372267255e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7408341765403748\n",
      "      kl: 0.012606637552380562\n",
      "      policy_loss: -0.0009658588678576052\n",
      "      total_loss: 62.20407485961914\n",
      "      vf_explained_var: 0.8271719217300415\n",
      "      vf_loss: 62.20502853393555\n",
      "    sample_time_ms: 18418.617\n",
      "    update_time_ms: 5.824\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.94766572397768\n",
      "  time_since_restore: 1735.1818208694458\n",
      "  time_this_iter_s: 22.488677740097046\n",
      "  time_total_s: 1735.1818208694458\n",
      "  timestamp: 1553123533\n",
      "  timesteps_since_restore: 760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 760000\n",
      "  training_iteration: 76\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1735 s, 76 iter, 760000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-12-35\n",
      "  done: false\n",
      "  episode_len_mean: 91.61467889908256\n",
      "  episode_reward_max: 375.96404884623405\n",
      "  episode_reward_mean: 192.96857823082777\n",
      "  episode_reward_min: -164.70977167968272\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 6776\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3734.101\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 770000\n",
      "    num_steps_trained: 770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8189898372267255e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7364361882209778\n",
      "      kl: 0.011639175936579704\n",
      "      policy_loss: -0.002600371139124036\n",
      "      total_loss: 41.16932678222656\n",
      "      vf_explained_var: 0.8501113653182983\n",
      "      vf_loss: 41.171932220458984\n",
      "    sample_time_ms: 18369.399\n",
      "    update_time_ms: 5.89\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.48428911541389\n",
      "  time_since_restore: 1756.6117324829102\n",
      "  time_this_iter_s: 21.429911613464355\n",
      "  time_total_s: 1756.6117324829102\n",
      "  timestamp: 1553123555\n",
      "  timesteps_since_restore: 770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 770000\n",
      "  training_iteration: 77\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1756 s, 77 iter, 770000 ts, 193 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-12-57\n",
      "  done: false\n",
      "  episode_len_mean: 85.78632478632478\n",
      "  episode_reward_max: 376.183427146892\n",
      "  episode_reward_mean: 153.69212438190021\n",
      "  episode_reward_min: -168.64518600867848\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 6893\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.837\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8189898372267255e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.710986316204071\n",
      "      kl: 0.011103339493274689\n",
      "      policy_loss: -0.0013294691452756524\n",
      "      total_loss: 59.01286315917969\n",
      "      vf_explained_var: 0.8286308646202087\n",
      "      vf_loss: 59.014198303222656\n",
      "    sample_time_ms: 18338.642\n",
      "    update_time_ms: 5.654\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.84606219095011\n",
      "  time_since_restore: 1778.4669308662415\n",
      "  time_this_iter_s: 21.8551983833313\n",
      "  time_total_s: 1778.4669308662415\n",
      "  timestamp: 1553123577\n",
      "  timesteps_since_restore: 780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 78\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1778 s, 78 iter, 780000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-13-19\n",
      "  done: false\n",
      "  episode_len_mean: 92.75\n",
      "  episode_reward_max: 375.2135392045481\n",
      "  episode_reward_mean: 204.56865054167295\n",
      "  episode_reward_min: -166.68056196531296\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 7001\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3725.25\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 790000\n",
      "    num_steps_trained: 790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8189898372267255e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.72994065284729\n",
      "      kl: 0.007654720451682806\n",
      "      policy_loss: -0.0011346789542585611\n",
      "      total_loss: 46.2671012878418\n",
      "      vf_explained_var: 0.8228303790092468\n",
      "      vf_loss: 46.26823806762695\n",
      "    sample_time_ms: 18365.144\n",
      "    update_time_ms: 5.655\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 102.28432527083648\n",
      "  time_since_restore: 1801.1285982131958\n",
      "  time_this_iter_s: 22.661667346954346\n",
      "  time_total_s: 1801.1285982131958\n",
      "  timestamp: 1553123599\n",
      "  timesteps_since_restore: 790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 790000\n",
      "  training_iteration: 79\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1801 s, 79 iter, 790000 ts, 205 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-13-42\n",
      "  done: false\n",
      "  episode_len_mean: 88.92857142857143\n",
      "  episode_reward_max: 374.41871532215674\n",
      "  episode_reward_mean: 179.39745252731518\n",
      "  episode_reward_min: -164.66657460878702\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 7113\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3733.095\n",
      "    load_time_ms: 1.673\n",
      "    num_steps_sampled: 800000\n",
      "    num_steps_trained: 800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.094949186133627e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7043386101722717\n",
      "      kl: 0.008277609944343567\n",
      "      policy_loss: -0.0015540604945272207\n",
      "      total_loss: 47.38984298706055\n",
      "      vf_explained_var: 0.83957439661026\n",
      "      vf_loss: 47.391395568847656\n",
      "    sample_time_ms: 18370.544\n",
      "    update_time_ms: 5.738\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.6987262636576\n",
      "  time_since_restore: 1823.2716891765594\n",
      "  time_this_iter_s: 22.143090963363647\n",
      "  time_total_s: 1823.2716891765594\n",
      "  timestamp: 1553123622\n",
      "  timesteps_since_restore: 800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 800000\n",
      "  training_iteration: 80\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1823 s, 80 iter, 800000 ts, 179 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 89.54464285714286\n",
      "  episode_reward_max: 376.8140348798432\n",
      "  episode_reward_mean: 184.3058962361699\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 7225\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.823\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.5474745930668137e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6935485601425171\n",
      "      kl: 0.0060779326595366\n",
      "      policy_loss: -0.0013496380997821689\n",
      "      total_loss: 36.99231719970703\n",
      "      vf_explained_var: 0.871644139289856\n",
      "      vf_loss: 36.9936637878418\n",
      "    sample_time_ms: 18267.863\n",
      "    update_time_ms: 5.59\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.15294811808495\n",
      "  time_since_restore: 1844.937509059906\n",
      "  time_this_iter_s: 21.665819883346558\n",
      "  time_total_s: 1844.937509059906\n",
      "  timestamp: 1553123643\n",
      "  timesteps_since_restore: 810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 81\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1844 s, 81 iter, 810000 ts, 184 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-14-26\n",
      "  done: false\n",
      "  episode_len_mean: 90.81818181818181\n",
      "  episode_reward_max: 376.22021965846693\n",
      "  episode_reward_mean: 188.30161553261968\n",
      "  episode_reward_min: -162.64380738368328\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 7335\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.574\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 820000\n",
      "    num_steps_trained: 820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2737372965334068e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6879332065582275\n",
      "      kl: 0.009532525204122066\n",
      "      policy_loss: -0.001304323785007\n",
      "      total_loss: 41.96277618408203\n",
      "      vf_explained_var: 0.8535496592521667\n",
      "      vf_loss: 41.964080810546875\n",
      "    sample_time_ms: 18280.541\n",
      "    update_time_ms: 5.172\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.15080776630982\n",
      "  time_since_restore: 1867.2495067119598\n",
      "  time_this_iter_s: 22.311997652053833\n",
      "  time_total_s: 1867.2495067119598\n",
      "  timestamp: 1553123666\n",
      "  timesteps_since_restore: 820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 820000\n",
      "  training_iteration: 82\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1867 s, 82 iter, 820000 ts, 188 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-14-48\n",
      "  done: false\n",
      "  episode_len_mean: 93.44339622641509\n",
      "  episode_reward_max: 379.37337984597895\n",
      "  episode_reward_mean: 210.759475167331\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 7441\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.014\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 830000\n",
      "    num_steps_trained: 830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1368686482667034e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6919376850128174\n",
      "      kl: 0.005493978504091501\n",
      "      policy_loss: -0.0008991360664367676\n",
      "      total_loss: 32.450469970703125\n",
      "      vf_explained_var: 0.8701124787330627\n",
      "      vf_loss: 32.45136642456055\n",
      "    sample_time_ms: 18352.806\n",
      "    update_time_ms: 5.19\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 105.3797375836655\n",
      "  time_since_restore: 1889.4494442939758\n",
      "  time_this_iter_s: 22.19993758201599\n",
      "  time_total_s: 1889.4494442939758\n",
      "  timestamp: 1553123688\n",
      "  timesteps_since_restore: 830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 830000\n",
      "  training_iteration: 83\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1889 s, 83 iter, 830000 ts, 211 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-15-10\n",
      "  done: false\n",
      "  episode_len_mean: 89.17699115044248\n",
      "  episode_reward_max: 380.78543296354593\n",
      "  episode_reward_mean: 174.74532327487248\n",
      "  episode_reward_min: -166.67534509595401\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 7554\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.914\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.684343241333517e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6973878741264343\n",
      "      kl: 0.006238977424800396\n",
      "      policy_loss: -0.001186004257760942\n",
      "      total_loss: 57.16098403930664\n",
      "      vf_explained_var: 0.8113183379173279\n",
      "      vf_loss: 57.16217041015625\n",
      "    sample_time_ms: 18306.986\n",
      "    update_time_ms: 5.259\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.37266163743624\n",
      "  time_since_restore: 1911.598790884018\n",
      "  time_this_iter_s: 22.149346590042114\n",
      "  time_total_s: 1911.598790884018\n",
      "  timestamp: 1553123710\n",
      "  timesteps_since_restore: 840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 84\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1911 s, 84 iter, 840000 ts, 175 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-15-32\n",
      "  done: false\n",
      "  episode_len_mean: 88.75\n",
      "  episode_reward_max: 379.83788307935095\n",
      "  episode_reward_mean: 177.90980448318257\n",
      "  episode_reward_min: -168.6366976044969\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 7666\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3733.726\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 850000\n",
      "    num_steps_trained: 850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.8421716206667585e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6708181500434875\n",
      "      kl: 0.012105156667530537\n",
      "      policy_loss: -0.0003625670215114951\n",
      "      total_loss: 50.045230865478516\n",
      "      vf_explained_var: 0.8343926668167114\n",
      "      vf_loss: 50.04559326171875\n",
      "    sample_time_ms: 18310.42\n",
      "    update_time_ms: 5.261\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.95490224159128\n",
      "  time_since_restore: 1933.3809020519257\n",
      "  time_this_iter_s: 21.782111167907715\n",
      "  time_total_s: 1933.3809020519257\n",
      "  timestamp: 1553123732\n",
      "  timesteps_since_restore: 850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 850000\n",
      "  training_iteration: 85\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1933 s, 85 iter, 850000 ts, 178 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-15-54\n",
      "  done: false\n",
      "  episode_len_mean: 92.44036697247707\n",
      "  episode_reward_max: 375.86108206923024\n",
      "  episode_reward_mean: 204.50248147588647\n",
      "  episode_reward_min: -166.67486463673825\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 7775\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.404\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 860000\n",
      "    num_steps_trained: 860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.8421716206667585e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6831135153770447\n",
      "      kl: 0.008932053111493587\n",
      "      policy_loss: -0.0019043867941945791\n",
      "      total_loss: 35.12038803100586\n",
      "      vf_explained_var: 0.8697892427444458\n",
      "      vf_loss: 35.12228775024414\n",
      "    sample_time_ms: 18269.008\n",
      "    update_time_ms: 5.274\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 102.25124073794323\n",
      "  time_since_restore: 1955.3097631931305\n",
      "  time_this_iter_s: 21.928861141204834\n",
      "  time_total_s: 1955.3097631931305\n",
      "  timestamp: 1553123754\n",
      "  timesteps_since_restore: 860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 860000\n",
      "  training_iteration: 86\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1955 s, 86 iter, 860000 ts, 205 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-16-16\n",
      "  done: false\n",
      "  episode_len_mean: 95.27619047619048\n",
      "  episode_reward_max: 378.302730313364\n",
      "  episode_reward_mean: 221.13216155633532\n",
      "  episode_reward_min: -166.67863100084045\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 7880\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.109\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4210858103333793e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6739212274551392\n",
      "      kl: 0.009116614237427711\n",
      "      policy_loss: -4.433897993294522e-05\n",
      "      total_loss: 51.8249626159668\n",
      "      vf_explained_var: 0.7836253046989441\n",
      "      vf_loss: 51.82500457763672\n",
      "    sample_time_ms: 18358.649\n",
      "    update_time_ms: 5.363\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 110.56608077816765\n",
      "  time_since_restore: 1977.6040134429932\n",
      "  time_this_iter_s: 22.29425024986267\n",
      "  time_total_s: 1977.6040134429932\n",
      "  timestamp: 1553123776\n",
      "  timesteps_since_restore: 870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 87\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1977 s, 87 iter, 870000 ts, 221 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-16-38\n",
      "  done: false\n",
      "  episode_len_mean: 87.33043478260869\n",
      "  episode_reward_max: 379.51377919087423\n",
      "  episode_reward_mean: 160.65687373566723\n",
      "  episode_reward_min: -164.66870608677576\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 7995\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.611\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.105429051666896e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6536308526992798\n",
      "      kl: 0.010370943695306778\n",
      "      policy_loss: -0.0005761776701547205\n",
      "      total_loss: 50.43157958984375\n",
      "      vf_explained_var: 0.8487992882728577\n",
      "      vf_loss: 50.43215560913086\n",
      "    sample_time_ms: 18358.409\n",
      "    update_time_ms: 5.368\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.32843686783362\n",
      "  time_since_restore: 1999.4198107719421\n",
      "  time_this_iter_s: 21.815797328948975\n",
      "  time_total_s: 1999.4198107719421\n",
      "  timestamp: 1553123798\n",
      "  timesteps_since_restore: 880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 88\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 1999 s, 88 iter, 880000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-17-00\n",
      "  done: false\n",
      "  episode_len_mean: 87.92105263157895\n",
      "  episode_reward_max: 379.74243577322017\n",
      "  episode_reward_mean: 170.9214938879502\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 8109\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.592\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 890000\n",
      "    num_steps_trained: 890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.105429051666896e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6521691679954529\n",
      "      kl: 0.010041775181889534\n",
      "      policy_loss: -0.0003665900439955294\n",
      "      total_loss: 46.3606071472168\n",
      "      vf_explained_var: 0.8573533892631531\n",
      "      vf_loss: 46.3609733581543\n",
      "    sample_time_ms: 18286.299\n",
      "    update_time_ms: 5.406\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.46074694397508\n",
      "  time_since_restore: 2021.3789501190186\n",
      "  time_this_iter_s: 21.959139347076416\n",
      "  time_total_s: 2021.3789501190186\n",
      "  timestamp: 1553123820\n",
      "  timesteps_since_restore: 890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 890000\n",
      "  training_iteration: 89\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2021 s, 89 iter, 890000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-17-22\n",
      "  done: false\n",
      "  episode_len_mean: 87.88392857142857\n",
      "  episode_reward_max: 380.3877451478812\n",
      "  episode_reward_mean: 167.88886815275947\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 8221\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.428\n",
      "    load_time_ms: 1.334\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.105429051666896e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6442209482192993\n",
      "      kl: 0.009831199422478676\n",
      "      policy_loss: -0.0006384410662576556\n",
      "      total_loss: 57.33298110961914\n",
      "      vf_explained_var: 0.8210127353668213\n",
      "      vf_loss: 57.333621978759766\n",
      "    sample_time_ms: 18299.524\n",
      "    update_time_ms: 5.291\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.94443407637972\n",
      "  time_since_restore: 2043.5393838882446\n",
      "  time_this_iter_s: 22.160433769226074\n",
      "  time_total_s: 2043.5393838882446\n",
      "  timestamp: 1553123842\n",
      "  timesteps_since_restore: 900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 90\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2043 s, 90 iter, 900000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-17-44\n",
      "  done: false\n",
      "  episode_len_mean: 85.05084745762711\n",
      "  episode_reward_max: 380.55590543134014\n",
      "  episode_reward_mean: 145.6096458932276\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 8339\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.947\n",
      "    load_time_ms: 1.323\n",
      "    num_steps_sampled: 910000\n",
      "    num_steps_trained: 910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.552714525833448e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6394931674003601\n",
      "      kl: 0.012985341250896454\n",
      "      policy_loss: -0.002354277530685067\n",
      "      total_loss: 49.92967987060547\n",
      "      vf_explained_var: 0.8634383082389832\n",
      "      vf_loss: 49.93203353881836\n",
      "    sample_time_ms: 18348.777\n",
      "    update_time_ms: 5.339\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.80482294661381\n",
      "  time_since_restore: 2065.6500158309937\n",
      "  time_this_iter_s: 22.110631942749023\n",
      "  time_total_s: 2065.6500158309937\n",
      "  timestamp: 1553123864\n",
      "  timesteps_since_restore: 910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 910000\n",
      "  training_iteration: 91\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2065 s, 91 iter, 910000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-18-07\n",
      "  done: false\n",
      "  episode_len_mean: 91.009009009009\n",
      "  episode_reward_max: 384.54899776621613\n",
      "  episode_reward_mean: 192.7814362699139\n",
      "  episode_reward_min: -166.67428778297443\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 8450\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.41\n",
      "    load_time_ms: 1.333\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.552714525833448e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6517149806022644\n",
      "      kl: 0.00816159974783659\n",
      "      policy_loss: 7.938077760627493e-05\n",
      "      total_loss: 46.908241271972656\n",
      "      vf_explained_var: 0.8345792889595032\n",
      "      vf_loss: 46.90816116333008\n",
      "    sample_time_ms: 18319.637\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.39071813495694\n",
      "  time_since_restore: 2087.7145597934723\n",
      "  time_this_iter_s: 22.064543962478638\n",
      "  time_total_s: 2087.7145597934723\n",
      "  timestamp: 1553123887\n",
      "  timesteps_since_restore: 920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 92\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2087 s, 92 iter, 920000 ts, 193 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-18-29\n",
      "  done: false\n",
      "  episode_len_mean: 86.35652173913043\n",
      "  episode_reward_max: 387.4060645621691\n",
      "  episode_reward_mean: 159.1785822601952\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 8565\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.979\n",
      "    load_time_ms: 1.375\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.776357262916724e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.610435962677002\n",
      "      kl: 0.012021134607493877\n",
      "      policy_loss: -0.0007076949113979936\n",
      "      total_loss: 64.73804473876953\n",
      "      vf_explained_var: 0.8108600974082947\n",
      "      vf_loss: 64.73875427246094\n",
      "    sample_time_ms: 18296.797\n",
      "    update_time_ms: 5.266\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.58929113009765\n",
      "  time_since_restore: 2109.7108097076416\n",
      "  time_this_iter_s: 21.99624991416931\n",
      "  time_total_s: 2109.7108097076416\n",
      "  timestamp: 1553123909\n",
      "  timesteps_since_restore: 930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 93\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2109 s, 93 iter, 930000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-18-50\n",
      "  done: false\n",
      "  episode_len_mean: 86.05172413793103\n",
      "  episode_reward_max: 389.3574912654946\n",
      "  episode_reward_mean: 153.2908958138373\n",
      "  episode_reward_min: -166.67339482277538\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 8681\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.14\n",
      "    load_time_ms: 1.447\n",
      "    num_steps_sampled: 940000\n",
      "    num_steps_trained: 940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.776357262916724e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6150975227355957\n",
      "      kl: 0.015653299167752266\n",
      "      policy_loss: -0.0008757534669712186\n",
      "      total_loss: 71.20439147949219\n",
      "      vf_explained_var: 0.7973213195800781\n",
      "      vf_loss: 71.20526885986328\n",
      "    sample_time_ms: 18286.39\n",
      "    update_time_ms: 5.184\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.64544790691868\n",
      "  time_since_restore: 2131.5313873291016\n",
      "  time_this_iter_s: 21.82057762145996\n",
      "  time_total_s: 2131.5313873291016\n",
      "  timestamp: 1553123930\n",
      "  timesteps_since_restore: 940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 940000\n",
      "  training_iteration: 94\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2131 s, 94 iter, 940000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-19-11\n",
      "  done: false\n",
      "  episode_len_mean: 87.40869565217392\n",
      "  episode_reward_max: 383.82171560641706\n",
      "  episode_reward_mean: 167.2307213411611\n",
      "  episode_reward_min: -162.58681677385175\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 8796\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.579\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 950000\n",
      "    num_steps_trained: 950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.776357262916724e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6006994843482971\n",
      "      kl: 0.006466373335570097\n",
      "      policy_loss: -0.0019259053515270352\n",
      "      total_loss: 58.35758972167969\n",
      "      vf_explained_var: 0.8170605897903442\n",
      "      vf_loss: 58.35952377319336\n",
      "    sample_time_ms: 18175.6\n",
      "    update_time_ms: 5.229\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.61536067058054\n",
      "  time_since_restore: 2152.3203806877136\n",
      "  time_this_iter_s: 20.78899335861206\n",
      "  time_total_s: 2152.3203806877136\n",
      "  timestamp: 1553123951\n",
      "  timesteps_since_restore: 950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 950000\n",
      "  training_iteration: 95\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2152 s, 95 iter, 950000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-19-33\n",
      "  done: false\n",
      "  episode_len_mean: 89.87387387387388\n",
      "  episode_reward_max: 380.6845153246487\n",
      "  episode_reward_mean: 183.8704053492369\n",
      "  episode_reward_min: -162.59454341501453\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 8907\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.567\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.88178631458362e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5980040431022644\n",
      "      kl: 0.008378861472010612\n",
      "      policy_loss: -0.00045152276288717985\n",
      "      total_loss: 50.94145965576172\n",
      "      vf_explained_var: 0.8304532170295715\n",
      "      vf_loss: 50.9419059753418\n",
      "    sample_time_ms: 18142.927\n",
      "    update_time_ms: 5.143\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.93520267461845\n",
      "  time_since_restore: 2173.942028284073\n",
      "  time_this_iter_s: 21.621647596359253\n",
      "  time_total_s: 2173.942028284073\n",
      "  timestamp: 1553123973\n",
      "  timesteps_since_restore: 960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 96\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2173 s, 96 iter, 960000 ts, 184 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-19-55\n",
      "  done: false\n",
      "  episode_len_mean: 89.41964285714286\n",
      "  episode_reward_max: 385.4869097000729\n",
      "  episode_reward_mean: 183.47376043676056\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 9019\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.079\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 970000\n",
      "    num_steps_trained: 970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.44089315729181e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5936764478683472\n",
      "      kl: 0.008522272109985352\n",
      "      policy_loss: -0.0006742599653080106\n",
      "      total_loss: 34.83187484741211\n",
      "      vf_explained_var: 0.8827527165412903\n",
      "      vf_loss: 34.83254623413086\n",
      "    sample_time_ms: 18086.734\n",
      "    update_time_ms: 5.082\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.73688021838026\n",
      "  time_since_restore: 2195.677440881729\n",
      "  time_this_iter_s: 21.73541259765625\n",
      "  time_total_s: 2195.677440881729\n",
      "  timestamp: 1553123995\n",
      "  timesteps_since_restore: 970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 970000\n",
      "  training_iteration: 97\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2195 s, 97 iter, 970000 ts, 183 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-20-16\n",
      "  done: false\n",
      "  episode_len_mean: 87.78070175438596\n",
      "  episode_reward_max: 384.84138263505037\n",
      "  episode_reward_mean: 167.66769069385685\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 9133\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.581\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 980000\n",
      "    num_steps_trained: 980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5615941286087036\n",
      "      kl: 0.015824411064386368\n",
      "      policy_loss: 0.000280428008409217\n",
      "      total_loss: 49.75004959106445\n",
      "      vf_explained_var: 0.8445631265640259\n",
      "      vf_loss: 49.7497673034668\n",
      "    sample_time_ms: 18041.338\n",
      "    update_time_ms: 5.152\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.83384534692844\n",
      "  time_since_restore: 2217.0233788490295\n",
      "  time_this_iter_s: 21.345937967300415\n",
      "  time_total_s: 2217.0233788490295\n",
      "  timestamp: 1553124016\n",
      "  timesteps_since_restore: 980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 980000\n",
      "  training_iteration: 98\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2217 s, 98 iter, 980000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-20-37\n",
      "  done: false\n",
      "  episode_len_mean: 94.14150943396227\n",
      "  episode_reward_max: 380.26357465687596\n",
      "  episode_reward_mean: 217.49967470517285\n",
      "  episode_reward_min: -162.57428463586803\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 9239\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.936\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5638331174850464\n",
      "      kl: 0.011654132045805454\n",
      "      policy_loss: -0.0010793537367135286\n",
      "      total_loss: 41.43455123901367\n",
      "      vf_explained_var: 0.8314445614814758\n",
      "      vf_loss: 41.435630798339844\n",
      "    sample_time_ms: 17958.706\n",
      "    update_time_ms: 5.214\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 108.74983735258641\n",
      "  time_since_restore: 2238.1087176799774\n",
      "  time_this_iter_s: 21.085338830947876\n",
      "  time_total_s: 2238.1087176799774\n",
      "  timestamp: 1553124037\n",
      "  timesteps_since_restore: 990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 99\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2238 s, 99 iter, 990000 ts, 217 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-20-59\n",
      "  done: false\n",
      "  episode_len_mean: 85.67521367521367\n",
      "  episode_reward_max: 387.5975029620487\n",
      "  episode_reward_mean: 150.95445851027625\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 9356\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.443\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.533337414264679\n",
      "      kl: 0.011606022715568542\n",
      "      policy_loss: -0.001551958848722279\n",
      "      total_loss: 58.40660858154297\n",
      "      vf_explained_var: 0.8320868015289307\n",
      "      vf_loss: 58.408164978027344\n",
      "    sample_time_ms: 17894.737\n",
      "    update_time_ms: 5.245\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.47722925513813\n",
      "  time_since_restore: 2259.6152894496918\n",
      "  time_this_iter_s: 21.506571769714355\n",
      "  time_total_s: 2259.6152894496918\n",
      "  timestamp: 1553124059\n",
      "  timesteps_since_restore: 1000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 100\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2259 s, 100 iter, 1000000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-21-21\n",
      "  done: false\n",
      "  episode_len_mean: 85.23076923076923\n",
      "  episode_reward_max: 383.9776495825148\n",
      "  episode_reward_mean: 150.82860210119102\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 9473\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.192\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 1010000\n",
      "    num_steps_trained: 1010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5140174031257629\n",
      "      kl: 0.012784376740455627\n",
      "      policy_loss: -0.0015776476357132196\n",
      "      total_loss: 61.005271911621094\n",
      "      vf_explained_var: 0.8247016668319702\n",
      "      vf_loss: 61.0068473815918\n",
      "    sample_time_ms: 17875.452\n",
      "    update_time_ms: 5.084\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.41430105059551\n",
      "  time_since_restore: 2281.5659029483795\n",
      "  time_this_iter_s: 21.950613498687744\n",
      "  time_total_s: 2281.5659029483795\n",
      "  timestamp: 1553124081\n",
      "  timesteps_since_restore: 1010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1010000\n",
      "  training_iteration: 101\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2281 s, 101 iter, 1010000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-21-43\n",
      "  done: false\n",
      "  episode_len_mean: 91.04545454545455\n",
      "  episode_reward_max: 381.13461108639933\n",
      "  episode_reward_mean: 197.91907844708075\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 9583\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.191\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5250459313392639\n",
      "      kl: 0.007199469488114119\n",
      "      policy_loss: 0.00011358190386090428\n",
      "      total_loss: 57.78269577026367\n",
      "      vf_explained_var: 0.7873431444168091\n",
      "      vf_loss: 57.782588958740234\n",
      "    sample_time_ms: 17829.766\n",
      "    update_time_ms: 5.254\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.95953922354039\n",
      "  time_since_restore: 2303.3643822669983\n",
      "  time_this_iter_s: 21.798479318618774\n",
      "  time_total_s: 2303.3643822669983\n",
      "  timestamp: 1553124103\n",
      "  timesteps_since_restore: 1020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 102\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2303 s, 102 iter, 1020000 ts, 198 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-22-04\n",
      "  done: false\n",
      "  episode_len_mean: 90.38181818181818\n",
      "  episode_reward_max: 382.30108535477495\n",
      "  episode_reward_mean: 191.02578094951397\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 9693\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.913\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 1030000\n",
      "    num_steps_trained: 1030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1102232893229526e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5073221921920776\n",
      "      kl: 0.015054730698466301\n",
      "      policy_loss: -0.0010893369326367974\n",
      "      total_loss: 54.010868072509766\n",
      "      vf_explained_var: 0.8051474094390869\n",
      "      vf_loss: 54.01195526123047\n",
      "    sample_time_ms: 17746.664\n",
      "    update_time_ms: 5.264\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.512890474757\n",
      "  time_since_restore: 2324.5685002803802\n",
      "  time_this_iter_s: 21.204118013381958\n",
      "  time_total_s: 2324.5685002803802\n",
      "  timestamp: 1553124124\n",
      "  timesteps_since_restore: 1030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1030000\n",
      "  training_iteration: 103\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2324 s, 103 iter, 1030000 ts, 191 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-22-26\n",
      "  done: false\n",
      "  episode_len_mean: 85.12711864406779\n",
      "  episode_reward_max: 385.90803088381256\n",
      "  episode_reward_mean: 154.5020246528965\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 9811\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.724\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1102232893229526e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5071991086006165\n",
      "      kl: 0.009726271964609623\n",
      "      policy_loss: 0.00013542290253099054\n",
      "      total_loss: 49.72696304321289\n",
      "      vf_explained_var: 0.8547660708427429\n",
      "      vf_loss: 49.72682571411133\n",
      "    sample_time_ms: 17752.629\n",
      "    update_time_ms: 5.258\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.25101232644828\n",
      "  time_since_restore: 2346.4455575942993\n",
      "  time_this_iter_s: 21.877057313919067\n",
      "  time_total_s: 2346.4455575942993\n",
      "  timestamp: 1553124146\n",
      "  timesteps_since_restore: 1040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 104\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2346 s, 104 iter, 1040000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-22-47\n",
      "  done: false\n",
      "  episode_len_mean: 82.475\n",
      "  episode_reward_max: 380.4746167278866\n",
      "  episode_reward_mean: 126.96938464389565\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 9931\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.589\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.551116446614763e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4927639067173004\n",
      "      kl: 0.010395691730082035\n",
      "      policy_loss: -8.898133091861382e-05\n",
      "      total_loss: 49.58195114135742\n",
      "      vf_explained_var: 0.8723537921905518\n",
      "      vf_loss: 49.58203887939453\n",
      "    sample_time_ms: 17843.367\n",
      "    update_time_ms: 5.168\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.484692321947826\n",
      "  time_since_restore: 2368.018971681595\n",
      "  time_this_iter_s: 21.573414087295532\n",
      "  time_total_s: 2368.018971681595\n",
      "  timestamp: 1553124167\n",
      "  timesteps_since_restore: 1050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 105\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2368 s, 105 iter, 1050000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-23-10\n",
      "  done: false\n",
      "  episode_len_mean: 87.88695652173914\n",
      "  episode_reward_max: 389.42246644224855\n",
      "  episode_reward_mean: 167.09711460846984\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 10046\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.932\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 1060000\n",
      "    num_steps_trained: 1060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.551116446614763e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4905886650085449\n",
      "      kl: 0.014110421761870384\n",
      "      policy_loss: -0.00018909387290477753\n",
      "      total_loss: 53.664825439453125\n",
      "      vf_explained_var: 0.8440960645675659\n",
      "      vf_loss: 53.66501235961914\n",
      "    sample_time_ms: 17892.07\n",
      "    update_time_ms: 5.313\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.54855730423496\n",
      "  time_since_restore: 2390.202070951462\n",
      "  time_this_iter_s: 22.183099269866943\n",
      "  time_total_s: 2390.202070951462\n",
      "  timestamp: 1553124190\n",
      "  timesteps_since_restore: 1060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1060000\n",
      "  training_iteration: 106\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2390 s, 106 iter, 1060000 ts, 167 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-23-31\n",
      "  done: false\n",
      "  episode_len_mean: 91.46296296296296\n",
      "  episode_reward_max: 386.4852199381008\n",
      "  episode_reward_mean: 188.18553942539842\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 10154\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.52\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 1070000\n",
      "    num_steps_trained: 1070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.551116446614763e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49003875255584717\n",
      "      kl: 0.012303014285862446\n",
      "      policy_loss: -0.001776024466380477\n",
      "      total_loss: 56.5742301940918\n",
      "      vf_explained_var: 0.8108996152877808\n",
      "      vf_loss: 56.57599639892578\n",
      "    sample_time_ms: 17856.294\n",
      "    update_time_ms: 5.709\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.09276971269918\n",
      "  time_since_restore: 2411.6003737449646\n",
      "  time_this_iter_s: 21.398302793502808\n",
      "  time_total_s: 2411.6003737449646\n",
      "  timestamp: 1553124211\n",
      "  timesteps_since_restore: 1070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1070000\n",
      "  training_iteration: 107\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2411 s, 107 iter, 1070000 ts, 188 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-23-53\n",
      "  done: false\n",
      "  episode_len_mean: 86.53448275862068\n",
      "  episode_reward_max: 384.109671739549\n",
      "  episode_reward_mean: 152.23106272606884\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 10270\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.334\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.551116446614763e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4956212043762207\n",
      "      kl: 0.006677832454442978\n",
      "      policy_loss: -0.0003069073718506843\n",
      "      total_loss: 50.81159210205078\n",
      "      vf_explained_var: 0.8559138774871826\n",
      "      vf_loss: 50.811893463134766\n",
      "    sample_time_ms: 17892.031\n",
      "    update_time_ms: 5.595\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.11553136303442\n",
      "  time_since_restore: 2433.329269886017\n",
      "  time_this_iter_s: 21.728896141052246\n",
      "  time_total_s: 2433.329269886017\n",
      "  timestamp: 1553124233\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 108\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2433 s, 108 iter, 1080000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-24-15\n",
      "  done: false\n",
      "  episode_len_mean: 88.29824561403508\n",
      "  episode_reward_max: 382.9646699472757\n",
      "  episode_reward_mean: 177.6531620768806\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 10384\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.049\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 1090000\n",
      "    num_steps_trained: 1090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7755582233073814e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.484591007232666\n",
      "      kl: 0.012900998815894127\n",
      "      policy_loss: -0.0031695091165602207\n",
      "      total_loss: 42.05589294433594\n",
      "      vf_explained_var: 0.8668432831764221\n",
      "      vf_loss: 42.05906295776367\n",
      "    sample_time_ms: 17997.662\n",
      "    update_time_ms: 5.522\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.8265810384403\n",
      "  time_since_restore: 2455.4779675006866\n",
      "  time_this_iter_s: 22.1486976146698\n",
      "  time_total_s: 2455.4779675006866\n",
      "  timestamp: 1553124255\n",
      "  timesteps_since_restore: 1090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1090000\n",
      "  training_iteration: 109\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2455 s, 109 iter, 1090000 ts, 178 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-24-37\n",
      "  done: false\n",
      "  episode_len_mean: 91.16363636363636\n",
      "  episode_reward_max: 386.10770882475066\n",
      "  episode_reward_mean: 189.72980084768605\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 10494\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.882\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 1100000\n",
      "    num_steps_trained: 1100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7755582233073814e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49939653277397156\n",
      "      kl: 0.00981343723833561\n",
      "      policy_loss: -0.0003740470274351537\n",
      "      total_loss: 56.67937469482422\n",
      "      vf_explained_var: 0.8135696053504944\n",
      "      vf_loss: 56.67973709106445\n",
      "    sample_time_ms: 18048.415\n",
      "    update_time_ms: 5.467\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.86490042384304\n",
      "  time_since_restore: 2477.477394104004\n",
      "  time_this_iter_s: 21.99942660331726\n",
      "  time_total_s: 2477.477394104004\n",
      "  timestamp: 1553124277\n",
      "  timesteps_since_restore: 1100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1100000\n",
      "  training_iteration: 110\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2477 s, 110 iter, 1100000 ts, 190 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-24-59\n",
      "  done: false\n",
      "  episode_len_mean: 87.97345132743362\n",
      "  episode_reward_max: 384.3727003108877\n",
      "  episode_reward_mean: 168.22118365937294\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 10607\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.014\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4803032875061035\n",
      "      kl: 0.010124447755515575\n",
      "      policy_loss: -0.0005108832265250385\n",
      "      total_loss: 50.53289794921875\n",
      "      vf_explained_var: 0.8458024263381958\n",
      "      vf_loss: 50.533409118652344\n",
      "    sample_time_ms: 18018.058\n",
      "    update_time_ms: 5.441\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.11059182968646\n",
      "  time_since_restore: 2499.0932700634003\n",
      "  time_this_iter_s: 21.615875959396362\n",
      "  time_total_s: 2499.0932700634003\n",
      "  timestamp: 1553124299\n",
      "  timesteps_since_restore: 1110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 111\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2499 s, 111 iter, 1110000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-25-22\n",
      "  done: false\n",
      "  episode_len_mean: 84.10924369747899\n",
      "  episode_reward_max: 387.6339130277117\n",
      "  episode_reward_mean: 127.50760110067725\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 10726\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.562\n",
      "    load_time_ms: 1.454\n",
      "    num_steps_sampled: 1120000\n",
      "    num_steps_trained: 1120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4467686414718628\n",
      "      kl: 0.012474183924496174\n",
      "      policy_loss: -0.00012493401300162077\n",
      "      total_loss: 68.98224639892578\n",
      "      vf_explained_var: 0.8350787162780762\n",
      "      vf_loss: 68.98238372802734\n",
      "    sample_time_ms: 18131.706\n",
      "    update_time_ms: 5.481\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.75380055033865\n",
      "  time_since_restore: 2522.034462451935\n",
      "  time_this_iter_s: 22.941192388534546\n",
      "  time_total_s: 2522.034462451935\n",
      "  timestamp: 1553124322\n",
      "  timesteps_since_restore: 1120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1120000\n",
      "  training_iteration: 112\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2522 s, 112 iter, 1120000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-25-44\n",
      "  done: false\n",
      "  episode_len_mean: 84.6864406779661\n",
      "  episode_reward_max: 385.58168898814404\n",
      "  episode_reward_mean: 128.26018482762987\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 10844\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.543\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 1130000\n",
      "    num_steps_trained: 1130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.46349287033081055\n",
      "      kl: 0.011839812621474266\n",
      "      policy_loss: -0.00021619406470563263\n",
      "      total_loss: 90.61236572265625\n",
      "      vf_explained_var: 0.7756239771842957\n",
      "      vf_loss: 90.61257934570312\n",
      "    sample_time_ms: 18216.585\n",
      "    update_time_ms: 5.59\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.13009241381494\n",
      "  time_since_restore: 2544.0672748088837\n",
      "  time_this_iter_s: 22.032812356948853\n",
      "  time_total_s: 2544.0672748088837\n",
      "  timestamp: 1553124344\n",
      "  timesteps_since_restore: 1130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1130000\n",
      "  training_iteration: 113\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2544 s, 113 iter, 1130000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-26-06\n",
      "  done: false\n",
      "  episode_len_mean: 82.9504132231405\n",
      "  episode_reward_max: 389.3349444102687\n",
      "  episode_reward_mean: 132.05616437613537\n",
      "  episode_reward_min: -164.68269458907986\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 10965\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.889\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4661206007003784\n",
      "      kl: 0.011145181953907013\n",
      "      policy_loss: 9.595511801308021e-05\n",
      "      total_loss: 54.72580337524414\n",
      "      vf_explained_var: 0.8577365279197693\n",
      "      vf_loss: 54.725711822509766\n",
      "    sample_time_ms: 18253.471\n",
      "    update_time_ms: 5.656\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.02808218806769\n",
      "  time_since_restore: 2566.30681347847\n",
      "  time_this_iter_s: 22.23953866958618\n",
      "  time_total_s: 2566.30681347847\n",
      "  timestamp: 1553124366\n",
      "  timesteps_since_restore: 1140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 114\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2566 s, 114 iter, 1140000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-26-28\n",
      "  done: false\n",
      "  episode_len_mean: 90.51818181818182\n",
      "  episode_reward_max: 385.89984521472275\n",
      "  episode_reward_mean: 179.35040006157033\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 11075\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.088\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 1150000\n",
      "    num_steps_trained: 1150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48225831985473633\n",
      "      kl: 0.01047353446483612\n",
      "      policy_loss: -0.0008611033554188907\n",
      "      total_loss: 65.60235595703125\n",
      "      vf_explained_var: 0.7907976508140564\n",
      "      vf_loss: 65.60321807861328\n",
      "    sample_time_ms: 18242.718\n",
      "    update_time_ms: 5.872\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.67520003078515\n",
      "  time_since_restore: 2587.7790179252625\n",
      "  time_this_iter_s: 21.472204446792603\n",
      "  time_total_s: 2587.7790179252625\n",
      "  timestamp: 1553124388\n",
      "  timesteps_since_restore: 1150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1150000\n",
      "  training_iteration: 115\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2587 s, 115 iter, 1150000 ts, 179 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-26-49\n",
      "  done: false\n",
      "  episode_len_mean: 94.47169811320755\n",
      "  episode_reward_max: 388.94227246037264\n",
      "  episode_reward_mean: 209.01100090181944\n",
      "  episode_reward_min: -162.59427638985264\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 11181\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.224\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 1160000\n",
      "    num_steps_trained: 1160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48521003127098083\n",
      "      kl: 0.0103846974670887\n",
      "      policy_loss: 0.00010811346146510914\n",
      "      total_loss: 63.7204475402832\n",
      "      vf_explained_var: 0.7650920748710632\n",
      "      vf_loss: 63.720340728759766\n",
      "    sample_time_ms: 18195.63\n",
      "    update_time_ms: 5.801\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 104.50550045090972\n",
      "  time_since_restore: 2609.4211308956146\n",
      "  time_this_iter_s: 21.642112970352173\n",
      "  time_total_s: 2609.4211308956146\n",
      "  timestamp: 1553124409\n",
      "  timesteps_since_restore: 1160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1160000\n",
      "  training_iteration: 116\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2609 s, 116 iter, 1160000 ts, 209 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-27-11\n",
      "  done: false\n",
      "  episode_len_mean: 89.57142857142857\n",
      "  episode_reward_max: 384.5710331464601\n",
      "  episode_reward_mean: 181.46440093345726\n",
      "  episode_reward_min: -162.57620345242566\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 11293\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.437\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.46908318996429443\n",
      "      kl: 0.010201113298535347\n",
      "      policy_loss: 0.0020632916130125523\n",
      "      total_loss: 52.190513610839844\n",
      "      vf_explained_var: 0.8341365456581116\n",
      "      vf_loss: 52.18844985961914\n",
      "    sample_time_ms: 18247.243\n",
      "    update_time_ms: 5.462\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.73220046672863\n",
      "  time_since_restore: 2631.526219367981\n",
      "  time_this_iter_s: 22.105088472366333\n",
      "  time_total_s: 2631.526219367981\n",
      "  timestamp: 1553124431\n",
      "  timesteps_since_restore: 1170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 117\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2631 s, 117 iter, 1170000 ts, 181 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-27-33\n",
      "  done: false\n",
      "  episode_len_mean: 87.8157894736842\n",
      "  episode_reward_max: 387.3653681536712\n",
      "  episode_reward_mean: 169.5966448141248\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 11407\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.828\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 1180000\n",
      "    num_steps_trained: 1180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4413619339466095\n",
      "      kl: 0.012161606922745705\n",
      "      policy_loss: -0.00047638133401051164\n",
      "      total_loss: 53.782814025878906\n",
      "      vf_explained_var: 0.8364306688308716\n",
      "      vf_loss: 53.78328323364258\n",
      "    sample_time_ms: 18245.517\n",
      "    update_time_ms: 5.516\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.7983224070624\n",
      "  time_since_restore: 2653.242362976074\n",
      "  time_this_iter_s: 21.71614360809326\n",
      "  time_total_s: 2653.242362976074\n",
      "  timestamp: 1553124453\n",
      "  timesteps_since_restore: 1180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1180000\n",
      "  training_iteration: 118\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2653 s, 118 iter, 1180000 ts, 170 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-27-55\n",
      "  done: false\n",
      "  episode_len_mean: 87.7280701754386\n",
      "  episode_reward_max: 389.26027930724973\n",
      "  episode_reward_mean: 160.34622913143946\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 11521\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.211\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 1190000\n",
      "    num_steps_trained: 1190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.44554412364959717\n",
      "      kl: 0.013613869436085224\n",
      "      policy_loss: -0.0009630070417188108\n",
      "      total_loss: 43.376853942871094\n",
      "      vf_explained_var: 0.8719163537025452\n",
      "      vf_loss: 43.37781524658203\n",
      "    sample_time_ms: 18238.023\n",
      "    update_time_ms: 5.506\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.17311456571973\n",
      "  time_since_restore: 2675.2881927490234\n",
      "  time_this_iter_s: 22.04582977294922\n",
      "  time_total_s: 2675.2881927490234\n",
      "  timestamp: 1553124475\n",
      "  timesteps_since_restore: 1190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1190000\n",
      "  training_iteration: 119\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2675 s, 119 iter, 1190000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-28-17\n",
      "  done: false\n",
      "  episode_len_mean: 87.98245614035088\n",
      "  episode_reward_max: 387.05307183776296\n",
      "  episode_reward_mean: 171.87330119171568\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 11635\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.542\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4123068153858185\n",
      "      kl: 0.011248812079429626\n",
      "      policy_loss: 0.0005355265457183123\n",
      "      total_loss: 53.974815368652344\n",
      "      vf_explained_var: 0.8315204977989197\n",
      "      vf_loss: 53.97428512573242\n",
      "    sample_time_ms: 18238.928\n",
      "    update_time_ms: 5.511\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.93665059585786\n",
      "  time_since_restore: 2697.262305498123\n",
      "  time_this_iter_s: 21.97411274909973\n",
      "  time_total_s: 2697.262305498123\n",
      "  timestamp: 1553124497\n",
      "  timesteps_since_restore: 1200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 120\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2697 s, 120 iter, 1200000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-28-40\n",
      "  done: false\n",
      "  episode_len_mean: 87.3716814159292\n",
      "  episode_reward_max: 387.9378420926463\n",
      "  episode_reward_mean: 166.57801787206176\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 11748\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.486\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 1210000\n",
      "    num_steps_trained: 1210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.41310766339302063\n",
      "      kl: 0.007458020467311144\n",
      "      policy_loss: 0.00038873881567269564\n",
      "      total_loss: 54.12302017211914\n",
      "      vf_explained_var: 0.8333006501197815\n",
      "      vf_loss: 54.12261962890625\n",
      "    sample_time_ms: 18304.458\n",
      "    update_time_ms: 5.56\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.28900893603088\n",
      "  time_since_restore: 2719.647757291794\n",
      "  time_this_iter_s: 22.385451793670654\n",
      "  time_total_s: 2719.647757291794\n",
      "  timestamp: 1553124520\n",
      "  timesteps_since_restore: 1210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1210000\n",
      "  training_iteration: 121\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2719 s, 121 iter, 1210000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-29-02\n",
      "  done: false\n",
      "  episode_len_mean: 88.70796460176992\n",
      "  episode_reward_max: 384.3498415363284\n",
      "  episode_reward_mean: 178.58339070917214\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 11861\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.892\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 1220000\n",
      "    num_steps_trained: 1220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3975028097629547\n",
      "      kl: 0.014964280650019646\n",
      "      policy_loss: 0.00028772212681360543\n",
      "      total_loss: 49.31584548950195\n",
      "      vf_explained_var: 0.8400506377220154\n",
      "      vf_loss: 49.31555938720703\n",
      "    sample_time_ms: 18231.511\n",
      "    update_time_ms: 5.404\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.29169535458605\n",
      "  time_since_restore: 2741.6732115745544\n",
      "  time_this_iter_s: 22.02545428276062\n",
      "  time_total_s: 2741.6732115745544\n",
      "  timestamp: 1553124542\n",
      "  timesteps_since_restore: 1220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1220000\n",
      "  training_iteration: 122\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2741 s, 122 iter, 1220000 ts, 179 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-29-23\n",
      "  done: false\n",
      "  episode_len_mean: 82.82644628099173\n",
      "  episode_reward_max: 389.10173702459036\n",
      "  episode_reward_mean: 135.57306848702314\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 11982\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.621\n",
      "    load_time_ms: 1.594\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.386929988861084\n",
      "      kl: 0.010502705350518227\n",
      "      policy_loss: -0.0004387962108012289\n",
      "      total_loss: 62.449493408203125\n",
      "      vf_explained_var: 0.8323866724967957\n",
      "      vf_loss: 62.44993209838867\n",
      "    sample_time_ms: 18184.437\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.78653424351157\n",
      "  time_since_restore: 2763.2026658058167\n",
      "  time_this_iter_s: 21.529454231262207\n",
      "  time_total_s: 2763.2026658058167\n",
      "  timestamp: 1553124563\n",
      "  timesteps_since_restore: 1230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 123\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2763 s, 123 iter, 1230000 ts, 136 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-29-45\n",
      "  done: false\n",
      "  episode_len_mean: 85.32478632478633\n",
      "  episode_reward_max: 387.9261450705825\n",
      "  episode_reward_mean: 150.90754043812615\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 12099\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.3\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 1240000\n",
      "    num_steps_trained: 1240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.39875081181526184\n",
      "      kl: 0.01289295218884945\n",
      "      policy_loss: -0.0027587064541876316\n",
      "      total_loss: 50.191650390625\n",
      "      vf_explained_var: 0.8607637286186218\n",
      "      vf_loss: 50.19440841674805\n",
      "    sample_time_ms: 18138.496\n",
      "    update_time_ms: 5.251\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.45377021906309\n",
      "  time_since_restore: 2784.997947216034\n",
      "  time_this_iter_s: 21.795281410217285\n",
      "  time_total_s: 2784.997947216034\n",
      "  timestamp: 1553124585\n",
      "  timesteps_since_restore: 1240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1240000\n",
      "  training_iteration: 124\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2784 s, 124 iter, 1240000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-30-07\n",
      "  done: false\n",
      "  episode_len_mean: 87.18103448275862\n",
      "  episode_reward_max: 384.64793692787487\n",
      "  episode_reward_mean: 162.6940324345712\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 12215\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.236\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 1250000\n",
      "    num_steps_trained: 1250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.40034639835357666\n",
      "      kl: 0.021836483851075172\n",
      "      policy_loss: 0.00018914540123660117\n",
      "      total_loss: 65.4384994506836\n",
      "      vf_explained_var: 0.8060316443443298\n",
      "      vf_loss: 65.43830871582031\n",
      "    sample_time_ms: 18139.741\n",
      "    update_time_ms: 5.101\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.3470162172856\n",
      "  time_since_restore: 2806.4391803741455\n",
      "  time_this_iter_s: 21.441233158111572\n",
      "  time_total_s: 2806.4391803741455\n",
      "  timestamp: 1553124607\n",
      "  timesteps_since_restore: 1250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1250000\n",
      "  training_iteration: 125\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2806 s, 125 iter, 1250000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-30-28\n",
      "  done: false\n",
      "  episode_len_mean: 93.5377358490566\n",
      "  episode_reward_max: 388.2182024503457\n",
      "  episode_reward_mean: 203.59508154086353\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 12321\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.361\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.42005273699760437\n",
      "      kl: 0.01798679120838642\n",
      "      policy_loss: -0.0008370010764338076\n",
      "      total_loss: 62.417442321777344\n",
      "      vf_explained_var: 0.7725735902786255\n",
      "      vf_loss: 62.41828155517578\n",
      "    sample_time_ms: 18133.637\n",
      "    update_time_ms: 5.002\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 101.79754077043178\n",
      "  time_since_restore: 2827.994744539261\n",
      "  time_this_iter_s: 21.555564165115356\n",
      "  time_total_s: 2827.994744539261\n",
      "  timestamp: 1553124628\n",
      "  timesteps_since_restore: 1260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 126\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2827 s, 126 iter, 1260000 ts, 204 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-30-50\n",
      "  done: false\n",
      "  episode_len_mean: 88.45614035087719\n",
      "  episode_reward_max: 385.86896913791537\n",
      "  episode_reward_mean: 163.67080431219807\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 12435\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3679.86\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 1270000\n",
      "    num_steps_trained: 1270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.41364601254463196\n",
      "      kl: 0.009587287902832031\n",
      "      policy_loss: -0.0006055301055312157\n",
      "      total_loss: 69.13890838623047\n",
      "      vf_explained_var: 0.7947931289672852\n",
      "      vf_loss: 69.13951110839844\n",
      "    sample_time_ms: 18136.758\n",
      "    update_time_ms: 5.014\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.83540215609904\n",
      "  time_since_restore: 2849.934923887253\n",
      "  time_this_iter_s: 21.940179347991943\n",
      "  time_total_s: 2849.934923887253\n",
      "  timestamp: 1553124650\n",
      "  timesteps_since_restore: 1270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1270000\n",
      "  training_iteration: 127\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2849 s, 127 iter, 1270000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-31-12\n",
      "  done: false\n",
      "  episode_len_mean: 92.76851851851852\n",
      "  episode_reward_max: 387.7020337530693\n",
      "  episode_reward_mean: 198.8305154930379\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 12543\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.267\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 1280000\n",
      "    num_steps_trained: 1280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.41840532422065735\n",
      "      kl: 0.010785586200654507\n",
      "      policy_loss: -0.0007241631974466145\n",
      "      total_loss: 59.098915100097656\n",
      "      vf_explained_var: 0.7909388542175293\n",
      "      vf_loss: 59.09963607788086\n",
      "    sample_time_ms: 18118.593\n",
      "    update_time_ms: 5.432\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 99.41525774651898\n",
      "  time_since_restore: 2871.561291217804\n",
      "  time_this_iter_s: 21.626367330551147\n",
      "  time_total_s: 2871.561291217804\n",
      "  timestamp: 1553124672\n",
      "  timesteps_since_restore: 1280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1280000\n",
      "  training_iteration: 128\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2871 s, 128 iter, 1280000 ts, 199 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-31-33\n",
      "  done: false\n",
      "  episode_len_mean: 85.34188034188034\n",
      "  episode_reward_max: 391.3323407447203\n",
      "  episode_reward_mean: 151.94602388380517\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 12660\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.841\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.38506633043289185\n",
      "      kl: 0.012110205367207527\n",
      "      policy_loss: -0.0015734403859823942\n",
      "      total_loss: 52.68984603881836\n",
      "      vf_explained_var: 0.8470494151115417\n",
      "      vf_loss: 52.6914176940918\n",
      "    sample_time_ms: 18068.343\n",
      "    update_time_ms: 5.949\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.97301194190258\n",
      "  time_since_restore: 2893.1287269592285\n",
      "  time_this_iter_s: 21.56743574142456\n",
      "  time_total_s: 2893.1287269592285\n",
      "  timestamp: 1553124693\n",
      "  timesteps_since_restore: 1290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 129\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2893 s, 129 iter, 1290000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-31-55\n",
      "  done: false\n",
      "  episode_len_mean: 90.05454545454545\n",
      "  episode_reward_max: 390.4320280901276\n",
      "  episode_reward_mean: 180.48468317390757\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 12770\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.772\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 1300000\n",
      "    num_steps_trained: 1300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3943828344345093\n",
      "      kl: 0.012955784797668457\n",
      "      policy_loss: -0.0006937250727787614\n",
      "      total_loss: 53.47575378417969\n",
      "      vf_explained_var: 0.8249744772911072\n",
      "      vf_loss: 53.47644805908203\n",
      "    sample_time_ms: 17996.941\n",
      "    update_time_ms: 6.077\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.24234158695378\n",
      "  time_since_restore: 2914.451753139496\n",
      "  time_this_iter_s: 21.323026180267334\n",
      "  time_total_s: 2914.451753139496\n",
      "  timestamp: 1553124715\n",
      "  timesteps_since_restore: 1300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1300000\n",
      "  training_iteration: 130\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2914 s, 130 iter, 1300000 ts, 180 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-32-17\n",
      "  done: false\n",
      "  episode_len_mean: 86.64655172413794\n",
      "  episode_reward_max: 390.1067968094178\n",
      "  episode_reward_mean: 161.93526813126243\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 12886\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.773\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 1310000\n",
      "    num_steps_trained: 1310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4057365357875824\n",
      "      kl: 0.009890790097415447\n",
      "      policy_loss: -0.0005033002234995365\n",
      "      total_loss: 60.34440231323242\n",
      "      vf_explained_var: 0.8237398862838745\n",
      "      vf_loss: 60.34490203857422\n",
      "    sample_time_ms: 17990.595\n",
      "    update_time_ms: 6.042\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.96763406563122\n",
      "  time_since_restore: 2936.698583126068\n",
      "  time_this_iter_s: 22.246829986572266\n",
      "  time_total_s: 2936.698583126068\n",
      "  timestamp: 1553124737\n",
      "  timesteps_since_restore: 1310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1310000\n",
      "  training_iteration: 131\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2936 s, 131 iter, 1310000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-32-39\n",
      "  done: false\n",
      "  episode_len_mean: 91.87037037037037\n",
      "  episode_reward_max: 383.7754771383854\n",
      "  episode_reward_mean: 201.92382691507666\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 12994\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.253\n",
      "    load_time_ms: 1.714\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.37772247195243835\n",
      "      kl: 0.012094354256987572\n",
      "      policy_loss: -0.001537817413918674\n",
      "      total_loss: 47.37361526489258\n",
      "      vf_explained_var: 0.8225683569908142\n",
      "      vf_loss: 47.37514877319336\n",
      "    sample_time_ms: 17961.544\n",
      "    update_time_ms: 5.908\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 100.96191345753833\n",
      "  time_since_restore: 2958.419305086136\n",
      "  time_this_iter_s: 21.72072196006775\n",
      "  time_total_s: 2958.419305086136\n",
      "  timestamp: 1553124759\n",
      "  timesteps_since_restore: 1320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 132\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2958 s, 132 iter, 1320000 ts, 202 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-33-01\n",
      "  done: false\n",
      "  episode_len_mean: 87.23275862068965\n",
      "  episode_reward_max: 385.19129476422955\n",
      "  episode_reward_mean: 162.59115345899713\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 13110\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.41\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 1330000\n",
      "    num_steps_trained: 1330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3623662292957306\n",
      "      kl: 0.011895635165274143\n",
      "      policy_loss: -0.0009512538090348244\n",
      "      total_loss: 44.12588119506836\n",
      "      vf_explained_var: 0.8748528957366943\n",
      "      vf_loss: 44.126834869384766\n",
      "    sample_time_ms: 18011.191\n",
      "    update_time_ms: 5.918\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.29557672949856\n",
      "  time_since_restore: 2980.496312379837\n",
      "  time_this_iter_s: 22.077007293701172\n",
      "  time_total_s: 2980.496312379837\n",
      "  timestamp: 1553124781\n",
      "  timesteps_since_restore: 1330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1330000\n",
      "  training_iteration: 133\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 2980 s, 133 iter, 1330000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-33-23\n",
      "  done: false\n",
      "  episode_len_mean: 83.20833333333333\n",
      "  episode_reward_max: 382.70095395537896\n",
      "  episode_reward_mean: 134.5505160137124\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 13230\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.555\n",
      "    load_time_ms: 1.764\n",
      "    num_steps_sampled: 1340000\n",
      "    num_steps_trained: 1340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3331947922706604\n",
      "      kl: 0.015295514836907387\n",
      "      policy_loss: 0.001447478192858398\n",
      "      total_loss: 65.96755981445312\n",
      "      vf_explained_var: 0.8268751502037048\n",
      "      vf_loss: 65.96611785888672\n",
      "    sample_time_ms: 18043.35\n",
      "    update_time_ms: 5.86\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.2752580068562\n",
      "  time_since_restore: 3002.627707719803\n",
      "  time_this_iter_s: 22.13139533996582\n",
      "  time_total_s: 3002.627707719803\n",
      "  timestamp: 1553124803\n",
      "  timesteps_since_restore: 1340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1340000\n",
      "  training_iteration: 134\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3002 s, 134 iter, 1340000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-33-45\n",
      "  done: false\n",
      "  episode_len_mean: 80.31451612903226\n",
      "  episode_reward_max: 386.8302535125519\n",
      "  episode_reward_mean: 116.10139911241288\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 13354\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.185\n",
      "    load_time_ms: 1.807\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.31670480966567993\n",
      "      kl: 0.008678601123392582\n",
      "      policy_loss: 0.0009368711616843939\n",
      "      total_loss: 54.040489196777344\n",
      "      vf_explained_var: 0.8672546148300171\n",
      "      vf_loss: 54.03955078125\n",
      "    sample_time_ms: 18072.987\n",
      "    update_time_ms: 6.387\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.05069955620645\n",
      "  time_since_restore: 3024.409387111664\n",
      "  time_this_iter_s: 21.781679391860962\n",
      "  time_total_s: 3024.409387111664\n",
      "  timestamp: 1553124825\n",
      "  timesteps_since_restore: 1350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 135\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3024 s, 135 iter, 1350000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-34-07\n",
      "  done: false\n",
      "  episode_len_mean: 86.81739130434782\n",
      "  episode_reward_max: 388.97944623309826\n",
      "  episode_reward_mean: 156.9087424272535\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 13469\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.645\n",
      "    load_time_ms: 1.792\n",
      "    num_steps_sampled: 1360000\n",
      "    num_steps_trained: 1360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.34944969415664673\n",
      "      kl: 0.013098735362291336\n",
      "      policy_loss: -0.0005323967197909951\n",
      "      total_loss: 67.21929931640625\n",
      "      vf_explained_var: 0.8081974983215332\n",
      "      vf_loss: 67.21984100341797\n",
      "    sample_time_ms: 18100.557\n",
      "    update_time_ms: 6.382\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.45437121362674\n",
      "  time_since_restore: 3046.2723701000214\n",
      "  time_this_iter_s: 21.862982988357544\n",
      "  time_total_s: 3046.2723701000214\n",
      "  timestamp: 1553124847\n",
      "  timesteps_since_restore: 1360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1360000\n",
      "  training_iteration: 136\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3046 s, 136 iter, 1360000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-34-29\n",
      "  done: false\n",
      "  episode_len_mean: 85.94871794871794\n",
      "  episode_reward_max: 387.5280607560595\n",
      "  episode_reward_mean: 147.92245592885948\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 13586\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.929\n",
      "    load_time_ms: 1.765\n",
      "    num_steps_sampled: 1370000\n",
      "    num_steps_trained: 1370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.36249107122421265\n",
      "      kl: 0.012669854797422886\n",
      "      policy_loss: -0.0018408512696623802\n",
      "      total_loss: 64.2251968383789\n",
      "      vf_explained_var: 0.8251573443412781\n",
      "      vf_loss: 64.22703552246094\n",
      "    sample_time_ms: 18121.463\n",
      "    update_time_ms: 6.352\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 73.96122796442975\n",
      "  time_since_restore: 3068.4324831962585\n",
      "  time_this_iter_s: 22.160113096237183\n",
      "  time_total_s: 3068.4324831962585\n",
      "  timestamp: 1553124869\n",
      "  timesteps_since_restore: 1370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1370000\n",
      "  training_iteration: 137\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3068 s, 137 iter, 1370000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-34-51\n",
      "  done: false\n",
      "  episode_len_mean: 84.93162393162393\n",
      "  episode_reward_max: 386.665639311393\n",
      "  episode_reward_mean: 143.33586411816856\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 13703\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.354\n",
      "    load_time_ms: 1.759\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3197680115699768\n",
      "      kl: 0.01346684992313385\n",
      "      policy_loss: -0.0007270888891071081\n",
      "      total_loss: 45.77507019042969\n",
      "      vf_explained_var: 0.8782943487167358\n",
      "      vf_loss: 45.77579879760742\n",
      "    sample_time_ms: 18192.461\n",
      "    update_time_ms: 5.986\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.66793205908427\n",
      "  time_since_restore: 3090.6684234142303\n",
      "  time_this_iter_s: 22.2359402179718\n",
      "  time_total_s: 3090.6684234142303\n",
      "  timestamp: 1553124891\n",
      "  timesteps_since_restore: 1380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 138\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3090 s, 138 iter, 1380000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-35-13\n",
      "  done: false\n",
      "  episode_len_mean: 93.95327102803738\n",
      "  episode_reward_max: 386.29014119509037\n",
      "  episode_reward_mean: 213.41269398289785\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 13810\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.256\n",
      "    load_time_ms: 1.72\n",
      "    num_steps_sampled: 1390000\n",
      "    num_steps_trained: 1390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3462277352809906\n",
      "      kl: 0.011082827113568783\n",
      "      policy_loss: -0.0025032253470271826\n",
      "      total_loss: 54.02312469482422\n",
      "      vf_explained_var: 0.7886149287223816\n",
      "      vf_loss: 54.0256233215332\n",
      "    sample_time_ms: 18194.953\n",
      "    update_time_ms: 5.543\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 106.70634699144892\n",
      "  time_since_restore: 3112.412517309189\n",
      "  time_this_iter_s: 21.744093894958496\n",
      "  time_total_s: 3112.412517309189\n",
      "  timestamp: 1553124913\n",
      "  timesteps_since_restore: 1390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1390000\n",
      "  training_iteration: 139\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3112 s, 139 iter, 1390000 ts, 213 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-35-35\n",
      "  done: false\n",
      "  episode_len_mean: 87.70175438596492\n",
      "  episode_reward_max: 386.60584996684713\n",
      "  episode_reward_mean: 162.81779636001122\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 13924\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.997\n",
      "    load_time_ms: 1.754\n",
      "    num_steps_sampled: 1400000\n",
      "    num_steps_trained: 1400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.34222227334976196\n",
      "      kl: 0.015080628916621208\n",
      "      policy_loss: 0.00036580616142600775\n",
      "      total_loss: 64.83197021484375\n",
      "      vf_explained_var: 0.8043763637542725\n",
      "      vf_loss: 64.83160400390625\n",
      "    sample_time_ms: 18189.866\n",
      "    update_time_ms: 5.394\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.40889818000562\n",
      "  time_since_restore: 3133.6616225242615\n",
      "  time_this_iter_s: 21.249105215072632\n",
      "  time_total_s: 3133.6616225242615\n",
      "  timestamp: 1553124935\n",
      "  timesteps_since_restore: 1400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1400000\n",
      "  training_iteration: 140\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3133 s, 140 iter, 1400000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-35-56\n",
      "  done: false\n",
      "  episode_len_mean: 89.20535714285714\n",
      "  episode_reward_max: 384.77452459371983\n",
      "  episode_reward_mean: 181.89291368914238\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 14036\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.322\n",
      "    load_time_ms: 1.675\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3071993589401245\n",
      "      kl: 0.009925353340804577\n",
      "      policy_loss: 0.001075613428838551\n",
      "      total_loss: 58.18415069580078\n",
      "      vf_explained_var: 0.8099208474159241\n",
      "      vf_loss: 58.18307876586914\n",
      "    sample_time_ms: 18151.45\n",
      "    update_time_ms: 5.508\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.94645684457116\n",
      "  time_since_restore: 3155.516692876816\n",
      "  time_this_iter_s: 21.85507035255432\n",
      "  time_total_s: 3155.516692876816\n",
      "  timestamp: 1553124956\n",
      "  timesteps_since_restore: 1410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 141\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3155 s, 141 iter, 1410000 ts, 182 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-36-18\n",
      "  done: false\n",
      "  episode_len_mean: 80.01612903225806\n",
      "  episode_reward_max: 387.03853698667774\n",
      "  episode_reward_mean: 112.9932245868158\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 14160\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.641\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 1420000\n",
      "    num_steps_trained: 1420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.28491827845573425\n",
      "      kl: 0.010304498486220837\n",
      "      policy_loss: -0.00024131475947797298\n",
      "      total_loss: 63.87560272216797\n",
      "      vf_explained_var: 0.8437271118164062\n",
      "      vf_loss: 63.87583923339844\n",
      "    sample_time_ms: 18162.264\n",
      "    update_time_ms: 5.581\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.49661229340789\n",
      "  time_since_restore: 3177.3585777282715\n",
      "  time_this_iter_s: 21.84188485145569\n",
      "  time_total_s: 3177.3585777282715\n",
      "  timestamp: 1553124978\n",
      "  timesteps_since_restore: 1420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1420000\n",
      "  training_iteration: 142\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3177 s, 142 iter, 1420000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-36-40\n",
      "  done: false\n",
      "  episode_len_mean: 88.85964912280701\n",
      "  episode_reward_max: 387.21542683044765\n",
      "  episode_reward_mean: 176.15357425805377\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 14274\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.649\n",
      "    load_time_ms: 1.692\n",
      "    num_steps_sampled: 1430000\n",
      "    num_steps_trained: 1430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3253122568130493\n",
      "      kl: 0.010327339172363281\n",
      "      policy_loss: -0.0010898587061092257\n",
      "      total_loss: 36.86629104614258\n",
      "      vf_explained_var: 0.8859978914260864\n",
      "      vf_loss: 36.86738204956055\n",
      "    sample_time_ms: 18085.897\n",
      "    update_time_ms: 5.727\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.07678712902687\n",
      "  time_since_restore: 3198.737913608551\n",
      "  time_this_iter_s: 21.37933588027954\n",
      "  time_total_s: 3198.737913608551\n",
      "  timestamp: 1553125000\n",
      "  timesteps_since_restore: 1430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1430000\n",
      "  training_iteration: 143\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3198 s, 143 iter, 1430000 ts, 176 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-37-01\n",
      "  done: false\n",
      "  episode_len_mean: 89.48648648648648\n",
      "  episode_reward_max: 387.3245447651339\n",
      "  episode_reward_mean: 179.19459645177272\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 14385\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.061\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.31316038966178894\n",
      "      kl: 0.013663212768733501\n",
      "      policy_loss: -5.146928015165031e-05\n",
      "      total_loss: 52.34783935546875\n",
      "      vf_explained_var: 0.8304089307785034\n",
      "      vf_loss: 52.3478889465332\n",
      "    sample_time_ms: 18030.423\n",
      "    update_time_ms: 5.82\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.59729822588638\n",
      "  time_since_restore: 3220.3478972911835\n",
      "  time_this_iter_s: 21.609983682632446\n",
      "  time_total_s: 3220.3478972911835\n",
      "  timestamp: 1553125021\n",
      "  timesteps_since_restore: 1440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 144\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3220 s, 144 iter, 1440000 ts, 179 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-37-23\n",
      "  done: false\n",
      "  episode_len_mean: 85.26495726495726\n",
      "  episode_reward_max: 383.5398118973635\n",
      "  episode_reward_mean: 148.95791321183\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 14502\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.056\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 1450000\n",
      "    num_steps_trained: 1450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2833167612552643\n",
      "      kl: 0.018522687256336212\n",
      "      policy_loss: -0.0004277693515177816\n",
      "      total_loss: 62.28427505493164\n",
      "      vf_explained_var: 0.8246981501579285\n",
      "      vf_loss: 62.284706115722656\n",
      "    sample_time_ms: 18030.659\n",
      "    update_time_ms: 5.256\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.47895660591502\n",
      "  time_since_restore: 3242.134429216385\n",
      "  time_this_iter_s: 21.786531925201416\n",
      "  time_total_s: 3242.134429216385\n",
      "  timestamp: 1553125043\n",
      "  timesteps_since_restore: 1450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1450000\n",
      "  training_iteration: 145\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3242 s, 145 iter, 1450000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-37-46\n",
      "  done: false\n",
      "  episode_len_mean: 89.62162162162163\n",
      "  episode_reward_max: 385.7008976448877\n",
      "  episode_reward_mean: 184.28841263840437\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 14613\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.728\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 1460000\n",
      "    num_steps_trained: 1460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2755805253982544\n",
      "      kl: 0.012713412754237652\n",
      "      policy_loss: -8.119145786622539e-05\n",
      "      total_loss: 42.61740493774414\n",
      "      vf_explained_var: 0.8595836162567139\n",
      "      vf_loss: 42.61748504638672\n",
      "    sample_time_ms: 18075.467\n",
      "    update_time_ms: 5.338\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.14420631920217\n",
      "  time_since_restore: 3264.4304842948914\n",
      "  time_this_iter_s: 22.29605507850647\n",
      "  time_total_s: 3264.4304842948914\n",
      "  timestamp: 1553125066\n",
      "  timesteps_since_restore: 1460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1460000\n",
      "  training_iteration: 146\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3264 s, 146 iter, 1460000 ts, 184 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-38-08\n",
      "  done: false\n",
      "  episode_len_mean: 88.84070796460178\n",
      "  episode_reward_max: 386.62216444523807\n",
      "  episode_reward_mean: 178.66097789170522\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 14726\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.238\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2665768563747406\n",
      "      kl: 0.014785785228013992\n",
      "      policy_loss: 0.0010585490381345153\n",
      "      total_loss: 41.5031623840332\n",
      "      vf_explained_var: 0.8646948337554932\n",
      "      vf_loss: 41.502098083496094\n",
      "    sample_time_ms: 18063.457\n",
      "    update_time_ms: 5.263\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.3304889458526\n",
      "  time_since_restore: 3286.5457577705383\n",
      "  time_this_iter_s: 22.115273475646973\n",
      "  time_total_s: 3286.5457577705383\n",
      "  timestamp: 1553125088\n",
      "  timesteps_since_restore: 1470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 147\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3286 s, 147 iter, 1470000 ts, 179 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 81.02439024390245\n",
      "  episode_reward_max: 380.09900465792816\n",
      "  episode_reward_mean: 123.11261134307848\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 14849\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.546\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 1480000\n",
      "    num_steps_trained: 1480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.21141360700130463\n",
      "      kl: 0.01353718526661396\n",
      "      policy_loss: 0.0007784110493957996\n",
      "      total_loss: 53.03038787841797\n",
      "      vf_explained_var: 0.8657026886940002\n",
      "      vf_loss: 53.02960968017578\n",
      "    sample_time_ms: 18069.705\n",
      "    update_time_ms: 5.373\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.55630567153924\n",
      "  time_since_restore: 3308.8570516109467\n",
      "  time_this_iter_s: 22.311293840408325\n",
      "  time_total_s: 3308.8570516109467\n",
      "  timestamp: 1553125110\n",
      "  timesteps_since_restore: 1480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1480000\n",
      "  training_iteration: 148\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3308 s, 148 iter, 1480000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-38-52\n",
      "  done: false\n",
      "  episode_len_mean: 94.10280373831776\n",
      "  episode_reward_max: 383.59828469895314\n",
      "  episode_reward_mean: 219.55073919877225\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 14956\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.195\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 1490000\n",
      "    num_steps_trained: 1490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2355978786945343\n",
      "      kl: 0.01122682448476553\n",
      "      policy_loss: -0.0004172099579591304\n",
      "      total_loss: 30.04288101196289\n",
      "      vf_explained_var: 0.8721911907196045\n",
      "      vf_loss: 30.043296813964844\n",
      "    sample_time_ms: 18109.048\n",
      "    update_time_ms: 5.262\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 109.77536959938612\n",
      "  time_since_restore: 3330.828640937805\n",
      "  time_this_iter_s: 21.97158932685852\n",
      "  time_total_s: 3330.828640937805\n",
      "  timestamp: 1553125132\n",
      "  timesteps_since_restore: 1490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1490000\n",
      "  training_iteration: 149\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3330 s, 149 iter, 1490000 ts, 220 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-39-14\n",
      "  done: false\n",
      "  episode_len_mean: 83.65\n",
      "  episode_reward_max: 384.14480742651114\n",
      "  episode_reward_mean: 142.69256569416686\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 15076\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.95\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.22938773036003113\n",
      "      kl: 0.012976661324501038\n",
      "      policy_loss: 0.00026945004356093705\n",
      "      total_loss: 48.07523727416992\n",
      "      vf_explained_var: 0.8677080869674683\n",
      "      vf_loss: 48.07497024536133\n",
      "    sample_time_ms: 18201.444\n",
      "    update_time_ms: 5.821\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.34628284708342\n",
      "  time_since_restore: 3353.03279709816\n",
      "  time_this_iter_s: 22.204156160354614\n",
      "  time_total_s: 3353.03279709816\n",
      "  timestamp: 1553125154\n",
      "  timesteps_since_restore: 1500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 150\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3353 s, 150 iter, 1500000 ts, 143 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-39-36\n",
      "  done: false\n",
      "  episode_len_mean: 86.40517241379311\n",
      "  episode_reward_max: 384.81894437214737\n",
      "  episode_reward_mean: 162.05373396988725\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 15192\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.348\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 1510000\n",
      "    num_steps_trained: 1510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.21290794014930725\n",
      "      kl: 0.015954123809933662\n",
      "      policy_loss: -0.0006059209699742496\n",
      "      total_loss: 59.29518508911133\n",
      "      vf_explained_var: 0.8273982405662537\n",
      "      vf_loss: 59.29578399658203\n",
      "    sample_time_ms: 18165.125\n",
      "    update_time_ms: 5.749\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.02686698494364\n",
      "  time_since_restore: 3374.5293905735016\n",
      "  time_this_iter_s: 21.496593475341797\n",
      "  time_total_s: 3374.5293905735016\n",
      "  timestamp: 1553125176\n",
      "  timesteps_since_restore: 1510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1510000\n",
      "  training_iteration: 151\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3374 s, 151 iter, 1510000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-39-58\n",
      "  done: false\n",
      "  episode_len_mean: 86.37391304347825\n",
      "  episode_reward_max: 386.47745197515235\n",
      "  episode_reward_mean: 166.6963876685168\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 15307\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.286\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 1520000\n",
      "    num_steps_trained: 1520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1874101161956787\n",
      "      kl: 0.02020837925374508\n",
      "      policy_loss: -0.001240903395228088\n",
      "      total_loss: 29.83407211303711\n",
      "      vf_explained_var: 0.9114373326301575\n",
      "      vf_loss: 29.83531379699707\n",
      "    sample_time_ms: 18240.84\n",
      "    update_time_ms: 5.814\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.34819383425837\n",
      "  time_since_restore: 3397.1075649261475\n",
      "  time_this_iter_s: 22.578174352645874\n",
      "  time_total_s: 3397.1075649261475\n",
      "  timestamp: 1553125198\n",
      "  timesteps_since_restore: 1520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1520000\n",
      "  training_iteration: 152\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3397 s, 152 iter, 1520000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-40-21\n",
      "  done: false\n",
      "  episode_len_mean: 90.009009009009\n",
      "  episode_reward_max: 381.27533451929065\n",
      "  episode_reward_mean: 189.2199365777669\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 15418\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.723\n",
      "    load_time_ms: 1.445\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.16289843618869781\n",
      "      kl: 0.0170635636895895\n",
      "      policy_loss: -0.0005942529533058405\n",
      "      total_loss: 39.616424560546875\n",
      "      vf_explained_var: 0.8702728152275085\n",
      "      vf_loss: 39.61701583862305\n",
      "    sample_time_ms: 18346.537\n",
      "    update_time_ms: 5.82\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.60996828888344\n",
      "  time_since_restore: 3419.4455296993256\n",
      "  time_this_iter_s: 22.3379647731781\n",
      "  time_total_s: 3419.4455296993256\n",
      "  timestamp: 1553125221\n",
      "  timesteps_since_restore: 1530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 153\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3419 s, 153 iter, 1530000 ts, 189 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-40-43\n",
      "  done: false\n",
      "  episode_len_mean: 89.46428571428571\n",
      "  episode_reward_max: 386.36508716406706\n",
      "  episode_reward_mean: 183.46738982112228\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 15530\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.969\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 1540000\n",
      "    num_steps_trained: 1540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.16616982221603394\n",
      "      kl: 0.017941566184163094\n",
      "      policy_loss: 0.0024452991783618927\n",
      "      total_loss: 49.12553787231445\n",
      "      vf_explained_var: 0.833115816116333\n",
      "      vf_loss: 49.12309265136719\n",
      "    sample_time_ms: 18386.194\n",
      "    update_time_ms: 5.795\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.73369491056113\n",
      "  time_since_restore: 3441.6117086410522\n",
      "  time_this_iter_s: 22.166178941726685\n",
      "  time_total_s: 3441.6117086410522\n",
      "  timestamp: 1553125243\n",
      "  timesteps_since_restore: 1540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1540000\n",
      "  training_iteration: 154\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3441 s, 154 iter, 1540000 ts, 183 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-41-05\n",
      "  done: false\n",
      "  episode_len_mean: 92.4862385321101\n",
      "  episode_reward_max: 382.15564162743976\n",
      "  episode_reward_mean: 208.05928435182372\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 15639\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.873\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 1550000\n",
      "    num_steps_trained: 1550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.15492306649684906\n",
      "      kl: 0.014384644106030464\n",
      "      policy_loss: -0.0001043004886014387\n",
      "      total_loss: 61.90680694580078\n",
      "      vf_explained_var: 0.7621403336524963\n",
      "      vf_loss: 61.90691375732422\n",
      "    sample_time_ms: 18440.341\n",
      "    update_time_ms: 5.848\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 104.02964217591187\n",
      "  time_since_restore: 3463.930123567581\n",
      "  time_this_iter_s: 22.31841492652893\n",
      "  time_total_s: 3463.930123567581\n",
      "  timestamp: 1553125265\n",
      "  timesteps_since_restore: 1550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1550000\n",
      "  training_iteration: 155\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3463 s, 155 iter, 1550000 ts, 208 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-41-28\n",
      "  done: false\n",
      "  episode_len_mean: 92.03703703703704\n",
      "  episode_reward_max: 382.3378179566991\n",
      "  episode_reward_mean: 203.7535643087757\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 15747\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.605\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.16775673627853394\n",
      "      kl: 0.013049151748418808\n",
      "      policy_loss: -0.00020382343791425228\n",
      "      total_loss: 56.46211624145508\n",
      "      vf_explained_var: 0.7924855351448059\n",
      "      vf_loss: 56.46232223510742\n",
      "    sample_time_ms: 18423.68\n",
      "    update_time_ms: 5.78\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 101.87678215438784\n",
      "  time_since_restore: 3486.082745552063\n",
      "  time_this_iter_s: 22.15262198448181\n",
      "  time_total_s: 3486.082745552063\n",
      "  timestamp: 1553125288\n",
      "  timesteps_since_restore: 1560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 156\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3486 s, 156 iter, 1560000 ts, 204 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-41-50\n",
      "  done: false\n",
      "  episode_len_mean: 84.14285714285714\n",
      "  episode_reward_max: 385.74377721144225\n",
      "  episode_reward_mean: 145.89407039754207\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 15866\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.614\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 1570000\n",
      "    num_steps_trained: 1570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12971538305282593\n",
      "      kl: 0.013961429707705975\n",
      "      policy_loss: 0.0005660223541781306\n",
      "      total_loss: 55.14868927001953\n",
      "      vf_explained_var: 0.8444697260856628\n",
      "      vf_loss: 55.14811706542969\n",
      "    sample_time_ms: 18431.998\n",
      "    update_time_ms: 5.807\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.94703519877099\n",
      "  time_since_restore: 3508.1627428531647\n",
      "  time_this_iter_s: 22.079997301101685\n",
      "  time_total_s: 3508.1627428531647\n",
      "  timestamp: 1553125310\n",
      "  timesteps_since_restore: 1570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1570000\n",
      "  training_iteration: 157\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3508 s, 157 iter, 1570000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-42-12\n",
      "  done: false\n",
      "  episode_len_mean: 88.24778761061947\n",
      "  episode_reward_max: 382.28295147868994\n",
      "  episode_reward_mean: 174.94222977992328\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 15979\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.859\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 1580000\n",
      "    num_steps_trained: 1580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.13221095502376556\n",
      "      kl: 0.015928898006677628\n",
      "      policy_loss: 0.001351664075627923\n",
      "      total_loss: 51.33613204956055\n",
      "      vf_explained_var: 0.8347038626670837\n",
      "      vf_loss: 51.33477783203125\n",
      "    sample_time_ms: 18435.493\n",
      "    update_time_ms: 5.801\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.47111488996163\n",
      "  time_since_restore: 3530.6036417484283\n",
      "  time_this_iter_s: 22.440898895263672\n",
      "  time_total_s: 3530.6036417484283\n",
      "  timestamp: 1553125332\n",
      "  timesteps_since_restore: 1580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1580000\n",
      "  training_iteration: 158\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3530 s, 158 iter, 1580000 ts, 175 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-42-34\n",
      "  done: false\n",
      "  episode_len_mean: 93.27102803738318\n",
      "  episode_reward_max: 384.7725217209544\n",
      "  episode_reward_mean: 207.7691491301819\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 16086\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.478\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12187343090772629\n",
      "      kl: 0.03741568699479103\n",
      "      policy_loss: 5.888098166906275e-05\n",
      "      total_loss: 53.58403396606445\n",
      "      vf_explained_var: 0.8075692653656006\n",
      "      vf_loss: 53.5839729309082\n",
      "    sample_time_ms: 18407.628\n",
      "    update_time_ms: 5.718\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 103.88457456509094\n",
      "  time_since_restore: 3552.2937076091766\n",
      "  time_this_iter_s: 21.69006586074829\n",
      "  time_total_s: 3552.2937076091766\n",
      "  timestamp: 1553125354\n",
      "  timesteps_since_restore: 1590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 159\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3552 s, 159 iter, 1590000 ts, 208 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 88.25438596491227\n",
      "  episode_reward_max: 385.17746814856537\n",
      "  episode_reward_mean: 173.86851701904476\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 16200\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.813\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 1600000\n",
      "    num_steps_trained: 1600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.10674522817134857\n",
      "      kl: 0.015259125269949436\n",
      "      policy_loss: 5.431473255157471e-05\n",
      "      total_loss: 61.7587890625\n",
      "      vf_explained_var: 0.8008998036384583\n",
      "      vf_loss: 61.75872802734375\n",
      "    sample_time_ms: 18396.27\n",
      "    update_time_ms: 5.179\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.9342585095224\n",
      "  time_since_restore: 3574.343154191971\n",
      "  time_this_iter_s: 22.04944658279419\n",
      "  time_total_s: 3574.343154191971\n",
      "  timestamp: 1553125376\n",
      "  timesteps_since_restore: 1600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1600000\n",
      "  training_iteration: 160\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3574 s, 160 iter, 1600000 ts, 174 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-43-18\n",
      "  done: false\n",
      "  episode_len_mean: 84.82905982905983\n",
      "  episode_reward_max: 385.3947178513986\n",
      "  episode_reward_mean: 149.5135420189055\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 16317\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.792\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 1610000\n",
      "    num_steps_trained: 1610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06760164350271225\n",
      "      kl: 0.013412260450422764\n",
      "      policy_loss: -0.0006581139750778675\n",
      "      total_loss: 56.24802780151367\n",
      "      vf_explained_var: 0.8402230739593506\n",
      "      vf_loss: 56.24869155883789\n",
      "    sample_time_ms: 18458.527\n",
      "    update_time_ms: 5.288\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.75677100945276\n",
      "  time_since_restore: 3596.4617755413055\n",
      "  time_this_iter_s: 22.118621349334717\n",
      "  time_total_s: 3596.4617755413055\n",
      "  timestamp: 1553125398\n",
      "  timesteps_since_restore: 1610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1610000\n",
      "  training_iteration: 161\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3596 s, 161 iter, 1610000 ts, 150 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-43-40\n",
      "  done: false\n",
      "  episode_len_mean: 84.05882352941177\n",
      "  episode_reward_max: 385.30959153042494\n",
      "  episode_reward_mean: 145.86852316633255\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 16436\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.252\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.041839953511953354\n",
      "      kl: 0.017743756994605064\n",
      "      policy_loss: 0.0008092239149846137\n",
      "      total_loss: 52.078704833984375\n",
      "      vf_explained_var: 0.8569685816764832\n",
      "      vf_loss: 52.07789611816406\n",
      "    sample_time_ms: 18386.25\n",
      "    update_time_ms: 5.225\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.93426158316626\n",
      "  time_since_restore: 3618.5132296085358\n",
      "  time_this_iter_s: 22.051454067230225\n",
      "  time_total_s: 3618.5132296085358\n",
      "  timestamp: 1553125420\n",
      "  timesteps_since_restore: 1620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 162\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3618 s, 162 iter, 1620000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-44-02\n",
      "  done: false\n",
      "  episode_len_mean: 95.19811320754717\n",
      "  episode_reward_max: 387.91924922069535\n",
      "  episode_reward_mean: 225.77242307467992\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 16542\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.157\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 1630000\n",
      "    num_steps_trained: 1630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.07665280252695084\n",
      "      kl: 0.013622797094285488\n",
      "      policy_loss: 0.0032224564347416162\n",
      "      total_loss: 25.638731002807617\n",
      "      vf_explained_var: 0.8992773294448853\n",
      "      vf_loss: 25.635509490966797\n",
      "    sample_time_ms: 18369.426\n",
      "    update_time_ms: 5.191\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 112.88621153733996\n",
      "  time_since_restore: 3640.6888616085052\n",
      "  time_this_iter_s: 22.175631999969482\n",
      "  time_total_s: 3640.6888616085052\n",
      "  timestamp: 1553125442\n",
      "  timesteps_since_restore: 1630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1630000\n",
      "  training_iteration: 163\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3640 s, 163 iter, 1630000 ts, 226 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-44-25\n",
      "  done: false\n",
      "  episode_len_mean: 86.77391304347826\n",
      "  episode_reward_max: 385.6090562405727\n",
      "  episode_reward_mean: 163.2909875637761\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 16657\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.486\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 1640000\n",
      "    num_steps_trained: 1640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06370538473129272\n",
      "      kl: 0.017282666638493538\n",
      "      policy_loss: 0.0014576283283531666\n",
      "      total_loss: 46.84059524536133\n",
      "      vf_explained_var: 0.8612444996833801\n",
      "      vf_loss: 46.83913803100586\n",
      "    sample_time_ms: 18410.156\n",
      "    update_time_ms: 5.178\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.64549378188802\n",
      "  time_since_restore: 3663.0775451660156\n",
      "  time_this_iter_s: 22.388683557510376\n",
      "  time_total_s: 3663.0775451660156\n",
      "  timestamp: 1553125465\n",
      "  timesteps_since_restore: 1640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1640000\n",
      "  training_iteration: 164\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3663 s, 164 iter, 1640000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-44-47\n",
      "  done: false\n",
      "  episode_len_mean: 90.41818181818182\n",
      "  episode_reward_max: 385.7466237000639\n",
      "  episode_reward_mean: 190.61449804609342\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 16767\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.268\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.056939199566841125\n",
      "      kl: 0.023274706676602364\n",
      "      policy_loss: 0.00038118698284961283\n",
      "      total_loss: 57.671905517578125\n",
      "      vf_explained_var: 0.8031933307647705\n",
      "      vf_loss: 57.67152404785156\n",
      "    sample_time_ms: 18367.827\n",
      "    update_time_ms: 5.182\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.3072490230467\n",
      "  time_since_restore: 3684.9689128398895\n",
      "  time_this_iter_s: 21.8913676738739\n",
      "  time_total_s: 3684.9689128398895\n",
      "  timestamp: 1553125487\n",
      "  timesteps_since_restore: 1650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 165\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3684 s, 165 iter, 1650000 ts, 191 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-45-08\n",
      "  done: false\n",
      "  episode_len_mean: 85.62931034482759\n",
      "  episode_reward_max: 385.5114748032588\n",
      "  episode_reward_mean: 157.3879455102015\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 16883\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.378\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 1660000\n",
      "    num_steps_trained: 1660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.043454043567180634\n",
      "      kl: 0.014864904806017876\n",
      "      policy_loss: 0.0012518396833911538\n",
      "      total_loss: 67.66134643554688\n",
      "      vf_explained_var: 0.7985979914665222\n",
      "      vf_loss: 67.66008758544922\n",
      "    sample_time_ms: 18306.136\n",
      "    update_time_ms: 5.359\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.69397275510073\n",
      "  time_since_restore: 3706.471301317215\n",
      "  time_this_iter_s: 21.50238847732544\n",
      "  time_total_s: 3706.471301317215\n",
      "  timestamp: 1553125508\n",
      "  timesteps_since_restore: 1660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1660000\n",
      "  training_iteration: 166\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3706 s, 166 iter, 1660000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 86.98260869565217\n",
      "  episode_reward_max: 382.2721634670778\n",
      "  episode_reward_mean: 165.46654859755037\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 16998\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.774\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 1670000\n",
      "    num_steps_trained: 1670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.04638485610485077\n",
      "      kl: 0.01417018473148346\n",
      "      policy_loss: 0.00038180412957444787\n",
      "      total_loss: 56.32350540161133\n",
      "      vf_explained_var: 0.8293125629425049\n",
      "      vf_loss: 56.323123931884766\n",
      "    sample_time_ms: 18272.126\n",
      "    update_time_ms: 5.348\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.73327429877517\n",
      "  time_since_restore: 3728.2443850040436\n",
      "  time_this_iter_s: 21.773083686828613\n",
      "  time_total_s: 3728.2443850040436\n",
      "  timestamp: 1553125530\n",
      "  timesteps_since_restore: 1670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1670000\n",
      "  training_iteration: 167\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3728 s, 167 iter, 1670000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-45-52\n",
      "  done: false\n",
      "  episode_len_mean: 85.94915254237289\n",
      "  episode_reward_max: 387.71723605080336\n",
      "  episode_reward_mean: 155.7594457678945\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 17116\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.374\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.05871386453509331\n",
      "      kl: 0.02738032303750515\n",
      "      policy_loss: 0.0017215341795235872\n",
      "      total_loss: 80.53015899658203\n",
      "      vf_explained_var: 0.7688401937484741\n",
      "      vf_loss: 80.5284423828125\n",
      "    sample_time_ms: 18217.143\n",
      "    update_time_ms: 5.119\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.87972288394724\n",
      "  time_since_restore: 3750.020030736923\n",
      "  time_this_iter_s: 21.77564573287964\n",
      "  time_total_s: 3750.020030736923\n",
      "  timestamp: 1553125552\n",
      "  timesteps_since_restore: 1680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 168\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3750 s, 168 iter, 1680000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-46-13\n",
      "  done: false\n",
      "  episode_len_mean: 83.39495798319328\n",
      "  episode_reward_max: 381.0369443331398\n",
      "  episode_reward_mean: 140.42986382858612\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 17235\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.964\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 1690000\n",
      "    num_steps_trained: 1690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.049427907913923264\n",
      "      kl: 0.013218305073678493\n",
      "      policy_loss: 3.800025297095999e-05\n",
      "      total_loss: 69.76400756835938\n",
      "      vf_explained_var: 0.8095168471336365\n",
      "      vf_loss: 69.76398468017578\n",
      "    sample_time_ms: 18182.028\n",
      "    update_time_ms: 5.286\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.21493191429306\n",
      "  time_since_restore: 3771.355884075165\n",
      "  time_this_iter_s: 21.335853338241577\n",
      "  time_total_s: 3771.355884075165\n",
      "  timestamp: 1553125573\n",
      "  timesteps_since_restore: 1690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1690000\n",
      "  training_iteration: 169\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3771 s, 169 iter, 1690000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 90.45945945945945\n",
      "  episode_reward_max: 384.0772401182257\n",
      "  episode_reward_mean: 190.41300217767\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 17346\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.942\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 1700000\n",
      "    num_steps_trained: 1700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08223184198141098\n",
      "      kl: 0.018758755177259445\n",
      "      policy_loss: 0.0003674913023132831\n",
      "      total_loss: 48.19925308227539\n",
      "      vf_explained_var: 0.8336101174354553\n",
      "      vf_loss: 48.19887924194336\n",
      "    sample_time_ms: 18113.601\n",
      "    update_time_ms: 5.442\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.20650108883503\n",
      "  time_since_restore: 3792.7298414707184\n",
      "  time_this_iter_s: 21.37395739555359\n",
      "  time_total_s: 3792.7298414707184\n",
      "  timestamp: 1553125595\n",
      "  timesteps_since_restore: 1700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1700000\n",
      "  training_iteration: 170\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3792 s, 170 iter, 1700000 ts, 190 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-46-56\n",
      "  done: false\n",
      "  episode_len_mean: 86.5304347826087\n",
      "  episode_reward_max: 385.2822330394588\n",
      "  episode_reward_mean: 164.52366952436796\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 17461\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.931\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06422889232635498\n",
      "      kl: 0.01762649603188038\n",
      "      policy_loss: -0.00039684868534095585\n",
      "      total_loss: 56.43276596069336\n",
      "      vf_explained_var: 0.8395621180534363\n",
      "      vf_loss: 56.433162689208984\n",
      "    sample_time_ms: 18054.053\n",
      "    update_time_ms: 5.219\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.26183476218401\n",
      "  time_since_restore: 3814.2301914691925\n",
      "  time_this_iter_s: 21.50034999847412\n",
      "  time_total_s: 3814.2301914691925\n",
      "  timestamp: 1553125616\n",
      "  timesteps_since_restore: 1710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 171\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3814 s, 171 iter, 1710000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-47-18\n",
      "  done: false\n",
      "  episode_len_mean: 78.85039370078741\n",
      "  episode_reward_max: 384.9674342628681\n",
      "  episode_reward_mean: 102.93334408295844\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 17588\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.026\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 1720000\n",
      "    num_steps_trained: 1720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.029487594962120056\n",
      "      kl: 0.023035110905766487\n",
      "      policy_loss: 0.0005029848543927073\n",
      "      total_loss: 65.51000213623047\n",
      "      vf_explained_var: 0.8511810302734375\n",
      "      vf_loss: 65.50950622558594\n",
      "    sample_time_ms: 18010.295\n",
      "    update_time_ms: 5.111\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.466672041479214\n",
      "  time_since_restore: 3835.6621408462524\n",
      "  time_this_iter_s: 21.431949377059937\n",
      "  time_total_s: 3835.6621408462524\n",
      "  timestamp: 1553125638\n",
      "  timesteps_since_restore: 1720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1720000\n",
      "  training_iteration: 172\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3835 s, 172 iter, 1720000 ts, 103 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-47-40\n",
      "  done: false\n",
      "  episode_len_mean: 86.08547008547009\n",
      "  episode_reward_max: 379.46886620730197\n",
      "  episode_reward_mean: 159.0210120824059\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 17705\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.629\n",
      "    load_time_ms: 1.594\n",
      "    num_steps_sampled: 1730000\n",
      "    num_steps_trained: 1730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.038869477808475494\n",
      "      kl: 0.015040295198559761\n",
      "      policy_loss: 0.0007247956236824393\n",
      "      total_loss: 55.066680908203125\n",
      "      vf_explained_var: 0.8417485356330872\n",
      "      vf_loss: 55.065956115722656\n",
      "    sample_time_ms: 17979.84\n",
      "    update_time_ms: 5.204\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.51050604120294\n",
      "  time_since_restore: 3857.821512699127\n",
      "  time_this_iter_s: 22.159371852874756\n",
      "  time_total_s: 3857.821512699127\n",
      "  timestamp: 1553125660\n",
      "  timesteps_since_restore: 1730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1730000\n",
      "  training_iteration: 173\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3857 s, 173 iter, 1730000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-48-02\n",
      "  done: false\n",
      "  episode_len_mean: 84.64102564102564\n",
      "  episode_reward_max: 382.1589919059944\n",
      "  episode_reward_mean: 144.69653913397377\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 17822\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.145\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.02808668650686741\n",
      "      kl: 0.021258030086755753\n",
      "      policy_loss: 0.003782646032050252\n",
      "      total_loss: 67.55037689208984\n",
      "      vf_explained_var: 0.8132315874099731\n",
      "      vf_loss: 67.54660034179688\n",
      "    sample_time_ms: 17946.664\n",
      "    update_time_ms: 5.184\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.34826956698689\n",
      "  time_since_restore: 3879.8740944862366\n",
      "  time_this_iter_s: 22.052581787109375\n",
      "  time_total_s: 3879.8740944862366\n",
      "  timestamp: 1553125682\n",
      "  timesteps_since_restore: 1740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 174\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3879 s, 174 iter, 1740000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-48-24\n",
      "  done: false\n",
      "  episode_len_mean: 84.09166666666667\n",
      "  episode_reward_max: 381.94861221472803\n",
      "  episode_reward_mean: 144.80948685567813\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 17942\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.825\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 1750000\n",
      "    num_steps_trained: 1750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0020742162596434355\n",
      "      kl: 0.020747581496834755\n",
      "      policy_loss: 0.00026780262123793364\n",
      "      total_loss: 54.96720886230469\n",
      "      vf_explained_var: 0.8489604592323303\n",
      "      vf_loss: 54.96694564819336\n",
      "    sample_time_ms: 17929.945\n",
      "    update_time_ms: 5.172\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.40474342783904\n",
      "  time_since_restore: 3901.614461183548\n",
      "  time_this_iter_s: 21.7403666973114\n",
      "  time_total_s: 3901.614461183548\n",
      "  timestamp: 1553125704\n",
      "  timesteps_since_restore: 1750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1750000\n",
      "  training_iteration: 175\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3901 s, 175 iter, 1750000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-48-46\n",
      "  done: false\n",
      "  episode_len_mean: 91.25925925925925\n",
      "  episode_reward_max: 381.0736152927775\n",
      "  episode_reward_mean: 195.57130037931415\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 18050\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.434\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 1760000\n",
      "    num_steps_trained: 1760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0057698143646121025\n",
      "      kl: 0.021634049713611603\n",
      "      policy_loss: 0.0007565789273940027\n",
      "      total_loss: 29.769018173217773\n",
      "      vf_explained_var: 0.8946046233177185\n",
      "      vf_loss: 29.768260955810547\n",
      "    sample_time_ms: 17955.212\n",
      "    update_time_ms: 5.579\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.78565018965708\n",
      "  time_since_restore: 3923.37491607666\n",
      "  time_this_iter_s: 21.760454893112183\n",
      "  time_total_s: 3923.37491607666\n",
      "  timestamp: 1553125726\n",
      "  timesteps_since_restore: 1760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1760000\n",
      "  training_iteration: 176\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3923 s, 176 iter, 1760000 ts, 196 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-49-08\n",
      "  done: false\n",
      "  episode_len_mean: 88.60526315789474\n",
      "  episode_reward_max: 384.5661175739466\n",
      "  episode_reward_mean: 176.81945031203523\n",
      "  episode_reward_min: -160.5193269718422\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 18164\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.203\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.007706657517701387\n",
      "      kl: 0.03803069889545441\n",
      "      policy_loss: 0.003487026784569025\n",
      "      total_loss: 58.387840270996094\n",
      "      vf_explained_var: 0.8137022852897644\n",
      "      vf_loss: 58.38435363769531\n",
      "    sample_time_ms: 17997.714\n",
      "    update_time_ms: 5.574\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.40972515601761\n",
      "  time_since_restore: 3945.5710463523865\n",
      "  time_this_iter_s: 22.19613027572632\n",
      "  time_total_s: 3945.5710463523865\n",
      "  timestamp: 1553125748\n",
      "  timesteps_since_restore: 1770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 177\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3945 s, 177 iter, 1770000 ts, 177 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-49-30\n",
      "  done: false\n",
      "  episode_len_mean: 76.09160305343511\n",
      "  episode_reward_max: 382.56715855499726\n",
      "  episode_reward_mean: 86.03142326815956\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 18295\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.289\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 1780000\n",
      "    num_steps_trained: 1780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.06098286807537079\n",
      "      kl: 0.018603438511490822\n",
      "      policy_loss: 0.0012524708872660995\n",
      "      total_loss: 81.12871551513672\n",
      "      vf_explained_var: 0.8263226747512817\n",
      "      vf_loss: 81.12745666503906\n",
      "    sample_time_ms: 18002.139\n",
      "    update_time_ms: 5.629\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.015711634079764\n",
      "  time_since_restore: 3967.3902723789215\n",
      "  time_this_iter_s: 21.819226026535034\n",
      "  time_total_s: 3967.3902723789215\n",
      "  timestamp: 1553125770\n",
      "  timesteps_since_restore: 1780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1780000\n",
      "  training_iteration: 178\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3967 s, 178 iter, 1780000 ts, 86 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 82.58677685950413\n",
      "  episode_reward_max: 382.8260885745653\n",
      "  episode_reward_mean: 128.79411562541927\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 18416\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.905\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 1790000\n",
      "    num_steps_trained: 1790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.04665270447731018\n",
      "      kl: 0.010391871444880962\n",
      "      policy_loss: -0.000711002794560045\n",
      "      total_loss: 60.502628326416016\n",
      "      vf_explained_var: 0.8415335416793823\n",
      "      vf_loss: 60.50334167480469\n",
      "    sample_time_ms: 18065.602\n",
      "    update_time_ms: 5.557\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.39705781270963\n",
      "  time_since_restore: 3989.3743782043457\n",
      "  time_this_iter_s: 21.984105825424194\n",
      "  time_total_s: 3989.3743782043457\n",
      "  timestamp: 1553125792\n",
      "  timesteps_since_restore: 1790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1790000\n",
      "  training_iteration: 179\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 3989 s, 179 iter, 1790000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-50-14\n",
      "  done: false\n",
      "  episode_len_mean: 85.33050847457628\n",
      "  episode_reward_max: 384.42688248436224\n",
      "  episode_reward_mean: 152.91660611620105\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 18534\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.221\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.048675816506147385\n",
      "      kl: 0.01422864943742752\n",
      "      policy_loss: 0.0009332458721473813\n",
      "      total_loss: 53.08457946777344\n",
      "      vf_explained_var: 0.852452278137207\n",
      "      vf_loss: 53.083641052246094\n",
      "    sample_time_ms: 18137.724\n",
      "    update_time_ms: 5.473\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.45830305810051\n",
      "  time_since_restore: 4011.462771177292\n",
      "  time_this_iter_s: 22.088392972946167\n",
      "  time_total_s: 4011.462771177292\n",
      "  timestamp: 1553125814\n",
      "  timesteps_since_restore: 1800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 180\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4011 s, 180 iter, 1800000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-50-36\n",
      "  done: false\n",
      "  episode_len_mean: 79.448\n",
      "  episode_reward_max: 384.2938280514148\n",
      "  episode_reward_mean: 111.47812342054898\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 18659\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.906\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 1810000\n",
      "    num_steps_trained: 1810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10622259229421616\n",
      "      kl: 0.019577888771891594\n",
      "      policy_loss: -0.00031061508343555033\n",
      "      total_loss: 78.71290588378906\n",
      "      vf_explained_var: 0.8146172761917114\n",
      "      vf_loss: 78.71321868896484\n",
      "    sample_time_ms: 18159.106\n",
      "    update_time_ms: 5.601\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.7390617102745\n",
      "  time_since_restore: 4033.185882091522\n",
      "  time_this_iter_s: 21.723110914230347\n",
      "  time_total_s: 4033.185882091522\n",
      "  timestamp: 1553125836\n",
      "  timesteps_since_restore: 1810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1810000\n",
      "  training_iteration: 181\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4033 s, 181 iter, 1810000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-50-57\n",
      "  done: false\n",
      "  episode_len_mean: 87.16666666666667\n",
      "  episode_reward_max: 386.48070996790835\n",
      "  episode_reward_mean: 165.41031280544385\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 18773\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.61\n",
      "    load_time_ms: 1.631\n",
      "    num_steps_sampled: 1820000\n",
      "    num_steps_trained: 1820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10579227656126022\n",
      "      kl: 0.02301325462758541\n",
      "      policy_loss: 0.0015190303092822433\n",
      "      total_loss: 48.42182922363281\n",
      "      vf_explained_var: 0.856736421585083\n",
      "      vf_loss: 48.420310974121094\n",
      "    sample_time_ms: 18181.905\n",
      "    update_time_ms: 5.691\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.70515640272193\n",
      "  time_since_restore: 4054.813187122345\n",
      "  time_this_iter_s: 21.627305030822754\n",
      "  time_total_s: 4054.813187122345\n",
      "  timestamp: 1553125857\n",
      "  timesteps_since_restore: 1820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1820000\n",
      "  training_iteration: 182\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4054 s, 182 iter, 1820000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-51-19\n",
      "  done: false\n",
      "  episode_len_mean: 88.87610619469027\n",
      "  episode_reward_max: 383.76894470834674\n",
      "  episode_reward_mean: 179.72617209514516\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 18886\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3677.892\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0862237885594368\n",
      "      kl: 0.016570396721363068\n",
      "      policy_loss: 0.00028124393429607153\n",
      "      total_loss: 60.149871826171875\n",
      "      vf_explained_var: 0.8101879954338074\n",
      "      vf_loss: 60.14958953857422\n",
      "    sample_time_ms: 18193.482\n",
      "    update_time_ms: 5.486\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.86308604757258\n",
      "  time_since_restore: 4076.7885665893555\n",
      "  time_this_iter_s: 21.975379467010498\n",
      "  time_total_s: 4076.7885665893555\n",
      "  timestamp: 1553125879\n",
      "  timesteps_since_restore: 1830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 183\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4076 s, 183 iter, 1830000 ts, 180 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-51-41\n",
      "  done: false\n",
      "  episode_len_mean: 79.01574803149606\n",
      "  episode_reward_max: 380.73602268033335\n",
      "  episode_reward_mean: 108.16477250114731\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 19013\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.26\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 1840000\n",
      "    num_steps_trained: 1840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12164175510406494\n",
      "      kl: 0.018804943189024925\n",
      "      policy_loss: 0.0011334816226735711\n",
      "      total_loss: 75.26142883300781\n",
      "      vf_explained_var: 0.8248106837272644\n",
      "      vf_loss: 75.26030731201172\n",
      "    sample_time_ms: 18171.096\n",
      "    update_time_ms: 6.101\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.08238625057365\n",
      "  time_since_restore: 4098.866005659103\n",
      "  time_this_iter_s: 22.077439069747925\n",
      "  time_total_s: 4098.866005659103\n",
      "  timestamp: 1553125901\n",
      "  timesteps_since_restore: 1840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1840000\n",
      "  training_iteration: 184\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4098 s, 184 iter, 1840000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-52-03\n",
      "  done: false\n",
      "  episode_len_mean: 86.14782608695653\n",
      "  episode_reward_max: 384.50396550612066\n",
      "  episode_reward_mean: 157.32065433636376\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 19128\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.283\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 1850000\n",
      "    num_steps_trained: 1850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11018520593643188\n",
      "      kl: 0.027608541771769524\n",
      "      policy_loss: 0.003687503281980753\n",
      "      total_loss: 67.81283569335938\n",
      "      vf_explained_var: 0.800381064414978\n",
      "      vf_loss: 67.80914306640625\n",
      "    sample_time_ms: 18176.946\n",
      "    update_time_ms: 6.037\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.66032716818188\n",
      "  time_since_restore: 4120.68220448494\n",
      "  time_this_iter_s: 21.81619882583618\n",
      "  time_total_s: 4120.68220448494\n",
      "  timestamp: 1553125923\n",
      "  timesteps_since_restore: 1850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1850000\n",
      "  training_iteration: 185\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4120 s, 185 iter, 1850000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-52-25\n",
      "  done: false\n",
      "  episode_len_mean: 84.25\n",
      "  episode_reward_max: 386.352321064612\n",
      "  episode_reward_mean: 147.20990636484063\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 19248\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.94\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.13239505887031555\n",
      "      kl: 0.0203783567994833\n",
      "      policy_loss: 0.003497547935694456\n",
      "      total_loss: 68.69274139404297\n",
      "      vf_explained_var: 0.8178500533103943\n",
      "      vf_loss: 68.68923950195312\n",
      "    sample_time_ms: 18168.862\n",
      "    update_time_ms: 5.418\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 73.60495318242032\n",
      "  time_since_restore: 4142.366683244705\n",
      "  time_this_iter_s: 21.684478759765625\n",
      "  time_total_s: 4142.366683244705\n",
      "  timestamp: 1553125945\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 186\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4142 s, 186 iter, 1860000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-52-47\n",
      "  done: false\n",
      "  episode_len_mean: 78.1796875\n",
      "  episode_reward_max: 385.5248466785079\n",
      "  episode_reward_mean: 92.62646429290658\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 19376\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.632\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 1870000\n",
      "    num_steps_trained: 1870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15546782314777374\n",
      "      kl: 0.027611542493104935\n",
      "      policy_loss: 0.003691034857183695\n",
      "      total_loss: 81.49034881591797\n",
      "      vf_explained_var: 0.8191525936126709\n",
      "      vf_loss: 81.48666381835938\n",
      "    sample_time_ms: 18130.554\n",
      "    update_time_ms: 5.495\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.31323214645329\n",
      "  time_since_restore: 4164.164872646332\n",
      "  time_this_iter_s: 21.798189401626587\n",
      "  time_total_s: 4164.164872646332\n",
      "  timestamp: 1553125967\n",
      "  timesteps_since_restore: 1870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1870000\n",
      "  training_iteration: 187\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4164 s, 187 iter, 1870000 ts, 92.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-53-09\n",
      "  done: false\n",
      "  episode_len_mean: 77.64341085271317\n",
      "  episode_reward_max: 380.95149408585945\n",
      "  episode_reward_mean: 96.5847102066144\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 19505\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.884\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 1880000\n",
      "    num_steps_trained: 1880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1771843284368515\n",
      "      kl: 0.02949509210884571\n",
      "      policy_loss: 0.00431994441896677\n",
      "      total_loss: 68.95695495605469\n",
      "      vf_explained_var: 0.8453840613365173\n",
      "      vf_loss: 68.95263671875\n",
      "    sample_time_ms: 18116.136\n",
      "    update_time_ms: 5.61\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.292355103307194\n",
      "  time_since_restore: 4185.88317656517\n",
      "  time_this_iter_s: 21.7183039188385\n",
      "  time_total_s: 4185.88317656517\n",
      "  timestamp: 1553125989\n",
      "  timesteps_since_restore: 1880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1880000\n",
      "  training_iteration: 188\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4185 s, 188 iter, 1880000 ts, 96.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-53-31\n",
      "  done: false\n",
      "  episode_len_mean: 87.21739130434783\n",
      "  episode_reward_max: 385.249443751114\n",
      "  episode_reward_mean: 168.3711691326622\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 19620\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.146\n",
      "    load_time_ms: 1.445\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1326756626367569\n",
      "      kl: 0.025166131556034088\n",
      "      policy_loss: 0.0007376930443570018\n",
      "      total_loss: 48.14438247680664\n",
      "      vf_explained_var: 0.852283775806427\n",
      "      vf_loss: 48.14364242553711\n",
      "    sample_time_ms: 18120.539\n",
      "    update_time_ms: 5.618\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.1855845663311\n",
      "  time_since_restore: 4207.925898551941\n",
      "  time_this_iter_s: 22.04272198677063\n",
      "  time_total_s: 4207.925898551941\n",
      "  timestamp: 1553126011\n",
      "  timesteps_since_restore: 1890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 189\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4207 s, 189 iter, 1890000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-53-53\n",
      "  done: false\n",
      "  episode_len_mean: 80.08870967741936\n",
      "  episode_reward_max: 384.8981386057851\n",
      "  episode_reward_mean: 114.54429868885902\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 19744\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.202\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 1900000\n",
      "    num_steps_trained: 1900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1783325970172882\n",
      "      kl: 0.025865616276860237\n",
      "      policy_loss: 0.001825320185162127\n",
      "      total_loss: 69.8456802368164\n",
      "      vf_explained_var: 0.8314647078514099\n",
      "      vf_loss: 69.84385681152344\n",
      "    sample_time_ms: 18149.022\n",
      "    update_time_ms: 5.631\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 57.27214934442953\n",
      "  time_since_restore: 4230.323791503906\n",
      "  time_this_iter_s: 22.397892951965332\n",
      "  time_total_s: 4230.323791503906\n",
      "  timestamp: 1553126033\n",
      "  timesteps_since_restore: 1900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1900000\n",
      "  training_iteration: 190\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4230 s, 190 iter, 1900000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-54-15\n",
      "  done: false\n",
      "  episode_len_mean: 81.67213114754098\n",
      "  episode_reward_max: 385.4084874980765\n",
      "  episode_reward_mean: 123.47670699541524\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 19866\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.238\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 1910000\n",
      "    num_steps_trained: 1910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15239936113357544\n",
      "      kl: 0.03049381636083126\n",
      "      policy_loss: 0.001434467500075698\n",
      "      total_loss: 61.811134338378906\n",
      "      vf_explained_var: 0.8431363105773926\n",
      "      vf_loss: 61.809696197509766\n",
      "    sample_time_ms: 18177.6\n",
      "    update_time_ms: 5.551\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.73835349770762\n",
      "  time_since_restore: 4252.335180521011\n",
      "  time_this_iter_s: 22.011389017105103\n",
      "  time_total_s: 4252.335180521011\n",
      "  timestamp: 1553126055\n",
      "  timesteps_since_restore: 1910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1910000\n",
      "  training_iteration: 191\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4252 s, 191 iter, 1910000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-54-37\n",
      "  done: false\n",
      "  episode_len_mean: 85.39830508474576\n",
      "  episode_reward_max: 387.2656888026\n",
      "  episode_reward_mean: 147.30527517686596\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 19984\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.215\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17569120228290558\n",
      "      kl: 0.0363723561167717\n",
      "      policy_loss: 0.0034163196105509996\n",
      "      total_loss: 68.3174819946289\n",
      "      vf_explained_var: 0.8125099539756775\n",
      "      vf_loss: 68.3140640258789\n",
      "    sample_time_ms: 18221.243\n",
      "    update_time_ms: 5.583\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 73.652637588433\n",
      "  time_since_restore: 4274.399383306503\n",
      "  time_this_iter_s: 22.064202785491943\n",
      "  time_total_s: 4274.399383306503\n",
      "  timestamp: 1553126077\n",
      "  timesteps_since_restore: 1920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 192\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4274 s, 192 iter, 1920000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-54-59\n",
      "  done: false\n",
      "  episode_len_mean: 87.52631578947368\n",
      "  episode_reward_max: 384.3328617591777\n",
      "  episode_reward_mean: 169.0750922943449\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 20098\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.816\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 1930000\n",
      "    num_steps_trained: 1930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1864103376865387\n",
      "      kl: 0.02520010806620121\n",
      "      policy_loss: 0.0010725796455517411\n",
      "      total_loss: 51.62375259399414\n",
      "      vf_explained_var: 0.8446586728096008\n",
      "      vf_loss: 51.622676849365234\n",
      "    sample_time_ms: 18228.319\n",
      "    update_time_ms: 5.568\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.53754614717246\n",
      "  time_since_restore: 4296.460995435715\n",
      "  time_this_iter_s: 22.061612129211426\n",
      "  time_total_s: 4296.460995435715\n",
      "  timestamp: 1553126099\n",
      "  timesteps_since_restore: 1930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1930000\n",
      "  training_iteration: 193\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4296 s, 193 iter, 1930000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-55-21\n",
      "  done: false\n",
      "  episode_len_mean: 84.83760683760684\n",
      "  episode_reward_max: 385.110862811652\n",
      "  episode_reward_mean: 148.83385471614085\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 20215\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.139\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 1940000\n",
      "    num_steps_trained: 1940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2141139656305313\n",
      "      kl: 0.027026304975152016\n",
      "      policy_loss: 0.002131212269887328\n",
      "      total_loss: 60.47815704345703\n",
      "      vf_explained_var: 0.8342747092247009\n",
      "      vf_loss: 60.47602462768555\n",
      "    sample_time_ms: 18176.782\n",
      "    update_time_ms: 5.147\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.41692735807042\n",
      "  time_since_restore: 4317.7713124752045\n",
      "  time_this_iter_s: 21.310317039489746\n",
      "  time_total_s: 4317.7713124752045\n",
      "  timestamp: 1553126121\n",
      "  timesteps_since_restore: 1940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1940000\n",
      "  training_iteration: 194\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4317 s, 194 iter, 1940000 ts, 149 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-55-42\n",
      "  done: false\n",
      "  episode_len_mean: 83.56198347107438\n",
      "  episode_reward_max: 382.81768656600366\n",
      "  episode_reward_mean: 136.46849048257047\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 20336\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.761\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.20606555044651031\n",
      "      kl: 0.032985370606184006\n",
      "      policy_loss: 0.007296556141227484\n",
      "      total_loss: 57.75835037231445\n",
      "      vf_explained_var: 0.8453221321105957\n",
      "      vf_loss: 57.75105667114258\n",
      "    sample_time_ms: 18134.416\n",
      "    update_time_ms: 5.138\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.23424524128522\n",
      "  time_since_restore: 4339.362894535065\n",
      "  time_this_iter_s: 21.59158205986023\n",
      "  time_total_s: 4339.362894535065\n",
      "  timestamp: 1553126142\n",
      "  timesteps_since_restore: 1950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 195\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4339 s, 195 iter, 1950000 ts, 136 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-56-04\n",
      "  done: false\n",
      "  episode_len_mean: 83.52941176470588\n",
      "  episode_reward_max: 384.15601703956645\n",
      "  episode_reward_mean: 136.35312350102384\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 20455\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.895\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 1960000\n",
      "    num_steps_trained: 1960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2307569980621338\n",
      "      kl: 0.03319018706679344\n",
      "      policy_loss: 0.0003086798533331603\n",
      "      total_loss: 71.98336029052734\n",
      "      vf_explained_var: 0.8082486391067505\n",
      "      vf_loss: 71.98306274414062\n",
      "    sample_time_ms: 18159.161\n",
      "    update_time_ms: 5.183\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.17656175051192\n",
      "  time_since_restore: 4361.299028635025\n",
      "  time_this_iter_s: 21.936134099960327\n",
      "  time_total_s: 4361.299028635025\n",
      "  timestamp: 1553126164\n",
      "  timesteps_since_restore: 1960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1960000\n",
      "  training_iteration: 196\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4361 s, 196 iter, 1960000 ts, 136 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-56-26\n",
      "  done: false\n",
      "  episode_len_mean: 79.60317460317461\n",
      "  episode_reward_max: 386.94776792154664\n",
      "  episode_reward_mean: 104.16291267576602\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 20581\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.458\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 1970000\n",
      "    num_steps_trained: 1970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24127040803432465\n",
      "      kl: 0.019241001456975937\n",
      "      policy_loss: 0.0007953032618388534\n",
      "      total_loss: 74.9325180053711\n",
      "      vf_explained_var: 0.8258870244026184\n",
      "      vf_loss: 74.93172454833984\n",
      "    sample_time_ms: 18154.894\n",
      "    update_time_ms: 5.152\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.08145633788301\n",
      "  time_since_restore: 4383.10232925415\n",
      "  time_this_iter_s: 21.803300619125366\n",
      "  time_total_s: 4383.10232925415\n",
      "  timestamp: 1553126186\n",
      "  timesteps_since_restore: 1970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1970000\n",
      "  training_iteration: 197\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4383 s, 197 iter, 1970000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-56-48\n",
      "  done: false\n",
      "  episode_len_mean: 80.264\n",
      "  episode_reward_max: 386.56587081578385\n",
      "  episode_reward_mean: 116.02086792359938\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 20706\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.31\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.23791874945163727\n",
      "      kl: 0.026297837495803833\n",
      "      policy_loss: 0.001027275575324893\n",
      "      total_loss: 64.12068939208984\n",
      "      vf_explained_var: 0.8465040326118469\n",
      "      vf_loss: 64.11966705322266\n",
      "    sample_time_ms: 18175.503\n",
      "    update_time_ms: 5.124\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.01043396179969\n",
      "  time_since_restore: 4404.993229627609\n",
      "  time_this_iter_s: 21.890900373458862\n",
      "  time_total_s: 4404.993229627609\n",
      "  timestamp: 1553126208\n",
      "  timesteps_since_restore: 1980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 198\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4404 s, 198 iter, 1980000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-57-10\n",
      "  done: false\n",
      "  episode_len_mean: 82.26446280991736\n",
      "  episode_reward_max: 386.7432477241492\n",
      "  episode_reward_mean: 131.95594601865932\n",
      "  episode_reward_min: -162.62400350531578\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 20827\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.899\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 1990000\n",
      "    num_steps_trained: 1990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.23539063334465027\n",
      "      kl: 0.0172505434602499\n",
      "      policy_loss: 0.002804239746183157\n",
      "      total_loss: 71.78593444824219\n",
      "      vf_explained_var: 0.8100415468215942\n",
      "      vf_loss: 71.78312683105469\n",
      "    sample_time_ms: 18165.314\n",
      "    update_time_ms: 5.119\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.97797300932966\n",
      "  time_since_restore: 4427.0383644104\n",
      "  time_this_iter_s: 22.045134782791138\n",
      "  time_total_s: 4427.0383644104\n",
      "  timestamp: 1553126230\n",
      "  timesteps_since_restore: 1990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1990000\n",
      "  training_iteration: 199\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4427 s, 199 iter, 1990000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-57-32\n",
      "  done: false\n",
      "  episode_len_mean: 84.08403361344538\n",
      "  episode_reward_max: 380.9742967111923\n",
      "  episode_reward_mean: 142.59390914145146\n",
      "  episode_reward_min: -164.65789287492277\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 20946\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.642\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 2000000\n",
      "    num_steps_trained: 2000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22584976255893707\n",
      "      kl: 0.028025241568684578\n",
      "      policy_loss: 0.0015820983098819852\n",
      "      total_loss: 59.08406066894531\n",
      "      vf_explained_var: 0.8402952551841736\n",
      "      vf_loss: 59.08247756958008\n",
      "    sample_time_ms: 18093.444\n",
      "    update_time_ms: 5.114\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.29695457072572\n",
      "  time_since_restore: 4448.692227125168\n",
      "  time_this_iter_s: 21.653862714767456\n",
      "  time_total_s: 4448.692227125168\n",
      "  timestamp: 1553126252\n",
      "  timesteps_since_restore: 2000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2000000\n",
      "  training_iteration: 200\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4448 s, 200 iter, 2000000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-57-54\n",
      "  done: false\n",
      "  episode_len_mean: 83.61666666666666\n",
      "  episode_reward_max: 386.92071609081506\n",
      "  episode_reward_mean: 137.74084306224395\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 21066\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.739\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.23222050070762634\n",
      "      kl: 0.02554161287844181\n",
      "      policy_loss: 0.0012347828596830368\n",
      "      total_loss: 62.84567642211914\n",
      "      vf_explained_var: 0.831953763961792\n",
      "      vf_loss: 62.844444274902344\n",
      "    sample_time_ms: 18138.104\n",
      "    update_time_ms: 5.138\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.87042153112198\n",
      "  time_since_restore: 4471.1198744773865\n",
      "  time_this_iter_s: 22.427647352218628\n",
      "  time_total_s: 4471.1198744773865\n",
      "  timestamp: 1553126274\n",
      "  timesteps_since_restore: 2010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 201\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4471 s, 201 iter, 2010000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-58-16\n",
      "  done: false\n",
      "  episode_len_mean: 83.58823529411765\n",
      "  episode_reward_max: 387.5307594049455\n",
      "  episode_reward_mean: 137.23161241866666\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 21185\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.094\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 2020000\n",
      "    num_steps_trained: 2020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24358820915222168\n",
      "      kl: 0.03317084163427353\n",
      "      policy_loss: 0.0021456158719956875\n",
      "      total_loss: 55.405574798583984\n",
      "      vf_explained_var: 0.8547758460044861\n",
      "      vf_loss: 55.40343475341797\n",
      "    sample_time_ms: 18075.577\n",
      "    update_time_ms: 5.09\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.61580620933333\n",
      "  time_since_restore: 4492.581879854202\n",
      "  time_this_iter_s: 21.462005376815796\n",
      "  time_total_s: 4492.581879854202\n",
      "  timestamp: 1553126296\n",
      "  timesteps_since_restore: 2020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2020000\n",
      "  training_iteration: 202\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4492 s, 202 iter, 2020000 ts, 137 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-58-39\n",
      "  done: false\n",
      "  episode_len_mean: 83.275\n",
      "  episode_reward_max: 386.32351873780937\n",
      "  episode_reward_mean: 137.24081131124765\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 21305\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.901\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 2030000\n",
      "    num_steps_trained: 2030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2661607265472412\n",
      "      kl: 0.026223119348287582\n",
      "      policy_loss: 0.002553069731220603\n",
      "      total_loss: 44.01008605957031\n",
      "      vf_explained_var: 0.8830124139785767\n",
      "      vf_loss: 44.007530212402344\n",
      "    sample_time_ms: 18127.968\n",
      "    update_time_ms: 5.181\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.6204056556238\n",
      "  time_since_restore: 4515.175284147263\n",
      "  time_this_iter_s: 22.593404293060303\n",
      "  time_total_s: 4515.175284147263\n",
      "  timestamp: 1553126319\n",
      "  timesteps_since_restore: 2030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2030000\n",
      "  training_iteration: 203\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4515 s, 203 iter, 2030000 ts, 137 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-59-00\n",
      "  done: false\n",
      "  episode_len_mean: 81.6829268292683\n",
      "  episode_reward_max: 386.6465602924461\n",
      "  episode_reward_mean: 120.18356778563763\n",
      "  episode_reward_min: -168.64969451114177\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 21428\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.255\n",
      "    load_time_ms: 1.471\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.26830536127090454\n",
      "      kl: 0.020182441920042038\n",
      "      policy_loss: 0.0030098159331828356\n",
      "      total_loss: 66.72855377197266\n",
      "      vf_explained_var: 0.8358177542686462\n",
      "      vf_loss: 66.72554016113281\n",
      "    sample_time_ms: 18147.147\n",
      "    update_time_ms: 4.946\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.09178389281882\n",
      "  time_since_restore: 4536.689892530441\n",
      "  time_this_iter_s: 21.51460838317871\n",
      "  time_total_s: 4536.689892530441\n",
      "  timestamp: 1553126340\n",
      "  timesteps_since_restore: 2040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 204\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4536 s, 204 iter, 2040000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-59-22\n",
      "  done: false\n",
      "  episode_len_mean: 84.45299145299145\n",
      "  episode_reward_max: 386.9187014413472\n",
      "  episode_reward_mean: 137.89168156831573\n",
      "  episode_reward_min: -164.71287258097172\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 21545\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.013\n",
      "    load_time_ms: 1.471\n",
      "    num_steps_sampled: 2050000\n",
      "    num_steps_trained: 2050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2752301096916199\n",
      "      kl: 0.08152087777853012\n",
      "      policy_loss: 0.009910772554576397\n",
      "      total_loss: 68.48167419433594\n",
      "      vf_explained_var: 0.8140522241592407\n",
      "      vf_loss: 68.47176361083984\n",
      "    sample_time_ms: 18230.48\n",
      "    update_time_ms: 5.017\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.94584078415787\n",
      "  time_since_restore: 4558.872046947479\n",
      "  time_this_iter_s: 22.182154417037964\n",
      "  time_total_s: 4558.872046947479\n",
      "  timestamp: 1553126362\n",
      "  timesteps_since_restore: 2050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2050000\n",
      "  training_iteration: 205\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4558 s, 205 iter, 2050000 ts, 138 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_00-59-44\n",
      "  done: false\n",
      "  episode_len_mean: 74.1470588235294\n",
      "  episode_reward_max: 386.9024760631285\n",
      "  episode_reward_mean: 62.90694995432226\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 21681\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.405\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 2060000\n",
      "    num_steps_trained: 2060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.505212647172114e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3372349739074707\n",
      "      kl: 0.02596021257340908\n",
      "      policy_loss: 0.002279288601130247\n",
      "      total_loss: 83.13673400878906\n",
      "      vf_explained_var: 0.8343891501426697\n",
      "      vf_loss: 83.13445281982422\n",
      "    sample_time_ms: 18190.018\n",
      "    update_time_ms: 5.722\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.453474977161115\n",
      "  time_since_restore: 4580.405468940735\n",
      "  time_this_iter_s: 21.533421993255615\n",
      "  time_total_s: 4580.405468940735\n",
      "  timestamp: 1553126384\n",
      "  timesteps_since_restore: 2060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2060000\n",
      "  training_iteration: 206\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4580 s, 206 iter, 2060000 ts, 62.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-00-06\n",
      "  done: false\n",
      "  episode_len_mean: 80.6829268292683\n",
      "  episode_reward_max: 385.59689351091953\n",
      "  episode_reward_mean: 108.42044745077476\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 21804\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.24\n",
      "    load_time_ms: 1.422\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.505212647172114e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.30889609456062317\n",
      "      kl: 0.028055796399712563\n",
      "      policy_loss: 0.004020051099359989\n",
      "      total_loss: 58.850311279296875\n",
      "      vf_explained_var: 0.861541748046875\n",
      "      vf_loss: 58.846290588378906\n",
      "    sample_time_ms: 18185.648\n",
      "    update_time_ms: 5.637\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.21022372538737\n",
      "  time_since_restore: 4602.151399612427\n",
      "  time_this_iter_s: 21.745930671691895\n",
      "  time_total_s: 4602.151399612427\n",
      "  timestamp: 1553126406\n",
      "  timesteps_since_restore: 2070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 207\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4602 s, 207 iter, 2070000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-00-27\n",
      "  done: false\n",
      "  episode_len_mean: 83.60833333333333\n",
      "  episode_reward_max: 386.8405241573518\n",
      "  episode_reward_mean: 133.51414275889954\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 21924\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.502\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 2080000\n",
      "    num_steps_trained: 2080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.505212647172114e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3182223439216614\n",
      "      kl: 0.02502538077533245\n",
      "      policy_loss: 0.002546493196859956\n",
      "      total_loss: 61.53033447265625\n",
      "      vf_explained_var: 0.842565655708313\n",
      "      vf_loss: 61.52778244018555\n",
      "    sample_time_ms: 18141.904\n",
      "    update_time_ms: 5.636\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.75707137944977\n",
      "  time_since_restore: 4623.640878677368\n",
      "  time_this_iter_s: 21.489479064941406\n",
      "  time_total_s: 4623.640878677368\n",
      "  timestamp: 1553126427\n",
      "  timesteps_since_restore: 2080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2080000\n",
      "  training_iteration: 208\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4623 s, 208 iter, 2080000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-00-49\n",
      "  done: false\n",
      "  episode_len_mean: 78.24806201550388\n",
      "  episode_reward_max: 386.3273480594511\n",
      "  episode_reward_mean: 97.70644072679876\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 22053\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.283\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 2090000\n",
      "    num_steps_trained: 2090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.505212647172114e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3631805181503296\n",
      "      kl: 0.031518831849098206\n",
      "      policy_loss: 0.0037113260477781296\n",
      "      total_loss: 79.15972900390625\n",
      "      vf_explained_var: 0.8226243853569031\n",
      "      vf_loss: 79.15602111816406\n",
      "    sample_time_ms: 18099.852\n",
      "    update_time_ms: 5.733\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.853220363399366\n",
      "  time_since_restore: 4645.127589941025\n",
      "  time_this_iter_s: 21.486711263656616\n",
      "  time_total_s: 4645.127589941025\n",
      "  timestamp: 1553126449\n",
      "  timesteps_since_restore: 2090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2090000\n",
      "  training_iteration: 209\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4645 s, 209 iter, 2090000 ts, 97.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-01-11\n",
      "  done: false\n",
      "  episode_len_mean: 85.17948717948718\n",
      "  episode_reward_max: 387.0000822005361\n",
      "  episode_reward_mean: 139.90399733836588\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 22170\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.496\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.505212647172114e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3330598473548889\n",
      "      kl: 0.030376948416233063\n",
      "      policy_loss: 0.003910371568053961\n",
      "      total_loss: 61.52806854248047\n",
      "      vf_explained_var: 0.8319352269172668\n",
      "      vf_loss: 61.52416229248047\n",
      "    sample_time_ms: 18126.528\n",
      "    update_time_ms: 5.746\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.95199866918294\n",
      "  time_since_restore: 4667.231178045273\n",
      "  time_this_iter_s: 22.103588104248047\n",
      "  time_total_s: 4667.231178045273\n",
      "  timestamp: 1553126471\n",
      "  timesteps_since_restore: 2100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 210\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4667 s, 210 iter, 2100000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-01-32\n",
      "  done: false\n",
      "  episode_len_mean: 87.4298245614035\n",
      "  episode_reward_max: 386.8315349915464\n",
      "  episode_reward_mean: 163.98172290048507\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 22284\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.653\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 2110000\n",
      "    num_steps_trained: 2110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.505212647172114e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3386678993701935\n",
      "      kl: 0.024990921840071678\n",
      "      policy_loss: 0.0042175306007266045\n",
      "      total_loss: 45.132232666015625\n",
      "      vf_explained_var: 0.8613823056221008\n",
      "      vf_loss: 45.12800979614258\n",
      "    sample_time_ms: 18036.472\n",
      "    update_time_ms: 5.82\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.99086145024255\n",
      "  time_since_restore: 4688.787440776825\n",
      "  time_this_iter_s: 21.556262731552124\n",
      "  time_total_s: 4688.787440776825\n",
      "  timestamp: 1553126492\n",
      "  timesteps_since_restore: 2110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2110000\n",
      "  training_iteration: 211\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4688 s, 211 iter, 2110000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-01-54\n",
      "  done: false\n",
      "  episode_len_mean: 81.77868852459017\n",
      "  episode_reward_max: 383.76748157938897\n",
      "  episode_reward_mean: 124.90759400744548\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 22406\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.425\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 2120000\n",
      "    num_steps_trained: 2120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.505212647172114e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3733658790588379\n",
      "      kl: 0.04234650358557701\n",
      "      policy_loss: 0.006704480852931738\n",
      "      total_loss: 58.455909729003906\n",
      "      vf_explained_var: 0.8535821437835693\n",
      "      vf_loss: 58.4492073059082\n",
      "    sample_time_ms: 18053.363\n",
      "    update_time_ms: 5.774\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.45379700372273\n",
      "  time_since_restore: 4710.386020898819\n",
      "  time_this_iter_s: 21.59858012199402\n",
      "  time_total_s: 4710.386020898819\n",
      "  timestamp: 1553126514\n",
      "  timesteps_since_restore: 2120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2120000\n",
      "  training_iteration: 212\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4710 s, 212 iter, 2120000 ts, 125 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-02-16\n",
      "  done: false\n",
      "  episode_len_mean: 86.98275862068965\n",
      "  episode_reward_max: 387.8083273174048\n",
      "  episode_reward_mean: 161.10376454031194\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 22522\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.274\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.757819940110452e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.36895307898521423\n",
      "      kl: 0.03718564286828041\n",
      "      policy_loss: 0.005334864836186171\n",
      "      total_loss: 48.369991302490234\n",
      "      vf_explained_var: 0.8597219586372375\n",
      "      vf_loss: 48.36465835571289\n",
      "    sample_time_ms: 17977.579\n",
      "    update_time_ms: 5.657\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.55188227015596\n",
      "  time_since_restore: 4732.178027153015\n",
      "  time_this_iter_s: 21.792006254196167\n",
      "  time_total_s: 4732.178027153015\n",
      "  timestamp: 1553126536\n",
      "  timesteps_since_restore: 2130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 213\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4732 s, 213 iter, 2130000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-02-37\n",
      "  done: false\n",
      "  episode_len_mean: 82.48333333333333\n",
      "  episode_reward_max: 384.972523584503\n",
      "  episode_reward_mean: 127.31158257671959\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 22642\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.637\n",
      "    load_time_ms: 1.434\n",
      "    num_steps_sampled: 2140000\n",
      "    num_steps_trained: 2140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.757819940110452e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39976218342781067\n",
      "      kl: 0.02827282063663006\n",
      "      policy_loss: 0.0020847145933657885\n",
      "      total_loss: 53.11130905151367\n",
      "      vf_explained_var: 0.8616372346878052\n",
      "      vf_loss: 53.10922622680664\n",
      "    sample_time_ms: 17978.572\n",
      "    update_time_ms: 5.659\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.655791288359794\n",
      "  time_since_restore: 4753.673343420029\n",
      "  time_this_iter_s: 21.49531626701355\n",
      "  time_total_s: 4753.673343420029\n",
      "  timestamp: 1553126557\n",
      "  timesteps_since_restore: 2140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2140000\n",
      "  training_iteration: 214\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4753 s, 214 iter, 2140000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-02-59\n",
      "  done: false\n",
      "  episode_len_mean: 82.17073170731707\n",
      "  episode_reward_max: 385.1618797773411\n",
      "  episode_reward_mean: 127.33023080066879\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 22765\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.346\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 2150000\n",
      "    num_steps_trained: 2150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.757819940110452e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4021866023540497\n",
      "      kl: 0.020852018147706985\n",
      "      policy_loss: 0.004796970169991255\n",
      "      total_loss: 56.01332092285156\n",
      "      vf_explained_var: 0.8608419895172119\n",
      "      vf_loss: 56.00852584838867\n",
      "    sample_time_ms: 17891.283\n",
      "    update_time_ms: 5.571\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.66511540033438\n",
      "  time_since_restore: 4775.020597219467\n",
      "  time_this_iter_s: 21.347253799438477\n",
      "  time_total_s: 4775.020597219467\n",
      "  timestamp: 1553126579\n",
      "  timesteps_since_restore: 2150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2150000\n",
      "  training_iteration: 215\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4775 s, 215 iter, 2150000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-03-21\n",
      "  done: false\n",
      "  episode_len_mean: 72.44525547445255\n",
      "  episode_reward_max: 382.45996419096247\n",
      "  episode_reward_mean: 59.574776429375255\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 22902\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.71\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.757819940110452e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4413588047027588\n",
      "      kl: 0.044283926486968994\n",
      "      policy_loss: 0.0061186994425952435\n",
      "      total_loss: 61.71244430541992\n",
      "      vf_explained_var: 0.8806380033493042\n",
      "      vf_loss: 61.706329345703125\n",
      "    sample_time_ms: 17940.452\n",
      "    update_time_ms: 4.856\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.78738821468763\n",
      "  time_since_restore: 4797.050147771835\n",
      "  time_this_iter_s: 22.029550552368164\n",
      "  time_total_s: 4797.050147771835\n",
      "  timestamp: 1553126601\n",
      "  timesteps_since_restore: 2160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 216\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4797 s, 216 iter, 2160000 ts, 59.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-03-43\n",
      "  done: false\n",
      "  episode_len_mean: 82.65289256198348\n",
      "  episode_reward_max: 384.42734561552896\n",
      "  episode_reward_mean: 127.86389797859238\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 23023\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.149\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 2170000\n",
      "    num_steps_trained: 2170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4636730879517958e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43174126744270325\n",
      "      kl: 0.03440796956419945\n",
      "      policy_loss: 0.0070101069286465645\n",
      "      total_loss: 54.81829833984375\n",
      "      vf_explained_var: 0.8618980646133423\n",
      "      vf_loss: 54.81128692626953\n",
      "    sample_time_ms: 17945.637\n",
      "    update_time_ms: 5.072\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.93194898929618\n",
      "  time_since_restore: 4818.9552574157715\n",
      "  time_this_iter_s: 21.905109643936157\n",
      "  time_total_s: 4818.9552574157715\n",
      "  timestamp: 1553126623\n",
      "  timesteps_since_restore: 2170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2170000\n",
      "  training_iteration: 217\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4818 s, 217 iter, 2170000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-04-04\n",
      "  done: false\n",
      "  episode_len_mean: 82.92561983471074\n",
      "  episode_reward_max: 382.1820125430799\n",
      "  episode_reward_mean: 130.4081215860924\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 23144\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.38\n",
      "    load_time_ms: 1.373\n",
      "    num_steps_sampled: 2180000\n",
      "    num_steps_trained: 2180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4636730879517958e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42196106910705566\n",
      "      kl: 0.03227362409234047\n",
      "      policy_loss: 0.00563488295301795\n",
      "      total_loss: 58.426456451416016\n",
      "      vf_explained_var: 0.8498950600624084\n",
      "      vf_loss: 58.42082214355469\n",
      "    sample_time_ms: 17890.869\n",
      "    update_time_ms: 5.009\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.20406079304618\n",
      "  time_since_restore: 4839.9073984622955\n",
      "  time_this_iter_s: 20.952141046524048\n",
      "  time_total_s: 4839.9073984622955\n",
      "  timestamp: 1553126644\n",
      "  timesteps_since_restore: 2180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2180000\n",
      "  training_iteration: 218\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4839 s, 218 iter, 2180000 ts, 130 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-04-25\n",
      "  done: false\n",
      "  episode_len_mean: 81.0650406504065\n",
      "  episode_reward_max: 382.17427750434706\n",
      "  episode_reward_mean: 118.8039102314065\n",
      "  episode_reward_min: -166.72038878962042\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 23267\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.227\n",
      "    load_time_ms: 1.378\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4636730879517958e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42915433645248413\n",
      "      kl: 0.05054502561688423\n",
      "      policy_loss: 0.005288318730890751\n",
      "      total_loss: 54.46831130981445\n",
      "      vf_explained_var: 0.8669189214706421\n",
      "      vf_loss: 54.46302795410156\n",
      "    sample_time_ms: 17901.438\n",
      "    update_time_ms: 4.871\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.40195511570327\n",
      "  time_since_restore: 4861.497195959091\n",
      "  time_this_iter_s: 21.589797496795654\n",
      "  time_total_s: 4861.497195959091\n",
      "  timestamp: 1553126665\n",
      "  timesteps_since_restore: 2190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 219\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4861 s, 219 iter, 2190000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-04-47\n",
      "  done: false\n",
      "  episode_len_mean: 82.925\n",
      "  episode_reward_max: 384.5398158299375\n",
      "  episode_reward_mean: 131.18475073796347\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 23387\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.366\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 2200000\n",
      "    num_steps_trained: 2200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1955092441867816e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4579102396965027\n",
      "      kl: 0.03220732882618904\n",
      "      policy_loss: 0.003474112134426832\n",
      "      total_loss: 66.3936538696289\n",
      "      vf_explained_var: 0.8281267881393433\n",
      "      vf_loss: 66.39017486572266\n",
      "    sample_time_ms: 17892.702\n",
      "    update_time_ms: 4.815\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.59237536898173\n",
      "  time_since_restore: 4883.334554433823\n",
      "  time_this_iter_s: 21.837358474731445\n",
      "  time_total_s: 4883.334554433823\n",
      "  timestamp: 1553126687\n",
      "  timesteps_since_restore: 2200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2200000\n",
      "  training_iteration: 220\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4883 s, 220 iter, 2200000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-05-10\n",
      "  done: false\n",
      "  episode_len_mean: 81.50806451612904\n",
      "  episode_reward_max: 382.4520229222348\n",
      "  episode_reward_mean: 122.18411295088434\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 23511\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.188\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 2210000\n",
      "    num_steps_trained: 2210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1955092441867816e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44370126724243164\n",
      "      kl: 0.06387362629175186\n",
      "      policy_loss: 0.007174428552389145\n",
      "      total_loss: 52.05115509033203\n",
      "      vf_explained_var: 0.8748288154602051\n",
      "      vf_loss: 52.04397964477539\n",
      "    sample_time_ms: 17953.065\n",
      "    update_time_ms: 4.801\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.092056475442185\n",
      "  time_since_restore: 4905.7031927108765\n",
      "  time_this_iter_s: 22.368638277053833\n",
      "  time_total_s: 4905.7031927108765\n",
      "  timestamp: 1553126710\n",
      "  timesteps_since_restore: 2210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2210000\n",
      "  training_iteration: 221\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4905 s, 221 iter, 2210000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-05-32\n",
      "  done: false\n",
      "  episode_len_mean: 89.74545454545455\n",
      "  episode_reward_max: 386.2271149547806\n",
      "  episode_reward_mean: 184.97323032909625\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 23621\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.565\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.2932642540210846e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.417145311832428\n",
      "      kl: 0.04190322011709213\n",
      "      policy_loss: 0.006425030529499054\n",
      "      total_loss: 55.39809799194336\n",
      "      vf_explained_var: 0.8146567940711975\n",
      "      vf_loss: 55.39167022705078\n",
      "    sample_time_ms: 17959.868\n",
      "    update_time_ms: 4.92\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.48661516454811\n",
      "  time_since_restore: 4927.396506309509\n",
      "  time_this_iter_s: 21.693313598632812\n",
      "  time_total_s: 4927.396506309509\n",
      "  timestamp: 1553126732\n",
      "  timesteps_since_restore: 2220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 222\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4927 s, 222 iter, 2220000 ts, 185 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-05-54\n",
      "  done: false\n",
      "  episode_len_mean: 78.6124031007752\n",
      "  episode_reward_max: 387.7402197174177\n",
      "  episode_reward_mean: 104.90311133955544\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 23750\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.421\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 2230000\n",
      "    num_steps_trained: 2230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.939896251784656e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4547150433063507\n",
      "      kl: 0.03037460707128048\n",
      "      policy_loss: 0.005489123519510031\n",
      "      total_loss: 68.41064453125\n",
      "      vf_explained_var: 0.8447836637496948\n",
      "      vf_loss: 68.4051513671875\n",
      "    sample_time_ms: 18015.039\n",
      "    update_time_ms: 4.975\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.451555669777726\n",
      "  time_since_restore: 4949.763296842575\n",
      "  time_this_iter_s: 22.366790533065796\n",
      "  time_total_s: 4949.763296842575\n",
      "  timestamp: 1553126754\n",
      "  timesteps_since_restore: 2230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2230000\n",
      "  training_iteration: 223\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4949 s, 223 iter, 2230000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-06-16\n",
      "  done: false\n",
      "  episode_len_mean: 87.36842105263158\n",
      "  episode_reward_max: 386.39966236796977\n",
      "  episode_reward_mean: 162.60266686066313\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 23864\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.073\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 2240000\n",
      "    num_steps_trained: 2240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.939896251784656e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4306866526603699\n",
      "      kl: 0.030061379075050354\n",
      "      policy_loss: 0.003642858238890767\n",
      "      total_loss: 59.23339080810547\n",
      "      vf_explained_var: 0.8189316987991333\n",
      "      vf_loss: 59.2297477722168\n",
      "    sample_time_ms: 18078.292\n",
      "    update_time_ms: 5.227\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.30133343033157\n",
      "  time_since_restore: 4971.903171539307\n",
      "  time_this_iter_s: 22.139874696731567\n",
      "  time_total_s: 4971.903171539307\n",
      "  timestamp: 1553126776\n",
      "  timesteps_since_restore: 2240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2240000\n",
      "  training_iteration: 224\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4971 s, 224 iter, 2240000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-06-38\n",
      "  done: false\n",
      "  episode_len_mean: 84.97435897435898\n",
      "  episode_reward_max: 384.9191712044463\n",
      "  episode_reward_mean: 151.10063141008564\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 23981\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.497\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.939896251784656e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44081544876098633\n",
      "      kl: 0.03603580221533775\n",
      "      policy_loss: 0.005580405239015818\n",
      "      total_loss: 52.72273254394531\n",
      "      vf_explained_var: 0.8521744012832642\n",
      "      vf_loss: 52.71715545654297\n",
      "    sample_time_ms: 18114.744\n",
      "    update_time_ms: 5.349\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.55031570504283\n",
      "  time_since_restore: 4993.604561090469\n",
      "  time_this_iter_s: 21.70138955116272\n",
      "  time_total_s: 4993.604561090469\n",
      "  timestamp: 1553126798\n",
      "  timesteps_since_restore: 2250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 225\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 4993 s, 225 iter, 2250000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-07-00\n",
      "  done: false\n",
      "  episode_len_mean: 79.74603174603175\n",
      "  episode_reward_max: 385.8182996370303\n",
      "  episode_reward_mean: 109.16878240611025\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 24107\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.609\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 2260000\n",
      "    num_steps_trained: 2260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.939896251784656e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4864925444126129\n",
      "      kl: 0.057691268622875214\n",
      "      policy_loss: 0.01078428328037262\n",
      "      total_loss: 73.07099914550781\n",
      "      vf_explained_var: 0.8285624384880066\n",
      "      vf_loss: 73.06021881103516\n",
      "    sample_time_ms: 18133.004\n",
      "    update_time_ms: 5.43\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.58439120305512\n",
      "  time_since_restore: 5015.818823814392\n",
      "  time_this_iter_s: 22.21426272392273\n",
      "  time_total_s: 5015.818823814392\n",
      "  timestamp: 1553126820\n",
      "  timesteps_since_restore: 2260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2260000\n",
      "  training_iteration: 226\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5015 s, 226 iter, 2260000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-07-22\n",
      "  done: false\n",
      "  episode_len_mean: 80.5241935483871\n",
      "  episode_reward_max: 382.8588192695841\n",
      "  episode_reward_mean: 116.4182398115304\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 24231\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.942\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 2270000\n",
      "    num_steps_trained: 2270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.409843085207277e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48836004734039307\n",
      "      kl: 0.033554937690496445\n",
      "      policy_loss: 0.005099072121083736\n",
      "      total_loss: 58.99029541015625\n",
      "      vf_explained_var: 0.8578628897666931\n",
      "      vf_loss: 58.98520278930664\n",
      "    sample_time_ms: 18159.045\n",
      "    update_time_ms: 5.288\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.2091199057652\n",
      "  time_since_restore: 5037.834789991379\n",
      "  time_this_iter_s: 22.015966176986694\n",
      "  time_total_s: 5037.834789991379\n",
      "  timestamp: 1553126842\n",
      "  timesteps_since_restore: 2270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2270000\n",
      "  training_iteration: 227\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5037 s, 227 iter, 2270000 ts, 116 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-07-44\n",
      "  done: false\n",
      "  episode_len_mean: 85.82758620689656\n",
      "  episode_reward_max: 388.0686483552542\n",
      "  episode_reward_mean: 158.15702316902122\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 24347\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.72\n",
      "    load_time_ms: 1.713\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.409843085207277e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.465786874294281\n",
      "      kl: 0.032694604247808456\n",
      "      policy_loss: 0.006448693107813597\n",
      "      total_loss: 42.62148666381836\n",
      "      vf_explained_var: 0.8760296702384949\n",
      "      vf_loss: 42.61503982543945\n",
      "    sample_time_ms: 18282.805\n",
      "    update_time_ms: 5.452\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.07851158451061\n",
      "  time_since_restore: 5059.976034164429\n",
      "  time_this_iter_s: 22.141244173049927\n",
      "  time_total_s: 5059.976034164429\n",
      "  timestamp: 1553126864\n",
      "  timesteps_since_restore: 2280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 228\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5059 s, 228 iter, 2280000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-08-06\n",
      "  done: false\n",
      "  episode_len_mean: 83.45833333333333\n",
      "  episode_reward_max: 383.25804292050606\n",
      "  episode_reward_mean: 137.53327739607678\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 24467\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.849\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 2290000\n",
      "    num_steps_trained: 2290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.409843085207277e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47629067301750183\n",
      "      kl: 0.03397667035460472\n",
      "      policy_loss: 0.003016110509634018\n",
      "      total_loss: 45.14530563354492\n",
      "      vf_explained_var: 0.8794084191322327\n",
      "      vf_loss: 45.14228820800781\n",
      "    sample_time_ms: 18280.841\n",
      "    update_time_ms: 5.468\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.76663869803839\n",
      "  time_since_restore: 5081.5769872665405\n",
      "  time_this_iter_s: 21.600953102111816\n",
      "  time_total_s: 5081.5769872665405\n",
      "  timestamp: 1553126886\n",
      "  timesteps_since_restore: 2290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2290000\n",
      "  training_iteration: 229\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5081 s, 229 iter, 2290000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-08-28\n",
      "  done: false\n",
      "  episode_len_mean: 84.85593220338983\n",
      "  episode_reward_max: 384.8286735508235\n",
      "  episode_reward_mean: 144.5337455181124\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 24585\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.288\n",
      "    load_time_ms: 1.652\n",
      "    num_steps_sampled: 2300000\n",
      "    num_steps_trained: 2300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.409843085207277e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4742630124092102\n",
      "      kl: 0.02929564006626606\n",
      "      policy_loss: 0.0031567090190947056\n",
      "      total_loss: 57.6562614440918\n",
      "      vf_explained_var: 0.8411227464675903\n",
      "      vf_loss: 57.653106689453125\n",
      "    sample_time_ms: 18317.537\n",
      "    update_time_ms: 5.497\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.26687275905617\n",
      "  time_since_restore: 5103.784982681274\n",
      "  time_this_iter_s: 22.207995414733887\n",
      "  time_total_s: 5103.784982681274\n",
      "  timestamp: 1553126908\n",
      "  timesteps_since_restore: 2300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2300000\n",
      "  training_iteration: 230\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5103 s, 230 iter, 2300000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-08-50\n",
      "  done: false\n",
      "  episode_len_mean: 82.33884297520662\n",
      "  episode_reward_max: 385.2817201969968\n",
      "  episode_reward_mean: 127.77331701528085\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 24706\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3676.393\n",
      "    load_time_ms: 1.661\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.409843085207277e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49778318405151367\n",
      "      kl: 0.03868958726525307\n",
      "      policy_loss: 0.007584706414490938\n",
      "      total_loss: 55.765724182128906\n",
      "      vf_explained_var: 0.8616606593132019\n",
      "      vf_loss: 55.75813674926758\n",
      "    sample_time_ms: 18250.857\n",
      "    update_time_ms: 5.425\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.88665850764042\n",
      "  time_since_restore: 5125.225764989853\n",
      "  time_this_iter_s: 21.44078230857849\n",
      "  time_total_s: 5125.225764989853\n",
      "  timestamp: 1553126930\n",
      "  timesteps_since_restore: 2310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 231\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5125 s, 231 iter, 2310000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-09-12\n",
      "  done: false\n",
      "  episode_len_mean: 80.26984126984127\n",
      "  episode_reward_max: 387.9173554265413\n",
      "  episode_reward_mean: 110.09966542418967\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 24832\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.04\n",
      "    load_time_ms: 1.741\n",
      "    num_steps_sampled: 2320000\n",
      "    num_steps_trained: 2320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.409843085207277e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49784934520721436\n",
      "      kl: 0.040804021060466766\n",
      "      policy_loss: 0.00719554303213954\n",
      "      total_loss: 60.682674407958984\n",
      "      vf_explained_var: 0.8489169478416443\n",
      "      vf_loss: 60.675479888916016\n",
      "    sample_time_ms: 18265.088\n",
      "    update_time_ms: 5.726\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.049832712094826\n",
      "  time_since_restore: 5147.12974524498\n",
      "  time_this_iter_s: 21.903980255126953\n",
      "  time_total_s: 5147.12974524498\n",
      "  timestamp: 1553126952\n",
      "  timesteps_since_restore: 2320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2320000\n",
      "  training_iteration: 232\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5147 s, 232 iter, 2320000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-09-33\n",
      "  done: false\n",
      "  episode_len_mean: 75.7175572519084\n",
      "  episode_reward_max: 383.3194105698339\n",
      "  episode_reward_mean: 81.6394713822939\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 24963\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.168\n",
      "    load_time_ms: 1.74\n",
      "    num_steps_sampled: 2330000\n",
      "    num_steps_trained: 2330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1114766954256388e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5077205300331116\n",
      "      kl: 0.03670569509267807\n",
      "      policy_loss: 0.008638676255941391\n",
      "      total_loss: 55.02765655517578\n",
      "      vf_explained_var: 0.8840662837028503\n",
      "      vf_loss: 55.01901626586914\n",
      "    sample_time_ms: 18156.608\n",
      "    update_time_ms: 5.711\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.81973569114696\n",
      "  time_since_restore: 5168.393890142441\n",
      "  time_this_iter_s: 21.264144897460938\n",
      "  time_total_s: 5168.393890142441\n",
      "  timestamp: 1553126973\n",
      "  timesteps_since_restore: 2330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2330000\n",
      "  training_iteration: 233\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5168 s, 233 iter, 2330000 ts, 81.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-09-55\n",
      "  done: false\n",
      "  episode_len_mean: 85.7948717948718\n",
      "  episode_reward_max: 386.2565041282745\n",
      "  episode_reward_mean: 148.92050201559599\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 25080\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.893\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1114766954256388e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48425421118736267\n",
      "      kl: 0.10212188959121704\n",
      "      policy_loss: 0.011765009723603725\n",
      "      total_loss: 69.49240112304688\n",
      "      vf_explained_var: 0.8127070069313049\n",
      "      vf_loss: 69.48064422607422\n",
      "    sample_time_ms: 18169.481\n",
      "    update_time_ms: 5.437\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.46025100779798\n",
      "  time_since_restore: 5190.665769815445\n",
      "  time_this_iter_s: 22.27187967300415\n",
      "  time_total_s: 5190.665769815445\n",
      "  timestamp: 1553126995\n",
      "  timesteps_since_restore: 2340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 234\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5190 s, 234 iter, 2340000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-10-17\n",
      "  done: false\n",
      "  episode_len_mean: 81.72357723577235\n",
      "  episode_reward_max: 385.188606668639\n",
      "  episode_reward_mean: 118.37058810334808\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 25203\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.722\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 2350000\n",
      "    num_steps_trained: 2350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6672148880420934e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5180338621139526\n",
      "      kl: 0.05816899985074997\n",
      "      policy_loss: 0.00405114283785224\n",
      "      total_loss: 73.08187866210938\n",
      "      vf_explained_var: 0.8193598985671997\n",
      "      vf_loss: 73.07782745361328\n",
      "    sample_time_ms: 18194.597\n",
      "    update_time_ms: 5.312\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.185294051674056\n",
      "  time_since_restore: 5212.623949766159\n",
      "  time_this_iter_s: 21.95817995071411\n",
      "  time_total_s: 5212.623949766159\n",
      "  timestamp: 1553127017\n",
      "  timesteps_since_restore: 2350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2350000\n",
      "  training_iteration: 235\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5212 s, 235 iter, 2350000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-10-39\n",
      "  done: false\n",
      "  episode_len_mean: 84.33898305084746\n",
      "  episode_reward_max: 386.06963172017197\n",
      "  episode_reward_mean: 135.43237178014098\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 25321\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.822\n",
      "    load_time_ms: 1.727\n",
      "    num_steps_sampled: 2360000\n",
      "    num_steps_trained: 2360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.5008221769667753e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5065528750419617\n",
      "      kl: 0.05559512972831726\n",
      "      policy_loss: 0.010374434292316437\n",
      "      total_loss: 59.89916229248047\n",
      "      vf_explained_var: 0.842945396900177\n",
      "      vf_loss: 59.88878631591797\n",
      "    sample_time_ms: 18166.098\n",
      "    update_time_ms: 5.368\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.71618589007048\n",
      "  time_since_restore: 5234.556921243668\n",
      "  time_this_iter_s: 21.932971477508545\n",
      "  time_total_s: 5234.556921243668\n",
      "  timestamp: 1553127039\n",
      "  timesteps_since_restore: 2360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2360000\n",
      "  training_iteration: 236\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5234 s, 236 iter, 2360000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-11-02\n",
      "  done: false\n",
      "  episode_len_mean: 87.43478260869566\n",
      "  episode_reward_max: 383.3270780802055\n",
      "  episode_reward_mean: 159.9030039358329\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 25436\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.438\n",
      "    load_time_ms: 1.726\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.751233885835622e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49852678179740906\n",
      "      kl: 0.04806840792298317\n",
      "      policy_loss: 0.009193835780024529\n",
      "      total_loss: 57.08646774291992\n",
      "      vf_explained_var: 0.8349766731262207\n",
      "      vf_loss: 57.077274322509766\n",
      "    sample_time_ms: 18194.762\n",
      "    update_time_ms: 5.785\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.95150196791646\n",
      "  time_since_restore: 5256.911041259766\n",
      "  time_this_iter_s: 22.354120016098022\n",
      "  time_total_s: 5256.911041259766\n",
      "  timestamp: 1553127062\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 237\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5256 s, 237 iter, 2370000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-11-23\n",
      "  done: false\n",
      "  episode_len_mean: 78.83333333333333\n",
      "  episode_reward_max: 384.6533103078905\n",
      "  episode_reward_mean: 100.84405487257412\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 25562\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.03\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 2380000\n",
      "    num_steps_trained: 2380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.626850208367974e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5509334802627563\n",
      "      kl: 0.04975606128573418\n",
      "      policy_loss: 0.010316151194274426\n",
      "      total_loss: 52.6762809753418\n",
      "      vf_explained_var: 0.8816404938697815\n",
      "      vf_loss: 52.665958404541016\n",
      "    sample_time_ms: 18096.445\n",
      "    update_time_ms: 5.672\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.42202743628705\n",
      "  time_since_restore: 5278.0950264930725\n",
      "  time_this_iter_s: 21.183985233306885\n",
      "  time_total_s: 5278.0950264930725\n",
      "  timestamp: 1553127083\n",
      "  timesteps_since_restore: 2380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2380000\n",
      "  training_iteration: 238\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5278 s, 238 iter, 2380000 ts, 101 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-11-45\n",
      "  done: false\n",
      "  episode_len_mean: 83.5\n",
      "  episode_reward_max: 385.65078539772406\n",
      "  episode_reward_mean: 128.8611077710924\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 25682\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.302\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 2390000\n",
      "    num_steps_trained: 2390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.440274692166502e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5550723075866699\n",
      "      kl: 0.05820460245013237\n",
      "      policy_loss: 0.00454149441793561\n",
      "      total_loss: 62.63767623901367\n",
      "      vf_explained_var: 0.8390203714370728\n",
      "      vf_loss: 62.63313293457031\n",
      "    sample_time_ms: 18128.788\n",
      "    update_time_ms: 6.315\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.4305538855462\n",
      "  time_since_restore: 5300.049645662308\n",
      "  time_this_iter_s: 21.95461916923523\n",
      "  time_total_s: 5300.049645662308\n",
      "  timestamp: 1553127105\n",
      "  timesteps_since_restore: 2390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2390000\n",
      "  training_iteration: 239\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5300 s, 239 iter, 2390000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-12-07\n",
      "  done: false\n",
      "  episode_len_mean: 81.7603305785124\n",
      "  episode_reward_max: 385.11071448447933\n",
      "  episode_reward_mean: 117.6674737039985\n",
      "  episode_reward_min: -168.63365446886064\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 25803\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.893\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.266041451979159e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5755168795585632\n",
      "      kl: 0.0363570973277092\n",
      "      policy_loss: 0.004226685501635075\n",
      "      total_loss: 70.77867126464844\n",
      "      vf_explained_var: 0.8284019231796265\n",
      "      vf_loss: 70.77444458007812\n",
      "    sample_time_ms: 18072.167\n",
      "    update_time_ms: 6.245\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.83373685199925\n",
      "  time_since_restore: 5321.723359584808\n",
      "  time_this_iter_s: 21.67371392250061\n",
      "  time_total_s: 5321.723359584808\n",
      "  timestamp: 1553127127\n",
      "  timesteps_since_restore: 2400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 240\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5321 s, 240 iter, 2400000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-12-29\n",
      "  done: false\n",
      "  episode_len_mean: 79.078125\n",
      "  episode_reward_max: 382.8685946161475\n",
      "  episode_reward_mean: 98.77683232066012\n",
      "  episode_reward_min: -164.8455907811785\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 25931\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.798\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 2410000\n",
      "    num_steps_trained: 2410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.266041451979159e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5607596039772034\n",
      "      kl: 0.08562658727169037\n",
      "      policy_loss: 0.017483191564679146\n",
      "      total_loss: 49.3618278503418\n",
      "      vf_explained_var: 0.8895474672317505\n",
      "      vf_loss: 49.34434509277344\n",
      "    sample_time_ms: 18150.746\n",
      "    update_time_ms: 6.326\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.38841616033005\n",
      "  time_since_restore: 5343.982050657272\n",
      "  time_this_iter_s: 22.25869107246399\n",
      "  time_total_s: 5343.982050657272\n",
      "  timestamp: 1553127149\n",
      "  timesteps_since_restore: 2410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2410000\n",
      "  training_iteration: 241\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5343 s, 241 iter, 2410000 ts, 98.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-12-51\n",
      "  done: false\n",
      "  episode_len_mean: 79.7063492063492\n",
      "  episode_reward_max: 386.19221843397384\n",
      "  episode_reward_mean: 98.61064660774188\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 26057\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.59\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 2420000\n",
      "    num_steps_trained: 2420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8990622606867998e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5849102139472961\n",
      "      kl: 0.03222528100013733\n",
      "      policy_loss: 0.006953381467610598\n",
      "      total_loss: 81.0576400756836\n",
      "      vf_explained_var: 0.8172940015792847\n",
      "      vf_loss: 81.05069732666016\n",
      "    sample_time_ms: 18178.384\n",
      "    update_time_ms: 6.092\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.30532330387095\n",
      "  time_since_restore: 5366.077955007553\n",
      "  time_this_iter_s: 22.09590435028076\n",
      "  time_total_s: 5366.077955007553\n",
      "  timestamp: 1553127171\n",
      "  timesteps_since_restore: 2420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2420000\n",
      "  training_iteration: 242\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5366 s, 242 iter, 2420000 ts, 98.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-13-12\n",
      "  done: false\n",
      "  episode_len_mean: 78.38582677165354\n",
      "  episode_reward_max: 385.81123765994477\n",
      "  episode_reward_mean: 90.03954868555779\n",
      "  episode_reward_min: -162.93605638202666\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 26184\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.482\n",
      "    load_time_ms: 1.428\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8990622606867998e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5706660747528076\n",
      "      kl: 0.052696265280246735\n",
      "      policy_loss: 0.006231025326997042\n",
      "      total_loss: 72.80728912353516\n",
      "      vf_explained_var: 0.8409300446510315\n",
      "      vf_loss: 72.80105590820312\n",
      "    sample_time_ms: 18132.757\n",
      "    update_time_ms: 6.207\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.01977434277888\n",
      "  time_since_restore: 5387.0718722343445\n",
      "  time_this_iter_s: 20.993917226791382\n",
      "  time_total_s: 5387.0718722343445\n",
      "  timestamp: 1553127192\n",
      "  timesteps_since_restore: 2430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 243\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5387 s, 243 iter, 2430000 ts, 90 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-13-33\n",
      "  done: false\n",
      "  episode_len_mean: 78.62698412698413\n",
      "  episode_reward_max: 383.0176405699359\n",
      "  episode_reward_mean: 89.61548251906567\n",
      "  episode_reward_min: -164.73511708804608\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 26310\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.554\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 2440000\n",
      "    num_steps_trained: 2440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.8485929774398934e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.59356689453125\n",
      "      kl: 0.052834559231996536\n",
      "      policy_loss: 0.004867561161518097\n",
      "      total_loss: 62.78246307373047\n",
      "      vf_explained_var: 0.861112654209137\n",
      "      vf_loss: 62.77759552001953\n",
      "    sample_time_ms: 18026.817\n",
      "    update_time_ms: 6.236\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.80774125953283\n",
      "  time_since_restore: 5408.285957574844\n",
      "  time_this_iter_s: 21.214085340499878\n",
      "  time_total_s: 5408.285957574844\n",
      "  timestamp: 1553127213\n",
      "  timesteps_since_restore: 2440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2440000\n",
      "  training_iteration: 244\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5408 s, 244 iter, 2440000 ts, 89.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-13-55\n",
      "  done: false\n",
      "  episode_len_mean: 79.71653543307086\n",
      "  episode_reward_max: 384.4483770297176\n",
      "  episode_reward_mean: 110.6401967012101\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 26437\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.498\n",
      "    load_time_ms: 1.471\n",
      "    num_steps_sampled: 2450000\n",
      "    num_steps_trained: 2450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.272889797032085e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.585312008857727\n",
      "      kl: 0.0454171858727932\n",
      "      policy_loss: 0.00870171096175909\n",
      "      total_loss: 58.60863494873047\n",
      "      vf_explained_var: 0.8638207912445068\n",
      "      vf_loss: 58.59993362426758\n",
      "    sample_time_ms: 18023.477\n",
      "    update_time_ms: 6.239\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.32009835060505\n",
      "  time_since_restore: 5430.199291467667\n",
      "  time_this_iter_s: 21.913333892822266\n",
      "  time_total_s: 5430.199291467667\n",
      "  timestamp: 1553127235\n",
      "  timesteps_since_restore: 2450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2450000\n",
      "  training_iteration: 245\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5430 s, 245 iter, 2450000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-14-17\n",
      "  done: false\n",
      "  episode_len_mean: 81.50819672131148\n",
      "  episode_reward_max: 383.21828802545076\n",
      "  episode_reward_mean: 112.85561104359573\n",
      "  episode_reward_min: -160.43563321336745\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 26559\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.212\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.40933419923976e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6009336709976196\n",
      "      kl: 0.05625338479876518\n",
      "      policy_loss: 0.005755349528044462\n",
      "      total_loss: 55.626277923583984\n",
      "      vf_explained_var: 0.8675886988639832\n",
      "      vf_loss: 55.62051773071289\n",
      "    sample_time_ms: 18006.915\n",
      "    update_time_ms: 6.114\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.427805521797865\n",
      "  time_since_restore: 5451.942589044571\n",
      "  time_this_iter_s: 21.743297576904297\n",
      "  time_total_s: 5451.942589044571\n",
      "  timestamp: 1553127257\n",
      "  timesteps_since_restore: 2460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 246\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5451 s, 246 iter, 2460000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-14-39\n",
      "  done: false\n",
      "  episode_len_mean: 81.6639344262295\n",
      "  episode_reward_max: 384.93548213117134\n",
      "  episode_reward_mean: 124.68482806577668\n",
      "  episode_reward_min: -164.86897385427\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 26681\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.218\n",
      "    load_time_ms: 1.399\n",
      "    num_steps_sampled: 2470000\n",
      "    num_steps_trained: 2470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.61400196060413e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5992329120635986\n",
      "      kl: 0.06410840153694153\n",
      "      policy_loss: 0.00940321758389473\n",
      "      total_loss: 63.69034194946289\n",
      "      vf_explained_var: 0.837614893913269\n",
      "      vf_loss: 63.680946350097656\n",
      "    sample_time_ms: 17943.585\n",
      "    update_time_ms: 5.713\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.34241403288833\n",
      "  time_since_restore: 5473.621432065964\n",
      "  time_this_iter_s: 21.678843021392822\n",
      "  time_total_s: 5473.621432065964\n",
      "  timestamp: 1553127279\n",
      "  timesteps_since_restore: 2470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2470000\n",
      "  training_iteration: 247\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5473 s, 247 iter, 2470000 ts, 125 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-15-01\n",
      "  done: false\n",
      "  episode_len_mean: 78.91338582677166\n",
      "  episode_reward_max: 382.4884436095499\n",
      "  episode_reward_mean: 98.62767323874716\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 26808\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.092\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 2480000\n",
      "    num_steps_trained: 2480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.442100062480048e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.577881395816803\n",
      "      kl: 0.05718936026096344\n",
      "      policy_loss: 0.005706785246729851\n",
      "      total_loss: 63.007938385009766\n",
      "      vf_explained_var: 0.8594492673873901\n",
      "      vf_loss: 63.002227783203125\n",
      "    sample_time_ms: 18008.895\n",
      "    update_time_ms: 5.674\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.31383661937357\n",
      "  time_since_restore: 5495.509959697723\n",
      "  time_this_iter_s: 21.888527631759644\n",
      "  time_total_s: 5495.509959697723\n",
      "  timestamp: 1553127301\n",
      "  timesteps_since_restore: 2480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2480000\n",
      "  training_iteration: 248\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5495 s, 248 iter, 2480000 ts, 98.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-15-23\n",
      "  done: false\n",
      "  episode_len_mean: 79.976\n",
      "  episode_reward_max: 385.57683268140096\n",
      "  episode_reward_mean: 104.90662560556406\n",
      "  episode_reward_min: -168.64209253808497\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 26933\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.274\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.163150623115664e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6052190065383911\n",
      "      kl: 0.05434795096516609\n",
      "      policy_loss: 0.009301829151809216\n",
      "      total_loss: 63.50457000732422\n",
      "      vf_explained_var: 0.855083167552948\n",
      "      vf_loss: 63.49526596069336\n",
      "    sample_time_ms: 18030.029\n",
      "    update_time_ms: 5.081\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.453312802782015\n",
      "  time_since_restore: 5517.629939556122\n",
      "  time_this_iter_s: 22.119979858398438\n",
      "  time_total_s: 5517.629939556122\n",
      "  timestamp: 1553127323\n",
      "  timesteps_since_restore: 2490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 249\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5517 s, 249 iter, 2490000 ts, 105 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-15-45\n",
      "  done: false\n",
      "  episode_len_mean: 87.43859649122807\n",
      "  episode_reward_max: 385.5552638425384\n",
      "  episode_reward_mean: 161.19844943565903\n",
      "  episode_reward_min: -162.9629425593281\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 27047\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.224\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 2500000\n",
      "    num_steps_trained: 2500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.244725140580108e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5969668030738831\n",
      "      kl: 0.04404321312904358\n",
      "      policy_loss: 0.008016065694391727\n",
      "      total_loss: 57.1723518371582\n",
      "      vf_explained_var: 0.8353948593139648\n",
      "      vf_loss: 57.16432571411133\n",
      "    sample_time_ms: 18096.761\n",
      "    update_time_ms: 5.254\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.59922471782951\n",
      "  time_since_restore: 5539.955064535141\n",
      "  time_this_iter_s: 22.325124979019165\n",
      "  time_total_s: 5539.955064535141\n",
      "  timestamp: 1553127345\n",
      "  timesteps_since_restore: 2500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2500000\n",
      "  training_iteration: 250\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5539 s, 250 iter, 2500000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-16-06\n",
      "  done: false\n",
      "  episode_len_mean: 76.25\n",
      "  episode_reward_max: 387.83124910404496\n",
      "  episode_reward_mean: 77.66658851195149\n",
      "  episode_reward_min: -162.62167001887798\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 27179\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.958\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 2510000\n",
      "    num_steps_trained: 2510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.867088902010244e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6321635842323303\n",
      "      kl: 0.048901356756687164\n",
      "      policy_loss: 0.008901760913431644\n",
      "      total_loss: 74.85006713867188\n",
      "      vf_explained_var: 0.8399693369865417\n",
      "      vf_loss: 74.84115600585938\n",
      "    sample_time_ms: 17990.293\n",
      "    update_time_ms: 5.251\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.83329425597575\n",
      "  time_since_restore: 5561.197926998138\n",
      "  time_this_iter_s: 21.242862462997437\n",
      "  time_total_s: 5561.197926998138\n",
      "  timestamp: 1553127366\n",
      "  timesteps_since_restore: 2510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2510000\n",
      "  training_iteration: 251\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5561 s, 251 iter, 2510000 ts, 77.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-16-28\n",
      "  done: false\n",
      "  episode_len_mean: 76.09160305343511\n",
      "  episode_reward_max: 386.7756848858672\n",
      "  episode_reward_mean: 80.17350800531278\n",
      "  episode_reward_min: -168.66292848416805\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 27310\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.243\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.300631500130794e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.608016312122345\n",
      "      kl: 0.0431203618645668\n",
      "      policy_loss: 0.006424223072826862\n",
      "      total_loss: 61.91879653930664\n",
      "      vf_explained_var: 0.8665358424186707\n",
      "      vf_loss: 61.912384033203125\n",
      "    sample_time_ms: 17925.515\n",
      "    update_time_ms: 5.234\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.086754002656384\n",
      "  time_since_restore: 5582.65957403183\n",
      "  time_this_iter_s: 21.461647033691406\n",
      "  time_total_s: 5582.65957403183\n",
      "  timestamp: 1553127388\n",
      "  timesteps_since_restore: 2520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 252\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5582 s, 252 iter, 2520000 ts, 80.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-16-49\n",
      "  done: false\n",
      "  episode_len_mean: 78.6796875\n",
      "  episode_reward_max: 382.5175728393999\n",
      "  episode_reward_mean: 98.12081787373604\n",
      "  episode_reward_min: -166.84911101969718\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 27438\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.659\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 2530000\n",
      "    num_steps_trained: 2530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.095094804428958e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5974339246749878\n",
      "      kl: 0.03509178385138512\n",
      "      policy_loss: 0.008510014973580837\n",
      "      total_loss: 56.51344680786133\n",
      "      vf_explained_var: 0.8719803094863892\n",
      "      vf_loss: 56.50493240356445\n",
      "    sample_time_ms: 17979.701\n",
      "    update_time_ms: 5.125\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.06040893686801\n",
      "  time_since_restore: 5604.0497217178345\n",
      "  time_this_iter_s: 21.39014768600464\n",
      "  time_total_s: 5604.0497217178345\n",
      "  timestamp: 1553127409\n",
      "  timesteps_since_restore: 2530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2530000\n",
      "  training_iteration: 253\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5604 s, 253 iter, 2530000 ts, 98.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-17-11\n",
      "  done: false\n",
      "  episode_len_mean: 78.09375\n",
      "  episode_reward_max: 384.42821984408573\n",
      "  episode_reward_mean: 91.46366842425218\n",
      "  episode_reward_min: -166.6933181116247\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 27566\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.979\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 2540000\n",
      "    num_steps_trained: 2540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.095094804428958e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6056999564170837\n",
      "      kl: 0.036827217787504196\n",
      "      policy_loss: 0.008829152211546898\n",
      "      total_loss: 56.785438537597656\n",
      "      vf_explained_var: 0.8747501969337463\n",
      "      vf_loss: 56.77660369873047\n",
      "    sample_time_ms: 18015.48\n",
      "    update_time_ms: 5.285\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.73183421212609\n",
      "  time_since_restore: 5625.706447601318\n",
      "  time_this_iter_s: 21.656725883483887\n",
      "  time_total_s: 5625.706447601318\n",
      "  timestamp: 1553127431\n",
      "  timesteps_since_restore: 2540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2540000\n",
      "  training_iteration: 254\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5625 s, 254 iter, 2540000 ts, 91.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-17-33\n",
      "  done: false\n",
      "  episode_len_mean: 76.22137404580153\n",
      "  episode_reward_max: 382.6410551970253\n",
      "  episode_reward_mean: 77.84505574894862\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 27697\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.663\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.095094804428958e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6227412223815918\n",
      "      kl: 0.09260853379964828\n",
      "      policy_loss: 0.008120142854750156\n",
      "      total_loss: 68.66718292236328\n",
      "      vf_explained_var: 0.8592768907546997\n",
      "      vf_loss: 68.6590576171875\n",
      "    sample_time_ms: 17986.473\n",
      "    update_time_ms: 5.281\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.922527874474326\n",
      "  time_since_restore: 5647.3263392448425\n",
      "  time_this_iter_s: 21.61989164352417\n",
      "  time_total_s: 5647.3263392448425\n",
      "  timestamp: 1553127453\n",
      "  timesteps_since_restore: 2550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 255\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5647 s, 255 iter, 2550000 ts, 77.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-17-54\n",
      "  done: false\n",
      "  episode_len_mean: 82.9\n",
      "  episode_reward_max: 382.6999302973403\n",
      "  episode_reward_mean: 132.7137859341935\n",
      "  episode_reward_min: -166.73175169857979\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 27817\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.837\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 2560000\n",
      "    num_steps_trained: 2560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6426424184016737e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.612988293170929\n",
      "      kl: 0.04836096987128258\n",
      "      policy_loss: 0.005689037032425404\n",
      "      total_loss: 51.90997314453125\n",
      "      vf_explained_var: 0.8641381859779358\n",
      "      vf_loss: 51.90428161621094\n",
      "    sample_time_ms: 17969.197\n",
      "    update_time_ms: 5.332\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.35689296709675\n",
      "  time_since_restore: 5668.889761924744\n",
      "  time_this_iter_s: 21.563422679901123\n",
      "  time_total_s: 5668.889761924744\n",
      "  timestamp: 1553127474\n",
      "  timesteps_since_restore: 2560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2560000\n",
      "  training_iteration: 256\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5668 s, 256 iter, 2560000 ts, 133 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-18-16\n",
      "  done: false\n",
      "  episode_len_mean: 84.96581196581197\n",
      "  episode_reward_max: 383.8220836079412\n",
      "  episode_reward_mean: 135.8975866922314\n",
      "  episode_reward_min: -166.69465526434422\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 27934\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.763\n",
      "    load_time_ms: 1.733\n",
      "    num_steps_sampled: 2570000\n",
      "    num_steps_trained: 2570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4639631511464777e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6040240526199341\n",
      "      kl: 0.04501760005950928\n",
      "      policy_loss: 0.009044800885021687\n",
      "      total_loss: 64.11898803710938\n",
      "      vf_explained_var: 0.8276275992393494\n",
      "      vf_loss: 64.10993957519531\n",
      "    sample_time_ms: 17922.988\n",
      "    update_time_ms: 5.365\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.94879334611572\n",
      "  time_since_restore: 5690.136935949326\n",
      "  time_this_iter_s: 21.24717402458191\n",
      "  time_total_s: 5690.136935949326\n",
      "  timestamp: 1553127496\n",
      "  timesteps_since_restore: 2570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2570000\n",
      "  training_iteration: 257\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5690 s, 257 iter, 2570000 ts, 136 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 80.08\n",
      "  episode_reward_max: 384.7241173517447\n",
      "  episode_reward_mean: 108.30431110429731\n",
      "  episode_reward_min: -168.67770051154136\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 28059\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.279\n",
      "    load_time_ms: 1.749\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.695944832598835e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6256616115570068\n",
      "      kl: 0.04214055836200714\n",
      "      policy_loss: 0.005332449451088905\n",
      "      total_loss: 64.76847076416016\n",
      "      vf_explained_var: 0.8440409898757935\n",
      "      vf_loss: 64.76313018798828\n",
      "    sample_time_ms: 17907.949\n",
      "    update_time_ms: 5.247\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.152155552148656\n",
      "  time_since_restore: 5711.835628271103\n",
      "  time_this_iter_s: 21.698692321777344\n",
      "  time_total_s: 5711.835628271103\n",
      "  timestamp: 1553127517\n",
      "  timesteps_since_restore: 2580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 258\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5711 s, 258 iter, 2580000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-18-59\n",
      "  done: false\n",
      "  episode_len_mean: 84.34166666666667\n",
      "  episode_reward_max: 386.0451647606553\n",
      "  episode_reward_mean: 137.5545744078973\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 28179\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.704\n",
      "    load_time_ms: 1.788\n",
      "    num_steps_sampled: 2590000\n",
      "    num_steps_trained: 2590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.5439183076894365e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.603043794631958\n",
      "      kl: 0.047186966985464096\n",
      "      policy_loss: 0.011298911646008492\n",
      "      total_loss: 63.499881744384766\n",
      "      vf_explained_var: 0.8298976421356201\n",
      "      vf_loss: 63.488582611083984\n",
      "    sample_time_ms: 17867.363\n",
      "    update_time_ms: 5.17\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.77728720394863\n",
      "  time_since_restore: 5733.574056386948\n",
      "  time_this_iter_s: 21.738428115844727\n",
      "  time_total_s: 5733.574056386948\n",
      "  timestamp: 1553127539\n",
      "  timesteps_since_restore: 2590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2590000\n",
      "  training_iteration: 259\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5733 s, 259 iter, 2590000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-19-21\n",
      "  done: false\n",
      "  episode_len_mean: 81.60655737704919\n",
      "  episode_reward_max: 387.21743361274275\n",
      "  episode_reward_mean: 119.0339805638705\n",
      "  episode_reward_min: -162.71902595731257\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 28301\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.777\n",
      "    load_time_ms: 1.795\n",
      "    num_steps_sampled: 2600000\n",
      "    num_steps_trained: 2600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.315878096808865e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5980848670005798\n",
      "      kl: 0.043964825570583344\n",
      "      policy_loss: 0.004641790874302387\n",
      "      total_loss: 51.24338150024414\n",
      "      vf_explained_var: 0.8736392259597778\n",
      "      vf_loss: 51.238739013671875\n",
      "    sample_time_ms: 17795.859\n",
      "    update_time_ms: 5.035\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.51699028193525\n",
      "  time_since_restore: 5755.1552946567535\n",
      "  time_this_iter_s: 21.581238269805908\n",
      "  time_total_s: 5755.1552946567535\n",
      "  timestamp: 1553127561\n",
      "  timesteps_since_restore: 2600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2600000\n",
      "  training_iteration: 260\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5755 s, 260 iter, 2600000 ts, 119 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-19-42\n",
      "  done: false\n",
      "  episode_len_mean: 80.41129032258064\n",
      "  episode_reward_max: 388.0986643574806\n",
      "  episode_reward_mean: 105.83984183149185\n",
      "  episode_reward_min: -166.72337168594836\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 28425\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.005\n",
      "    load_time_ms: 1.848\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2473815451147403e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5974587202072144\n",
      "      kl: 0.03888419270515442\n",
      "      policy_loss: 0.004331781528890133\n",
      "      total_loss: 61.28101348876953\n",
      "      vf_explained_var: 0.8598683476448059\n",
      "      vf_loss: 61.27668762207031\n",
      "    sample_time_ms: 17827.923\n",
      "    update_time_ms: 4.95\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.919920915745934\n",
      "  time_since_restore: 5776.801157712936\n",
      "  time_this_iter_s: 21.64586305618286\n",
      "  time_total_s: 5776.801157712936\n",
      "  timestamp: 1553127582\n",
      "  timesteps_since_restore: 2610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 261\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5776 s, 261 iter, 2610000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-20-04\n",
      "  done: false\n",
      "  episode_len_mean: 81.5609756097561\n",
      "  episode_reward_max: 384.7870928953886\n",
      "  episode_reward_mean: 108.37111633698163\n",
      "  episode_reward_min: -164.6664560324812\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 28548\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.902\n",
      "    load_time_ms: 1.816\n",
      "    num_steps_sampled: 2620000\n",
      "    num_steps_trained: 2620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2473815451147403e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5837223529815674\n",
      "      kl: 0.04459179937839508\n",
      "      policy_loss: 0.006394863128662109\n",
      "      total_loss: 42.73031234741211\n",
      "      vf_explained_var: 0.8967756628990173\n",
      "      vf_loss: 42.723915100097656\n",
      "    sample_time_ms: 17839.224\n",
      "    update_time_ms: 4.775\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.18555816849081\n",
      "  time_since_restore: 5798.382606267929\n",
      "  time_this_iter_s: 21.581448554992676\n",
      "  time_total_s: 5798.382606267929\n",
      "  timestamp: 1553127604\n",
      "  timesteps_since_restore: 2620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2620000\n",
      "  training_iteration: 262\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5798 s, 262 iter, 2620000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-20-26\n",
      "  done: false\n",
      "  episode_len_mean: 82.27049180327869\n",
      "  episode_reward_max: 386.5908124756175\n",
      "  episode_reward_mean: 117.86110731585582\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 28670\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.665\n",
      "    load_time_ms: 1.855\n",
      "    num_steps_sampled: 2630000\n",
      "    num_steps_trained: 2630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8710724023754052e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.583728015422821\n",
      "      kl: 0.043605297803878784\n",
      "      policy_loss: 0.004454773385077715\n",
      "      total_loss: 75.85283660888672\n",
      "      vf_explained_var: 0.8200631141662598\n",
      "      vf_loss: 75.84838104248047\n",
      "    sample_time_ms: 17899.525\n",
      "    update_time_ms: 4.892\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.93055365792791\n",
      "  time_since_restore: 5820.355648756027\n",
      "  time_this_iter_s: 21.973042488098145\n",
      "  time_total_s: 5820.355648756027\n",
      "  timestamp: 1553127626\n",
      "  timesteps_since_restore: 2630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2630000\n",
      "  training_iteration: 263\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5820 s, 263 iter, 2630000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-20-48\n",
      "  done: false\n",
      "  episode_len_mean: 83.87288135593221\n",
      "  episode_reward_max: 386.43913659905587\n",
      "  episode_reward_mean: 126.64573061228478\n",
      "  episode_reward_min: -166.84221273275853\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 28788\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.346\n",
      "    load_time_ms: 1.837\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.8066087729696973e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5664204359054565\n",
      "      kl: 0.035871926695108414\n",
      "      policy_loss: 0.004303689114749432\n",
      "      total_loss: 64.98292541503906\n",
      "      vf_explained_var: 0.8311948776245117\n",
      "      vf_loss: 64.97863006591797\n",
      "    sample_time_ms: 17918.559\n",
      "    update_time_ms: 4.785\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.3228653061424\n",
      "  time_since_restore: 5842.098670959473\n",
      "  time_this_iter_s: 21.743022203445435\n",
      "  time_total_s: 5842.098670959473\n",
      "  timestamp: 1553127648\n",
      "  timesteps_since_restore: 2640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 264\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5842 s, 264 iter, 2640000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-21-10\n",
      "  done: false\n",
      "  episode_len_mean: 81.59349593495935\n",
      "  episode_reward_max: 388.0291557644809\n",
      "  episode_reward_mean: 113.37349679061941\n",
      "  episode_reward_min: -168.70954420861244\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 28911\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.615\n",
      "    load_time_ms: 1.823\n",
      "    num_steps_sampled: 2650000\n",
      "    num_steps_trained: 2650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.8066087729696973e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6158798336982727\n",
      "      kl: 0.05005577206611633\n",
      "      policy_loss: 0.00725680124014616\n",
      "      total_loss: 60.64878845214844\n",
      "      vf_explained_var: 0.8475369215011597\n",
      "      vf_loss: 60.64152526855469\n",
      "    sample_time_ms: 17910.005\n",
      "    update_time_ms: 5.083\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.686748395309706\n",
      "  time_since_restore: 5863.691601037979\n",
      "  time_this_iter_s: 21.59293007850647\n",
      "  time_total_s: 5863.691601037979\n",
      "  timestamp: 1553127670\n",
      "  timesteps_since_restore: 2650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2650000\n",
      "  training_iteration: 265\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5863 s, 265 iter, 2650000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-21-31\n",
      "  done: false\n",
      "  episode_len_mean: 86.33620689655173\n",
      "  episode_reward_max: 383.3964344588433\n",
      "  episode_reward_mean: 141.81834731472063\n",
      "  episode_reward_min: -160.6697643235588\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 29027\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.147\n",
      "    load_time_ms: 1.779\n",
      "    num_steps_sampled: 2660000\n",
      "    num_steps_trained: 2660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.2099129900479565e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5793448686599731\n",
      "      kl: 0.06049271300435066\n",
      "      policy_loss: 0.008605210110545158\n",
      "      total_loss: 58.85262680053711\n",
      "      vf_explained_var: 0.8429678678512573\n",
      "      vf_loss: 58.844024658203125\n",
      "    sample_time_ms: 17936.179\n",
      "    update_time_ms: 5.118\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.9091736573603\n",
      "  time_since_restore: 5885.540015697479\n",
      "  time_this_iter_s: 21.848414659500122\n",
      "  time_total_s: 5885.540015697479\n",
      "  timestamp: 1553127691\n",
      "  timesteps_since_restore: 2660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2660000\n",
      "  training_iteration: 266\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5885 s, 266 iter, 2660000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-21-54\n",
      "  done: false\n",
      "  episode_len_mean: 78.04724409448819\n",
      "  episode_reward_max: 383.99702788552617\n",
      "  episode_reward_mean: 82.29741628441523\n",
      "  episode_reward_min: -168.64072963925838\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 29154\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.997\n",
      "    load_time_ms: 1.764\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.314869146258756e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6086527109146118\n",
      "      kl: 0.052555352449417114\n",
      "      policy_loss: 0.006499201990664005\n",
      "      total_loss: 65.35802459716797\n",
      "      vf_explained_var: 0.8540846705436707\n",
      "      vf_loss: 65.35151672363281\n",
      "    sample_time_ms: 18069.452\n",
      "    update_time_ms: 5.05\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.14870814220761\n",
      "  time_since_restore: 5908.097935676575\n",
      "  time_this_iter_s: 22.55791997909546\n",
      "  time_total_s: 5908.097935676575\n",
      "  timestamp: 1553127714\n",
      "  timesteps_since_restore: 2670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 267\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5908 s, 267 iter, 2670000 ts, 82.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-22-16\n",
      "  done: false\n",
      "  episode_len_mean: 82.89344262295081\n",
      "  episode_reward_max: 386.8612180032637\n",
      "  episode_reward_mean: 117.1827021388033\n",
      "  episode_reward_min: -166.7351163041258\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 29276\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.341\n",
      "    load_time_ms: 1.748\n",
      "    num_steps_sampled: 2680000\n",
      "    num_steps_trained: 2680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.472304397014492e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6018148064613342\n",
      "      kl: 0.03514900431036949\n",
      "      policy_loss: 0.004991940688341856\n",
      "      total_loss: 72.0516357421875\n",
      "      vf_explained_var: 0.8273593187332153\n",
      "      vf_loss: 72.04663848876953\n",
      "    sample_time_ms: 18095.658\n",
      "    update_time_ms: 5.216\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.59135106940165\n",
      "  time_since_restore: 5930.052123785019\n",
      "  time_this_iter_s: 21.954188108444214\n",
      "  time_total_s: 5930.052123785019\n",
      "  timestamp: 1553127736\n",
      "  timesteps_since_restore: 2680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2680000\n",
      "  training_iteration: 268\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5930 s, 268 iter, 2680000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-22-38\n",
      "  done: false\n",
      "  episode_len_mean: 75.1203007518797\n",
      "  episode_reward_max: 385.4597613794012\n",
      "  episode_reward_mean: 54.13680079622088\n",
      "  episode_reward_min: -164.72142824968338\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 29409\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.239\n",
      "    load_time_ms: 1.71\n",
      "    num_steps_sampled: 2690000\n",
      "    num_steps_trained: 2690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.472304397014492e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6370204091072083\n",
      "      kl: 0.037092097103595734\n",
      "      policy_loss: 0.005789912771433592\n",
      "      total_loss: 86.13525390625\n",
      "      vf_explained_var: 0.8268752694129944\n",
      "      vf_loss: 86.12945556640625\n",
      "    sample_time_ms: 18099.792\n",
      "    update_time_ms: 5.223\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.068400398110448\n",
      "  time_since_restore: 5951.810323476791\n",
      "  time_this_iter_s: 21.75819969177246\n",
      "  time_total_s: 5951.810323476791\n",
      "  timestamp: 1553127758\n",
      "  timesteps_since_restore: 2690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2690000\n",
      "  training_iteration: 269\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5951 s, 269 iter, 2690000 ts, 54.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-23-00\n",
      "  done: false\n",
      "  episode_len_mean: 78.84126984126983\n",
      "  episode_reward_max: 386.14868104623696\n",
      "  episode_reward_mean: 80.80511031231032\n",
      "  episode_reward_min: -166.70600480362415\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 29535\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.857\n",
      "    load_time_ms: 1.647\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.472304397014492e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6383938789367676\n",
      "      kl: 0.062244586646556854\n",
      "      policy_loss: 0.010224456898868084\n",
      "      total_loss: 67.60673522949219\n",
      "      vf_explained_var: 0.8531548976898193\n",
      "      vf_loss: 67.59651184082031\n",
      "    sample_time_ms: 18136.136\n",
      "    update_time_ms: 5.317\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.40255515615516\n",
      "  time_since_restore: 5973.819476366043\n",
      "  time_this_iter_s: 22.00915288925171\n",
      "  time_total_s: 5973.819476366043\n",
      "  timestamp: 1553127780\n",
      "  timesteps_since_restore: 2700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 270\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5973 s, 270 iter, 2700000 ts, 80.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-23-22\n",
      "  done: false\n",
      "  episode_len_mean: 74.6044776119403\n",
      "  episode_reward_max: 385.9266567766969\n",
      "  episode_reward_mean: 58.55105506694158\n",
      "  episode_reward_min: -166.69401794454097\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 29669\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.788\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 2710000\n",
      "    num_steps_trained: 2710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4208454562642664e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6591271758079529\n",
      "      kl: 0.055414922535419464\n",
      "      policy_loss: 0.008766353130340576\n",
      "      total_loss: 67.8625717163086\n",
      "      vf_explained_var: 0.8658526539802551\n",
      "      vf_loss: 67.85381317138672\n",
      "    sample_time_ms: 18154.135\n",
      "    update_time_ms: 5.469\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.27552753347079\n",
      "  time_since_restore: 5995.556195259094\n",
      "  time_this_iter_s: 21.736718893051147\n",
      "  time_total_s: 5995.556195259094\n",
      "  timestamp: 1553127802\n",
      "  timesteps_since_restore: 2710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2710000\n",
      "  training_iteration: 271\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 5995 s, 271 iter, 2710000 ts, 58.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-23-44\n",
      "  done: false\n",
      "  episode_len_mean: 75.1203007518797\n",
      "  episode_reward_max: 386.4104675714382\n",
      "  episode_reward_mean: 50.46901338453802\n",
      "  episode_reward_min: -164.68446391507626\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 29802\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.457\n",
      "    load_time_ms: 1.679\n",
      "    num_steps_sampled: 2720000\n",
      "    num_steps_trained: 2720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1312681166337638e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6734029650688171\n",
      "      kl: 0.03892603889107704\n",
      "      policy_loss: 0.007079760078340769\n",
      "      total_loss: 87.89447784423828\n",
      "      vf_explained_var: 0.8290521502494812\n",
      "      vf_loss: 87.88739776611328\n",
      "    sample_time_ms: 18226.873\n",
      "    update_time_ms: 5.94\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.23450669226901\n",
      "  time_since_restore: 6017.860136508942\n",
      "  time_this_iter_s: 22.303941249847412\n",
      "  time_total_s: 6017.860136508942\n",
      "  timestamp: 1553127824\n",
      "  timesteps_since_restore: 2720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2720000\n",
      "  training_iteration: 272\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6017 s, 272 iter, 2720000 ts, 50.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-24-06\n",
      "  done: false\n",
      "  episode_len_mean: 70.97887323943662\n",
      "  episode_reward_max: 385.39209844315906\n",
      "  episode_reward_mean: 32.92660464456094\n",
      "  episode_reward_min: -168.746576771822\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 29944\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.874\n",
      "    load_time_ms: 1.655\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1312681166337638e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6928834915161133\n",
      "      kl: 0.04417461156845093\n",
      "      policy_loss: 0.005272972397506237\n",
      "      total_loss: 79.14732360839844\n",
      "      vf_explained_var: 0.8559103608131409\n",
      "      vf_loss: 79.14205169677734\n",
      "    sample_time_ms: 18197.545\n",
      "    update_time_ms: 5.82\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.46330232228048\n",
      "  time_since_restore: 6039.570922136307\n",
      "  time_this_iter_s: 21.710785627365112\n",
      "  time_total_s: 6039.570922136307\n",
      "  timestamp: 1553127846\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 273\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6039 s, 273 iter, 2730000 ts, 32.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 77.14615384615385\n",
      "  episode_reward_max: 384.58994088448\n",
      "  episode_reward_mean: 59.13367211635439\n",
      "  episode_reward_min: -164.80683525892735\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 30074\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.339\n",
      "    load_time_ms: 1.657\n",
      "    num_steps_sampled: 2740000\n",
      "    num_steps_trained: 2740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.196902378238553e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6562963724136353\n",
      "      kl: 0.04573729261755943\n",
      "      policy_loss: 0.009861377999186516\n",
      "      total_loss: 82.12828826904297\n",
      "      vf_explained_var: 0.8343433737754822\n",
      "      vf_loss: 82.1184310913086\n",
      "    sample_time_ms: 18227.476\n",
      "    update_time_ms: 5.747\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.56683605817719\n",
      "  time_since_restore: 6061.6446578502655\n",
      "  time_this_iter_s: 22.07373571395874\n",
      "  time_total_s: 6061.6446578502655\n",
      "  timestamp: 1553127868\n",
      "  timesteps_since_restore: 2740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2740000\n",
      "  training_iteration: 274\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6061 s, 274 iter, 2740000 ts, 59.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-24-50\n",
      "  done: false\n",
      "  episode_len_mean: 80.44715447154472\n",
      "  episode_reward_max: 384.5946479625099\n",
      "  episode_reward_mean: 101.08480632111066\n",
      "  episode_reward_min: -168.71043938251972\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 30197\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.109\n",
      "    load_time_ms: 1.635\n",
      "    num_steps_sampled: 2750000\n",
      "    num_steps_trained: 2750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.795353025256743e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6433189511299133\n",
      "      kl: 0.045851364731788635\n",
      "      policy_loss: 0.003556194482371211\n",
      "      total_loss: 70.94438934326172\n",
      "      vf_explained_var: 0.8390927314758301\n",
      "      vf_loss: 70.94083404541016\n",
      "    sample_time_ms: 18269.741\n",
      "    update_time_ms: 5.535\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.542403160555324\n",
      "  time_since_restore: 6083.573545217514\n",
      "  time_this_iter_s: 21.928887367248535\n",
      "  time_total_s: 6083.573545217514\n",
      "  timestamp: 1553127890\n",
      "  timesteps_since_restore: 2750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2750000\n",
      "  training_iteration: 275\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6083 s, 275 iter, 2750000 ts, 101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-25-12\n",
      "  done: false\n",
      "  episode_len_mean: 74.82222222222222\n",
      "  episode_reward_max: 387.1589166692887\n",
      "  episode_reward_mean: 54.72096673938208\n",
      "  episode_reward_min: -168.67368744143488\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 30332\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.99\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.193029808935658e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6991471648216248\n",
      "      kl: 0.043234579265117645\n",
      "      policy_loss: 0.00858102273195982\n",
      "      total_loss: 77.6865234375\n",
      "      vf_explained_var: 0.8486274480819702\n",
      "      vf_loss: 77.67794799804688\n",
      "    sample_time_ms: 18235.999\n",
      "    update_time_ms: 5.442\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.36048336969104\n",
      "  time_since_restore: 6105.264231204987\n",
      "  time_this_iter_s: 21.690685987472534\n",
      "  time_total_s: 6105.264231204987\n",
      "  timestamp: 1553127912\n",
      "  timesteps_since_restore: 2760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 276\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6105 s, 276 iter, 2760000 ts, 54.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-25-33\n",
      "  done: false\n",
      "  episode_len_mean: 73.4888888888889\n",
      "  episode_reward_max: 387.87687928657044\n",
      "  episode_reward_mean: 43.045553865410746\n",
      "  episode_reward_min: -166.81111057528494\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 30467\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.438\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 2770000\n",
      "    num_steps_trained: 2770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0789546339706746e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7034314274787903\n",
      "      kl: 0.05722372233867645\n",
      "      policy_loss: 0.007950173690915108\n",
      "      total_loss: 80.176025390625\n",
      "      vf_explained_var: 0.8482581973075867\n",
      "      vf_loss: 80.1680679321289\n",
      "    sample_time_ms: 18145.751\n",
      "    update_time_ms: 5.433\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.522776932705373\n",
      "  time_since_restore: 6126.9219698905945\n",
      "  time_this_iter_s: 21.65773868560791\n",
      "  time_total_s: 6126.9219698905945\n",
      "  timestamp: 1553127933\n",
      "  timesteps_since_restore: 2770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2770000\n",
      "  training_iteration: 277\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6126 s, 277 iter, 2770000 ts, 43 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-25-55\n",
      "  done: false\n",
      "  episode_len_mean: 69.52413793103449\n",
      "  episode_reward_max: 384.3289492114829\n",
      "  episode_reward_mean: 8.369905720826592\n",
      "  episode_reward_min: -166.73001988836765\n",
      "  episodes_this_iter: 145\n",
      "  episodes_total: 30612\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.624\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 2780000\n",
      "    num_steps_trained: 2780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6184317341155774e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6905251741409302\n",
      "      kl: 0.048746030777692795\n",
      "      policy_loss: 0.004747172351926565\n",
      "      total_loss: 77.7134780883789\n",
      "      vf_explained_var: 0.8652325868606567\n",
      "      vf_loss: 77.708740234375\n",
      "    sample_time_ms: 18105.565\n",
      "    update_time_ms: 5.412\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 4.184952860413288\n",
      "  time_since_restore: 6148.446934461594\n",
      "  time_this_iter_s: 21.524964570999146\n",
      "  time_total_s: 6148.446934461594\n",
      "  timestamp: 1553127955\n",
      "  timesteps_since_restore: 2780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2780000\n",
      "  training_iteration: 278\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6148 s, 278 iter, 2780000 ts, 8.37 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-26-16\n",
      "  done: false\n",
      "  episode_len_mean: 76.38461538461539\n",
      "  episode_reward_max: 388.45708023282606\n",
      "  episode_reward_mean: 59.54401782529733\n",
      "  episode_reward_min: -168.68579322179795\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 30742\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.456\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.427647926434018e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6741744875907898\n",
      "      kl: 0.040286097675561905\n",
      "      policy_loss: 0.004480325151234865\n",
      "      total_loss: 71.36647033691406\n",
      "      vf_explained_var: 0.8554325699806213\n",
      "      vf_loss: 71.36200714111328\n",
      "    sample_time_ms: 18040.487\n",
      "    update_time_ms: 5.45\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.772008912648666\n",
      "  time_since_restore: 6169.573524475098\n",
      "  time_this_iter_s: 21.12659001350403\n",
      "  time_total_s: 6169.573524475098\n",
      "  timestamp: 1553127976\n",
      "  timesteps_since_restore: 2790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 279\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6169 s, 279 iter, 2790000 ts, 59.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-26-38\n",
      "  done: false\n",
      "  episode_len_mean: 73.21167883211679\n",
      "  episode_reward_max: 386.5604935834418\n",
      "  episode_reward_mean: 44.326053977802694\n",
      "  episode_reward_min: -164.6881440959835\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 30879\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.075\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 2800000\n",
      "    num_steps_trained: 2800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.64147254017233e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6827975511550903\n",
      "      kl: 0.04041138291358948\n",
      "      policy_loss: 0.006473093293607235\n",
      "      total_loss: 94.81243133544922\n",
      "      vf_explained_var: 0.8138019442558289\n",
      "      vf_loss: 94.80596160888672\n",
      "    sample_time_ms: 18032.541\n",
      "    update_time_ms: 5.401\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.16302698890134\n",
      "  time_since_restore: 6191.4599351882935\n",
      "  time_this_iter_s: 21.8864107131958\n",
      "  time_total_s: 6191.4599351882935\n",
      "  timestamp: 1553127998\n",
      "  timesteps_since_restore: 2800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2800000\n",
      "  training_iteration: 280\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6191 s, 280 iter, 2800000 ts, 44.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-27-00\n",
      "  done: false\n",
      "  episode_len_mean: 74.47014925373135\n",
      "  episode_reward_max: 389.24276696399295\n",
      "  episode_reward_mean: 52.20120592037583\n",
      "  episode_reward_min: -166.7460591044092\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 31013\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.309\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 2810000\n",
      "    num_steps_trained: 2810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.462207509215888e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6953204274177551\n",
      "      kl: 0.057247344404459\n",
      "      policy_loss: 0.010823491029441357\n",
      "      total_loss: 78.68229675292969\n",
      "      vf_explained_var: 0.8438186645507812\n",
      "      vf_loss: 78.67147064208984\n",
      "    sample_time_ms: 18076.756\n",
      "    update_time_ms: 5.271\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.100602960187906\n",
      "  time_since_restore: 6213.639204025269\n",
      "  time_this_iter_s: 22.179268836975098\n",
      "  time_total_s: 6213.639204025269\n",
      "  timestamp: 1553128020\n",
      "  timesteps_since_restore: 2810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2810000\n",
      "  training_iteration: 281\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6213 s, 281 iter, 2810000 ts, 52.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-27-22\n",
      "  done: false\n",
      "  episode_len_mean: 74.2910447761194\n",
      "  episode_reward_max: 385.87605416684374\n",
      "  episode_reward_mean: 54.97688918841094\n",
      "  episode_reward_min: -166.78605452772618\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 31147\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.324\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.193310613302529e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6780028939247131\n",
      "      kl: 0.050273772329092026\n",
      "      policy_loss: 0.01146452222019434\n",
      "      total_loss: 74.06967163085938\n",
      "      vf_explained_var: 0.8537811040878296\n",
      "      vf_loss: 74.0582046508789\n",
      "    sample_time_ms: 18026.703\n",
      "    update_time_ms: 4.812\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.48844459420547\n",
      "  time_since_restore: 6235.455602407455\n",
      "  time_this_iter_s: 21.81639838218689\n",
      "  time_total_s: 6235.455602407455\n",
      "  timestamp: 1553128042\n",
      "  timesteps_since_restore: 2820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 282\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6235 s, 282 iter, 2820000 ts, 55 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-27-44\n",
      "  done: false\n",
      "  episode_len_mean: 78.18604651162791\n",
      "  episode_reward_max: 384.69595541777085\n",
      "  episode_reward_mean: 72.66407964563133\n",
      "  episode_reward_min: -166.77000266465188\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 31276\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.991\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 2830000\n",
      "    num_steps_trained: 2830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2289966787315532e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6801792979240417\n",
      "      kl: 0.4055686295032501\n",
      "      policy_loss: 0.01226211991161108\n",
      "      total_loss: 83.92841339111328\n",
      "      vf_explained_var: 0.8242616057395935\n",
      "      vf_loss: 83.91615295410156\n",
      "    sample_time_ms: 18019.523\n",
      "    update_time_ms: 4.863\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.332039822815666\n",
      "  time_since_restore: 6257.072765827179\n",
      "  time_this_iter_s: 21.61716341972351\n",
      "  time_total_s: 6257.072765827179\n",
      "  timestamp: 1553128064\n",
      "  timesteps_since_restore: 2830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2830000\n",
      "  training_iteration: 283\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6257 s, 283 iter, 2830000 ts, 72.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-28-05\n",
      "  done: false\n",
      "  episode_len_mean: 73.99253731343283\n",
      "  episode_reward_max: 389.181944892284\n",
      "  episode_reward_mean: 42.77854751451106\n",
      "  episode_reward_min: -163.20437810352087\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 31410\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.472\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 2840000\n",
      "    num_steps_trained: 2840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8434948012568952e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6863446235656738\n",
      "      kl: 0.03892437741160393\n",
      "      policy_loss: 0.006434000562876463\n",
      "      total_loss: 76.08071899414062\n",
      "      vf_explained_var: 0.8537259101867676\n",
      "      vf_loss: 76.07427978515625\n",
      "    sample_time_ms: 17980.633\n",
      "    update_time_ms: 4.925\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.389273757255527\n",
      "  time_since_restore: 6278.783931732178\n",
      "  time_this_iter_s: 21.71116590499878\n",
      "  time_total_s: 6278.783931732178\n",
      "  timestamp: 1553128085\n",
      "  timesteps_since_restore: 2840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2840000\n",
      "  training_iteration: 284\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6278 s, 284 iter, 2840000 ts, 42.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-28-27\n",
      "  done: false\n",
      "  episode_len_mean: 73.21167883211679\n",
      "  episode_reward_max: 385.82451777629575\n",
      "  episode_reward_mean: 39.21983998914363\n",
      "  episode_reward_min: -164.78991345867158\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 31547\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.165\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8434948012568952e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6991627812385559\n",
      "      kl: 0.04886597767472267\n",
      "      policy_loss: 0.00916221085935831\n",
      "      total_loss: 78.08265686035156\n",
      "      vf_explained_var: 0.8557465672492981\n",
      "      vf_loss: 78.073486328125\n",
      "    sample_time_ms: 17972.794\n",
      "    update_time_ms: 4.945\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.60991999457181\n",
      "  time_since_restore: 6300.696170091629\n",
      "  time_this_iter_s: 21.912238359451294\n",
      "  time_total_s: 6300.696170091629\n",
      "  timestamp: 1553128107\n",
      "  timesteps_since_restore: 2850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 285\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6300 s, 285 iter, 2850000 ts, 39.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-28-49\n",
      "  done: false\n",
      "  episode_len_mean: 73.94852941176471\n",
      "  episode_reward_max: 386.45283897784606\n",
      "  episode_reward_mean: 42.31069630912033\n",
      "  episode_reward_min: -166.75181658908366\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 31683\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.738\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 2860000\n",
      "    num_steps_trained: 2860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.765242201885343e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7004636526107788\n",
      "      kl: 0.043734557926654816\n",
      "      policy_loss: 0.007833235897123814\n",
      "      total_loss: 71.4034423828125\n",
      "      vf_explained_var: 0.8649823069572449\n",
      "      vf_loss: 71.3956069946289\n",
      "    sample_time_ms: 18030.652\n",
      "    update_time_ms: 4.906\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.155348154560166\n",
      "  time_since_restore: 6322.779434919357\n",
      "  time_this_iter_s: 22.08326482772827\n",
      "  time_total_s: 6322.779434919357\n",
      "  timestamp: 1553128129\n",
      "  timesteps_since_restore: 2860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2860000\n",
      "  training_iteration: 286\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6322 s, 286 iter, 2860000 ts, 42.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-29-11\n",
      "  done: false\n",
      "  episode_len_mean: 72.52898550724638\n",
      "  episode_reward_max: 385.4095352300609\n",
      "  episode_reward_mean: 37.59623753707383\n",
      "  episode_reward_min: -166.78420552488802\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 31821\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.354\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 2870000\n",
      "    num_steps_trained: 2870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.147863302828014e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7075201869010925\n",
      "      kl: 0.03919985145330429\n",
      "      policy_loss: 0.005674685351550579\n",
      "      total_loss: 73.1812744140625\n",
      "      vf_explained_var: 0.8623414635658264\n",
      "      vf_loss: 73.17560577392578\n",
      "    sample_time_ms: 18017.439\n",
      "    update_time_ms: 5.365\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.79811876853691\n",
      "  time_since_restore: 6344.465759038925\n",
      "  time_this_iter_s: 21.68632411956787\n",
      "  time_total_s: 6344.465759038925\n",
      "  timestamp: 1553128151\n",
      "  timesteps_since_restore: 2870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2870000\n",
      "  training_iteration: 287\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6344 s, 287 iter, 2870000 ts, 37.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-29-33\n",
      "  done: false\n",
      "  episode_len_mean: 77.17829457364341\n",
      "  episode_reward_max: 387.34852164615677\n",
      "  episode_reward_mean: 72.99160696601024\n",
      "  episode_reward_min: -164.683390596118\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 31950\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.906\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.147863302828014e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7008124589920044\n",
      "      kl: 0.17980681359767914\n",
      "      policy_loss: 0.02175876498222351\n",
      "      total_loss: 74.3658447265625\n",
      "      vf_explained_var: 0.8429248332977295\n",
      "      vf_loss: 74.34407806396484\n",
      "    sample_time_ms: 18027.944\n",
      "    update_time_ms: 5.203\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.495803483005105\n",
      "  time_since_restore: 6366.096890211105\n",
      "  time_this_iter_s: 21.631131172180176\n",
      "  time_total_s: 6366.096890211105\n",
      "  timestamp: 1553128173\n",
      "  timesteps_since_restore: 2880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 288\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6366 s, 288 iter, 2880000 ts, 73 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 77.63565891472868\n",
      "  episode_reward_max: 383.703656438757\n",
      "  episode_reward_mean: 78.66029232864331\n",
      "  episode_reward_min: -168.68819905516148\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 32079\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.827\n",
      "    load_time_ms: 1.451\n",
      "    num_steps_sampled: 2890000\n",
      "    num_steps_trained: 2890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.221794607297326e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6725555658340454\n",
      "      kl: 0.03637129068374634\n",
      "      policy_loss: 0.005681321956217289\n",
      "      total_loss: 65.03339385986328\n",
      "      vf_explained_var: 0.8630879521369934\n",
      "      vf_loss: 65.02771759033203\n",
      "    sample_time_ms: 18135.386\n",
      "    update_time_ms: 5.15\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.330146164321654\n",
      "  time_since_restore: 6388.2787828445435\n",
      "  time_this_iter_s: 22.18189263343811\n",
      "  time_total_s: 6388.2787828445435\n",
      "  timestamp: 1553128195\n",
      "  timesteps_since_restore: 2890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2890000\n",
      "  training_iteration: 289\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6388 s, 289 iter, 2890000 ts, 78.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-30-18\n",
      "  done: false\n",
      "  episode_len_mean: 73.51470588235294\n",
      "  episode_reward_max: 389.81563365177976\n",
      "  episode_reward_mean: 50.02061276755599\n",
      "  episode_reward_min: -168.73473839327335\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 32215\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.499\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 2900000\n",
      "    num_steps_trained: 2900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.221794607297326e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6876137852668762\n",
      "      kl: 0.042810168117284775\n",
      "      policy_loss: 0.009122216142714024\n",
      "      total_loss: 74.54569244384766\n",
      "      vf_explained_var: 0.8523010015487671\n",
      "      vf_loss: 74.53656768798828\n",
      "    sample_time_ms: 18192.375\n",
      "    update_time_ms: 5.099\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.010306383778\n",
      "  time_since_restore: 6410.714175462723\n",
      "  time_this_iter_s: 22.43539261817932\n",
      "  time_total_s: 6410.714175462723\n",
      "  timestamp: 1553128218\n",
      "  timesteps_since_restore: 2900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2900000\n",
      "  training_iteration: 290\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6410 s, 290 iter, 2900000 ts, 50 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-30-40\n",
      "  done: false\n",
      "  episode_len_mean: 73.54074074074074\n",
      "  episode_reward_max: 388.10571649244696\n",
      "  episode_reward_mean: 31.59769540113449\n",
      "  episode_reward_min: -166.68874650975704\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 32350\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.433\n",
      "    load_time_ms: 1.454\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.332695033448246e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7000099420547485\n",
      "      kl: 0.044555749744176865\n",
      "      policy_loss: 0.004243527539074421\n",
      "      total_loss: 82.75025177001953\n",
      "      vf_explained_var: 0.8426011204719543\n",
      "      vf_loss: 82.74600982666016\n",
      "    sample_time_ms: 18187.424\n",
      "    update_time_ms: 5.325\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.798847700567245\n",
      "  time_since_restore: 6432.903939247131\n",
      "  time_this_iter_s: 22.18976378440857\n",
      "  time_total_s: 6432.903939247131\n",
      "  timestamp: 1553128240\n",
      "  timesteps_since_restore: 2910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 291\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6432 s, 291 iter, 2910000 ts, 31.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-31-02\n",
      "  done: false\n",
      "  episode_len_mean: 77.95348837209302\n",
      "  episode_reward_max: 386.2015102604214\n",
      "  episode_reward_mean: 76.5210153135885\n",
      "  episode_reward_min: -168.74444738945007\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 32479\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.426\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 2920000\n",
      "    num_steps_trained: 2920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3999038039891332e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6609549522399902\n",
      "      kl: 0.0538792684674263\n",
      "      policy_loss: 0.008690929040312767\n",
      "      total_loss: 69.67743682861328\n",
      "      vf_explained_var: 0.8536247611045837\n",
      "      vf_loss: 69.66874694824219\n",
      "    sample_time_ms: 18174.584\n",
      "    update_time_ms: 5.425\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.260507656794246\n",
      "  time_since_restore: 6454.625548124313\n",
      "  time_this_iter_s: 21.721608877182007\n",
      "  time_total_s: 6454.625548124313\n",
      "  timestamp: 1553128262\n",
      "  timesteps_since_restore: 2920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2920000\n",
      "  training_iteration: 292\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6454 s, 292 iter, 2920000 ts, 76.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-31-23\n",
      "  done: false\n",
      "  episode_len_mean: 73.62043795620438\n",
      "  episode_reward_max: 385.1921850147872\n",
      "  episode_reward_mean: 40.90705226607278\n",
      "  episode_reward_min: -164.7008102501297\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 32616\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.051\n",
      "    load_time_ms: 1.473\n",
      "    num_steps_sampled: 2930000\n",
      "    num_steps_trained: 2930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.099855983539456e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6993622183799744\n",
      "      kl: 0.043591104447841644\n",
      "      policy_loss: 0.007704854942858219\n",
      "      total_loss: 65.03361511230469\n",
      "      vf_explained_var: 0.8770022392272949\n",
      "      vf_loss: 65.0259017944336\n",
      "    sample_time_ms: 18187.284\n",
      "    update_time_ms: 5.345\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.45352613303639\n",
      "  time_since_restore: 6476.3560202121735\n",
      "  time_this_iter_s: 21.730472087860107\n",
      "  time_total_s: 6476.3560202121735\n",
      "  timestamp: 1553128283\n",
      "  timesteps_since_restore: 2930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2930000\n",
      "  training_iteration: 293\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6476 s, 293 iter, 2930000 ts, 40.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-31-45\n",
      "  done: false\n",
      "  episode_len_mean: 71.45323741007195\n",
      "  episode_reward_max: 386.3793647698595\n",
      "  episode_reward_mean: 24.270836819595456\n",
      "  episode_reward_min: -164.7224763159418\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 32755\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.553\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.149784599809635e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7379376888275146\n",
      "      kl: 0.07004006206989288\n",
      "      policy_loss: 0.01092528086155653\n",
      "      total_loss: 84.08001708984375\n",
      "      vf_explained_var: 0.8477007746696472\n",
      "      vf_loss: 84.06908416748047\n",
      "    sample_time_ms: 18198.585\n",
      "    update_time_ms: 5.485\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.135418409797731\n",
      "  time_since_restore: 6498.1378536224365\n",
      "  time_this_iter_s: 21.78183341026306\n",
      "  time_total_s: 6498.1378536224365\n",
      "  timestamp: 1553128305\n",
      "  timesteps_since_restore: 2940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 294\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6498 s, 294 iter, 2940000 ts, 24.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-32-07\n",
      "  done: false\n",
      "  episode_len_mean: 75.76335877862596\n",
      "  episode_reward_max: 385.062440838424\n",
      "  episode_reward_mean: 65.79267405302045\n",
      "  episode_reward_min: -168.75399021967888\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 32886\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.47\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 2950000\n",
      "    num_steps_trained: 2950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.724676205825062e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7203754782676697\n",
      "      kl: 0.05443510785698891\n",
      "      policy_loss: 0.009917075745761395\n",
      "      total_loss: 71.9828872680664\n",
      "      vf_explained_var: 0.8528631329536438\n",
      "      vf_loss: 71.97297668457031\n",
      "    sample_time_ms: 18159.067\n",
      "    update_time_ms: 5.44\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.896337026510224\n",
      "  time_since_restore: 6519.626074552536\n",
      "  time_this_iter_s: 21.488220930099487\n",
      "  time_total_s: 6519.626074552536\n",
      "  timestamp: 1553128327\n",
      "  timesteps_since_restore: 2950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2950000\n",
      "  training_iteration: 295\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6519 s, 295 iter, 2950000 ts, 65.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-32-28\n",
      "  done: false\n",
      "  episode_len_mean: 69.08904109589041\n",
      "  episode_reward_max: 383.5423848514401\n",
      "  episode_reward_mean: 12.820014059153193\n",
      "  episode_reward_min: -162.59979321440696\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 33032\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.147\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 2960000\n",
      "    num_steps_trained: 2960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.087014863849106e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7272346615791321\n",
      "      kl: 0.046101320534944534\n",
      "      policy_loss: 0.010258485563099384\n",
      "      total_loss: 74.90408325195312\n",
      "      vf_explained_var: 0.8707345724105835\n",
      "      vf_loss: 74.8938217163086\n",
      "    sample_time_ms: 18100.006\n",
      "    update_time_ms: 5.557\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.410007029576599\n",
      "  time_since_restore: 6541.110584974289\n",
      "  time_this_iter_s: 21.48451042175293\n",
      "  time_total_s: 6541.110584974289\n",
      "  timestamp: 1553128348\n",
      "  timesteps_since_restore: 2960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2960000\n",
      "  training_iteration: 296\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6541 s, 296 iter, 2960000 ts, 12.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-32-49\n",
      "  done: false\n",
      "  episode_len_mean: 77.921875\n",
      "  episode_reward_max: 387.502422164204\n",
      "  episode_reward_mean: 82.89813574232785\n",
      "  episode_reward_min: -168.6691422699356\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 33160\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.757\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0630518687548829e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7120153903961182\n",
      "      kl: 0.06527940183877945\n",
      "      policy_loss: 0.010527096688747406\n",
      "      total_loss: 66.0233383178711\n",
      "      vf_explained_var: 0.8580781817436218\n",
      "      vf_loss: 66.0128173828125\n",
      "    sample_time_ms: 18060.726\n",
      "    update_time_ms: 5.259\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.44906787116392\n",
      "  time_since_restore: 6562.24551153183\n",
      "  time_this_iter_s: 21.134926557540894\n",
      "  time_total_s: 6562.24551153183\n",
      "  timestamp: 1553128369\n",
      "  timesteps_since_restore: 2970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 297\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6562 s, 297 iter, 2970000 ts, 82.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-33-11\n",
      "  done: false\n",
      "  episode_len_mean: 77.41538461538461\n",
      "  episode_reward_max: 384.1525958350294\n",
      "  episode_reward_mean: 69.49327696899067\n",
      "  episode_reward_min: -167.06106498369218\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 33290\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.982\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 2980000\n",
      "    num_steps_trained: 2980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5945778031323243e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6809379458427429\n",
      "      kl: 0.03996308520436287\n",
      "      policy_loss: 0.007282752078026533\n",
      "      total_loss: 65.06147003173828\n",
      "      vf_explained_var: 0.8631176948547363\n",
      "      vf_loss: 65.05418395996094\n",
      "    sample_time_ms: 18009.848\n",
      "    update_time_ms: 5.422\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.746638484495335\n",
      "  time_since_restore: 6583.4927134513855\n",
      "  time_this_iter_s: 21.247201919555664\n",
      "  time_total_s: 6583.4927134513855\n",
      "  timestamp: 1553128391\n",
      "  timesteps_since_restore: 2980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2980000\n",
      "  training_iteration: 298\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6583 s, 298 iter, 2980000 ts, 69.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-33-32\n",
      "  done: false\n",
      "  episode_len_mean: 79.12\n",
      "  episode_reward_max: 389.14866477796636\n",
      "  episode_reward_mean: 80.58078491363422\n",
      "  episode_reward_min: -168.77063021012782\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 33415\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.998\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 2990000\n",
      "    num_steps_trained: 2990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5945778031323243e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6993569135665894\n",
      "      kl: 0.034512683749198914\n",
      "      policy_loss: 0.005733299069106579\n",
      "      total_loss: 78.41466522216797\n",
      "      vf_explained_var: 0.8267895579338074\n",
      "      vf_loss: 78.40892791748047\n",
      "    sample_time_ms: 17969.915\n",
      "    update_time_ms: 5.411\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.2903924568171\n",
      "  time_since_restore: 6605.262941122055\n",
      "  time_this_iter_s: 21.770227670669556\n",
      "  time_total_s: 6605.262941122055\n",
      "  timestamp: 1553128412\n",
      "  timesteps_since_restore: 2990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2990000\n",
      "  training_iteration: 299\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6605 s, 299 iter, 2990000 ts, 80.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-33-55\n",
      "  done: false\n",
      "  episode_len_mean: 76.54198473282443\n",
      "  episode_reward_max: 383.1592985514056\n",
      "  episode_reward_mean: 59.94466567070389\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 33546\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.037\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5945778031323243e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.709500253200531\n",
      "      kl: 0.04167936369776726\n",
      "      policy_loss: 0.005385152995586395\n",
      "      total_loss: 70.87966918945312\n",
      "      vf_explained_var: 0.8571928143501282\n",
      "      vf_loss: 70.8742904663086\n",
      "    sample_time_ms: 17959.156\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.972332835351935\n",
      "  time_since_restore: 6627.639302492142\n",
      "  time_this_iter_s: 22.37636137008667\n",
      "  time_total_s: 6627.639302492142\n",
      "  timestamp: 1553128435\n",
      "  timesteps_since_restore: 3000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 300\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6627 s, 300 iter, 3000000 ts, 59.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-34-17\n",
      "  done: false\n",
      "  episode_len_mean: 69.7972027972028\n",
      "  episode_reward_max: 387.49357545217737\n",
      "  episode_reward_mean: 11.174676520890467\n",
      "  episode_reward_min: -168.75430321499346\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 33689\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.791\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 3010000\n",
      "    num_steps_trained: 3010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3918673708323013e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7514325380325317\n",
      "      kl: 0.07110825926065445\n",
      "      policy_loss: 0.009815041907131672\n",
      "      total_loss: 77.15337371826172\n",
      "      vf_explained_var: 0.8634946942329407\n",
      "      vf_loss: 77.14356994628906\n",
      "    sample_time_ms: 17942.381\n",
      "    update_time_ms: 5.157\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 5.58733826044523\n",
      "  time_since_restore: 6649.556499958038\n",
      "  time_this_iter_s: 21.917197465896606\n",
      "  time_total_s: 6649.556499958038\n",
      "  timestamp: 1553128457\n",
      "  timesteps_since_restore: 3010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3010000\n",
      "  training_iteration: 301\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6649 s, 301 iter, 3010000 ts, 11.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-34-38\n",
      "  done: false\n",
      "  episode_len_mean: 75.37878787878788\n",
      "  episode_reward_max: 383.77225852317173\n",
      "  episode_reward_mean: 48.98572795103324\n",
      "  episode_reward_min: -166.74366082796095\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 33821\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.766\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 3020000\n",
      "    num_steps_trained: 3020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.5878009452261495e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7150587439537048\n",
      "      kl: 0.06158849596977234\n",
      "      policy_loss: 0.010302791371941566\n",
      "      total_loss: 57.049434661865234\n",
      "      vf_explained_var: 0.8906991481781006\n",
      "      vf_loss: 57.03913879394531\n",
      "    sample_time_ms: 17888.97\n",
      "    update_time_ms: 5.341\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.492863975516624\n",
      "  time_since_restore: 6670.662574768066\n",
      "  time_this_iter_s: 21.106074810028076\n",
      "  time_total_s: 6670.662574768066\n",
      "  timestamp: 1553128478\n",
      "  timesteps_since_restore: 3020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3020000\n",
      "  training_iteration: 302\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6670 s, 302 iter, 3020000 ts, 49 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-35-00\n",
      "  done: false\n",
      "  episode_len_mean: 75.64661654135338\n",
      "  episode_reward_max: 385.88754048199314\n",
      "  episode_reward_mean: 58.46471969489971\n",
      "  episode_reward_min: -164.705725633111\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 33954\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.621\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 3030000\n",
      "    num_steps_trained: 3030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.381700862727712e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7447506785392761\n",
      "      kl: 0.04095655307173729\n",
      "      policy_loss: 0.003543386934325099\n",
      "      total_loss: 71.9267349243164\n",
      "      vf_explained_var: 0.8534066677093506\n",
      "      vf_loss: 71.92318725585938\n",
      "    sample_time_ms: 17932.661\n",
      "    update_time_ms: 5.49\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.232359847449857\n",
      "  time_since_restore: 6692.862271785736\n",
      "  time_this_iter_s: 22.199697017669678\n",
      "  time_total_s: 6692.862271785736\n",
      "  timestamp: 1553128500\n",
      "  timesteps_since_restore: 3030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3030000\n",
      "  training_iteration: 303\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6692 s, 303 iter, 3030000 ts, 58.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-35-22\n",
      "  done: false\n",
      "  episode_len_mean: 75.95454545454545\n",
      "  episode_reward_max: 385.306103666981\n",
      "  episode_reward_mean: 60.712030511821425\n",
      "  episode_reward_min: -164.68380244740487\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 34086\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.053\n",
      "    load_time_ms: 1.671\n",
      "    num_steps_sampled: 3040000\n",
      "    num_steps_trained: 3040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.072552404314592e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7583121061325073\n",
      "      kl: 0.05152873322367668\n",
      "      policy_loss: 0.006443462334573269\n",
      "      total_loss: 68.53086853027344\n",
      "      vf_explained_var: 0.8594499230384827\n",
      "      vf_loss: 68.52442932128906\n",
      "    sample_time_ms: 17932.37\n",
      "    update_time_ms: 5.389\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.356015255910716\n",
      "  time_since_restore: 6714.627285957336\n",
      "  time_this_iter_s: 21.765014171600342\n",
      "  time_total_s: 6714.627285957336\n",
      "  timestamp: 1553128522\n",
      "  timesteps_since_restore: 3040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3040000\n",
      "  training_iteration: 304\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6714 s, 304 iter, 3040000 ts, 60.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-35-44\n",
      "  done: false\n",
      "  episode_len_mean: 73.56617647058823\n",
      "  episode_reward_max: 387.1127332310196\n",
      "  episode_reward_mean: 44.020869007802055\n",
      "  episode_reward_min: -165.21695851078272\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 34222\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.059\n",
      "    load_time_ms: 1.661\n",
      "    num_steps_sampled: 3050000\n",
      "    num_steps_trained: 3050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.210882683011505e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7682371139526367\n",
      "      kl: 0.07956857979297638\n",
      "      policy_loss: 0.010298884473741055\n",
      "      total_loss: 68.36335754394531\n",
      "      vf_explained_var: 0.8687939047813416\n",
      "      vf_loss: 68.35305786132812\n",
      "    sample_time_ms: 17989.19\n",
      "    update_time_ms: 5.835\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.010434503901028\n",
      "  time_since_restore: 6736.688861846924\n",
      "  time_this_iter_s: 22.061575889587402\n",
      "  time_total_s: 6736.688861846924\n",
      "  timestamp: 1553128544\n",
      "  timesteps_since_restore: 3050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3050000\n",
      "  training_iteration: 305\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6736 s, 305 iter, 3050000 ts, 44 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-36-06\n",
      "  done: false\n",
      "  episode_len_mean: 71.37142857142857\n",
      "  episode_reward_max: 386.12142088082544\n",
      "  episode_reward_mean: 30.602581816071616\n",
      "  episode_reward_min: -166.8376909502411\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 34362\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.263\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 3060000\n",
      "    num_steps_trained: 3060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8163241577440203e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7644155025482178\n",
      "      kl: 0.05839626118540764\n",
      "      policy_loss: 0.008104590699076653\n",
      "      total_loss: 68.50753021240234\n",
      "      vf_explained_var: 0.8747189044952393\n",
      "      vf_loss: 68.49942779541016\n",
      "    sample_time_ms: 17994.811\n",
      "    update_time_ms: 5.846\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.3012909080358\n",
      "  time_since_restore: 6758.2679805755615\n",
      "  time_this_iter_s: 21.579118728637695\n",
      "  time_total_s: 6758.2679805755615\n",
      "  timestamp: 1553128566\n",
      "  timesteps_since_restore: 3060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3060000\n",
      "  training_iteration: 306\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6758 s, 306 iter, 3060000 ts, 30.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-36-28\n",
      "  done: false\n",
      "  episode_len_mean: 74.4962962962963\n",
      "  episode_reward_max: 385.0100359690458\n",
      "  episode_reward_mean: 52.17493146553648\n",
      "  episode_reward_min: -168.73960563465596\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 34497\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.581\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 3070000\n",
      "    num_steps_trained: 3070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7244864142517145e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.758855938911438\n",
      "      kl: 0.054098427295684814\n",
      "      policy_loss: 0.009660974144935608\n",
      "      total_loss: 67.67869567871094\n",
      "      vf_explained_var: 0.8668187260627747\n",
      "      vf_loss: 67.66903686523438\n",
      "    sample_time_ms: 18098.438\n",
      "    update_time_ms: 5.651\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.08746573276824\n",
      "  time_since_restore: 6780.43989777565\n",
      "  time_this_iter_s: 22.1719172000885\n",
      "  time_total_s: 6780.43989777565\n",
      "  timestamp: 1553128588\n",
      "  timesteps_since_restore: 3070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3070000\n",
      "  training_iteration: 307\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6780 s, 307 iter, 3070000 ts, 52.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-36-50\n",
      "  done: false\n",
      "  episode_len_mean: 72.10071942446044\n",
      "  episode_reward_max: 386.7910882699543\n",
      "  episode_reward_mean: 29.44400352693312\n",
      "  episode_reward_min: -168.85249348947048\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 34636\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.908\n",
      "    load_time_ms: 1.633\n",
      "    num_steps_sampled: 3080000\n",
      "    num_steps_trained: 3080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.086729177288362e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7681074142456055\n",
      "      kl: 0.07385214418172836\n",
      "      policy_loss: 0.013147654943168163\n",
      "      total_loss: 72.0733413696289\n",
      "      vf_explained_var: 0.868111252784729\n",
      "      vf_loss: 72.06018829345703\n",
      "    sample_time_ms: 18189.709\n",
      "    update_time_ms: 5.672\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.722001763466563\n",
      "  time_since_restore: 6802.485778808594\n",
      "  time_this_iter_s: 22.045881032943726\n",
      "  time_total_s: 6802.485778808594\n",
      "  timestamp: 1553128610\n",
      "  timesteps_since_restore: 3080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3080000\n",
      "  training_iteration: 308\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6802 s, 308 iter, 3080000 ts, 29.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-37-12\n",
      "  done: false\n",
      "  episode_len_mean: 73.80597014925372\n",
      "  episode_reward_max: 387.43902688472076\n",
      "  episode_reward_mean: 53.39382333340589\n",
      "  episode_reward_min: -167.13771716192008\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 34770\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.301\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 3090000\n",
      "    num_steps_trained: 3090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.130093765932543e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7613390684127808\n",
      "      kl: 0.043172579258680344\n",
      "      policy_loss: 0.007908064872026443\n",
      "      total_loss: 66.7407455444336\n",
      "      vf_explained_var: 0.8715894818305969\n",
      "      vf_loss: 66.73283386230469\n",
      "    sample_time_ms: 18160.483\n",
      "    update_time_ms: 5.826\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.69691166670295\n",
      "  time_since_restore: 6824.211207151413\n",
      "  time_this_iter_s: 21.725428342819214\n",
      "  time_total_s: 6824.211207151413\n",
      "  timestamp: 1553128632\n",
      "  timesteps_since_restore: 3090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3090000\n",
      "  training_iteration: 309\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6824 s, 309 iter, 3090000 ts, 53.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-37-33\n",
      "  done: false\n",
      "  episode_len_mean: 71.31914893617021\n",
      "  episode_reward_max: 385.8233267139794\n",
      "  episode_reward_mean: 19.0137445338081\n",
      "  episode_reward_min: -166.96429047199726\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 34911\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.133\n",
      "    load_time_ms: 1.633\n",
      "    num_steps_sampled: 3100000\n",
      "    num_steps_trained: 3100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.195140648898814e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7778124809265137\n",
      "      kl: 0.04338011518120766\n",
      "      policy_loss: 0.007351672742515802\n",
      "      total_loss: 88.70724487304688\n",
      "      vf_explained_var: 0.8386558890342712\n",
      "      vf_loss: 88.69989776611328\n",
      "    sample_time_ms: 18077.71\n",
      "    update_time_ms: 5.849\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.50687226690405\n",
      "  time_since_restore: 6845.737930774689\n",
      "  time_this_iter_s: 21.526723623275757\n",
      "  time_total_s: 6845.737930774689\n",
      "  timestamp: 1553128653\n",
      "  timesteps_since_restore: 3100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3100000\n",
      "  training_iteration: 310\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6845 s, 310 iter, 3100000 ts, 19 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 75.28030303030303\n",
      "  episode_reward_max: 386.0802527788768\n",
      "  episode_reward_mean: 56.857213518733005\n",
      "  episode_reward_min: -166.79929212626456\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 35043\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.056\n",
      "    load_time_ms: 1.684\n",
      "    num_steps_sampled: 3110000\n",
      "    num_steps_trained: 3110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3792711683890957e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7689635157585144\n",
      "      kl: 0.0420122928917408\n",
      "      policy_loss: 0.008064436726272106\n",
      "      total_loss: 61.13648223876953\n",
      "      vf_explained_var: 0.8782563805580139\n",
      "      vf_loss: 61.12841796875\n",
      "    sample_time_ms: 18072.011\n",
      "    update_time_ms: 5.914\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.428606759366502\n",
      "  time_since_restore: 6867.62207365036\n",
      "  time_this_iter_s: 21.884142875671387\n",
      "  time_total_s: 6867.62207365036\n",
      "  timestamp: 1553128675\n",
      "  timesteps_since_restore: 3110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3110000\n",
      "  training_iteration: 311\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6867 s, 311 iter, 3110000 ts, 56.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-38-17\n",
      "  done: false\n",
      "  episode_len_mean: 75.90977443609023\n",
      "  episode_reward_max: 384.9652710233036\n",
      "  episode_reward_mean: 67.0769081732224\n",
      "  episode_reward_min: -168.90436446424962\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 35176\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.857\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 3120000\n",
      "    num_steps_trained: 3120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0689068946921907e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7646090984344482\n",
      "      kl: 0.0462353341281414\n",
      "      policy_loss: 0.011654085479676723\n",
      "      total_loss: 68.3995361328125\n",
      "      vf_explained_var: 0.8622426986694336\n",
      "      vf_loss: 68.38788604736328\n",
      "    sample_time_ms: 18146.052\n",
      "    update_time_ms: 5.633\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.53845408661119\n",
      "  time_since_restore: 6889.511915445328\n",
      "  time_this_iter_s: 21.88984179496765\n",
      "  time_total_s: 6889.511915445328\n",
      "  timestamp: 1553128697\n",
      "  timesteps_since_restore: 3120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3120000\n",
      "  training_iteration: 312\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6889 s, 312 iter, 3120000 ts, 67.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-38-39\n",
      "  done: false\n",
      "  episode_len_mean: 72.42753623188406\n",
      "  episode_reward_max: 386.1823741405746\n",
      "  episode_reward_mean: 27.71772917480729\n",
      "  episode_reward_min: -166.86754609891415\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 35314\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.839\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 3130000\n",
      "    num_steps_trained: 3130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.1033599157126446e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7822939157485962\n",
      "      kl: 0.04948151856660843\n",
      "      policy_loss: 0.00831624772399664\n",
      "      total_loss: 85.09902954101562\n",
      "      vf_explained_var: 0.8454237580299377\n",
      "      vf_loss: 85.09070587158203\n",
      "    sample_time_ms: 18143.801\n",
      "    update_time_ms: 5.917\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 13.858864587403641\n",
      "  time_since_restore: 6911.725618124008\n",
      "  time_this_iter_s: 22.21370267868042\n",
      "  time_total_s: 6911.725618124008\n",
      "  timestamp: 1553128719\n",
      "  timesteps_since_restore: 3130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3130000\n",
      "  training_iteration: 313\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6911 s, 313 iter, 3130000 ts, 27.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-39-02\n",
      "  done: false\n",
      "  episode_len_mean: 74.81203007518798\n",
      "  episode_reward_max: 386.68495091265424\n",
      "  episode_reward_mean: 39.039951352205605\n",
      "  episode_reward_min: -164.84412941297532\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 35447\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.287\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 3140000\n",
      "    num_steps_trained: 3140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.655040015677514e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7765840291976929\n",
      "      kl: 0.044558752328157425\n",
      "      policy_loss: 0.009545974433422089\n",
      "      total_loss: 61.0952262878418\n",
      "      vf_explained_var: 0.8848849534988403\n",
      "      vf_loss: 61.08568572998047\n",
      "    sample_time_ms: 18167.876\n",
      "    update_time_ms: 6.145\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.519975676102806\n",
      "  time_since_restore: 6933.776180744171\n",
      "  time_this_iter_s: 22.050562620162964\n",
      "  time_total_s: 6933.776180744171\n",
      "  timestamp: 1553128742\n",
      "  timesteps_since_restore: 3140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3140000\n",
      "  training_iteration: 314\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6933 s, 314 iter, 3140000 ts, 39 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-39-23\n",
      "  done: false\n",
      "  episode_len_mean: 72.72992700729927\n",
      "  episode_reward_max: 384.6830770574099\n",
      "  episode_reward_mean: 32.6982131959103\n",
      "  episode_reward_min: -162.59269389482975\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 35584\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.474\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 3150000\n",
      "    num_steps_trained: 3150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.982559170864988e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.760452926158905\n",
      "      kl: 0.05887063220143318\n",
      "      policy_loss: 0.011950954794883728\n",
      "      total_loss: 87.11650848388672\n",
      "      vf_explained_var: 0.8390303254127502\n",
      "      vf_loss: 87.10456848144531\n",
      "    sample_time_ms: 18110.611\n",
      "    update_time_ms: 5.644\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.34910659795515\n",
      "  time_since_restore: 6955.263789176941\n",
      "  time_this_iter_s: 21.487608432769775\n",
      "  time_total_s: 6955.263789176941\n",
      "  timestamp: 1553128763\n",
      "  timesteps_since_restore: 3150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3150000\n",
      "  training_iteration: 315\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6955 s, 315 iter, 3150000 ts, 32.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-39-45\n",
      "  done: false\n",
      "  episode_len_mean: 73.41176470588235\n",
      "  episode_reward_max: 386.2047327560039\n",
      "  episode_reward_mean: 27.72304349493951\n",
      "  episode_reward_min: -166.7773478623295\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 35720\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.586\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 3160000\n",
      "    num_steps_trained: 3160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.047383989316586e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7523588538169861\n",
      "      kl: 0.034898824989795685\n",
      "      policy_loss: 0.002560327760875225\n",
      "      total_loss: 82.81343841552734\n",
      "      vf_explained_var: 0.8467257618904114\n",
      "      vf_loss: 82.81087493896484\n",
      "    sample_time_ms: 18106.724\n",
      "    update_time_ms: 5.722\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 13.861521747469752\n",
      "  time_since_restore: 6976.76407790184\n",
      "  time_this_iter_s: 21.500288724899292\n",
      "  time_total_s: 6976.76407790184\n",
      "  timestamp: 1553128785\n",
      "  timesteps_since_restore: 3160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3160000\n",
      "  training_iteration: 316\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6976 s, 316 iter, 3160000 ts, 27.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-40-06\n",
      "  done: false\n",
      "  episode_len_mean: 74.31851851851852\n",
      "  episode_reward_max: 385.5891243829877\n",
      "  episode_reward_mean: 51.565067226656865\n",
      "  episode_reward_min: -166.89793654021264\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 35855\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.719\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 3170000\n",
      "    num_steps_trained: 3170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.047383989316586e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7529895305633545\n",
      "      kl: 0.03204912319779396\n",
      "      policy_loss: 0.0048474338836967945\n",
      "      total_loss: 69.76599884033203\n",
      "      vf_explained_var: 0.8624786138534546\n",
      "      vf_loss: 69.76115417480469\n",
      "    sample_time_ms: 18069.661\n",
      "    update_time_ms: 5.814\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.782533613328436\n",
      "  time_since_restore: 6998.57957816124\n",
      "  time_this_iter_s: 21.815500259399414\n",
      "  time_total_s: 6998.57957816124\n",
      "  timestamp: 1553128806\n",
      "  timesteps_since_restore: 3170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3170000\n",
      "  training_iteration: 317\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 6998 s, 317 iter, 3170000 ts, 51.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-40-28\n",
      "  done: false\n",
      "  episode_len_mean: 70.59154929577464\n",
      "  episode_reward_max: 386.34671588874676\n",
      "  episode_reward_mean: 18.12944196934939\n",
      "  episode_reward_min: -166.73582746550082\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 35997\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.655\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 3180000\n",
      "    num_steps_trained: 3180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.047383989316586e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7657425999641418\n",
      "      kl: 0.054050665348768234\n",
      "      policy_loss: 0.00371204549446702\n",
      "      total_loss: 74.47528839111328\n",
      "      vf_explained_var: 0.865871250629425\n",
      "      vf_loss: 74.4715805053711\n",
      "    sample_time_ms: 18010.015\n",
      "    update_time_ms: 5.805\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.064720984674693\n",
      "  time_since_restore: 7020.047718763351\n",
      "  time_this_iter_s: 21.468140602111816\n",
      "  time_total_s: 7020.047718763351\n",
      "  timestamp: 1553128828\n",
      "  timesteps_since_restore: 3180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3180000\n",
      "  training_iteration: 318\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7020 s, 318 iter, 3180000 ts, 18.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-40-50\n",
      "  done: false\n",
      "  episode_len_mean: 70.11888111888112\n",
      "  episode_reward_max: 387.9313474200076\n",
      "  episode_reward_mean: 15.28732219642763\n",
      "  episode_reward_min: -167.24575265326737\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 36140\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.851\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 3190000\n",
      "    num_steps_trained: 3190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5710760408182978e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7891387939453125\n",
      "      kl: 0.06063237413764\n",
      "      policy_loss: 0.008781174197793007\n",
      "      total_loss: 91.88868713378906\n",
      "      vf_explained_var: 0.8382455706596375\n",
      "      vf_loss: 91.8799057006836\n",
      "    sample_time_ms: 18043.651\n",
      "    update_time_ms: 5.715\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.6436610982138165\n",
      "  time_since_restore: 7041.9032435417175\n",
      "  time_this_iter_s: 21.85552477836609\n",
      "  time_total_s: 7041.9032435417175\n",
      "  timestamp: 1553128850\n",
      "  timesteps_since_restore: 3190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3190000\n",
      "  training_iteration: 319\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7041 s, 319 iter, 3190000 ts, 15.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-41-12\n",
      "  done: false\n",
      "  episode_len_mean: 69.22758620689655\n",
      "  episode_reward_max: 387.2208549241616\n",
      "  episode_reward_mean: 8.969598642346124\n",
      "  episode_reward_min: -164.72863240310193\n",
      "  episodes_this_iter: 145\n",
      "  episodes_total: 36285\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.352\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 3200000\n",
      "    num_steps_trained: 3200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.356613549636677e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7781835794448853\n",
      "      kl: 0.05364396050572395\n",
      "      policy_loss: 0.00798085518181324\n",
      "      total_loss: 75.21482849121094\n",
      "      vf_explained_var: 0.8708206415176392\n",
      "      vf_loss: 75.20684051513672\n",
      "    sample_time_ms: 18134.545\n",
      "    update_time_ms: 6.055\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 4.484799321173062\n",
      "  time_since_restore: 7064.416642904282\n",
      "  time_this_iter_s: 22.513399362564087\n",
      "  time_total_s: 7064.416642904282\n",
      "  timestamp: 1553128872\n",
      "  timesteps_since_restore: 3200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3200000\n",
      "  training_iteration: 320\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7064 s, 320 iter, 3200000 ts, 8.97 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-41-34\n",
      "  done: false\n",
      "  episode_len_mean: 72.30656934306569\n",
      "  episode_reward_max: 386.57726466852\n",
      "  episode_reward_mean: 33.5572165298791\n",
      "  episode_reward_min: -168.83500094720364\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 36422\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.527\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 3210000\n",
      "    num_steps_trained: 3210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.534921688697068e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7625570893287659\n",
      "      kl: 0.06339842081069946\n",
      "      policy_loss: 0.01234342809766531\n",
      "      total_loss: 78.55003356933594\n",
      "      vf_explained_var: 0.8536437749862671\n",
      "      vf_loss: 78.53768920898438\n",
      "    sample_time_ms: 18121.668\n",
      "    update_time_ms: 5.969\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.778608264939546\n",
      "  time_since_restore: 7086.160710811615\n",
      "  time_this_iter_s: 21.744067907333374\n",
      "  time_total_s: 7086.160710811615\n",
      "  timestamp: 1553128894\n",
      "  timesteps_since_restore: 3210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3210000\n",
      "  training_iteration: 321\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7086 s, 321 iter, 3210000 ts, 33.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-41-56\n",
      "  done: false\n",
      "  episode_len_mean: 75.47368421052632\n",
      "  episode_reward_max: 386.86352030935393\n",
      "  episode_reward_mean: 53.95251161066286\n",
      "  episode_reward_min: -168.91350244101523\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 36555\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.05\n",
      "    load_time_ms: 1.631\n",
      "    num_steps_sampled: 3220000\n",
      "    num_steps_trained: 3220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.302382305671927e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7579130530357361\n",
      "      kl: 0.051501695066690445\n",
      "      policy_loss: 0.009364786557853222\n",
      "      total_loss: 73.06451416015625\n",
      "      vf_explained_var: 0.8562816977500916\n",
      "      vf_loss: 73.05516052246094\n",
      "    sample_time_ms: 18090.037\n",
      "    update_time_ms: 6.118\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.976255805331423\n",
      "  time_since_restore: 7107.719512462616\n",
      "  time_this_iter_s: 21.558801651000977\n",
      "  time_total_s: 7107.719512462616\n",
      "  timestamp: 1553128916\n",
      "  timesteps_since_restore: 3220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3220000\n",
      "  training_iteration: 322\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7107 s, 322 iter, 3220000 ts, 54 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-42-18\n",
      "  done: false\n",
      "  episode_len_mean: 69.48611111111111\n",
      "  episode_reward_max: 387.3674489696446\n",
      "  episode_reward_mean: 3.7675496636103754\n",
      "  episode_reward_min: -164.74082339998722\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 36699\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.064\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 3230000\n",
      "    num_steps_trained: 3230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.95357391325524e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7518483400344849\n",
      "      kl: 0.04834025725722313\n",
      "      policy_loss: 0.009282495826482773\n",
      "      total_loss: 69.04035949707031\n",
      "      vf_explained_var: 0.8812234401702881\n",
      "      vf_loss: 69.03108215332031\n",
      "    sample_time_ms: 18082.783\n",
      "    update_time_ms: 5.717\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 1.8837748318051892\n",
      "  time_since_restore: 7129.779350280762\n",
      "  time_this_iter_s: 22.059837818145752\n",
      "  time_total_s: 7129.779350280762\n",
      "  timestamp: 1553128938\n",
      "  timesteps_since_restore: 3230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3230000\n",
      "  training_iteration: 323\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7129 s, 323 iter, 3230000 ts, 3.77 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-42-40\n",
      "  done: false\n",
      "  episode_len_mean: 71.75714285714285\n",
      "  episode_reward_max: 387.4506459515632\n",
      "  episode_reward_mean: 22.088312887445213\n",
      "  episode_reward_min: -166.81121342476845\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 36839\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.504\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 3240000\n",
      "    num_steps_trained: 3240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1930358596146107e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7465221881866455\n",
      "      kl: 0.059404704719781876\n",
      "      policy_loss: 0.012469775043427944\n",
      "      total_loss: 66.15798950195312\n",
      "      vf_explained_var: 0.8782423138618469\n",
      "      vf_loss: 66.14552307128906\n",
      "    sample_time_ms: 18094.64\n",
      "    update_time_ms: 5.45\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.044156443722605\n",
      "  time_since_restore: 7152.048651456833\n",
      "  time_this_iter_s: 22.269301176071167\n",
      "  time_total_s: 7152.048651456833\n",
      "  timestamp: 1553128960\n",
      "  timesteps_since_restore: 3240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3240000\n",
      "  training_iteration: 324\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7152 s, 324 iter, 3240000 ts, 22.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-43-02\n",
      "  done: false\n",
      "  episode_len_mean: 69.36111111111111\n",
      "  episode_reward_max: 387.3491255185953\n",
      "  episode_reward_mean: 4.847283047356914\n",
      "  episode_reward_min: -165.01958207115172\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 36983\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.736\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 3250000\n",
      "    num_steps_trained: 3250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7895539713208564e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7469547986984253\n",
      "      kl: 0.050621259957551956\n",
      "      policy_loss: 0.006322597619146109\n",
      "      total_loss: 78.12298583984375\n",
      "      vf_explained_var: 0.8649657964706421\n",
      "      vf_loss: 78.11666107177734\n",
      "    sample_time_ms: 18168.617\n",
      "    update_time_ms: 5.489\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 2.42364152367846\n",
      "  time_since_restore: 7174.262506008148\n",
      "  time_this_iter_s: 22.213854551315308\n",
      "  time_total_s: 7174.262506008148\n",
      "  timestamp: 1553128982\n",
      "  timesteps_since_restore: 3250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3250000\n",
      "  training_iteration: 325\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7174 s, 325 iter, 3250000 ts, 4.85 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-43-25\n",
      "  done: false\n",
      "  episode_len_mean: 66.58666666666667\n",
      "  episode_reward_max: 385.1572388882622\n",
      "  episode_reward_mean: -7.7954651935001005\n",
      "  episode_reward_min: -166.91659877988337\n",
      "  episodes_this_iter: 150\n",
      "  episodes_total: 37133\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.707\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 3260000\n",
      "    num_steps_trained: 3260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.684330684132874e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7625567317008972\n",
      "      kl: 0.039552170783281326\n",
      "      policy_loss: 0.008007434196770191\n",
      "      total_loss: 82.59810638427734\n",
      "      vf_explained_var: 0.8622348308563232\n",
      "      vf_loss: 82.59009552001953\n",
      "    sample_time_ms: 18218.93\n",
      "    update_time_ms: 5.287\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -3.897732596750052\n",
      "  time_since_restore: 7196.273926496506\n",
      "  time_this_iter_s: 22.011420488357544\n",
      "  time_total_s: 7196.273926496506\n",
      "  timestamp: 1553129005\n",
      "  timesteps_since_restore: 3260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3260000\n",
      "  training_iteration: 326\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7196 s, 326 iter, 3260000 ts, -7.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-43-47\n",
      "  done: false\n",
      "  episode_len_mean: 72.73722627737226\n",
      "  episode_reward_max: 387.09372682717554\n",
      "  episode_reward_mean: 33.90607554301994\n",
      "  episode_reward_min: -163.99848932549\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 37270\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.171\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 3270000\n",
      "    num_steps_trained: 3270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.684330684132874e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.735213577747345\n",
      "      kl: 0.033725421875715256\n",
      "      policy_loss: 0.005312465131282806\n",
      "      total_loss: 70.85467529296875\n",
      "      vf_explained_var: 0.8670306205749512\n",
      "      vf_loss: 70.84935760498047\n",
      "    sample_time_ms: 18301.968\n",
      "    update_time_ms: 5.566\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.953037771509962\n",
      "  time_since_restore: 7218.930256128311\n",
      "  time_this_iter_s: 22.65632963180542\n",
      "  time_total_s: 7218.930256128311\n",
      "  timestamp: 1553129027\n",
      "  timesteps_since_restore: 3270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3270000\n",
      "  training_iteration: 327\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7218 s, 327 iter, 3270000 ts, 33.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-44-09\n",
      "  done: false\n",
      "  episode_len_mean: 73.72592592592592\n",
      "  episode_reward_max: 389.104921097672\n",
      "  episode_reward_mean: 42.60016321432707\n",
      "  episode_reward_min: -163.20442401113746\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 37405\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.866\n",
      "    load_time_ms: 1.65\n",
      "    num_steps_sampled: 3280000\n",
      "    num_steps_trained: 3280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.684330684132874e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.725489616394043\n",
      "      kl: 0.0787709578871727\n",
      "      policy_loss: 0.008640124462544918\n",
      "      total_loss: 75.55718231201172\n",
      "      vf_explained_var: 0.8558032512664795\n",
      "      vf_loss: 75.54853057861328\n",
      "    sample_time_ms: 18316.491\n",
      "    update_time_ms: 5.399\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.300081607163534\n",
      "  time_since_restore: 7240.516499042511\n",
      "  time_this_iter_s: 21.58624291419983\n",
      "  time_total_s: 7240.516499042511\n",
      "  timestamp: 1553129049\n",
      "  timesteps_since_restore: 3280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3280000\n",
      "  training_iteration: 328\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7240 s, 328 iter, 3280000 ts, 42.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-44-30\n",
      "  done: false\n",
      "  episode_len_mean: 73.62773722627738\n",
      "  episode_reward_max: 386.4561476559146\n",
      "  episode_reward_mean: 39.18051265864236\n",
      "  episode_reward_min: -166.92186852189542\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 37542\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.327\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 3290000\n",
      "    num_steps_trained: 3290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.026496389997192e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7195213437080383\n",
      "      kl: 0.04625700041651726\n",
      "      policy_loss: 0.007790981326252222\n",
      "      total_loss: 73.6041030883789\n",
      "      vf_explained_var: 0.8622297644615173\n",
      "      vf_loss: 73.59630584716797\n",
      "    sample_time_ms: 18273.797\n",
      "    update_time_ms: 5.353\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.590256329321168\n",
      "  time_since_restore: 7261.94326043129\n",
      "  time_this_iter_s: 21.426761388778687\n",
      "  time_total_s: 7261.94326043129\n",
      "  timestamp: 1553129070\n",
      "  timesteps_since_restore: 3290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3290000\n",
      "  training_iteration: 329\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7261 s, 329 iter, 3290000 ts, 39.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-44-53\n",
      "  done: false\n",
      "  episode_len_mean: 71.76258992805755\n",
      "  episode_reward_max: 387.8879829828817\n",
      "  episode_reward_mean: 29.18302897343096\n",
      "  episode_reward_min: -166.9980579955244\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 37681\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.487\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 3300000\n",
      "    num_steps_trained: 3300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.039744403096847e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7376176118850708\n",
      "      kl: 0.06255199015140533\n",
      "      policy_loss: 0.005709432996809483\n",
      "      total_loss: 76.69347381591797\n",
      "      vf_explained_var: 0.8592530488967896\n",
      "      vf_loss: 76.68775177001953\n",
      "    sample_time_ms: 18254.496\n",
      "    update_time_ms: 5.017\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.591514486715486\n",
      "  time_since_restore: 7284.141428232193\n",
      "  time_this_iter_s: 22.19816780090332\n",
      "  time_total_s: 7284.141428232193\n",
      "  timestamp: 1553129093\n",
      "  timesteps_since_restore: 3300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3300000\n",
      "  training_iteration: 330\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7284 s, 330 iter, 3300000 ts, 29.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-45-15\n",
      "  done: false\n",
      "  episode_len_mean: 64.31612903225806\n",
      "  episode_reward_max: 387.87805585447524\n",
      "  episode_reward_mean: -17.55486040187622\n",
      "  episode_reward_min: -167.0494963885808\n",
      "  episodes_this_iter: 155\n",
      "  episodes_total: 37836\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.613\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 3310000\n",
      "    num_steps_trained: 3310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.059615695150569e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7645605206489563\n",
      "      kl: 0.04119729995727539\n",
      "      policy_loss: 0.008576747961342335\n",
      "      total_loss: 86.99640655517578\n",
      "      vf_explained_var: 0.8614705204963684\n",
      "      vf_loss: 86.98783111572266\n",
      "    sample_time_ms: 18297.679\n",
      "    update_time_ms: 5.076\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -8.77743020093811\n",
      "  time_since_restore: 7306.310763120651\n",
      "  time_this_iter_s: 22.169334888458252\n",
      "  time_total_s: 7306.310763120651\n",
      "  timestamp: 1553129115\n",
      "  timesteps_since_restore: 3310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3310000\n",
      "  training_iteration: 331\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7306 s, 331 iter, 3310000 ts, -17.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-45-36\n",
      "  done: false\n",
      "  episode_len_mean: 72.6086956521739\n",
      "  episode_reward_max: 382.8769263637894\n",
      "  episode_reward_mean: 38.8436853054697\n",
      "  episode_reward_min: -167.00083350070952\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 37974\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.314\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 3320000\n",
      "    num_steps_trained: 3320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00013589423906523734\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7230268716812134\n",
      "      kl: 0.053680334240198135\n",
      "      policy_loss: 0.009513812139630318\n",
      "      total_loss: 81.33507537841797\n",
      "      vf_explained_var: 0.8478918075561523\n",
      "      vf_loss: 81.3255615234375\n",
      "    sample_time_ms: 18279.811\n",
      "    update_time_ms: 5.266\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.421842652734842\n",
      "  time_since_restore: 7327.692128896713\n",
      "  time_this_iter_s: 21.38136577606201\n",
      "  time_total_s: 7327.692128896713\n",
      "  timestamp: 1553129136\n",
      "  timesteps_since_restore: 3320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3320000\n",
      "  training_iteration: 332\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7327 s, 332 iter, 3320000 ts, 38.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-45-58\n",
      "  done: false\n",
      "  episode_len_mean: 70.83802816901408\n",
      "  episode_reward_max: 384.2713737670324\n",
      "  episode_reward_mean: 20.267683863060935\n",
      "  episode_reward_min: -166.99244840654373\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 38116\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.454\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 3330000\n",
      "    num_steps_trained: 3330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00020384133676998317\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7235434055328369\n",
      "      kl: 0.04430486634373665\n",
      "      policy_loss: 0.008262934163212776\n",
      "      total_loss: 50.64698028564453\n",
      "      vf_explained_var: 0.9121999740600586\n",
      "      vf_loss: 50.638710021972656\n",
      "    sample_time_ms: 18296.111\n",
      "    update_time_ms: 5.227\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 10.133841931530474\n",
      "  time_since_restore: 7349.948134183884\n",
      "  time_this_iter_s: 22.25600528717041\n",
      "  time_total_s: 7349.948134183884\n",
      "  timestamp: 1553129158\n",
      "  timesteps_since_restore: 3330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3330000\n",
      "  training_iteration: 333\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7349 s, 333 iter, 3330000 ts, 20.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-46-21\n",
      "  done: false\n",
      "  episode_len_mean: 73.27407407407408\n",
      "  episode_reward_max: 388.0842989877434\n",
      "  episode_reward_mean: 33.869595842764575\n",
      "  episode_reward_min: -169.10601761790753\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 38251\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3679.99\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 3340000\n",
      "    num_steps_trained: 3340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00030576204881072044\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7150711417198181\n",
      "      kl: 0.04136572405695915\n",
      "      policy_loss: 0.004761241376399994\n",
      "      total_loss: 56.42243194580078\n",
      "      vf_explained_var: 0.8923652768135071\n",
      "      vf_loss: 56.41765594482422\n",
      "    sample_time_ms: 18333.862\n",
      "    update_time_ms: 5.198\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.934797921382284\n",
      "  time_since_restore: 7372.4429931640625\n",
      "  time_this_iter_s: 22.494858980178833\n",
      "  time_total_s: 7372.4429931640625\n",
      "  timestamp: 1553129181\n",
      "  timesteps_since_restore: 3340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3340000\n",
      "  training_iteration: 334\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7372 s, 334 iter, 3340000 ts, 33.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-46-43\n",
      "  done: false\n",
      "  episode_len_mean: 74.05925925925926\n",
      "  episode_reward_max: 387.55249100656664\n",
      "  episode_reward_mean: 39.952186935755755\n",
      "  episode_reward_min: -166.8759837345743\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 38386\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.367\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 3350000\n",
      "    num_steps_trained: 3350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0004586430441122502\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7180145978927612\n",
      "      kl: 0.05199722573161125\n",
      "      policy_loss: 0.006441062781959772\n",
      "      total_loss: 70.66505432128906\n",
      "      vf_explained_var: 0.8669590353965759\n",
      "      vf_loss: 70.6585922241211\n",
      "    sample_time_ms: 18291.655\n",
      "    update_time_ms: 5.247\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.976093467877885\n",
      "  time_since_restore: 7394.325459241867\n",
      "  time_this_iter_s: 21.882466077804565\n",
      "  time_total_s: 7394.325459241867\n",
      "  timestamp: 1553129203\n",
      "  timesteps_since_restore: 3350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3350000\n",
      "  training_iteration: 335\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7394 s, 335 iter, 3350000 ts, 40 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-47-05\n",
      "  done: false\n",
      "  episode_len_mean: 68.92465753424658\n",
      "  episode_reward_max: 388.5241398875194\n",
      "  episode_reward_mean: 5.089240780122571\n",
      "  episode_reward_min: -167.2220417326951\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 38532\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.124\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 3360000\n",
      "    num_steps_trained: 3360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006879646680317819\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7284336686134338\n",
      "      kl: 0.117645762860775\n",
      "      policy_loss: 0.028168324381113052\n",
      "      total_loss: 62.60675811767578\n",
      "      vf_explained_var: 0.893497884273529\n",
      "      vf_loss: 62.57849884033203\n",
      "    sample_time_ms: 18307.083\n",
      "    update_time_ms: 5.554\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 2.5446203900612874\n",
      "  time_since_restore: 7416.513691902161\n",
      "  time_this_iter_s: 22.18823266029358\n",
      "  time_total_s: 7416.513691902161\n",
      "  timestamp: 1553129225\n",
      "  timesteps_since_restore: 3360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3360000\n",
      "  training_iteration: 336\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7416 s, 336 iter, 3360000 ts, 5.09 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-47-27\n",
      "  done: false\n",
      "  episode_len_mean: 75.9469696969697\n",
      "  episode_reward_max: 383.0439008805201\n",
      "  episode_reward_mean: 48.59525141222573\n",
      "  episode_reward_min: -164.74516167851925\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 38664\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.188\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 3370000\n",
      "    num_steps_trained: 3370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010319468565285206\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6903292536735535\n",
      "      kl: 0.06198672577738762\n",
      "      policy_loss: 0.0059961057268083096\n",
      "      total_loss: 64.23189544677734\n",
      "      vf_explained_var: 0.8760610818862915\n",
      "      vf_loss: 64.22583770751953\n",
      "    sample_time_ms: 18260.613\n",
      "    update_time_ms: 5.264\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.297625706112864\n",
      "  time_since_restore: 7438.662766456604\n",
      "  time_this_iter_s: 22.14907455444336\n",
      "  time_total_s: 7438.662766456604\n",
      "  timestamp: 1553129247\n",
      "  timesteps_since_restore: 3370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3370000\n",
      "  training_iteration: 337\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7438 s, 337 iter, 3370000 ts, 48.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-47-49\n",
      "  done: false\n",
      "  episode_len_mean: 73.29411764705883\n",
      "  episode_reward_max: 387.3641155050467\n",
      "  episode_reward_mean: 39.690922802372036\n",
      "  episode_reward_min: -162.62044113823413\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 38800\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.738\n",
      "    load_time_ms: 1.635\n",
      "    num_steps_sampled: 3380000\n",
      "    num_steps_trained: 3380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0015479204012081027\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7215175032615662\n",
      "      kl: 0.030481301248073578\n",
      "      policy_loss: 0.00678689731284976\n",
      "      total_loss: 71.15458679199219\n",
      "      vf_explained_var: 0.8647862672805786\n",
      "      vf_loss: 71.14775085449219\n",
      "    sample_time_ms: 18257.928\n",
      "    update_time_ms: 5.363\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.845461401186018\n",
      "  time_since_restore: 7460.243132352829\n",
      "  time_this_iter_s: 21.580365896224976\n",
      "  time_total_s: 7460.243132352829\n",
      "  timestamp: 1553129269\n",
      "  timesteps_since_restore: 3380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3380000\n",
      "  training_iteration: 338\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7460 s, 338 iter, 3380000 ts, 39.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-48-11\n",
      "  done: false\n",
      "  episode_len_mean: 72.23913043478261\n",
      "  episode_reward_max: 388.4735150113566\n",
      "  episode_reward_mean: 38.80301163875144\n",
      "  episode_reward_min: -167.31521865287067\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 38938\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.751\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 3390000\n",
      "    num_steps_trained: 3390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0015479204012081027\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7274622917175293\n",
      "      kl: 0.043392278254032135\n",
      "      policy_loss: 0.010345159098505974\n",
      "      total_loss: 67.48273468017578\n",
      "      vf_explained_var: 0.8727579116821289\n",
      "      vf_loss: 67.47232055664062\n",
      "    sample_time_ms: 18298.175\n",
      "    update_time_ms: 5.574\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.40150581937572\n",
      "  time_since_restore: 7482.157284259796\n",
      "  time_this_iter_s: 21.914151906967163\n",
      "  time_total_s: 7482.157284259796\n",
      "  timestamp: 1553129291\n",
      "  timesteps_since_restore: 3390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3390000\n",
      "  training_iteration: 339\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7482 s, 339 iter, 3390000 ts, 38.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-48-33\n",
      "  done: false\n",
      "  episode_len_mean: 71.81294964028777\n",
      "  episode_reward_max: 382.9592888149971\n",
      "  episode_reward_mean: 30.20653053720443\n",
      "  episode_reward_min: -162.67362206074236\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 39077\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.444\n",
      "    load_time_ms: 1.713\n",
      "    num_steps_sampled: 3400000\n",
      "    num_steps_trained: 3400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.002321880543604493\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6932990550994873\n",
      "      kl: 1.73115873336792\n",
      "      policy_loss: 0.028977470472455025\n",
      "      total_loss: 63.91227340698242\n",
      "      vf_explained_var: 0.8849858045578003\n",
      "      vf_loss: 63.87928009033203\n",
      "    sample_time_ms: 18263.454\n",
      "    update_time_ms: 5.634\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.103265268602215\n",
      "  time_since_restore: 7504.058793306351\n",
      "  time_this_iter_s: 21.901509046554565\n",
      "  time_total_s: 7504.058793306351\n",
      "  timestamp: 1553129313\n",
      "  timesteps_since_restore: 3400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3400000\n",
      "  training_iteration: 340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7504 s, 340 iter, 3400000 ts, 30.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-48-55\n",
      "  done: false\n",
      "  episode_len_mean: 70.66433566433567\n",
      "  episode_reward_max: 388.80696651489797\n",
      "  episode_reward_mean: 18.142649785405098\n",
      "  episode_reward_min: -165.23005699017287\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 39220\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.278\n",
      "    load_time_ms: 1.756\n",
      "    num_steps_sampled: 3410000\n",
      "    num_steps_trained: 3410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0034828209318220615\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6761385798454285\n",
      "      kl: 0.04943295568227768\n",
      "      policy_loss: 0.009170003235340118\n",
      "      total_loss: 73.52070617675781\n",
      "      vf_explained_var: 0.8720728754997253\n",
      "      vf_loss: 73.51136779785156\n",
      "    sample_time_ms: 18248.93\n",
      "    update_time_ms: 5.611\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.071324892702544\n",
      "  time_since_restore: 7526.109738111496\n",
      "  time_this_iter_s: 22.050944805145264\n",
      "  time_total_s: 7526.109738111496\n",
      "  timestamp: 1553129335\n",
      "  timesteps_since_restore: 3410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3410000\n",
      "  training_iteration: 341\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7526 s, 341 iter, 3410000 ts, 18.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-49-18\n",
      "  done: false\n",
      "  episode_len_mean: 72.4963503649635\n",
      "  episode_reward_max: 386.86689712022775\n",
      "  episode_reward_mean: 30.386537087298624\n",
      "  episode_reward_min: -167.08954688730478\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 39357\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.561\n",
      "    load_time_ms: 1.804\n",
      "    num_steps_sampled: 3420000\n",
      "    num_steps_trained: 3420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.005224231164902449\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6629621386528015\n",
      "      kl: 0.035470932722091675\n",
      "      policy_loss: 0.006910097785294056\n",
      "      total_loss: 71.8348388671875\n",
      "      vf_explained_var: 0.8664035201072693\n",
      "      vf_loss: 71.82775115966797\n",
      "    sample_time_ms: 18355.58\n",
      "    update_time_ms: 5.243\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.193268543649312\n",
      "  time_since_restore: 7548.618846178055\n",
      "  time_this_iter_s: 22.509108066558838\n",
      "  time_total_s: 7548.618846178055\n",
      "  timestamp: 1553129358\n",
      "  timesteps_since_restore: 3420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3420000\n",
      "  training_iteration: 342\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7548 s, 342 iter, 3420000 ts, 30.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-49-40\n",
      "  done: false\n",
      "  episode_len_mean: 70.16901408450704\n",
      "  episode_reward_max: 385.4236892282321\n",
      "  episode_reward_mean: 20.06016927748963\n",
      "  episode_reward_min: -162.83939947804453\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 39499\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3731.902\n",
      "    load_time_ms: 1.761\n",
      "    num_steps_sampled: 3430000\n",
      "    num_steps_trained: 3430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.005224231164902449\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6899017095565796\n",
      "      kl: 0.03326765075325966\n",
      "      policy_loss: 0.005428638309240341\n",
      "      total_loss: 67.08802795410156\n",
      "      vf_explained_var: 0.8826677203178406\n",
      "      vf_loss: 67.08242797851562\n",
      "    sample_time_ms: 18329.848\n",
      "    update_time_ms: 5.388\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 10.030084638744814\n",
      "  time_since_restore: 7570.834197998047\n",
      "  time_this_iter_s: 22.215351819992065\n",
      "  time_total_s: 7570.834197998047\n",
      "  timestamp: 1553129380\n",
      "  timesteps_since_restore: 3430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3430000\n",
      "  training_iteration: 343\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7570 s, 343 iter, 3430000 ts, 20.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-50-01\n",
      "  done: false\n",
      "  episode_len_mean: 69.38620689655173\n",
      "  episode_reward_max: 387.38744255196684\n",
      "  episode_reward_mean: 13.68347901244216\n",
      "  episode_reward_min: -166.973846909132\n",
      "  episodes_this_iter: 145\n",
      "  episodes_total: 39644\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.464\n",
      "    load_time_ms: 1.738\n",
      "    num_steps_sampled: 3440000\n",
      "    num_steps_trained: 3440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.005224231164902449\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7199165225028992\n",
      "      kl: 0.040390271693468094\n",
      "      policy_loss: 0.009352292865514755\n",
      "      total_loss: 77.41119384765625\n",
      "      vf_explained_var: 0.8654274344444275\n",
      "      vf_loss: 77.40162658691406\n",
      "    sample_time_ms: 18242.661\n",
      "    update_time_ms: 5.385\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.841739506221082\n",
      "  time_since_restore: 7592.4923231601715\n",
      "  time_this_iter_s: 21.658125162124634\n",
      "  time_total_s: 7592.4923231601715\n",
      "  timestamp: 1553129401\n",
      "  timesteps_since_restore: 3440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3440000\n",
      "  training_iteration: 344\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7592 s, 344 iter, 3440000 ts, 13.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-50-24\n",
      "  done: false\n",
      "  episode_len_mean: 72.10144927536231\n",
      "  episode_reward_max: 385.811623174525\n",
      "  episode_reward_mean: 36.33081731872809\n",
      "  episode_reward_min: -163.446097712543\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 39782\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3725.204\n",
      "    load_time_ms: 1.707\n",
      "    num_steps_sampled: 3450000\n",
      "    num_steps_trained: 3450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00783634651452303\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7046902179718018\n",
      "      kl: 0.04833393543958664\n",
      "      policy_loss: 0.005955052096396685\n",
      "      total_loss: 61.70425033569336\n",
      "      vf_explained_var: 0.886663556098938\n",
      "      vf_loss: 61.69791030883789\n",
      "    sample_time_ms: 18271.952\n",
      "    update_time_ms: 5.28\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.165408659364033\n",
      "  time_since_restore: 7614.561598539352\n",
      "  time_this_iter_s: 22.069275379180908\n",
      "  time_total_s: 7614.561598539352\n",
      "  timestamp: 1553129424\n",
      "  timesteps_since_restore: 3450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3450000\n",
      "  training_iteration: 345\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7614 s, 345 iter, 3450000 ts, 36.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-50-45\n",
      "  done: false\n",
      "  episode_len_mean: 70.33566433566433\n",
      "  episode_reward_max: 385.17425864315436\n",
      "  episode_reward_mean: 19.978106705704796\n",
      "  episode_reward_min: -167.00408038290976\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 39925\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.526\n",
      "    load_time_ms: 1.744\n",
      "    num_steps_sampled: 3460000\n",
      "    num_steps_trained: 3460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011754520237445831\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7089303731918335\n",
      "      kl: 0.047146350145339966\n",
      "      policy_loss: 0.00948056485503912\n",
      "      total_loss: 71.67536926269531\n",
      "      vf_explained_var: 0.8714196681976318\n",
      "      vf_loss: 71.66533660888672\n",
      "    sample_time_ms: 18234.978\n",
      "    update_time_ms: 5.055\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.9890533528524\n",
      "  time_since_restore: 7636.374340295792\n",
      "  time_this_iter_s: 21.81274175643921\n",
      "  time_total_s: 7636.374340295792\n",
      "  timestamp: 1553129445\n",
      "  timesteps_since_restore: 3460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3460000\n",
      "  training_iteration: 346\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7636 s, 346 iter, 3460000 ts, 20 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-51-07\n",
      "  done: false\n",
      "  episode_len_mean: 75.19548872180451\n",
      "  episode_reward_max: 387.89140880120226\n",
      "  episode_reward_mean: 47.39267756126228\n",
      "  episode_reward_min: -163.73872773339986\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 40058\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3725.968\n",
      "    load_time_ms: 1.663\n",
      "    num_steps_sampled: 3470000\n",
      "    num_steps_trained: 3470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017631782218813896\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7232272028923035\n",
      "      kl: 0.04295308142900467\n",
      "      policy_loss: 0.007237541489303112\n",
      "      total_loss: 77.00027465820312\n",
      "      vf_explained_var: 0.8519688248634338\n",
      "      vf_loss: 76.99227905273438\n",
      "    sample_time_ms: 18152.321\n",
      "    update_time_ms: 5.093\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.696338780631137\n",
      "  time_since_restore: 7657.707547187805\n",
      "  time_this_iter_s: 21.33320689201355\n",
      "  time_total_s: 7657.707547187805\n",
      "  timestamp: 1553129467\n",
      "  timesteps_since_restore: 3470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3470000\n",
      "  training_iteration: 347\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7657 s, 347 iter, 3470000 ts, 47.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-51-29\n",
      "  done: false\n",
      "  episode_len_mean: 70.52482269503547\n",
      "  episode_reward_max: 387.5891011542397\n",
      "  episode_reward_mean: 15.80957054406802\n",
      "  episode_reward_min: -167.10773213502407\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 40199\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.266\n",
      "    load_time_ms: 1.688\n",
      "    num_steps_sampled: 3480000\n",
      "    num_steps_trained: 3480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02644767425954342\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7233049273490906\n",
      "      kl: 0.027195032685995102\n",
      "      policy_loss: 0.006151895504444838\n",
      "      total_loss: 60.13926696777344\n",
      "      vf_explained_var: 0.8933708071708679\n",
      "      vf_loss: 60.13240051269531\n",
      "    sample_time_ms: 18226.51\n",
      "    update_time_ms: 5.34\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.9047852720340055\n",
      "  time_since_restore: 7679.974871635437\n",
      "  time_this_iter_s: 22.267324447631836\n",
      "  time_total_s: 7679.974871635437\n",
      "  timestamp: 1553129489\n",
      "  timesteps_since_restore: 3480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3480000\n",
      "  training_iteration: 348\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7679 s, 348 iter, 3480000 ts, 15.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-51-51\n",
      "  done: false\n",
      "  episode_len_mean: 77.35384615384615\n",
      "  episode_reward_max: 387.0341605776675\n",
      "  episode_reward_mean: 63.173711268419275\n",
      "  episode_reward_min: -162.62983038040636\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 40329\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.659\n",
      "    load_time_ms: 1.712\n",
      "    num_steps_sampled: 3490000\n",
      "    num_steps_trained: 3490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02644767425954342\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6826649904251099\n",
      "      kl: 0.03842110559344292\n",
      "      policy_loss: 0.00875053834170103\n",
      "      total_loss: 74.58114624023438\n",
      "      vf_explained_var: 0.8483628630638123\n",
      "      vf_loss: 74.57138061523438\n",
      "    sample_time_ms: 18245.342\n",
      "    update_time_ms: 5.239\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.586855634209638\n",
      "  time_since_restore: 7701.978016376495\n",
      "  time_this_iter_s: 22.00314474105835\n",
      "  time_total_s: 7701.978016376495\n",
      "  timestamp: 1553129511\n",
      "  timesteps_since_restore: 3490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3490000\n",
      "  training_iteration: 349\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7701 s, 349 iter, 3490000 ts, 63.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-52-14\n",
      "  done: false\n",
      "  episode_len_mean: 71.53571428571429\n",
      "  episode_reward_max: 388.4075814066938\n",
      "  episode_reward_mean: 26.80919816116729\n",
      "  episode_reward_min: -169.10259694835185\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 40469\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.88\n",
      "    load_time_ms: 1.664\n",
      "    num_steps_sampled: 3500000\n",
      "    num_steps_trained: 3500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02644767425954342\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7178006172180176\n",
      "      kl: 0.0491987019777298\n",
      "      policy_loss: 0.007730592507869005\n",
      "      total_loss: 69.02118682861328\n",
      "      vf_explained_var: 0.8750653266906738\n",
      "      vf_loss: 69.01215362548828\n",
      "    sample_time_ms: 18309.235\n",
      "    update_time_ms: 5.283\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 13.404599080583644\n",
      "  time_since_restore: 7724.486712217331\n",
      "  time_this_iter_s: 22.50869584083557\n",
      "  time_total_s: 7724.486712217331\n",
      "  timestamp: 1553129534\n",
      "  timesteps_since_restore: 3500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3500000\n",
      "  training_iteration: 350\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7724 s, 350 iter, 3500000 ts, 26.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-52-36\n",
      "  done: false\n",
      "  episode_len_mean: 74.57142857142857\n",
      "  episode_reward_max: 387.7476622658698\n",
      "  episode_reward_mean: 46.60880841869397\n",
      "  episode_reward_min: -169.1808509052658\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 40602\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.227\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 3510000\n",
      "    num_steps_trained: 3510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.039671506732702255\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7218669652938843\n",
      "      kl: 0.04142918437719345\n",
      "      policy_loss: 0.007448937743902206\n",
      "      total_loss: 75.7284164428711\n",
      "      vf_explained_var: 0.8520675897598267\n",
      "      vf_loss: 75.71932220458984\n",
      "    sample_time_ms: 18334.023\n",
      "    update_time_ms: 5.34\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.304404209346984\n",
      "  time_since_restore: 7746.77706360817\n",
      "  time_this_iter_s: 22.290351390838623\n",
      "  time_total_s: 7746.77706360817\n",
      "  timestamp: 1553129556\n",
      "  timesteps_since_restore: 3510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3510000\n",
      "  training_iteration: 351\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7746 s, 351 iter, 3510000 ts, 46.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-52-58\n",
      "  done: false\n",
      "  episode_len_mean: 75.87878787878788\n",
      "  episode_reward_max: 389.5481252406135\n",
      "  episode_reward_mean: 56.08749003082913\n",
      "  episode_reward_min: -167.3367537595892\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 40734\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.816\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 3520000\n",
      "    num_steps_trained: 3520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7212501168251038\n",
      "      kl: 0.03627188876271248\n",
      "      policy_loss: 0.005881245248019695\n",
      "      total_loss: 65.73023986816406\n",
      "      vf_explained_var: 0.8676434755325317\n",
      "      vf_loss: 65.72220611572266\n",
      "    sample_time_ms: 18249.194\n",
      "    update_time_ms: 5.407\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.043745015414565\n",
      "  time_since_restore: 7768.5221927165985\n",
      "  time_this_iter_s: 21.745129108428955\n",
      "  time_total_s: 7768.5221927165985\n",
      "  timestamp: 1553129578\n",
      "  timesteps_since_restore: 3520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3520000\n",
      "  training_iteration: 352\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7768 s, 352 iter, 3520000 ts, 56.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-53-20\n",
      "  done: false\n",
      "  episode_len_mean: 69.67832167832168\n",
      "  episode_reward_max: 385.79386793967984\n",
      "  episode_reward_mean: 17.758940763086393\n",
      "  episode_reward_min: -163.7279619044328\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 40877\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.945\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 3530000\n",
      "    num_steps_trained: 3530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7328062653541565\n",
      "      kl: 0.03087022341787815\n",
      "      policy_loss: 0.005308111198246479\n",
      "      total_loss: 76.59368896484375\n",
      "      vf_explained_var: 0.8650227189064026\n",
      "      vf_loss: 76.58654022216797\n",
      "    sample_time_ms: 18297.635\n",
      "    update_time_ms: 5.618\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.879470381543195\n",
      "  time_since_restore: 7790.982570886612\n",
      "  time_this_iter_s: 22.460378170013428\n",
      "  time_total_s: 7790.982570886612\n",
      "  timestamp: 1553129600\n",
      "  timesteps_since_restore: 3530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3530000\n",
      "  training_iteration: 353\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7790 s, 353 iter, 3530000 ts, 17.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-53-43\n",
      "  done: false\n",
      "  episode_len_mean: 71.75714285714285\n",
      "  episode_reward_max: 387.65505169667256\n",
      "  episode_reward_mean: 26.957235129870906\n",
      "  episode_reward_min: -164.93150014182567\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 41017\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.077\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 3540000\n",
      "    num_steps_trained: 3540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7145599722862244\n",
      "      kl: 0.0319284163415432\n",
      "      policy_loss: 0.007798288017511368\n",
      "      total_loss: 66.1547622680664\n",
      "      vf_explained_var: 0.8803349733352661\n",
      "      vf_loss: 66.14506530761719\n",
      "    sample_time_ms: 18338.531\n",
      "    update_time_ms: 5.634\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 13.478617564935451\n",
      "  time_since_restore: 7813.168869972229\n",
      "  time_this_iter_s: 22.186299085617065\n",
      "  time_total_s: 7813.168869972229\n",
      "  timestamp: 1553129623\n",
      "  timesteps_since_restore: 3540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3540000\n",
      "  training_iteration: 354\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7813 s, 354 iter, 3540000 ts, 27 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-54-04\n",
      "  done: false\n",
      "  episode_len_mean: 71.32624113475177\n",
      "  episode_reward_max: 388.10748571735013\n",
      "  episode_reward_mean: 13.978699547985988\n",
      "  episode_reward_min: -167.05887716635704\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 41158\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.903\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 3550000\n",
      "    num_steps_trained: 3550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6916937232017517\n",
      "      kl: 0.038512323051691055\n",
      "      policy_loss: 0.008117289282381535\n",
      "      total_loss: 62.098670959472656\n",
      "      vf_explained_var: 0.8917988538742065\n",
      "      vf_loss: 62.08826446533203\n",
      "    sample_time_ms: 18287.15\n",
      "    update_time_ms: 5.899\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.989349773992994\n",
      "  time_since_restore: 7834.7569353580475\n",
      "  time_this_iter_s: 21.58806538581848\n",
      "  time_total_s: 7834.7569353580475\n",
      "  timestamp: 1553129644\n",
      "  timesteps_since_restore: 3550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3550000\n",
      "  training_iteration: 355\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7834 s, 355 iter, 3550000 ts, 14 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-54-26\n",
      "  done: false\n",
      "  episode_len_mean: 70.33802816901408\n",
      "  episode_reward_max: 389.83489597369083\n",
      "  episode_reward_mean: 11.829085356938869\n",
      "  episode_reward_min: -165.14791792156936\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 41300\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.838\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 3560000\n",
      "    num_steps_trained: 3560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7077608108520508\n",
      "      kl: 0.04261072352528572\n",
      "      policy_loss: 0.007723349146544933\n",
      "      total_loss: 77.46360778808594\n",
      "      vf_explained_var: 0.8633192181587219\n",
      "      vf_loss: 77.4533462524414\n",
      "    sample_time_ms: 18248.114\n",
      "    update_time_ms: 6.113\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 5.914542678469435\n",
      "  time_since_restore: 7856.145530462265\n",
      "  time_this_iter_s: 21.38859510421753\n",
      "  time_total_s: 7856.145530462265\n",
      "  timestamp: 1553129666\n",
      "  timesteps_since_restore: 3560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3560000\n",
      "  training_iteration: 356\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7856 s, 356 iter, 3560000 ts, 11.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-54-48\n",
      "  done: false\n",
      "  episode_len_mean: 71.44285714285714\n",
      "  episode_reward_max: 387.8425078009392\n",
      "  episode_reward_mean: 22.40213773378985\n",
      "  episode_reward_min: -167.7479234764242\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 41440\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.665\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 3570000\n",
      "    num_steps_trained: 3570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6823639869689941\n",
      "      kl: 0.024041712284088135\n",
      "      policy_loss: 0.003352191299200058\n",
      "      total_loss: 66.54976654052734\n",
      "      vf_explained_var: 0.8800762891769409\n",
      "      vf_loss: 66.54425811767578\n",
      "    sample_time_ms: 18314.048\n",
      "    update_time_ms: 6.037\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.201068866894921\n",
      "  time_since_restore: 7878.126503705978\n",
      "  time_this_iter_s: 21.98097324371338\n",
      "  time_total_s: 7878.126503705978\n",
      "  timestamp: 1553129688\n",
      "  timesteps_since_restore: 3570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3570000\n",
      "  training_iteration: 357\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7878 s, 357 iter, 3570000 ts, 22.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-55-09\n",
      "  done: false\n",
      "  episode_len_mean: 72.31884057971014\n",
      "  episode_reward_max: 388.58148133354\n",
      "  episode_reward_mean: 28.85940966961466\n",
      "  episode_reward_min: -165.74714322641134\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 41578\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.218\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 3580000\n",
      "    num_steps_trained: 3580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6867325305938721\n",
      "      kl: 0.03242415562272072\n",
      "      policy_loss: 0.0034881692845374346\n",
      "      total_loss: 79.37008666992188\n",
      "      vf_explained_var: 0.8540748953819275\n",
      "      vf_loss: 79.36370849609375\n",
      "    sample_time_ms: 18237.793\n",
      "    update_time_ms: 5.819\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.429704834807321\n",
      "  time_since_restore: 7899.670163393021\n",
      "  time_this_iter_s: 21.543659687042236\n",
      "  time_total_s: 7899.670163393021\n",
      "  timestamp: 1553129709\n",
      "  timesteps_since_restore: 3580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3580000\n",
      "  training_iteration: 358\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7899 s, 358 iter, 3580000 ts, 28.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-55-31\n",
      "  done: false\n",
      "  episode_len_mean: 71.63309352517986\n",
      "  episode_reward_max: 386.5694184033391\n",
      "  episode_reward_mean: 15.84010766924505\n",
      "  episode_reward_min: -167.28605493470667\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 41717\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.402\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 3590000\n",
      "    num_steps_trained: 3590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6904599070549011\n",
      "      kl: 0.028380142524838448\n",
      "      policy_loss: 0.003623753320425749\n",
      "      total_loss: 61.039424896240234\n",
      "      vf_explained_var: 0.8897314071655273\n",
      "      vf_loss: 61.03326416015625\n",
      "    sample_time_ms: 18192.099\n",
      "    update_time_ms: 6.181\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.920053834622531\n",
      "  time_since_restore: 7921.204299926758\n",
      "  time_this_iter_s: 21.534136533737183\n",
      "  time_total_s: 7921.204299926758\n",
      "  timestamp: 1553129731\n",
      "  timesteps_since_restore: 3590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3590000\n",
      "  training_iteration: 359\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7921 s, 359 iter, 3590000 ts, 15.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-55-53\n",
      "  done: false\n",
      "  episode_len_mean: 68.1156462585034\n",
      "  episode_reward_max: 386.1004429832765\n",
      "  episode_reward_mean: 0.02593182927868071\n",
      "  episode_reward_min: -167.37382695021867\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 41864\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.887\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 3600000\n",
      "    num_steps_trained: 3600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7175024151802063\n",
      "      kl: 0.0346488282084465\n",
      "      policy_loss: 0.0075720432214438915\n",
      "      total_loss: 66.05892181396484\n",
      "      vf_explained_var: 0.8869892954826355\n",
      "      vf_loss: 66.04825592041016\n",
      "    sample_time_ms: 18141.47\n",
      "    update_time_ms: 6.035\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 0.012965914639347317\n",
      "  time_since_restore: 7943.201239347458\n",
      "  time_this_iter_s: 21.996939420700073\n",
      "  time_total_s: 7943.201239347458\n",
      "  timestamp: 1553129753\n",
      "  timesteps_since_restore: 3600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3600000\n",
      "  training_iteration: 360\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7943 s, 360 iter, 3600000 ts, 0.0259 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-56-15\n",
      "  done: false\n",
      "  episode_len_mean: 61.31901840490798\n",
      "  episode_reward_max: 387.7023692247604\n",
      "  episode_reward_mean: -51.010291863373574\n",
      "  episode_reward_min: -165.5562230125928\n",
      "  episodes_this_iter: 163\n",
      "  episodes_total: 42027\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.841\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 3610000\n",
      "    num_steps_trained: 3610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.752446174621582\n",
      "      kl: 0.026126064360141754\n",
      "      policy_loss: 0.004619601182639599\n",
      "      total_loss: 77.22801971435547\n",
      "      vf_explained_var: 0.8799706697463989\n",
      "      vf_loss: 77.2210693359375\n",
      "    sample_time_ms: 18117.914\n",
      "    update_time_ms: 6.036\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -25.505145931686787\n",
      "  time_since_restore: 7965.2368359565735\n",
      "  time_this_iter_s: 22.0355966091156\n",
      "  time_total_s: 7965.2368359565735\n",
      "  timestamp: 1553129775\n",
      "  timesteps_since_restore: 3610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3610000\n",
      "  training_iteration: 361\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7965 s, 361 iter, 3610000 ts, -51 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-56-36\n",
      "  done: false\n",
      "  episode_len_mean: 70.95035460992908\n",
      "  episode_reward_max: 386.7820602946605\n",
      "  episode_reward_mean: 23.07990405962834\n",
      "  episode_reward_min: -167.16976910122872\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 42168\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.696\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 3620000\n",
      "    num_steps_trained: 3620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.700171947479248\n",
      "      kl: 0.03116588667035103\n",
      "      policy_loss: 0.007151277270168066\n",
      "      total_loss: 65.43679809570312\n",
      "      vf_explained_var: 0.8810060024261475\n",
      "      vf_loss: 65.42686462402344\n",
      "    sample_time_ms: 18057.755\n",
      "    update_time_ms: 6.298\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.539952029814167\n",
      "  time_since_restore: 7986.231703281403\n",
      "  time_this_iter_s: 20.9948673248291\n",
      "  time_total_s: 7986.231703281403\n",
      "  timestamp: 1553129796\n",
      "  timesteps_since_restore: 3620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3620000\n",
      "  training_iteration: 362\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 7986 s, 362 iter, 3620000 ts, 23.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-56-58\n",
      "  done: false\n",
      "  episode_len_mean: 69.34722222222223\n",
      "  episode_reward_max: 383.0563242946143\n",
      "  episode_reward_mean: 7.965096625792364\n",
      "  episode_reward_min: -167.5097686904931\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 42312\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.747\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 3630000\n",
      "    num_steps_trained: 3630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6789032220840454\n",
      "      kl: 0.030790911987423897\n",
      "      policy_loss: 0.004600499756634235\n",
      "      total_loss: 74.21988677978516\n",
      "      vf_explained_var: 0.8711062669754028\n",
      "      vf_loss: 74.2125244140625\n",
      "    sample_time_ms: 18000.647\n",
      "    update_time_ms: 5.958\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 3.9825483128961787\n",
      "  time_since_restore: 8008.107603549957\n",
      "  time_this_iter_s: 21.875900268554688\n",
      "  time_total_s: 8008.107603549957\n",
      "  timestamp: 1553129818\n",
      "  timesteps_since_restore: 3630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3630000\n",
      "  training_iteration: 363\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8008 s, 363 iter, 3630000 ts, 7.97 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-57-20\n",
      "  done: false\n",
      "  episode_len_mean: 68.08843537414965\n",
      "  episode_reward_max: 384.3159631476256\n",
      "  episode_reward_mean: 3.960213101769918\n",
      "  episode_reward_min: -167.19594903942584\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 42459\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3673.715\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 3640000\n",
      "    num_steps_trained: 3640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6963201761245728\n",
      "      kl: 0.033873558044433594\n",
      "      policy_loss: 0.006084182299673557\n",
      "      total_loss: 57.34590530395508\n",
      "      vf_explained_var: 0.9017024636268616\n",
      "      vf_loss: 57.336795806884766\n",
      "    sample_time_ms: 18015.67\n",
      "    update_time_ms: 6.025\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 1.9801065508849531\n",
      "  time_since_restore: 8030.315803289413\n",
      "  time_this_iter_s: 22.208199739456177\n",
      "  time_total_s: 8030.315803289413\n",
      "  timestamp: 1553129840\n",
      "  timesteps_since_restore: 3640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3640000\n",
      "  training_iteration: 364\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8030 s, 364 iter, 3640000 ts, 3.96 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-57-42\n",
      "  done: false\n",
      "  episode_len_mean: 65.73202614379085\n",
      "  episode_reward_max: 387.8126954320386\n",
      "  episode_reward_mean: -12.374725335561163\n",
      "  episode_reward_min: -164.8407753711009\n",
      "  episodes_this_iter: 153\n",
      "  episodes_total: 42612\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.385\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 3650000\n",
      "    num_steps_trained: 3650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7243273854255676\n",
      "      kl: 0.022781457751989365\n",
      "      policy_loss: 0.003912809770554304\n",
      "      total_loss: 71.16284942626953\n",
      "      vf_explained_var: 0.8824185132980347\n",
      "      vf_loss: 71.15689849853516\n",
      "    sample_time_ms: 18053.352\n",
      "    update_time_ms: 6.392\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -6.187362667780583\n",
      "  time_since_restore: 8052.382413387299\n",
      "  time_this_iter_s: 22.066610097885132\n",
      "  time_total_s: 8052.382413387299\n",
      "  timestamp: 1553129862\n",
      "  timesteps_since_restore: 3650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3650000\n",
      "  training_iteration: 365\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8052 s, 365 iter, 3650000 ts, -12.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-58-04\n",
      "  done: false\n",
      "  episode_len_mean: 68.0204081632653\n",
      "  episode_reward_max: 387.01923036778794\n",
      "  episode_reward_mean: -5.639980241062012\n",
      "  episode_reward_min: -167.1103300159836\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 42759\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.917\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 3660000\n",
      "    num_steps_trained: 3660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7123779654502869\n",
      "      kl: 0.09797412902116776\n",
      "      policy_loss: 0.014812015928328037\n",
      "      total_loss: 79.51212310791016\n",
      "      vf_explained_var: 0.8672108054161072\n",
      "      vf_loss: 79.48856353759766\n",
      "    sample_time_ms: 18070.978\n",
      "    update_time_ms: 6.647\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -2.819990120531006\n",
      "  time_since_restore: 8073.978531837463\n",
      "  time_this_iter_s: 21.596118450164795\n",
      "  time_total_s: 8073.978531837463\n",
      "  timestamp: 1553129884\n",
      "  timesteps_since_restore: 3660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3660000\n",
      "  training_iteration: 366\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8073 s, 366 iter, 3660000 ts, -5.64 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-58-26\n",
      "  done: false\n",
      "  episode_len_mean: 72.37956204379562\n",
      "  episode_reward_max: 387.90463723916696\n",
      "  episode_reward_mean: 29.13961738646842\n",
      "  episode_reward_min: -167.28920993688345\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 42896\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.982\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 3670000\n",
      "    num_steps_trained: 3670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6775228977203369\n",
      "      kl: 0.03165842220187187\n",
      "      policy_loss: 0.008035040460526943\n",
      "      total_loss: 58.654258728027344\n",
      "      vf_explained_var: 0.8916201591491699\n",
      "      vf_loss: 58.641990661621094\n",
      "    sample_time_ms: 18049.014\n",
      "    update_time_ms: 6.607\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.569808693234206\n",
      "  time_since_restore: 8095.759905576706\n",
      "  time_this_iter_s: 21.781373739242554\n",
      "  time_total_s: 8095.759905576706\n",
      "  timestamp: 1553129906\n",
      "  timesteps_since_restore: 3670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3670000\n",
      "  training_iteration: 367\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8095 s, 367 iter, 3670000 ts, 29.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-58-47\n",
      "  done: false\n",
      "  episode_len_mean: 67.51006711409396\n",
      "  episode_reward_max: 384.73755849623046\n",
      "  episode_reward_mean: -6.394531819384392\n",
      "  episode_reward_min: -167.14971473249437\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 43045\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.976\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 3680000\n",
      "    num_steps_trained: 3680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6937744617462158\n",
      "      kl: 0.02421775460243225\n",
      "      policy_loss: 0.006594131235033274\n",
      "      total_loss: 72.54145812988281\n",
      "      vf_explained_var: 0.8765756487846375\n",
      "      vf_loss: 72.53162384033203\n",
      "    sample_time_ms: 18033.233\n",
      "    update_time_ms: 6.506\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -3.1972659096921983\n",
      "  time_since_restore: 8117.116062402725\n",
      "  time_this_iter_s: 21.356156826019287\n",
      "  time_total_s: 8117.116062402725\n",
      "  timestamp: 1553129927\n",
      "  timesteps_since_restore: 3680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3680000\n",
      "  training_iteration: 368\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8117 s, 368 iter, 3680000 ts, -6.39 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-59-09\n",
      "  done: false\n",
      "  episode_len_mean: 68.10958904109589\n",
      "  episode_reward_max: 385.0342628879964\n",
      "  episode_reward_mean: -10.33148661062236\n",
      "  episode_reward_min: -162.84913427659512\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 43191\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.378\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 3690000\n",
      "    num_steps_trained: 3690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.705723762512207\n",
      "      kl: 0.018543008714914322\n",
      "      policy_loss: 1.0933249541267287e-05\n",
      "      total_loss: 58.03839874267578\n",
      "      vf_explained_var: 0.9023118615150452\n",
      "      vf_loss: 58.03590774536133\n",
      "    sample_time_ms: 18060.149\n",
      "    update_time_ms: 6.272\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -5.165743305311184\n",
      "  time_since_restore: 8138.887693405151\n",
      "  time_this_iter_s: 21.771631002426147\n",
      "  time_total_s: 8138.887693405151\n",
      "  timestamp: 1553129949\n",
      "  timesteps_since_restore: 3690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3690000\n",
      "  training_iteration: 369\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8138 s, 369 iter, 3690000 ts, -10.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-59-31\n",
      "  done: false\n",
      "  episode_len_mean: 72.7463768115942\n",
      "  episode_reward_max: 387.3629517914189\n",
      "  episode_reward_mean: 33.54452920908028\n",
      "  episode_reward_min: -167.24968940844775\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 43329\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.795\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 3700000\n",
      "    num_steps_trained: 3700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6865459084510803\n",
      "      kl: 0.02176731638610363\n",
      "      policy_loss: 0.0022546350955963135\n",
      "      total_loss: 66.41026306152344\n",
      "      vf_explained_var: 0.87857586145401\n",
      "      vf_loss: 66.40508270263672\n",
      "    sample_time_ms: 18026.473\n",
      "    update_time_ms: 6.343\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.772264604540137\n",
      "  time_since_restore: 8160.554091930389\n",
      "  time_this_iter_s: 21.666398525238037\n",
      "  time_total_s: 8160.554091930389\n",
      "  timestamp: 1553129971\n",
      "  timesteps_since_restore: 3700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3700000\n",
      "  training_iteration: 370\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8160 s, 370 iter, 3700000 ts, 33.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_01-59-53\n",
      "  done: false\n",
      "  episode_len_mean: 70.1118881118881\n",
      "  episode_reward_max: 388.40463733081936\n",
      "  episode_reward_mean: 12.346885363909509\n",
      "  episode_reward_min: -169.11148885556696\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 43472\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.9\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 3710000\n",
      "    num_steps_trained: 3710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6827204823493958\n",
      "      kl: 0.030720802024006844\n",
      "      policy_loss: 0.005739168263971806\n",
      "      total_loss: 75.37418365478516\n",
      "      vf_explained_var: 0.8649671673774719\n",
      "      vf_loss: 75.36433410644531\n",
      "    sample_time_ms: 18012.69\n",
      "    update_time_ms: 6.213\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.173442681954761\n",
      "  time_since_restore: 8182.452504873276\n",
      "  time_this_iter_s: 21.898412942886353\n",
      "  time_total_s: 8182.452504873276\n",
      "  timestamp: 1553129993\n",
      "  timesteps_since_restore: 3710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3710000\n",
      "  training_iteration: 371\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8182 s, 371 iter, 3710000 ts, 12.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-00-15\n",
      "  done: false\n",
      "  episode_len_mean: 70.43262411347517\n",
      "  episode_reward_max: 386.26061644445593\n",
      "  episode_reward_mean: 9.264453312609188\n",
      "  episode_reward_min: -165.04209284808874\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 43613\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.582\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 3720000\n",
      "    num_steps_trained: 3720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6809393167495728\n",
      "      kl: 0.02088511548936367\n",
      "      policy_loss: 0.0025046442169696093\n",
      "      total_loss: 58.81313705444336\n",
      "      vf_explained_var: 0.8958004713058472\n",
      "      vf_loss: 58.807830810546875\n",
      "    sample_time_ms: 18127.415\n",
      "    update_time_ms: 5.861\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 4.6322266563045975\n",
      "  time_since_restore: 8204.607595682144\n",
      "  time_this_iter_s: 22.155090808868408\n",
      "  time_total_s: 8204.607595682144\n",
      "  timestamp: 1553130015\n",
      "  timesteps_since_restore: 3720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3720000\n",
      "  training_iteration: 372\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8204 s, 372 iter, 3720000 ts, 9.26 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-00-37\n",
      "  done: false\n",
      "  episode_len_mean: 69.99295774647888\n",
      "  episode_reward_max: 387.32087507813225\n",
      "  episode_reward_mean: 18.873957980647734\n",
      "  episode_reward_min: -167.01724248453618\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 43755\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.813\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 3730000\n",
      "    num_steps_trained: 3730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6950871348381042\n",
      "      kl: 0.03413066640496254\n",
      "      policy_loss: 0.006621658802032471\n",
      "      total_loss: 68.42730712890625\n",
      "      vf_explained_var: 0.8801060914993286\n",
      "      vf_loss: 68.41610717773438\n",
      "    sample_time_ms: 18145.293\n",
      "    update_time_ms: 5.977\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.436978990323865\n",
      "  time_since_restore: 8226.676392316818\n",
      "  time_this_iter_s: 22.068796634674072\n",
      "  time_total_s: 8226.676392316818\n",
      "  timestamp: 1553130037\n",
      "  timesteps_since_restore: 3730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3730000\n",
      "  training_iteration: 373\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8226 s, 373 iter, 3730000 ts, 18.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-00-59\n",
      "  done: false\n",
      "  episode_len_mean: 68.32432432432432\n",
      "  episode_reward_max: 387.1081490300807\n",
      "  episode_reward_mean: -1.0444738496339796\n",
      "  episode_reward_min: -165.27270538571122\n",
      "  episodes_this_iter: 148\n",
      "  episodes_total: 43903\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.163\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 3740000\n",
      "    num_steps_trained: 3740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6937224268913269\n",
      "      kl: 0.022457974031567574\n",
      "      policy_loss: 0.0022732142824679613\n",
      "      total_loss: 67.20826721191406\n",
      "      vf_explained_var: 0.8871690630912781\n",
      "      vf_loss: 67.20297241210938\n",
      "    sample_time_ms: 18136.57\n",
      "    update_time_ms: 5.987\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -0.5222369248169929\n",
      "  time_since_restore: 8248.838686227798\n",
      "  time_this_iter_s: 22.162293910980225\n",
      "  time_total_s: 8248.838686227798\n",
      "  timestamp: 1553130059\n",
      "  timesteps_since_restore: 3740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3740000\n",
      "  training_iteration: 374\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8248 s, 374 iter, 3740000 ts, -1.04 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-01-21\n",
      "  done: false\n",
      "  episode_len_mean: 66.18543046357615\n",
      "  episode_reward_max: 384.3195929150023\n",
      "  episode_reward_mean: -13.626246086752422\n",
      "  episode_reward_min: -167.5507565622592\n",
      "  episodes_this_iter: 151\n",
      "  episodes_total: 44054\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3677.676\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 3750000\n",
      "    num_steps_trained: 3750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7000954747200012\n",
      "      kl: 0.028132572770118713\n",
      "      policy_loss: 0.004739740863442421\n",
      "      total_loss: 78.26730346679688\n",
      "      vf_explained_var: 0.8689721822738647\n",
      "      vf_loss: 78.25880432128906\n",
      "    sample_time_ms: 18159.992\n",
      "    update_time_ms: 5.398\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -6.813123043376211\n",
      "  time_since_restore: 8271.005678415298\n",
      "  time_this_iter_s: 22.1669921875\n",
      "  time_total_s: 8271.005678415298\n",
      "  timestamp: 1553130081\n",
      "  timesteps_since_restore: 3750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3750000\n",
      "  training_iteration: 375\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8271 s, 375 iter, 3750000 ts, -13.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-01-43\n",
      "  done: false\n",
      "  episode_len_mean: 70.84397163120568\n",
      "  episode_reward_max: 388.5405823075999\n",
      "  episode_reward_mean: 30.06815998499546\n",
      "  episode_reward_min: -165.0189797089958\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 44195\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.762\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 3760000\n",
      "    num_steps_trained: 3760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.666195273399353\n",
      "      kl: 0.023063860833644867\n",
      "      policy_loss: 0.003990730736404657\n",
      "      total_loss: 67.42926025390625\n",
      "      vf_explained_var: 0.8793976902961731\n",
      "      vf_loss: 67.42218780517578\n",
      "    sample_time_ms: 18179.864\n",
      "    update_time_ms: 5.138\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.034079992497727\n",
      "  time_since_restore: 8292.976202487946\n",
      "  time_this_iter_s: 21.970524072647095\n",
      "  time_total_s: 8292.976202487946\n",
      "  timestamp: 1553130103\n",
      "  timesteps_since_restore: 3760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3760000\n",
      "  training_iteration: 376\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8292 s, 376 iter, 3760000 ts, 30.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-02-05\n",
      "  done: false\n",
      "  episode_len_mean: 68.56164383561644\n",
      "  episode_reward_max: 384.35909563281206\n",
      "  episode_reward_mean: 1.36148769613218\n",
      "  episode_reward_min: -167.23142184826375\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 44341\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.419\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 3770000\n",
      "    num_steps_trained: 3770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6908904910087585\n",
      "      kl: 0.027804436162114143\n",
      "      policy_loss: 0.004505846183747053\n",
      "      total_loss: 72.05609130859375\n",
      "      vf_explained_var: 0.8761082291603088\n",
      "      vf_loss: 72.0478515625\n",
      "    sample_time_ms: 18193.736\n",
      "    update_time_ms: 5.239\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 0.6807438480660916\n",
      "  time_since_restore: 8314.905319690704\n",
      "  time_this_iter_s: 21.92911720275879\n",
      "  time_total_s: 8314.905319690704\n",
      "  timestamp: 1553130125\n",
      "  timesteps_since_restore: 3770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3770000\n",
      "  training_iteration: 377\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8314 s, 377 iter, 3770000 ts, 1.36 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-02-27\n",
      "  done: false\n",
      "  episode_len_mean: 68.29251700680273\n",
      "  episode_reward_max: 386.140853443455\n",
      "  episode_reward_mean: -2.46928250182867\n",
      "  episode_reward_min: -167.01062180921076\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 44488\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.595\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 3780000\n",
      "    num_steps_trained: 3780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6924848556518555\n",
      "      kl: 0.02232952043414116\n",
      "      policy_loss: 0.003994862083345652\n",
      "      total_loss: 55.546775817871094\n",
      "      vf_explained_var: 0.9058117270469666\n",
      "      vf_loss: 55.53978729248047\n",
      "    sample_time_ms: 18236.114\n",
      "    update_time_ms: 5.285\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -1.23464125091434\n",
      "  time_since_restore: 8336.697661161423\n",
      "  time_this_iter_s: 21.792341470718384\n",
      "  time_total_s: 8336.697661161423\n",
      "  timestamp: 1553130147\n",
      "  timesteps_since_restore: 3780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3780000\n",
      "  training_iteration: 378\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8336 s, 378 iter, 3780000 ts, -2.47 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-02-49\n",
      "  done: false\n",
      "  episode_len_mean: 70.07042253521126\n",
      "  episode_reward_max: 386.53365136202996\n",
      "  episode_reward_mean: 11.682130326255725\n",
      "  episode_reward_min: -164.919908346262\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 44630\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.243\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 3790000\n",
      "    num_steps_trained: 3790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6905660629272461\n",
      "      kl: 0.02513224072754383\n",
      "      policy_loss: 0.004718580283224583\n",
      "      total_loss: 65.49616241455078\n",
      "      vf_explained_var: 0.8858028054237366\n",
      "      vf_loss: 65.48808288574219\n",
      "    sample_time_ms: 18272.604\n",
      "    update_time_ms: 5.06\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 5.841065163127859\n",
      "  time_since_restore: 8358.861637115479\n",
      "  time_this_iter_s: 22.163975954055786\n",
      "  time_total_s: 8358.861637115479\n",
      "  timestamp: 1553130169\n",
      "  timesteps_since_restore: 3790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3790000\n",
      "  training_iteration: 379\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8358 s, 379 iter, 3790000 ts, 11.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-03-12\n",
      "  done: false\n",
      "  episode_len_mean: 71.20567375886525\n",
      "  episode_reward_max: 381.5943995151224\n",
      "  episode_reward_mean: 24.58126446404196\n",
      "  episode_reward_min: -166.98037247785567\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 44771\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.44\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 3800000\n",
      "    num_steps_trained: 3800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6843727231025696\n",
      "      kl: 0.019909048452973366\n",
      "      policy_loss: 0.0031160416547209024\n",
      "      total_loss: 69.75670623779297\n",
      "      vf_explained_var: 0.8739399313926697\n",
      "      vf_loss: 69.75092315673828\n",
      "    sample_time_ms: 18315.532\n",
      "    update_time_ms: 5.107\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.29063223202098\n",
      "  time_since_restore: 8381.099145412445\n",
      "  time_this_iter_s: 22.237508296966553\n",
      "  time_total_s: 8381.099145412445\n",
      "  timestamp: 1553130192\n",
      "  timesteps_since_restore: 3800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3800000\n",
      "  training_iteration: 380\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8381 s, 380 iter, 3800000 ts, 24.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-03-33\n",
      "  done: false\n",
      "  episode_len_mean: 70.59154929577464\n",
      "  episode_reward_max: 386.98589016840765\n",
      "  episode_reward_mean: 14.686081666826231\n",
      "  episode_reward_min: -167.03920699795722\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 44913\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.273\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 3810000\n",
      "    num_steps_trained: 3810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6641396284103394\n",
      "      kl: 0.021292785182595253\n",
      "      policy_loss: 0.0054054101929068565\n",
      "      total_loss: 70.68751525878906\n",
      "      vf_explained_var: 0.8743995428085327\n",
      "      vf_loss: 70.67925262451172\n",
      "    sample_time_ms: 18291.603\n",
      "    update_time_ms: 5.198\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.343040833413114\n",
      "  time_since_restore: 8402.766509056091\n",
      "  time_this_iter_s: 21.66736364364624\n",
      "  time_total_s: 8402.766509056091\n",
      "  timestamp: 1553130213\n",
      "  timesteps_since_restore: 3810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3810000\n",
      "  training_iteration: 381\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8402 s, 381 iter, 3810000 ts, 14.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-03-55\n",
      "  done: false\n",
      "  episode_len_mean: 74.5\n",
      "  episode_reward_max: 385.6033323853818\n",
      "  episode_reward_mean: 48.335254752224266\n",
      "  episode_reward_min: -166.89350134881974\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 45047\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.938\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 3820000\n",
      "    num_steps_trained: 3820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6729025840759277\n",
      "      kl: 0.022330626845359802\n",
      "      policy_loss: 0.0025147567503154278\n",
      "      total_loss: 69.08364868164062\n",
      "      vf_explained_var: 0.8651854395866394\n",
      "      vf_loss: 69.07814025878906\n",
      "    sample_time_ms: 18294.067\n",
      "    update_time_ms: 5.248\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.167627376112122\n",
      "  time_since_restore: 8424.976520061493\n",
      "  time_this_iter_s: 22.21001100540161\n",
      "  time_total_s: 8424.976520061493\n",
      "  timestamp: 1553130235\n",
      "  timesteps_since_restore: 3820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3820000\n",
      "  training_iteration: 382\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8424 s, 382 iter, 3820000 ts, 48.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 70.55633802816901\n",
      "  episode_reward_max: 385.27799371728963\n",
      "  episode_reward_mean: 14.400778111006666\n",
      "  episode_reward_min: -164.93621173342706\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 45189\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.088\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 3830000\n",
      "    num_steps_trained: 3830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6987388730049133\n",
      "      kl: 0.023257022723555565\n",
      "      policy_loss: 0.004845964256674051\n",
      "      total_loss: 71.13221740722656\n",
      "      vf_explained_var: 0.8739328384399414\n",
      "      vf_loss: 71.12425994873047\n",
      "    sample_time_ms: 18300.736\n",
      "    update_time_ms: 5.123\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.200389055503336\n",
      "  time_since_restore: 8447.11187696457\n",
      "  time_this_iter_s: 22.135356903076172\n",
      "  time_total_s: 8447.11187696457\n",
      "  timestamp: 1553130258\n",
      "  timesteps_since_restore: 3830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3830000\n",
      "  training_iteration: 383\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8447 s, 383 iter, 3830000 ts, 14.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-04-40\n",
      "  done: false\n",
      "  episode_len_mean: 69.13103448275862\n",
      "  episode_reward_max: 384.08210061243307\n",
      "  episode_reward_mean: 1.0953559761599019\n",
      "  episode_reward_min: -163.68378570595027\n",
      "  episodes_this_iter: 145\n",
      "  episodes_total: 45334\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.898\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 3840000\n",
      "    num_steps_trained: 3840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6824483871459961\n",
      "      kl: 0.018810506910085678\n",
      "      policy_loss: 0.00194680190179497\n",
      "      total_loss: 58.75565719604492\n",
      "      vf_explained_var: 0.8988984227180481\n",
      "      vf_loss: 58.751190185546875\n",
      "    sample_time_ms: 18299.608\n",
      "    update_time_ms: 5.294\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 0.5476779880799469\n",
      "  time_since_restore: 8469.33669757843\n",
      "  time_this_iter_s: 22.224820613861084\n",
      "  time_total_s: 8469.33669757843\n",
      "  timestamp: 1553130280\n",
      "  timesteps_since_restore: 3840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3840000\n",
      "  training_iteration: 384\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8469 s, 384 iter, 3840000 ts, 1.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-05-02\n",
      "  done: false\n",
      "  episode_len_mean: 67.0945945945946\n",
      "  episode_reward_max: 388.05884032701323\n",
      "  episode_reward_mean: -8.25999196520268\n",
      "  episode_reward_min: -166.89986865552902\n",
      "  episodes_this_iter: 148\n",
      "  episodes_total: 45482\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3731.571\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 3850000\n",
      "    num_steps_trained: 3850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7243947982788086\n",
      "      kl: 0.0252595916390419\n",
      "      policy_loss: 0.0073684025555849075\n",
      "      total_loss: 66.76177215576172\n",
      "      vf_explained_var: 0.8868193030357361\n",
      "      vf_loss: 66.75101470947266\n",
      "    sample_time_ms: 18259.342\n",
      "    update_time_ms: 5.484\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -4.129995982601343\n",
      "  time_since_restore: 8491.172504901886\n",
      "  time_this_iter_s: 21.83580732345581\n",
      "  time_total_s: 8491.172504901886\n",
      "  timestamp: 1553130302\n",
      "  timesteps_since_restore: 3850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3850000\n",
      "  training_iteration: 385\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8491 s, 385 iter, 3850000 ts, -8.26 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-05-24\n",
      "  done: false\n",
      "  episode_len_mean: 66.73154362416108\n",
      "  episode_reward_max: 384.1322933598289\n",
      "  episode_reward_mean: -8.222770872447548\n",
      "  episode_reward_min: -166.9743544095421\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 45631\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.786\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 3860000\n",
      "    num_steps_trained: 3860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7251904010772705\n",
      "      kl: 0.024015894159674644\n",
      "      policy_loss: 0.0037486040964722633\n",
      "      total_loss: 61.30210876464844\n",
      "      vf_explained_var: 0.8972133994102478\n",
      "      vf_loss: 61.29514694213867\n",
      "    sample_time_ms: 18258.349\n",
      "    update_time_ms: 5.273\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -4.111385436223773\n",
      "  time_since_restore: 8512.902333974838\n",
      "  time_this_iter_s: 21.72982907295227\n",
      "  time_total_s: 8512.902333974838\n",
      "  timestamp: 1553130324\n",
      "  timesteps_since_restore: 3860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3860000\n",
      "  training_iteration: 386\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8512 s, 386 iter, 3860000 ts, -8.22 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-05-46\n",
      "  done: false\n",
      "  episode_len_mean: 72.94160583941606\n",
      "  episode_reward_max: 385.7821457726225\n",
      "  episode_reward_mean: 33.48956162491117\n",
      "  episode_reward_min: -164.9622990845108\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 45768\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.953\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 3870000\n",
      "    num_steps_trained: 3870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6918286085128784\n",
      "      kl: 0.026647720485925674\n",
      "      policy_loss: 0.004649882670491934\n",
      "      total_loss: 66.4667739868164\n",
      "      vf_explained_var: 0.8737542629241943\n",
      "      vf_loss: 66.45854949951172\n",
      "    sample_time_ms: 18329.529\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.744780812455584\n",
      "  time_since_restore: 8535.503647327423\n",
      "  time_this_iter_s: 22.60131335258484\n",
      "  time_total_s: 8535.503647327423\n",
      "  timestamp: 1553130346\n",
      "  timesteps_since_restore: 3870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3870000\n",
      "  training_iteration: 387\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8535 s, 387 iter, 3870000 ts, 33.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-06-09\n",
      "  done: false\n",
      "  episode_len_mean: 72.7956204379562\n",
      "  episode_reward_max: 385.87820304921\n",
      "  episode_reward_mean: 37.45328464370904\n",
      "  episode_reward_min: -165.73564729573965\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 45905\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.669\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 3880000\n",
      "    num_steps_trained: 3880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.691465437412262\n",
      "      kl: 0.02504936419427395\n",
      "      policy_loss: 0.0025523726362735033\n",
      "      total_loss: 52.60095977783203\n",
      "      vf_explained_var: 0.9014949202537537\n",
      "      vf_loss: 52.59505081176758\n",
      "    sample_time_ms: 18378.325\n",
      "    update_time_ms: 5.427\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.72664232185451\n",
      "  time_since_restore: 8557.820229291916\n",
      "  time_this_iter_s: 22.316581964492798\n",
      "  time_total_s: 8557.820229291916\n",
      "  timestamp: 1553130369\n",
      "  timesteps_since_restore: 3880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3880000\n",
      "  training_iteration: 388\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8557 s, 388 iter, 3880000 ts, 37.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-06-30\n",
      "  done: false\n",
      "  episode_len_mean: 70.16083916083916\n",
      "  episode_reward_max: 387.0937124843242\n",
      "  episode_reward_mean: 14.160945560337906\n",
      "  episode_reward_min: -167.28085660126447\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 46048\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.441\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 3890000\n",
      "    num_steps_trained: 3890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6831156611442566\n",
      "      kl: 0.023776598274707794\n",
      "      policy_loss: 0.0012482895981520414\n",
      "      total_loss: 62.50562286376953\n",
      "      vf_explained_var: 0.8894023299217224\n",
      "      vf_loss: 62.50117874145508\n",
      "    sample_time_ms: 18321.161\n",
      "    update_time_ms: 5.523\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.080472780168949\n",
      "  time_since_restore: 8579.412391424179\n",
      "  time_this_iter_s: 21.592162132263184\n",
      "  time_total_s: 8579.412391424179\n",
      "  timestamp: 1553130390\n",
      "  timesteps_since_restore: 3890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3890000\n",
      "  training_iteration: 389\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8579 s, 389 iter, 3890000 ts, 14.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-06-52\n",
      "  done: false\n",
      "  episode_len_mean: 69.79861111111111\n",
      "  episode_reward_max: 385.3275482993636\n",
      "  episode_reward_mean: 15.211714447119542\n",
      "  episode_reward_min: -167.3448253249192\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 46192\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.978\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 3900000\n",
      "    num_steps_trained: 3900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7015515565872192\n",
      "      kl: 0.025820598006248474\n",
      "      policy_loss: 0.008385221473872662\n",
      "      total_loss: 71.1545639038086\n",
      "      vf_explained_var: 0.8729634284973145\n",
      "      vf_loss: 71.14273071289062\n",
      "    sample_time_ms: 18329.712\n",
      "    update_time_ms: 5.424\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.605857223559765\n",
      "  time_since_restore: 8601.598058700562\n",
      "  time_this_iter_s: 22.185667276382446\n",
      "  time_total_s: 8601.598058700562\n",
      "  timestamp: 1553130412\n",
      "  timesteps_since_restore: 3900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3900000\n",
      "  training_iteration: 390\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8601 s, 390 iter, 3900000 ts, 15.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-07-15\n",
      "  done: false\n",
      "  episode_len_mean: 73.58823529411765\n",
      "  episode_reward_max: 384.8701318028304\n",
      "  episode_reward_mean: 40.206415932676315\n",
      "  episode_reward_min: -167.1092223083639\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 46328\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.832\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 3910000\n",
      "    num_steps_trained: 3910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6819871068000793\n",
      "      kl: 0.031101783737540245\n",
      "      policy_loss: 0.003334208158776164\n",
      "      total_loss: 67.74614715576172\n",
      "      vf_explained_var: 0.869549572467804\n",
      "      vf_loss: 67.7386474609375\n",
      "    sample_time_ms: 18373.142\n",
      "    update_time_ms: 5.456\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.103207966338157\n",
      "  time_since_restore: 8623.697758436203\n",
      "  time_this_iter_s: 22.09969973564148\n",
      "  time_total_s: 8623.697758436203\n",
      "  timestamp: 1553130435\n",
      "  timesteps_since_restore: 3910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3910000\n",
      "  training_iteration: 391\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8623 s, 391 iter, 3910000 ts, 40.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-07-36\n",
      "  done: false\n",
      "  episode_len_mean: 75.78030303030303\n",
      "  episode_reward_max: 385.77350882640974\n",
      "  episode_reward_mean: 51.737713082004674\n",
      "  episode_reward_min: -163.09021814223766\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 46460\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.374\n",
      "    load_time_ms: 1.441\n",
      "    num_steps_sampled: 3920000\n",
      "    num_steps_trained: 3920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6677533388137817\n",
      "      kl: 0.018446527421474457\n",
      "      policy_loss: 0.004798647947609425\n",
      "      total_loss: 60.227664947509766\n",
      "      vf_explained_var: 0.8822770714759827\n",
      "      vf_loss: 60.22039031982422\n",
      "    sample_time_ms: 18282.715\n",
      "    update_time_ms: 5.627\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.868856541002337\n",
      "  time_since_restore: 8644.965700626373\n",
      "  time_this_iter_s: 21.267942190170288\n",
      "  time_total_s: 8644.965700626373\n",
      "  timestamp: 1553130456\n",
      "  timesteps_since_restore: 3920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3920000\n",
      "  training_iteration: 392\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8644 s, 392 iter, 3920000 ts, 51.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-07-58\n",
      "  done: false\n",
      "  episode_len_mean: 66.54966887417218\n",
      "  episode_reward_max: 387.1520429709416\n",
      "  episode_reward_mean: -18.204980416483096\n",
      "  episode_reward_min: -167.2963410474324\n",
      "  episodes_this_iter: 151\n",
      "  episodes_total: 46611\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.972\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 3930000\n",
      "    num_steps_trained: 3930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7151402235031128\n",
      "      kl: 0.023911211639642715\n",
      "      policy_loss: 0.003958037123084068\n",
      "      total_loss: 71.90786743164062\n",
      "      vf_explained_var: 0.8794001936912537\n",
      "      vf_loss: 71.90070343017578\n",
      "    sample_time_ms: 18265.275\n",
      "    update_time_ms: 5.642\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -9.102490208241553\n",
      "  time_since_restore: 8666.910301208496\n",
      "  time_this_iter_s: 21.944600582122803\n",
      "  time_total_s: 8666.910301208496\n",
      "  timestamp: 1553130478\n",
      "  timesteps_since_restore: 3930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3930000\n",
      "  training_iteration: 393\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8666 s, 393 iter, 3930000 ts, -18.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-08-19\n",
      "  done: false\n",
      "  episode_len_mean: 71.83453237410072\n",
      "  episode_reward_max: 390.7143385618514\n",
      "  episode_reward_mean: 23.043450707890553\n",
      "  episode_reward_min: -167.07598386200905\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 46750\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3676.675\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 3940000\n",
      "    num_steps_trained: 3940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6553156971931458\n",
      "      kl: 0.027172990143299103\n",
      "      policy_loss: 0.004060148727148771\n",
      "      total_loss: 69.25725555419922\n",
      "      vf_explained_var: 0.8754422068595886\n",
      "      vf_loss: 69.24956512451172\n",
      "    sample_time_ms: 18206.466\n",
      "    update_time_ms: 5.454\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.521725353945275\n",
      "  time_since_restore: 8688.408656358719\n",
      "  time_this_iter_s: 21.49835515022278\n",
      "  time_total_s: 8688.408656358719\n",
      "  timestamp: 1553130499\n",
      "  timesteps_since_restore: 3940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3940000\n",
      "  training_iteration: 394\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8688 s, 394 iter, 3940000 ts, 23 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 67.78231292517007\n",
      "  episode_reward_max: 385.9587810550308\n",
      "  episode_reward_mean: -0.9786172252185252\n",
      "  episode_reward_min: -169.15930760225297\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 46897\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.065\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 3950000\n",
      "    num_steps_trained: 3950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6584839224815369\n",
      "      kl: 0.02018756978213787\n",
      "      policy_loss: 0.002304683206602931\n",
      "      total_loss: 58.73881912231445\n",
      "      vf_explained_var: 0.9000803828239441\n",
      "      vf_loss: 58.73381042480469\n",
      "    sample_time_ms: 18151.77\n",
      "    update_time_ms: 5.837\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -0.48930861260925335\n",
      "  time_since_restore: 8709.754495382309\n",
      "  time_this_iter_s: 21.345839023590088\n",
      "  time_total_s: 8709.754495382309\n",
      "  timestamp: 1553130521\n",
      "  timesteps_since_restore: 3950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3950000\n",
      "  training_iteration: 395\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8709 s, 395 iter, 3950000 ts, -0.979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-09-02\n",
      "  done: false\n",
      "  episode_len_mean: 70.64539007092199\n",
      "  episode_reward_max: 385.70289146334255\n",
      "  episode_reward_mean: 14.243989457200556\n",
      "  episode_reward_min: -165.2393433247471\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 47038\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.055\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 3960000\n",
      "    num_steps_trained: 3960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6413251161575317\n",
      "      kl: 0.018398907035589218\n",
      "      policy_loss: 0.0035198910627514124\n",
      "      total_loss: 59.693172454833984\n",
      "      vf_explained_var: 0.8947368264198303\n",
      "      vf_loss: 59.68718719482422\n",
      "    sample_time_ms: 18122.282\n",
      "    update_time_ms: 5.804\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.121994728600274\n",
      "  time_since_restore: 8731.274096727371\n",
      "  time_this_iter_s: 21.519601345062256\n",
      "  time_total_s: 8731.274096727371\n",
      "  timestamp: 1553130542\n",
      "  timesteps_since_restore: 3960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3960000\n",
      "  training_iteration: 396\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8731 s, 396 iter, 3960000 ts, 14.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-09-24\n",
      "  done: false\n",
      "  episode_len_mean: 68.7687074829932\n",
      "  episode_reward_max: 384.63364797494063\n",
      "  episode_reward_mean: 7.976798173028902\n",
      "  episode_reward_min: -167.22580627074478\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 47185\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.713\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 3970000\n",
      "    num_steps_trained: 3970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6543655395507812\n",
      "      kl: 0.02310183085501194\n",
      "      policy_loss: 0.0016297086840495467\n",
      "      total_loss: 72.24201202392578\n",
      "      vf_explained_var: 0.8752743601799011\n",
      "      vf_loss: 72.23728942871094\n",
      "    sample_time_ms: 18010.614\n",
      "    update_time_ms: 5.553\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 3.9883990865144496\n",
      "  time_since_restore: 8752.763380765915\n",
      "  time_this_iter_s: 21.4892840385437\n",
      "  time_total_s: 8752.763380765915\n",
      "  timestamp: 1553130564\n",
      "  timesteps_since_restore: 3970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3970000\n",
      "  training_iteration: 397\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8752 s, 397 iter, 3970000 ts, 7.98 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-09-45\n",
      "  done: false\n",
      "  episode_len_mean: 73.65185185185184\n",
      "  episode_reward_max: 387.47304172108966\n",
      "  episode_reward_mean: 45.4772391408374\n",
      "  episode_reward_min: -166.92001772662638\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 47320\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.84\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 3980000\n",
      "    num_steps_trained: 3980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6586430668830872\n",
      "      kl: 0.02717708609998226\n",
      "      policy_loss: 0.004832272883504629\n",
      "      total_loss: 64.5440444946289\n",
      "      vf_explained_var: 0.8767726421356201\n",
      "      vf_loss: 64.53557586669922\n",
      "    sample_time_ms: 17928.964\n",
      "    update_time_ms: 5.604\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.738619570418695\n",
      "  time_since_restore: 8774.226522922516\n",
      "  time_this_iter_s: 21.463142156600952\n",
      "  time_total_s: 8774.226522922516\n",
      "  timestamp: 1553130585\n",
      "  timesteps_since_restore: 3980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3980000\n",
      "  training_iteration: 398\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8774 s, 398 iter, 3980000 ts, 45.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-10-08\n",
      "  done: false\n",
      "  episode_len_mean: 71.07801418439716\n",
      "  episode_reward_max: 386.9157087506475\n",
      "  episode_reward_mean: 28.221213232400718\n",
      "  episode_reward_min: -167.37055797078847\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 47461\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.066\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 3990000\n",
      "    num_steps_trained: 3990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6599174737930298\n",
      "      kl: 0.028432173654437065\n",
      "      policy_loss: 0.00663237227126956\n",
      "      total_loss: 61.52177047729492\n",
      "      vf_explained_var: 0.8872201442718506\n",
      "      vf_loss: 61.511329650878906\n",
      "    sample_time_ms: 17979.346\n",
      "    update_time_ms: 5.523\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.110606616200362\n",
      "  time_since_restore: 8796.32361125946\n",
      "  time_this_iter_s: 22.09708833694458\n",
      "  time_total_s: 8796.32361125946\n",
      "  timestamp: 1553130608\n",
      "  timesteps_since_restore: 3990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3990000\n",
      "  training_iteration: 399\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8796 s, 399 iter, 3990000 ts, 28.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-10-30\n",
      "  done: false\n",
      "  episode_len_mean: 68.67586206896551\n",
      "  episode_reward_max: 389.0540195210859\n",
      "  episode_reward_mean: 3.8080562550446277\n",
      "  episode_reward_min: -167.40695680370567\n",
      "  episodes_this_iter: 145\n",
      "  episodes_total: 47606\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.521\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 4000000\n",
      "    num_steps_trained: 4000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6542389988899231\n",
      "      kl: 0.02270030602812767\n",
      "      policy_loss: 0.007445951458066702\n",
      "      total_loss: 65.86455535888672\n",
      "      vf_explained_var: 0.8872064352035522\n",
      "      vf_loss: 65.85405731201172\n",
      "    sample_time_ms: 17984.873\n",
      "    update_time_ms: 5.592\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 1.9040281275223117\n",
      "  time_since_restore: 8818.568556070328\n",
      "  time_this_iter_s: 22.24494481086731\n",
      "  time_total_s: 8818.568556070328\n",
      "  timestamp: 1553130630\n",
      "  timesteps_since_restore: 4000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4000000\n",
      "  training_iteration: 400\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8818 s, 400 iter, 4000000 ts, 3.81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-10-53\n",
      "  done: false\n",
      "  episode_len_mean: 70.11888111888112\n",
      "  episode_reward_max: 387.7406048960285\n",
      "  episode_reward_mean: 12.425516114804614\n",
      "  episode_reward_min: -166.9613777151966\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 47749\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.506\n",
      "    load_time_ms: 1.65\n",
      "    num_steps_sampled: 4010000\n",
      "    num_steps_trained: 4010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6634469628334045\n",
      "      kl: 0.02886493317782879\n",
      "      policy_loss: 0.005990887526422739\n",
      "      total_loss: 55.43666076660156\n",
      "      vf_explained_var: 0.9001039266586304\n",
      "      vf_loss: 55.42680740356445\n",
      "    sample_time_ms: 18061.501\n",
      "    update_time_ms: 5.764\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.212758057402303\n",
      "  time_since_restore: 8841.488939523697\n",
      "  time_this_iter_s: 22.92038345336914\n",
      "  time_total_s: 8841.488939523697\n",
      "  timestamp: 1553130653\n",
      "  timesteps_since_restore: 4010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4010000\n",
      "  training_iteration: 401\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8841 s, 401 iter, 4010000 ts, 12.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-11-15\n",
      "  done: false\n",
      "  episode_len_mean: 67.78767123287672\n",
      "  episode_reward_max: 386.73397220676776\n",
      "  episode_reward_mean: -5.3973635351747005\n",
      "  episode_reward_min: -166.93333479317664\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 47895\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.493\n",
      "    load_time_ms: 1.691\n",
      "    num_steps_sampled: 4020000\n",
      "    num_steps_trained: 4020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.681613564491272\n",
      "      kl: 0.020731743425130844\n",
      "      policy_loss: 0.002238235902041197\n",
      "      total_loss: 61.16870880126953\n",
      "      vf_explained_var: 0.8961209058761597\n",
      "      vf_loss: 61.163692474365234\n",
      "    sample_time_ms: 18107.026\n",
      "    update_time_ms: 5.838\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -2.6986817675873525\n",
      "  time_since_restore: 8863.246110200882\n",
      "  time_this_iter_s: 21.75717067718506\n",
      "  time_total_s: 8863.246110200882\n",
      "  timestamp: 1553130675\n",
      "  timesteps_since_restore: 4020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4020000\n",
      "  training_iteration: 402\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8863 s, 402 iter, 4020000 ts, -5.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-11-36\n",
      "  done: false\n",
      "  episode_len_mean: 67.44666666666667\n",
      "  episode_reward_max: 384.41223557249833\n",
      "  episode_reward_mean: -4.732705963859151\n",
      "  episode_reward_min: -167.0833293810153\n",
      "  episodes_this_iter: 150\n",
      "  episodes_total: 48045\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.325\n",
      "    load_time_ms: 1.709\n",
      "    num_steps_sampled: 4030000\n",
      "    num_steps_trained: 4030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.668001115322113\n",
      "      kl: 0.0284271202981472\n",
      "      policy_loss: 0.007162482477724552\n",
      "      total_loss: 70.66716766357422\n",
      "      vf_explained_var: 0.8786110281944275\n",
      "      vf_loss: 70.65619659423828\n",
      "    sample_time_ms: 18030.92\n",
      "    update_time_ms: 5.87\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -2.366352981929574\n",
      "  time_since_restore: 8884.470727920532\n",
      "  time_this_iter_s: 21.22461771965027\n",
      "  time_total_s: 8884.470727920532\n",
      "  timestamp: 1553130696\n",
      "  timesteps_since_restore: 4030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4030000\n",
      "  training_iteration: 403\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8884 s, 403 iter, 4030000 ts, -4.73 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-11-58\n",
      "  done: false\n",
      "  episode_len_mean: 66.52348993288591\n",
      "  episode_reward_max: 387.785931748871\n",
      "  episode_reward_mean: -20.790492710577375\n",
      "  episode_reward_min: -167.3515633187556\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 48194\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.838\n",
      "    load_time_ms: 1.721\n",
      "    num_steps_sampled: 4040000\n",
      "    num_steps_trained: 4040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6776866316795349\n",
      "      kl: 0.027640262618660927\n",
      "      policy_loss: 0.004381907172501087\n",
      "      total_loss: 48.27525329589844\n",
      "      vf_explained_var: 0.920590341091156\n",
      "      vf_loss: 48.26716995239258\n",
      "    sample_time_ms: 18081.881\n",
      "    update_time_ms: 5.839\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -10.395246355288693\n",
      "  time_since_restore: 8906.506269931793\n",
      "  time_this_iter_s: 22.035542011260986\n",
      "  time_total_s: 8906.506269931793\n",
      "  timestamp: 1553130718\n",
      "  timesteps_since_restore: 4040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4040000\n",
      "  training_iteration: 404\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8906 s, 404 iter, 4040000 ts, -20.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-12-20\n",
      "  done: false\n",
      "  episode_len_mean: 70.35664335664336\n",
      "  episode_reward_max: 388.77238071390946\n",
      "  episode_reward_mean: 17.80115615639316\n",
      "  episode_reward_min: -166.9740976239109\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 48337\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.28\n",
      "    load_time_ms: 1.688\n",
      "    num_steps_sampled: 4050000\n",
      "    num_steps_trained: 4050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6778460741043091\n",
      "      kl: 0.024628061801195145\n",
      "      policy_loss: 0.0040015350095927715\n",
      "      total_loss: 59.549503326416016\n",
      "      vf_explained_var: 0.8962997794151306\n",
      "      vf_loss: 59.542205810546875\n",
      "    sample_time_ms: 18160.656\n",
      "    update_time_ms: 5.23\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.90057807819658\n",
      "  time_since_restore: 8928.528548240662\n",
      "  time_this_iter_s: 22.022278308868408\n",
      "  time_total_s: 8928.528548240662\n",
      "  timestamp: 1553130740\n",
      "  timesteps_since_restore: 4050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4050000\n",
      "  training_iteration: 405\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8928 s, 405 iter, 4050000 ts, 17.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-12-43\n",
      "  done: false\n",
      "  episode_len_mean: 66.68666666666667\n",
      "  episode_reward_max: 386.0858766459113\n",
      "  episode_reward_mean: -14.18973169884157\n",
      "  episode_reward_min: -167.22324900993345\n",
      "  episodes_this_iter: 150\n",
      "  episodes_total: 48487\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.579\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 4060000\n",
      "    num_steps_trained: 4060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.67556232213974\n",
      "      kl: 0.024856368079781532\n",
      "      policy_loss: 0.0033504534512758255\n",
      "      total_loss: 69.46101379394531\n",
      "      vf_explained_var: 0.8833703398704529\n",
      "      vf_loss: 69.45433044433594\n",
      "    sample_time_ms: 18242.149\n",
      "    update_time_ms: 5.368\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -7.094865849420785\n",
      "  time_since_restore: 8951.043169260025\n",
      "  time_this_iter_s: 22.514621019363403\n",
      "  time_total_s: 8951.043169260025\n",
      "  timestamp: 1553130763\n",
      "  timesteps_since_restore: 4060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4060000\n",
      "  training_iteration: 406\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8951 s, 406 iter, 4060000 ts, -14.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-13-04\n",
      "  done: false\n",
      "  episode_len_mean: 71.00714285714285\n",
      "  episode_reward_max: 387.7503565930515\n",
      "  episode_reward_mean: 17.82015248158505\n",
      "  episode_reward_min: -164.9636398470068\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 48627\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.357\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 4070000\n",
      "    num_steps_trained: 4070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.632373034954071\n",
      "      kl: 0.01741224154829979\n",
      "      policy_loss: 0.002945598680526018\n",
      "      total_loss: 56.387264251708984\n",
      "      vf_explained_var: 0.9005062580108643\n",
      "      vf_loss: 56.38198471069336\n",
      "    sample_time_ms: 18222.813\n",
      "    update_time_ms: 5.43\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.910076240792517\n",
      "  time_since_restore: 8972.378724336624\n",
      "  time_this_iter_s: 21.33555507659912\n",
      "  time_total_s: 8972.378724336624\n",
      "  timestamp: 1553130784\n",
      "  timesteps_since_restore: 4070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4070000\n",
      "  training_iteration: 407\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8972 s, 407 iter, 4070000 ts, 17.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-13-26\n",
      "  done: false\n",
      "  episode_len_mean: 66.72185430463576\n",
      "  episode_reward_max: 385.57636459752473\n",
      "  episode_reward_mean: -13.129878437034149\n",
      "  episode_reward_min: -162.7829154930973\n",
      "  episodes_this_iter: 151\n",
      "  episodes_total: 48778\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.461\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 4080000\n",
      "    num_steps_trained: 4080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6602082848548889\n",
      "      kl: 0.027568163350224495\n",
      "      policy_loss: 0.005978638771921396\n",
      "      total_loss: 71.22257232666016\n",
      "      vf_explained_var: 0.8810630440711975\n",
      "      vf_loss: 71.21290588378906\n",
      "    sample_time_ms: 18250.181\n",
      "    update_time_ms: 5.413\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -6.56493921851707\n",
      "  time_since_restore: 8994.116824388504\n",
      "  time_this_iter_s: 21.738100051879883\n",
      "  time_total_s: 8994.116824388504\n",
      "  timestamp: 1553130806\n",
      "  timesteps_since_restore: 4080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4080000\n",
      "  training_iteration: 408\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 8994 s, 408 iter, 4080000 ts, -13.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-13-48\n",
      "  done: false\n",
      "  episode_len_mean: 70.38028169014085\n",
      "  episode_reward_max: 384.9269453503129\n",
      "  episode_reward_mean: 5.346020295879462\n",
      "  episode_reward_min: -167.08915667631865\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 48920\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.724\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 4090000\n",
      "    num_steps_trained: 4090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6391164064407349\n",
      "      kl: 0.018432265147566795\n",
      "      policy_loss: 0.0016521861543878913\n",
      "      total_loss: 56.47637939453125\n",
      "      vf_explained_var: 0.9005221128463745\n",
      "      vf_loss: 56.472267150878906\n",
      "    sample_time_ms: 18307.434\n",
      "    update_time_ms: 5.536\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 2.673010147939733\n",
      "  time_since_restore: 9016.797854661942\n",
      "  time_this_iter_s: 22.6810302734375\n",
      "  time_total_s: 9016.797854661942\n",
      "  timestamp: 1553130828\n",
      "  timesteps_since_restore: 4090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4090000\n",
      "  training_iteration: 409\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9016 s, 409 iter, 4090000 ts, 5.35 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-14-10\n",
      "  done: false\n",
      "  episode_len_mean: 71.94964028776978\n",
      "  episode_reward_max: 384.4547932608825\n",
      "  episode_reward_mean: 16.947579723202285\n",
      "  episode_reward_min: -167.41721920629976\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 49059\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.984\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 4100000\n",
      "    num_steps_trained: 4100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6459439396858215\n",
      "      kl: 0.02174144610762596\n",
      "      policy_loss: 0.0038255895487964153\n",
      "      total_loss: 61.45479202270508\n",
      "      vf_explained_var: 0.8860510587692261\n",
      "      vf_loss: 61.44804763793945\n",
      "    sample_time_ms: 18256.477\n",
      "    update_time_ms: 5.648\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.473789861601139\n",
      "  time_since_restore: 9038.610131502151\n",
      "  time_this_iter_s: 21.81227684020996\n",
      "  time_total_s: 9038.610131502151\n",
      "  timestamp: 1553130850\n",
      "  timesteps_since_restore: 4100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4100000\n",
      "  training_iteration: 410\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9038 s, 410 iter, 4100000 ts, 16.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-14-32\n",
      "  done: false\n",
      "  episode_len_mean: 69.35416666666667\n",
      "  episode_reward_max: 384.8893460538328\n",
      "  episode_reward_mean: 8.446811406289488\n",
      "  episode_reward_min: -167.34891985305785\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 49203\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.01\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 4110000\n",
      "    num_steps_trained: 4110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6595814824104309\n",
      "      kl: 0.02731386572122574\n",
      "      policy_loss: 0.0048944405280053616\n",
      "      total_loss: 68.67792510986328\n",
      "      vf_explained_var: 0.8812475800514221\n",
      "      vf_loss: 68.66937255859375\n",
      "    sample_time_ms: 18132.692\n",
      "    update_time_ms: 5.387\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 4.223405703144745\n",
      "  time_since_restore: 9060.227982997894\n",
      "  time_this_iter_s: 21.617851495742798\n",
      "  time_total_s: 9060.227982997894\n",
      "  timestamp: 1553130872\n",
      "  timesteps_since_restore: 4110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4110000\n",
      "  training_iteration: 411\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9060 s, 411 iter, 4110000 ts, 8.45 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-14-54\n",
      "  done: false\n",
      "  episode_len_mean: 67.10810810810811\n",
      "  episode_reward_max: 387.8541355025213\n",
      "  episode_reward_mean: -12.137092184076112\n",
      "  episode_reward_min: -167.0361285375023\n",
      "  episodes_this_iter: 148\n",
      "  episodes_total: 49351\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.377\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 4120000\n",
      "    num_steps_trained: 4120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6631577014923096\n",
      "      kl: 0.017593704164028168\n",
      "      policy_loss: 0.004144397098571062\n",
      "      total_loss: 55.568145751953125\n",
      "      vf_explained_var: 0.9071994423866272\n",
      "      vf_loss: 55.561641693115234\n",
      "    sample_time_ms: 18171.947\n",
      "    update_time_ms: 5.117\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -6.068546092038054\n",
      "  time_since_restore: 9082.35122513771\n",
      "  time_this_iter_s: 22.123242139816284\n",
      "  time_total_s: 9082.35122513771\n",
      "  timestamp: 1553130894\n",
      "  timesteps_since_restore: 4120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4120000\n",
      "  training_iteration: 412\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9082 s, 412 iter, 4120000 ts, -12.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-15-16\n",
      "  done: false\n",
      "  episode_len_mean: 71.53571428571429\n",
      "  episode_reward_max: 387.92855443164444\n",
      "  episode_reward_mean: 31.56172516115063\n",
      "  episode_reward_min: -169.10270713600158\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 49491\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.59\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 4130000\n",
      "    num_steps_trained: 4130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6617774963378906\n",
      "      kl: 0.027397818863391876\n",
      "      policy_loss: 0.004977807402610779\n",
      "      total_loss: 72.36824035644531\n",
      "      vf_explained_var: 0.8686453104019165\n",
      "      vf_loss: 72.3595962524414\n",
      "    sample_time_ms: 18245.355\n",
      "    update_time_ms: 5.174\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.780862580575308\n",
      "  time_since_restore: 9104.291322469711\n",
      "  time_this_iter_s: 21.940097332000732\n",
      "  time_total_s: 9104.291322469711\n",
      "  timestamp: 1553130916\n",
      "  timesteps_since_restore: 4130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4130000\n",
      "  training_iteration: 413\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9104 s, 413 iter, 4130000 ts, 31.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-15-38\n",
      "  done: false\n",
      "  episode_len_mean: 71.22695035460993\n",
      "  episode_reward_max: 387.51655003233134\n",
      "  episode_reward_mean: 21.97256757529494\n",
      "  episode_reward_min: -167.02011224993706\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 49632\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.567\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 4140000\n",
      "    num_steps_trained: 4140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6440852284431458\n",
      "      kl: 0.022532684728503227\n",
      "      policy_loss: 0.0029825891833752394\n",
      "      total_loss: 70.05679321289062\n",
      "      vf_explained_var: 0.8739344477653503\n",
      "      vf_loss: 70.05079650878906\n",
      "    sample_time_ms: 18192.965\n",
      "    update_time_ms: 5.181\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 10.986283787647478\n",
      "  time_since_restore: 9125.853497743607\n",
      "  time_this_iter_s: 21.562175273895264\n",
      "  time_total_s: 9125.853497743607\n",
      "  timestamp: 1553130938\n",
      "  timesteps_since_restore: 4140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4140000\n",
      "  training_iteration: 414\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9125 s, 414 iter, 4140000 ts, 22 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-16-00\n",
      "  done: false\n",
      "  episode_len_mean: 72.32374100719424\n",
      "  episode_reward_max: 386.6624140535138\n",
      "  episode_reward_mean: 25.120945106295395\n",
      "  episode_reward_min: -167.01116843863966\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 49771\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.867\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 4150000\n",
      "    num_steps_trained: 4150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6566112637519836\n",
      "      kl: 0.02064397744834423\n",
      "      policy_loss: 0.00519199064001441\n",
      "      total_loss: 66.32080078125\n",
      "      vf_explained_var: 0.8787402510643005\n",
      "      vf_loss: 66.31285095214844\n",
      "    sample_time_ms: 18231.642\n",
      "    update_time_ms: 5.35\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.560472553147697\n",
      "  time_since_restore: 9148.28423166275\n",
      "  time_this_iter_s: 22.430733919143677\n",
      "  time_total_s: 9148.28423166275\n",
      "  timestamp: 1553130960\n",
      "  timesteps_since_restore: 4150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4150000\n",
      "  training_iteration: 415\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9148 s, 415 iter, 4150000 ts, 25.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-16-22\n",
      "  done: false\n",
      "  episode_len_mean: 69.36363636363636\n",
      "  episode_reward_max: 387.43335448556843\n",
      "  episode_reward_mean: 13.041195846921187\n",
      "  episode_reward_min: -168.94363184746743\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 49914\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.804\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 4160000\n",
      "    num_steps_trained: 4160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6799190044403076\n",
      "      kl: 0.02157703973352909\n",
      "      policy_loss: 0.004276059567928314\n",
      "      total_loss: 73.32283020019531\n",
      "      vf_explained_var: 0.8685945272445679\n",
      "      vf_loss: 73.31565856933594\n",
      "    sample_time_ms: 18230.763\n",
      "    update_time_ms: 5.253\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.520597923460592\n",
      "  time_since_restore: 9170.57966709137\n",
      "  time_this_iter_s: 22.295435428619385\n",
      "  time_total_s: 9170.57966709137\n",
      "  timestamp: 1553130982\n",
      "  timesteps_since_restore: 4160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4160000\n",
      "  training_iteration: 416\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9170 s, 416 iter, 4160000 ts, 13 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 66.43046357615894\n",
      "  episode_reward_max: 387.359548376033\n",
      "  episode_reward_mean: -8.99001792413306\n",
      "  episode_reward_min: -166.97466735478878\n",
      "  episodes_this_iter: 151\n",
      "  episodes_total: 50065\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.096\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 4170000\n",
      "    num_steps_trained: 4170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6644144654273987\n",
      "      kl: 0.02541329339146614\n",
      "      policy_loss: 0.004454209469258785\n",
      "      total_loss: 61.0673713684082\n",
      "      vf_explained_var: 0.8965905904769897\n",
      "      vf_loss: 61.05950927734375\n",
      "    sample_time_ms: 18255.608\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -4.495008962066526\n",
      "  time_since_restore: 9192.16398692131\n",
      "  time_this_iter_s: 21.584319829940796\n",
      "  time_total_s: 9192.16398692131\n",
      "  timestamp: 1553131004\n",
      "  timesteps_since_restore: 4170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4170000\n",
      "  training_iteration: 417\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9192 s, 417 iter, 4170000 ts, -8.99 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-17-06\n",
      "  done: false\n",
      "  episode_len_mean: 67.22818791946308\n",
      "  episode_reward_max: 382.68127296910814\n",
      "  episode_reward_mean: -15.661386580452298\n",
      "  episode_reward_min: -167.09259295937062\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 50214\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.307\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 4180000\n",
      "    num_steps_trained: 4180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6419849991798401\n",
      "      kl: 0.021304160356521606\n",
      "      policy_loss: 0.002270736265927553\n",
      "      total_loss: 58.165138244628906\n",
      "      vf_explained_var: 0.9029507637023926\n",
      "      vf_loss: 58.16001892089844\n",
      "    sample_time_ms: 18278.977\n",
      "    update_time_ms: 5.328\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -7.830693290226151\n",
      "  time_since_restore: 9214.156038999557\n",
      "  time_this_iter_s: 21.99205207824707\n",
      "  time_total_s: 9214.156038999557\n",
      "  timestamp: 1553131026\n",
      "  timesteps_since_restore: 4180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4180000\n",
      "  training_iteration: 418\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9214 s, 418 iter, 4180000 ts, -15.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 68.30344827586207\n",
      "  episode_reward_max: 386.64471674513265\n",
      "  episode_reward_mean: -6.815891137504677\n",
      "  episode_reward_min: -167.02798901542664\n",
      "  episodes_this_iter: 145\n",
      "  episodes_total: 50359\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.983\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 4190000\n",
      "    num_steps_trained: 4190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6700990200042725\n",
      "      kl: 0.027539735659956932\n",
      "      policy_loss: 0.005148430820554495\n",
      "      total_loss: 63.181522369384766\n",
      "      vf_explained_var: 0.8928582668304443\n",
      "      vf_loss: 63.17268753051758\n",
      "    sample_time_ms: 18262.017\n",
      "    update_time_ms: 5.206\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -3.4079455687523423\n",
      "  time_since_restore: 9236.660838365555\n",
      "  time_this_iter_s: 22.504799365997314\n",
      "  time_total_s: 9236.660838365555\n",
      "  timestamp: 1553131049\n",
      "  timesteps_since_restore: 4190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4190000\n",
      "  training_iteration: 419\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9236 s, 419 iter, 4190000 ts, -6.82 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 68.68707482993197\n",
      "  episode_reward_max: 388.3595518678665\n",
      "  episode_reward_mean: 11.173643186974076\n",
      "  episode_reward_min: -166.93508147427082\n",
      "  episodes_this_iter: 147\n",
      "  episodes_total: 50506\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.898\n",
      "    load_time_ms: 1.452\n",
      "    num_steps_sampled: 4200000\n",
      "    num_steps_trained: 4200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6443597078323364\n",
      "      kl: 0.018934478983283043\n",
      "      policy_loss: 0.0015809285687282681\n",
      "      total_loss: 64.70511627197266\n",
      "      vf_explained_var: 0.8884132504463196\n",
      "      vf_loss: 64.70099639892578\n",
      "    sample_time_ms: 18314.013\n",
      "    update_time_ms: 5.036\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 5.586821593487038\n",
      "  time_since_restore: 9258.908595085144\n",
      "  time_this_iter_s: 22.247756719589233\n",
      "  time_total_s: 9258.908595085144\n",
      "  timestamp: 1553131071\n",
      "  timesteps_since_restore: 4200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4200000\n",
      "  training_iteration: 420\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9258 s, 420 iter, 4200000 ts, 11.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-18-13\n",
      "  done: false\n",
      "  episode_len_mean: 71.45714285714286\n",
      "  episode_reward_max: 384.6494441662241\n",
      "  episode_reward_mean: 11.118708774553127\n",
      "  episode_reward_min: -163.7774405307436\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 50646\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.506\n",
      "    load_time_ms: 1.421\n",
      "    num_steps_sampled: 4210000\n",
      "    num_steps_trained: 4210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6384292840957642\n",
      "      kl: 0.027082055807113647\n",
      "      policy_loss: 0.005186218768358231\n",
      "      total_loss: 61.1877326965332\n",
      "      vf_explained_var: 0.8906036615371704\n",
      "      vf_loss: 61.17891311645508\n",
      "    sample_time_ms: 18330.369\n",
      "    update_time_ms: 5.121\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 5.559354387276556\n",
      "  time_since_restore: 9280.904776573181\n",
      "  time_this_iter_s: 21.99618148803711\n",
      "  time_total_s: 9280.904776573181\n",
      "  timestamp: 1553131093\n",
      "  timesteps_since_restore: 4210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4210000\n",
      "  training_iteration: 421\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9280 s, 421 iter, 4210000 ts, 11.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-18-35\n",
      "  done: false\n",
      "  episode_len_mean: 66.35099337748345\n",
      "  episode_reward_max: 386.6147343574092\n",
      "  episode_reward_mean: -10.79708912901707\n",
      "  episode_reward_min: -166.99725891431808\n",
      "  episodes_this_iter: 151\n",
      "  episodes_total: 50797\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.456\n",
      "    load_time_ms: 1.363\n",
      "    num_steps_sampled: 4220000\n",
      "    num_steps_trained: 4220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6657736897468567\n",
      "      kl: 0.02138330601155758\n",
      "      policy_loss: 0.006094521377235651\n",
      "      total_loss: 65.9408187866211\n",
      "      vf_explained_var: 0.8911952376365662\n",
      "      vf_loss: 65.9318618774414\n",
      "    sample_time_ms: 18292.984\n",
      "    update_time_ms: 5.183\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -5.398544564508542\n",
      "  time_since_restore: 9302.669357538223\n",
      "  time_this_iter_s: 21.764580965042114\n",
      "  time_total_s: 9302.669357538223\n",
      "  timestamp: 1553131115\n",
      "  timesteps_since_restore: 4220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4220000\n",
      "  training_iteration: 422\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9302 s, 422 iter, 4220000 ts, -10.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-18-57\n",
      "  done: false\n",
      "  episode_len_mean: 66.13422818791946\n",
      "  episode_reward_max: 382.7120394476956\n",
      "  episode_reward_mean: -17.131587019866227\n",
      "  episode_reward_min: -166.83089261671543\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 50946\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.453\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 4230000\n",
      "    num_steps_trained: 4230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6628025770187378\n",
      "      kl: 0.021787280216813087\n",
      "      policy_loss: 0.00439432030543685\n",
      "      total_loss: 64.82817077636719\n",
      "      vf_explained_var: 0.8922547698020935\n",
      "      vf_loss: 64.82085418701172\n",
      "    sample_time_ms: 18276.734\n",
      "    update_time_ms: 5.112\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -8.565793509933114\n",
      "  time_since_restore: 9324.438329458237\n",
      "  time_this_iter_s: 21.768971920013428\n",
      "  time_total_s: 9324.438329458237\n",
      "  timestamp: 1553131137\n",
      "  timesteps_since_restore: 4230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4230000\n",
      "  training_iteration: 423\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9324 s, 423 iter, 4230000 ts, -17.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 66.3112582781457\n",
      "  episode_reward_max: 386.6911803901466\n",
      "  episode_reward_mean: -10.05937848905082\n",
      "  episode_reward_min: -167.04954867323875\n",
      "  episodes_this_iter: 151\n",
      "  episodes_total: 51097\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.577\n",
      "    load_time_ms: 1.365\n",
      "    num_steps_sampled: 4240000\n",
      "    num_steps_trained: 4240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6737225651741028\n",
      "      kl: 0.023745130747556686\n",
      "      policy_loss: 0.004802390467375517\n",
      "      total_loss: 62.004207611083984\n",
      "      vf_explained_var: 0.8985032439231873\n",
      "      vf_loss: 61.996219635009766\n",
      "    sample_time_ms: 18345.521\n",
      "    update_time_ms: 5.156\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -5.029689244525419\n",
      "  time_since_restore: 9346.61946940422\n",
      "  time_this_iter_s: 22.181139945983887\n",
      "  time_total_s: 9346.61946940422\n",
      "  timestamp: 1553131159\n",
      "  timesteps_since_restore: 4240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4240000\n",
      "  training_iteration: 424\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9346 s, 424 iter, 4240000 ts, -10.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-19-41\n",
      "  done: false\n",
      "  episode_len_mean: 67.41610738255034\n",
      "  episode_reward_max: 386.10134733648243\n",
      "  episode_reward_mean: -1.8767410842596846\n",
      "  episode_reward_min: -169.05491432222368\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 51246\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.201\n",
      "    load_time_ms: 1.367\n",
      "    num_steps_sampled: 4250000\n",
      "    num_steps_trained: 4250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6386082172393799\n",
      "      kl: 0.019214540719985962\n",
      "      policy_loss: 0.003990659955888987\n",
      "      total_loss: 50.70532989501953\n",
      "      vf_explained_var: 0.9126681089401245\n",
      "      vf_loss: 50.69876480102539\n",
      "    sample_time_ms: 18326.194\n",
      "    update_time_ms: 5.092\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -0.9383705421298374\n",
      "  time_since_restore: 9369.013749599457\n",
      "  time_this_iter_s: 22.394280195236206\n",
      "  time_total_s: 9369.013749599457\n",
      "  timestamp: 1553131181\n",
      "  timesteps_since_restore: 4250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4250000\n",
      "  training_iteration: 425\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9369 s, 425 iter, 4250000 ts, -1.88 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-20-03\n",
      "  done: false\n",
      "  episode_len_mean: 69.99300699300699\n",
      "  episode_reward_max: 387.3469779820992\n",
      "  episode_reward_mean: 20.60809287478295\n",
      "  episode_reward_min: -165.2407889007592\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 51389\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.898\n",
      "    load_time_ms: 1.383\n",
      "    num_steps_sampled: 4260000\n",
      "    num_steps_trained: 4260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6522973775863647\n",
      "      kl: 0.030891986563801765\n",
      "      policy_loss: 0.010567143559455872\n",
      "      total_loss: 69.30596160888672\n",
      "      vf_explained_var: 0.8773888945579529\n",
      "      vf_loss: 69.29126739501953\n",
      "    sample_time_ms: 18288.658\n",
      "    update_time_ms: 5.058\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 10.304046437391476\n",
      "  time_since_restore: 9390.959542036057\n",
      "  time_this_iter_s: 21.94579243659973\n",
      "  time_total_s: 9390.959542036057\n",
      "  timestamp: 1553131203\n",
      "  timesteps_since_restore: 4260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4260000\n",
      "  training_iteration: 426\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9390 s, 426 iter, 4260000 ts, 20.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-20-26\n",
      "  done: false\n",
      "  episode_len_mean: 72.23021582733813\n",
      "  episode_reward_max: 387.36239500182336\n",
      "  episode_reward_mean: 39.0493349480079\n",
      "  episode_reward_min: -166.78990107604506\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 51528\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.895\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 4270000\n",
      "    num_steps_trained: 4270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6455524563789368\n",
      "      kl: 0.02484748885035515\n",
      "      policy_loss: 0.00362123129889369\n",
      "      total_loss: 61.02774429321289\n",
      "      vf_explained_var: 0.8858515620231628\n",
      "      vf_loss: 61.02079391479492\n",
      "    sample_time_ms: 18382.606\n",
      "    update_time_ms: 4.857\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.524667474003948\n",
      "  time_since_restore: 9413.47783613205\n",
      "  time_this_iter_s: 22.518294095993042\n",
      "  time_total_s: 9413.47783613205\n",
      "  timestamp: 1553131226\n",
      "  timesteps_since_restore: 4270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4270000\n",
      "  training_iteration: 427\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9413 s, 427 iter, 4270000 ts, 39 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-20-48\n",
      "  done: false\n",
      "  episode_len_mean: 71.31914893617021\n",
      "  episode_reward_max: 387.0761589210136\n",
      "  episode_reward_mean: 23.44754367221324\n",
      "  episode_reward_min: -166.94988513216018\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 51669\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.865\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 4280000\n",
      "    num_steps_trained: 4280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.64578777551651\n",
      "      kl: 0.023933053016662598\n",
      "      policy_loss: 0.0015727081336081028\n",
      "      total_loss: 52.48666000366211\n",
      "      vf_explained_var: 0.9079778790473938\n",
      "      vf_loss: 52.48188018798828\n",
      "    sample_time_ms: 18377.92\n",
      "    update_time_ms: 5.077\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.723771836106616\n",
      "  time_since_restore: 9435.3856112957\n",
      "  time_this_iter_s: 21.907775163650513\n",
      "  time_total_s: 9435.3856112957\n",
      "  timestamp: 1553131248\n",
      "  timesteps_since_restore: 4280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4280000\n",
      "  training_iteration: 428\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9435 s, 428 iter, 4280000 ts, 23.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-21-09\n",
      "  done: false\n",
      "  episode_len_mean: 71.88321167883211\n",
      "  episode_reward_max: 386.00902676893327\n",
      "  episode_reward_mean: 25.61534592834861\n",
      "  episode_reward_min: -166.87237267681598\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 51806\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.103\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 4290000\n",
      "    num_steps_trained: 4290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6442453861236572\n",
      "      kl: 0.02067769132554531\n",
      "      policy_loss: 0.0041182576678693295\n",
      "      total_loss: 60.398826599121094\n",
      "      vf_explained_var: 0.8868780136108398\n",
      "      vf_loss: 60.391944885253906\n",
      "    sample_time_ms: 18280.376\n",
      "    update_time_ms: 5.613\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.807672964174298\n",
      "  time_since_restore: 9456.921375513077\n",
      "  time_this_iter_s: 21.53576421737671\n",
      "  time_total_s: 9456.921375513077\n",
      "  timestamp: 1553131269\n",
      "  timesteps_since_restore: 4290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4290000\n",
      "  training_iteration: 429\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9456 s, 429 iter, 4290000 ts, 25.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-21-32\n",
      "  done: false\n",
      "  episode_len_mean: 70.56643356643356\n",
      "  episode_reward_max: 387.24184271431966\n",
      "  episode_reward_mean: 16.706881487509122\n",
      "  episode_reward_min: -166.73699688860415\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 51949\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.175\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 4300000\n",
      "    num_steps_trained: 4300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6769682168960571\n",
      "      kl: 0.024655772373080254\n",
      "      policy_loss: 0.005857677664607763\n",
      "      total_loss: 61.879676818847656\n",
      "      vf_explained_var: 0.8913354873657227\n",
      "      vf_loss: 61.87052536010742\n",
      "    sample_time_ms: 18289.168\n",
      "    update_time_ms: 5.806\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.353440743754565\n",
      "  time_since_restore: 9479.262555837631\n",
      "  time_this_iter_s: 22.341180324554443\n",
      "  time_total_s: 9479.262555837631\n",
      "  timestamp: 1553131292\n",
      "  timesteps_since_restore: 4300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4300000\n",
      "  training_iteration: 430\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9479 s, 430 iter, 4300000 ts, 16.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-21-54\n",
      "  done: false\n",
      "  episode_len_mean: 71.44285714285714\n",
      "  episode_reward_max: 387.25902232974374\n",
      "  episode_reward_mean: 17.41524367114768\n",
      "  episode_reward_min: -164.85576671060562\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 52089\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.786\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 4310000\n",
      "    num_steps_trained: 4310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6498742699623108\n",
      "      kl: 0.029064983129501343\n",
      "      policy_loss: 0.0018914651591330767\n",
      "      total_loss: 57.65510940551758\n",
      "      vf_explained_var: 0.8948910236358643\n",
      "      vf_loss: 57.64932632446289\n",
      "    sample_time_ms: 18383.361\n",
      "    update_time_ms: 5.75\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.70762183557384\n",
      "  time_since_restore: 9502.022341489792\n",
      "  time_this_iter_s: 22.759785652160645\n",
      "  time_total_s: 9502.022341489792\n",
      "  timestamp: 1553131314\n",
      "  timesteps_since_restore: 4310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4310000\n",
      "  training_iteration: 431\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9502 s, 431 iter, 4310000 ts, 17.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-22-16\n",
      "  done: false\n",
      "  episode_len_mean: 71.33333333333333\n",
      "  episode_reward_max: 387.46859677561645\n",
      "  episode_reward_mean: 23.31489693805685\n",
      "  episode_reward_min: -164.98655695411207\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 52230\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.261\n",
      "    load_time_ms: 1.661\n",
      "    num_steps_sampled: 4320000\n",
      "    num_steps_trained: 4320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6436894536018372\n",
      "      kl: 0.025720063596963882\n",
      "      policy_loss: 0.005650065839290619\n",
      "      total_loss: 70.38068389892578\n",
      "      vf_explained_var: 0.8724923729896545\n",
      "      vf_loss: 70.37159729003906\n",
      "    sample_time_ms: 18404.114\n",
      "    update_time_ms: 6.079\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.657448469028425\n",
      "  time_since_restore: 9523.956072568893\n",
      "  time_this_iter_s: 21.933731079101562\n",
      "  time_total_s: 9523.956072568893\n",
      "  timestamp: 1553131336\n",
      "  timesteps_since_restore: 4320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4320000\n",
      "  training_iteration: 432\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9523 s, 432 iter, 4320000 ts, 23.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-22-38\n",
      "  done: false\n",
      "  episode_len_mean: 73.59701492537313\n",
      "  episode_reward_max: 387.2796718287342\n",
      "  episode_reward_mean: 40.79422517463263\n",
      "  episode_reward_min: -166.83590901180744\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 52364\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.469\n",
      "    load_time_ms: 1.706\n",
      "    num_steps_sampled: 4330000\n",
      "    num_steps_trained: 4330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6276828050613403\n",
      "      kl: 0.02504078857600689\n",
      "      policy_loss: 0.003988636191934347\n",
      "      total_loss: 58.81322479248047\n",
      "      vf_explained_var: 0.8845353722572327\n",
      "      vf_loss: 58.80588912963867\n",
      "    sample_time_ms: 18389.802\n",
      "    update_time_ms: 5.984\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.39711258731632\n",
      "  time_since_restore: 9545.773530006409\n",
      "  time_this_iter_s: 21.81745743751526\n",
      "  time_total_s: 9545.773530006409\n",
      "  timestamp: 1553131358\n",
      "  timesteps_since_restore: 4330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4330000\n",
      "  training_iteration: 433\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9545 s, 433 iter, 4330000 ts, 40.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-23-01\n",
      "  done: false\n",
      "  episode_len_mean: 76.12121212121212\n",
      "  episode_reward_max: 388.6694918782985\n",
      "  episode_reward_mean: 64.27359584495443\n",
      "  episode_reward_min: -166.9164017556572\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 52496\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.059\n",
      "    load_time_ms: 1.687\n",
      "    num_steps_sampled: 4340000\n",
      "    num_steps_trained: 4340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6234613060951233\n",
      "      kl: 0.02525552548468113\n",
      "      policy_loss: 0.006211590953171253\n",
      "      total_loss: 62.91487121582031\n",
      "      vf_explained_var: 0.8744006752967834\n",
      "      vf_loss: 62.9052734375\n",
      "    sample_time_ms: 18412.7\n",
      "    update_time_ms: 6.592\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.13679792247721\n",
      "  time_since_restore: 9568.205179214478\n",
      "  time_this_iter_s: 22.431649208068848\n",
      "  time_total_s: 9568.205179214478\n",
      "  timestamp: 1553131381\n",
      "  timesteps_since_restore: 4340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4340000\n",
      "  training_iteration: 434\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9568 s, 434 iter, 4340000 ts, 64.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-23-23\n",
      "  done: false\n",
      "  episode_len_mean: 73.72058823529412\n",
      "  episode_reward_max: 389.6983595603341\n",
      "  episode_reward_mean: 40.24236599543209\n",
      "  episode_reward_min: -169.0374540524149\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 52632\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.361\n",
      "    load_time_ms: 1.725\n",
      "    num_steps_sampled: 4350000\n",
      "    num_steps_trained: 4350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6246201992034912\n",
      "      kl: 0.02264299988746643\n",
      "      policy_loss: 0.006687767803668976\n",
      "      total_loss: 54.16755676269531\n",
      "      vf_explained_var: 0.8993250727653503\n",
      "      vf_loss: 54.15782928466797\n",
      "    sample_time_ms: 18419.217\n",
      "    update_time_ms: 6.54\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.121182997716044\n",
      "  time_since_restore: 9590.490418195724\n",
      "  time_this_iter_s: 22.28523898124695\n",
      "  time_total_s: 9590.490418195724\n",
      "  timestamp: 1553131403\n",
      "  timesteps_since_restore: 4350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4350000\n",
      "  training_iteration: 435\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9590 s, 435 iter, 4350000 ts, 40.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-23-45\n",
      "  done: false\n",
      "  episode_len_mean: 74.95488721804512\n",
      "  episode_reward_max: 388.8243869197726\n",
      "  episode_reward_mean: 49.73412082707741\n",
      "  episode_reward_min: -166.79168055173398\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 52765\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.957\n",
      "    load_time_ms: 1.709\n",
      "    num_steps_sampled: 4360000\n",
      "    num_steps_trained: 4360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6110056638717651\n",
      "      kl: 0.027867160737514496\n",
      "      policy_loss: 0.005156295374035835\n",
      "      total_loss: 61.474727630615234\n",
      "      vf_explained_var: 0.8793939352035522\n",
      "      vf_loss: 61.46584701538086\n",
      "    sample_time_ms: 18437.654\n",
      "    update_time_ms: 7.257\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.867060413538702\n",
      "  time_since_restore: 9612.581575155258\n",
      "  time_this_iter_s: 22.09115695953369\n",
      "  time_total_s: 9612.581575155258\n",
      "  timestamp: 1553131425\n",
      "  timesteps_since_restore: 4360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4360000\n",
      "  training_iteration: 436\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9612 s, 436 iter, 4360000 ts, 49.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-24-07\n",
      "  done: false\n",
      "  episode_len_mean: 70.72340425531915\n",
      "  episode_reward_max: 388.11610615699857\n",
      "  episode_reward_mean: 13.792406368193769\n",
      "  episode_reward_min: -169.11204898807048\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 52906\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.523\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 4370000\n",
      "    num_steps_trained: 4370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6572187542915344\n",
      "      kl: 0.02471771650016308\n",
      "      policy_loss: 0.003057349007576704\n",
      "      total_loss: 57.13842010498047\n",
      "      vf_explained_var: 0.8978889584541321\n",
      "      vf_loss: 57.132049560546875\n",
      "    sample_time_ms: 18402.449\n",
      "    update_time_ms: 7.283\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.8962031840968825\n",
      "  time_since_restore: 9634.720089673996\n",
      "  time_this_iter_s: 22.138514518737793\n",
      "  time_total_s: 9634.720089673996\n",
      "  timestamp: 1553131447\n",
      "  timesteps_since_restore: 4370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4370000\n",
      "  training_iteration: 437\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9634 s, 437 iter, 4370000 ts, 13.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-24-29\n",
      "  done: false\n",
      "  episode_len_mean: 68.10135135135135\n",
      "  episode_reward_max: 385.91941189268516\n",
      "  episode_reward_mean: 2.74858753963328\n",
      "  episode_reward_min: -166.87028155693054\n",
      "  episodes_this_iter: 148\n",
      "  episodes_total: 53054\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.744\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 4380000\n",
      "    num_steps_trained: 4380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6373501420021057\n",
      "      kl: 0.031194588169455528\n",
      "      policy_loss: 0.006248462945222855\n",
      "      total_loss: 57.730587005615234\n",
      "      vf_explained_var: 0.9002610445022583\n",
      "      vf_loss: 57.72016525268555\n",
      "    sample_time_ms: 18387.539\n",
      "    update_time_ms: 7.095\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 1.3742937698166393\n",
      "  time_since_restore: 9656.49920296669\n",
      "  time_this_iter_s: 21.779113292694092\n",
      "  time_total_s: 9656.49920296669\n",
      "  timestamp: 1553131469\n",
      "  timesteps_since_restore: 4380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4380000\n",
      "  training_iteration: 438\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9656 s, 438 iter, 4380000 ts, 2.75 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-24-51\n",
      "  done: false\n",
      "  episode_len_mean: 67.36486486486487\n",
      "  episode_reward_max: 385.4771449460415\n",
      "  episode_reward_mean: -0.5013340870566256\n",
      "  episode_reward_min: -166.80341983243466\n",
      "  episodes_this_iter: 148\n",
      "  episodes_total: 53202\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.68\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 4390000\n",
      "    num_steps_trained: 4390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6594170928001404\n",
      "      kl: 0.020647268742322922\n",
      "      policy_loss: 0.004075841046869755\n",
      "      total_loss: 56.16960906982422\n",
      "      vf_explained_var: 0.9056224226951599\n",
      "      vf_loss: 56.16276550292969\n",
      "    sample_time_ms: 18455.522\n",
      "    update_time_ms: 6.623\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -0.25066704352830943\n",
      "  time_since_restore: 9678.704614400864\n",
      "  time_this_iter_s: 22.205411434173584\n",
      "  time_total_s: 9678.704614400864\n",
      "  timestamp: 1553131491\n",
      "  timesteps_since_restore: 4390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4390000\n",
      "  training_iteration: 439\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9678 s, 439 iter, 4390000 ts, -0.501 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-25-14\n",
      "  done: false\n",
      "  episode_len_mean: 71.70714285714286\n",
      "  episode_reward_max: 384.966074220656\n",
      "  episode_reward_mean: 26.467160700222482\n",
      "  episode_reward_min: -166.83962990173342\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 53342\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.258\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 4400000\n",
      "    num_steps_trained: 4400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6310113072395325\n",
      "      kl: 0.0191796962171793\n",
      "      policy_loss: 0.0008376814075745642\n",
      "      total_loss: 62.34397506713867\n",
      "      vf_explained_var: 0.8872036933898926\n",
      "      vf_loss: 62.340576171875\n",
      "    sample_time_ms: 18432.99\n",
      "    update_time_ms: 6.546\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 13.233580350111241\n",
      "  time_since_restore: 9700.82278752327\n",
      "  time_this_iter_s: 22.118173122406006\n",
      "  time_total_s: 9700.82278752327\n",
      "  timestamp: 1553131514\n",
      "  timesteps_since_restore: 4400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4400000\n",
      "  training_iteration: 440\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9700 s, 440 iter, 4400000 ts, 26.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-25-36\n",
      "  done: false\n",
      "  episode_len_mean: 67.0\n",
      "  episode_reward_max: 387.76566320481015\n",
      "  episode_reward_mean: -10.247177225220295\n",
      "  episode_reward_min: -167.4908032254243\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 53491\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.133\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 4410000\n",
      "    num_steps_trained: 4410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6646736264228821\n",
      "      kl: 0.02132446877658367\n",
      "      policy_loss: 0.0021987981162965298\n",
      "      total_loss: 67.88043212890625\n",
      "      vf_explained_var: 0.8885576128959656\n",
      "      vf_loss: 67.87538146972656\n",
      "    sample_time_ms: 18393.32\n",
      "    update_time_ms: 6.59\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -5.123588612610146\n",
      "  time_since_restore: 9723.123999118805\n",
      "  time_this_iter_s: 22.30121159553528\n",
      "  time_total_s: 9723.123999118805\n",
      "  timestamp: 1553131536\n",
      "  timesteps_since_restore: 4410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4410000\n",
      "  training_iteration: 441\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9723 s, 441 iter, 4410000 ts, -10.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-25-58\n",
      "  done: false\n",
      "  episode_len_mean: 70.2027972027972\n",
      "  episode_reward_max: 386.61547219106575\n",
      "  episode_reward_mean: 10.698709081608989\n",
      "  episode_reward_min: -167.0220398411417\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 53634\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.459\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 4420000\n",
      "    num_steps_trained: 4420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6481543183326721\n",
      "      kl: 0.01385138463228941\n",
      "      policy_loss: 0.003341579344123602\n",
      "      total_loss: 67.1620101928711\n",
      "      vf_explained_var: 0.8810381889343262\n",
      "      vf_loss: 67.15681457519531\n",
      "    sample_time_ms: 18437.525\n",
      "    update_time_ms: 6.211\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 5.349354540804489\n",
      "  time_since_restore: 9745.506252288818\n",
      "  time_this_iter_s: 22.382253170013428\n",
      "  time_total_s: 9745.506252288818\n",
      "  timestamp: 1553131558\n",
      "  timesteps_since_restore: 4420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4420000\n",
      "  training_iteration: 442\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9745 s, 442 iter, 4420000 ts, 10.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-26-21\n",
      "  done: false\n",
      "  episode_len_mean: 72.08759124087591\n",
      "  episode_reward_max: 386.59600204588736\n",
      "  episode_reward_mean: 36.97693076768048\n",
      "  episode_reward_min: -168.82583639856816\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 53771\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3675.03\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 4430000\n",
      "    num_steps_trained: 4430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6249767541885376\n",
      "      kl: 0.024171262979507446\n",
      "      policy_loss: 0.006334235891699791\n",
      "      total_loss: 62.91974639892578\n",
      "      vf_explained_var: 0.8808276653289795\n",
      "      vf_loss: 62.91018295288086\n",
      "    sample_time_ms: 18503.169\n",
      "    update_time_ms: 6.267\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.48846538384024\n",
      "  time_since_restore: 9767.815903425217\n",
      "  time_this_iter_s: 22.309651136398315\n",
      "  time_total_s: 9767.815903425217\n",
      "  timestamp: 1553131581\n",
      "  timesteps_since_restore: 4430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4430000\n",
      "  training_iteration: 443\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9767 s, 443 iter, 4430000 ts, 37 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-26-43\n",
      "  done: false\n",
      "  episode_len_mean: 73.8905109489051\n",
      "  episode_reward_max: 387.55149810189516\n",
      "  episode_reward_mean: 39.73319067707322\n",
      "  episode_reward_min: -168.84092809745312\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 53908\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.862\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 4440000\n",
      "    num_steps_trained: 4440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6383504867553711\n",
      "      kl: 0.031601306051015854\n",
      "      policy_loss: 0.005899590440094471\n",
      "      total_loss: 65.9736328125\n",
      "      vf_explained_var: 0.8755608797073364\n",
      "      vf_loss: 65.9635009765625\n",
      "    sample_time_ms: 18463.644\n",
      "    update_time_ms: 6.14\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.86659533853661\n",
      "  time_since_restore: 9789.92007637024\n",
      "  time_this_iter_s: 22.104172945022583\n",
      "  time_total_s: 9789.92007637024\n",
      "  timestamp: 1553131603\n",
      "  timesteps_since_restore: 4440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4440000\n",
      "  training_iteration: 444\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9789 s, 444 iter, 4440000 ts, 39.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-27-05\n",
      "  done: false\n",
      "  episode_len_mean: 70.06993006993007\n",
      "  episode_reward_max: 386.34113885559645\n",
      "  episode_reward_mean: 18.35021940605358\n",
      "  episode_reward_min: -168.81989543267727\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 54051\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.364\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 4450000\n",
      "    num_steps_trained: 4450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6496772766113281\n",
      "      kl: 0.02303818240761757\n",
      "      policy_loss: 0.0018811539048328996\n",
      "      total_loss: 67.73896789550781\n",
      "      vf_explained_var: 0.8785292506217957\n",
      "      vf_loss: 67.73400115966797\n",
      "    sample_time_ms: 18450.043\n",
      "    update_time_ms: 6.103\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.175109703026793\n",
      "  time_since_restore: 9812.062371492386\n",
      "  time_this_iter_s: 22.142295122146606\n",
      "  time_total_s: 9812.062371492386\n",
      "  timestamp: 1553131625\n",
      "  timesteps_since_restore: 4450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4450000\n",
      "  training_iteration: 445\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9812 s, 445 iter, 4450000 ts, 18.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-27-27\n",
      "  done: false\n",
      "  episode_len_mean: 69.13194444444444\n",
      "  episode_reward_max: 384.2699853409333\n",
      "  episode_reward_mean: 7.560759014185363\n",
      "  episode_reward_min: -163.72344890775918\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 54195\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.95\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 4460000\n",
      "    num_steps_trained: 4460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6399562358856201\n",
      "      kl: 0.02429313026368618\n",
      "      policy_loss: 0.0027521627489477396\n",
      "      total_loss: 65.17938995361328\n",
      "      vf_explained_var: 0.8860059976577759\n",
      "      vf_loss: 65.17338562011719\n",
      "    sample_time_ms: 18469.281\n",
      "    update_time_ms: 5.381\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 3.7803795070926802\n",
      "  time_since_restore: 9834.356613874435\n",
      "  time_this_iter_s: 22.29424238204956\n",
      "  time_total_s: 9834.356613874435\n",
      "  timestamp: 1553131647\n",
      "  timesteps_since_restore: 4460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4460000\n",
      "  training_iteration: 446\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9834 s, 446 iter, 4460000 ts, 7.56 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-27-50\n",
      "  done: false\n",
      "  episode_len_mean: 72.45255474452554\n",
      "  episode_reward_max: 386.0860226140683\n",
      "  episode_reward_mean: 33.57728584612439\n",
      "  episode_reward_min: -164.6925669946337\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 54332\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.925\n",
      "    load_time_ms: 1.61\n",
      "    num_steps_sampled: 4470000\n",
      "    num_steps_trained: 4470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6477875709533691\n",
      "      kl: 0.021303396672010422\n",
      "      policy_loss: 0.003583124140277505\n",
      "      total_loss: 63.746131896972656\n",
      "      vf_explained_var: 0.8794445991516113\n",
      "      vf_loss: 63.73969650268555\n",
      "    sample_time_ms: 18473.496\n",
      "    update_time_ms: 5.413\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.7886429230622\n",
      "  time_since_restore: 9856.559873819351\n",
      "  time_this_iter_s: 22.20325994491577\n",
      "  time_total_s: 9856.559873819351\n",
      "  timestamp: 1553131670\n",
      "  timesteps_since_restore: 4470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4470000\n",
      "  training_iteration: 447\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9856 s, 447 iter, 4470000 ts, 33.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-28-12\n",
      "  done: false\n",
      "  episode_len_mean: 66.64\n",
      "  episode_reward_max: 385.6339024466972\n",
      "  episode_reward_mean: -10.628096463523283\n",
      "  episode_reward_min: -166.8744049033785\n",
      "  episodes_this_iter: 150\n",
      "  episodes_total: 54482\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.373\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 4480000\n",
      "    num_steps_trained: 4480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6535714268684387\n",
      "      kl: 0.02751259319484234\n",
      "      policy_loss: 0.005787998903542757\n",
      "      total_loss: 64.54130554199219\n",
      "      vf_explained_var: 0.8915766477584839\n",
      "      vf_loss: 64.5318374633789\n",
      "    sample_time_ms: 18531.513\n",
      "    update_time_ms: 5.506\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -5.314048231761638\n",
      "  time_since_restore: 9879.033182621002\n",
      "  time_this_iter_s: 22.473308801651\n",
      "  time_total_s: 9879.033182621002\n",
      "  timestamp: 1553131692\n",
      "  timesteps_since_restore: 4480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4480000\n",
      "  training_iteration: 448\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9879 s, 448 iter, 4480000 ts, -10.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-28-34\n",
      "  done: false\n",
      "  episode_len_mean: 76.39393939393939\n",
      "  episode_reward_max: 385.4646706901939\n",
      "  episode_reward_mean: 60.155420735034276\n",
      "  episode_reward_min: -168.85341325625419\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 54614\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.096\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 4490000\n",
      "    num_steps_trained: 4490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6140753030776978\n",
      "      kl: 0.027111763134598732\n",
      "      policy_loss: 0.005029403138905764\n",
      "      total_loss: 52.60994338989258\n",
      "      vf_explained_var: 0.8937132358551025\n",
      "      vf_loss: 52.60127639770508\n",
      "    sample_time_ms: 18535.138\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.07771036751714\n",
      "  time_since_restore: 9901.270452976227\n",
      "  time_this_iter_s: 22.23727035522461\n",
      "  time_total_s: 9901.270452976227\n",
      "  timestamp: 1553131714\n",
      "  timesteps_since_restore: 4490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4490000\n",
      "  training_iteration: 449\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9901 s, 449 iter, 4490000 ts, 60.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-28-57\n",
      "  done: false\n",
      "  episode_len_mean: 71.48920863309353\n",
      "  episode_reward_max: 387.1681458464762\n",
      "  episode_reward_mean: 34.027728785003184\n",
      "  episode_reward_min: -166.8405821195507\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 54753\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.365\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 4500000\n",
      "    num_steps_trained: 4500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6380038261413574\n",
      "      kl: 0.020886464044451714\n",
      "      policy_loss: 0.001341919880360365\n",
      "      total_loss: 62.031951904296875\n",
      "      vf_explained_var: 0.8859648108482361\n",
      "      vf_loss: 62.02780532836914\n",
      "    sample_time_ms: 18553.365\n",
      "    update_time_ms: 5.373\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.01386439250158\n",
      "  time_since_restore: 9923.593878030777\n",
      "  time_this_iter_s: 22.32342505455017\n",
      "  time_total_s: 9923.593878030777\n",
      "  timestamp: 1553131737\n",
      "  timesteps_since_restore: 4500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4500000\n",
      "  training_iteration: 450\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9923 s, 450 iter, 4500000 ts, 34 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-29-19\n",
      "  done: false\n",
      "  episode_len_mean: 72.84782608695652\n",
      "  episode_reward_max: 384.7130832583912\n",
      "  episode_reward_mean: 39.01480482956017\n",
      "  episode_reward_min: -166.819949236598\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 54891\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.663\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 4510000\n",
      "    num_steps_trained: 4510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6494548320770264\n",
      "      kl: 0.024966299533843994\n",
      "      policy_loss: 0.004335526376962662\n",
      "      total_loss: 60.744510650634766\n",
      "      vf_explained_var: 0.8853573799133301\n",
      "      vf_loss: 60.7368278503418\n",
      "    sample_time_ms: 18532.616\n",
      "    update_time_ms: 5.343\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.507402414780085\n",
      "  time_since_restore: 9945.710270643234\n",
      "  time_this_iter_s: 22.116392612457275\n",
      "  time_total_s: 9945.710270643234\n",
      "  timestamp: 1553131759\n",
      "  timesteps_since_restore: 4510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4510000\n",
      "  training_iteration: 451\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9945 s, 451 iter, 4510000 ts, 39 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-29-41\n",
      "  done: false\n",
      "  episode_len_mean: 72.20143884892086\n",
      "  episode_reward_max: 387.3402020162241\n",
      "  episode_reward_mean: 30.108280430668863\n",
      "  episode_reward_min: -166.84231016990185\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 55030\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3731.218\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 4520000\n",
      "    num_steps_trained: 4520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6338045001029968\n",
      "      kl: 0.016815854236483574\n",
      "      policy_loss: 0.00532312598079443\n",
      "      total_loss: 60.51780319213867\n",
      "      vf_explained_var: 0.8873408436775208\n",
      "      vf_loss: 60.51022720336914\n",
      "    sample_time_ms: 18442.328\n",
      "    update_time_ms: 5.905\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.05414021533442\n",
      "  time_since_restore: 9967.501469135284\n",
      "  time_this_iter_s: 21.79119849205017\n",
      "  time_total_s: 9967.501469135284\n",
      "  timestamp: 1553131781\n",
      "  timesteps_since_restore: 4520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4520000\n",
      "  training_iteration: 452\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9967 s, 452 iter, 4520000 ts, 30.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-30-03\n",
      "  done: false\n",
      "  episode_len_mean: 70.54609929078015\n",
      "  episode_reward_max: 387.28514078781103\n",
      "  episode_reward_mean: 15.863311961155874\n",
      "  episode_reward_min: -166.8261196920538\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 55171\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3728.205\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 4530000\n",
      "    num_steps_trained: 4530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6576182842254639\n",
      "      kl: 0.03199145197868347\n",
      "      policy_loss: 0.003148163203150034\n",
      "      total_loss: 66.56919860839844\n",
      "      vf_explained_var: 0.8815779089927673\n",
      "      vf_loss: 66.56177520751953\n",
      "    sample_time_ms: 18402.204\n",
      "    update_time_ms: 5.854\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.931655980577937\n",
      "  time_since_restore: 9989.379341363907\n",
      "  time_this_iter_s: 21.877872228622437\n",
      "  time_total_s: 9989.379341363907\n",
      "  timestamp: 1553131803\n",
      "  timesteps_since_restore: 4530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4530000\n",
      "  training_iteration: 453\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 9989 s, 453 iter, 4530000 ts, 15.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-30-25\n",
      "  done: false\n",
      "  episode_len_mean: 71.51428571428572\n",
      "  episode_reward_max: 388.8617402096667\n",
      "  episode_reward_mean: 24.57175027396289\n",
      "  episode_reward_min: -166.98874583658218\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 55311\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.322\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 4540000\n",
      "    num_steps_trained: 4540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6230183839797974\n",
      "      kl: 0.027869900688529015\n",
      "      policy_loss: 0.004473431035876274\n",
      "      total_loss: 52.2320442199707\n",
      "      vf_explained_var: 0.9050422310829163\n",
      "      vf_loss: 52.22383499145508\n",
      "    sample_time_ms: 18430.059\n",
      "    update_time_ms: 5.263\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.285875136981444\n",
      "  time_since_restore: 10011.675138235092\n",
      "  time_this_iter_s: 22.295796871185303\n",
      "  time_total_s: 10011.675138235092\n",
      "  timestamp: 1553131825\n",
      "  timesteps_since_restore: 4540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4540000\n",
      "  training_iteration: 454\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10011 s, 454 iter, 4540000 ts, 24.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-30-48\n",
      "  done: false\n",
      "  episode_len_mean: 71.07801418439716\n",
      "  episode_reward_max: 387.0212113985819\n",
      "  episode_reward_mean: 16.58265223968089\n",
      "  episode_reward_min: -164.93982017954826\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 55452\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.219\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 4550000\n",
      "    num_steps_trained: 4550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6195369362831116\n",
      "      kl: 0.029015278443694115\n",
      "      policy_loss: 0.003944843076169491\n",
      "      total_loss: 60.181640625\n",
      "      vf_explained_var: 0.8925096392631531\n",
      "      vf_loss: 60.17380142211914\n",
      "    sample_time_ms: 18462.307\n",
      "    update_time_ms: 5.382\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.291326119840438\n",
      "  time_since_restore: 10034.120973825455\n",
      "  time_this_iter_s: 22.44583559036255\n",
      "  time_total_s: 10034.120973825455\n",
      "  timestamp: 1553131848\n",
      "  timesteps_since_restore: 4550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4550000\n",
      "  training_iteration: 455\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10034 s, 455 iter, 4550000 ts, 16.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-31-09\n",
      "  done: false\n",
      "  episode_len_mean: 67.12162162162163\n",
      "  episode_reward_max: 383.787639886855\n",
      "  episode_reward_mean: -0.5114138922908814\n",
      "  episode_reward_min: -164.76788166924953\n",
      "  episodes_this_iter: 148\n",
      "  episodes_total: 55600\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.111\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 4560000\n",
      "    num_steps_trained: 4560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6354162693023682\n",
      "      kl: 0.029250022023916245\n",
      "      policy_loss: 0.00673720333725214\n",
      "      total_loss: 54.46323013305664\n",
      "      vf_explained_var: 0.9067249894142151\n",
      "      vf_loss: 54.452579498291016\n",
      "    sample_time_ms: 18400.008\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -0.2557069461454409\n",
      "  time_since_restore: 10055.770493745804\n",
      "  time_this_iter_s: 21.64951992034912\n",
      "  time_total_s: 10055.770493745804\n",
      "  timestamp: 1553131869\n",
      "  timesteps_since_restore: 4560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4560000\n",
      "  training_iteration: 456\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10055 s, 456 iter, 4560000 ts, -0.511 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-31-32\n",
      "  done: false\n",
      "  episode_len_mean: 74.35820895522389\n",
      "  episode_reward_max: 384.12977223685243\n",
      "  episode_reward_mean: 52.97180289168208\n",
      "  episode_reward_min: -168.97434595653056\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 55734\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.918\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 4570000\n",
      "    num_steps_trained: 4570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6147745847702026\n",
      "      kl: 0.019060393795371056\n",
      "      policy_loss: 0.0024339875672012568\n",
      "      total_loss: 53.2421760559082\n",
      "      vf_explained_var: 0.8937575221061707\n",
      "      vf_loss: 53.23719024658203\n",
      "    sample_time_ms: 18423.67\n",
      "    update_time_ms: 5.609\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.48590144584104\n",
      "  time_since_restore: 10078.200632810593\n",
      "  time_this_iter_s: 22.43013906478882\n",
      "  time_total_s: 10078.200632810593\n",
      "  timestamp: 1553131892\n",
      "  timesteps_since_restore: 4570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4570000\n",
      "  training_iteration: 457\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10078 s, 457 iter, 4570000 ts, 53 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-31-53\n",
      "  done: false\n",
      "  episode_len_mean: 70.4055944055944\n",
      "  episode_reward_max: 387.39821408118274\n",
      "  episode_reward_mean: 17.0640907359099\n",
      "  episode_reward_min: -164.92010091098786\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 55877\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.547\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 4580000\n",
      "    num_steps_trained: 4580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6271592974662781\n",
      "      kl: 0.020367160439491272\n",
      "      policy_loss: 0.00402827188372612\n",
      "      total_loss: 54.62052917480469\n",
      "      vf_explained_var: 0.9034335613250732\n",
      "      vf_loss: 54.61376953125\n",
      "    sample_time_ms: 18340.428\n",
      "    update_time_ms: 5.62\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.532045367954947\n",
      "  time_since_restore: 10099.731680631638\n",
      "  time_this_iter_s: 21.531047821044922\n",
      "  time_total_s: 10099.731680631638\n",
      "  timestamp: 1553131913\n",
      "  timesteps_since_restore: 4580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4580000\n",
      "  training_iteration: 458\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10099 s, 458 iter, 4580000 ts, 17.1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-32-15\n",
      "  done: false\n",
      "  episode_len_mean: 74.35555555555555\n",
      "  episode_reward_max: 386.9398763299107\n",
      "  episode_reward_mean: 44.27656090437717\n",
      "  episode_reward_min: -164.7758772531414\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 56012\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.384\n",
      "    load_time_ms: 1.624\n",
      "    num_steps_sampled: 4590000\n",
      "    num_steps_trained: 4590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6159377694129944\n",
      "      kl: 0.02776716649532318\n",
      "      policy_loss: 0.00587565079331398\n",
      "      total_loss: 58.26611328125\n",
      "      vf_explained_var: 0.8854864835739136\n",
      "      vf_loss: 58.25651550292969\n",
      "    sample_time_ms: 18301.32\n",
      "    update_time_ms: 5.859\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.138280452188578\n",
      "  time_since_restore: 10121.570789337158\n",
      "  time_this_iter_s: 21.83910870552063\n",
      "  time_total_s: 10121.570789337158\n",
      "  timestamp: 1553131935\n",
      "  timesteps_since_restore: 4590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4590000\n",
      "  training_iteration: 459\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10121 s, 459 iter, 4590000 ts, 44.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-32-37\n",
      "  done: false\n",
      "  episode_len_mean: 71.61151079136691\n",
      "  episode_reward_max: 385.73327894837155\n",
      "  episode_reward_mean: 31.102273321264757\n",
      "  episode_reward_min: -164.8023967317009\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 56151\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.118\n",
      "    load_time_ms: 1.645\n",
      "    num_steps_sampled: 4600000\n",
      "    num_steps_trained: 4600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6079520583152771\n",
      "      kl: 0.01499254535883665\n",
      "      policy_loss: 0.004307275637984276\n",
      "      total_loss: 61.9731559753418\n",
      "      vf_explained_var: 0.884773850440979\n",
      "      vf_loss: 61.966835021972656\n",
      "    sample_time_ms: 18261.377\n",
      "    update_time_ms: 5.854\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.551136660632379\n",
      "  time_since_restore: 10143.473022699356\n",
      "  time_this_iter_s: 21.902233362197876\n",
      "  time_total_s: 10143.473022699356\n",
      "  timestamp: 1553131957\n",
      "  timesteps_since_restore: 4600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4600000\n",
      "  training_iteration: 460\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10143 s, 460 iter, 4600000 ts, 31.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-32-59\n",
      "  done: false\n",
      "  episode_len_mean: 73.88235294117646\n",
      "  episode_reward_max: 388.95462594859794\n",
      "  episode_reward_mean: 43.90220655498029\n",
      "  episode_reward_min: -168.97260847422123\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 56287\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.151\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 4610000\n",
      "    num_steps_trained: 4610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6046875715255737\n",
      "      kl: 0.02018226496875286\n",
      "      policy_loss: 0.0004129337321501225\n",
      "      total_loss: 59.855281829833984\n",
      "      vf_explained_var: 0.8872021436691284\n",
      "      vf_loss: 59.85216522216797\n",
      "    sample_time_ms: 18184.311\n",
      "    update_time_ms: 5.905\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.95110327749014\n",
      "  time_since_restore: 10164.856556653976\n",
      "  time_this_iter_s: 21.38353395462036\n",
      "  time_total_s: 10164.856556653976\n",
      "  timestamp: 1553131979\n",
      "  timesteps_since_restore: 4610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4610000\n",
      "  training_iteration: 461\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10164 s, 461 iter, 4610000 ts, 43.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-33-20\n",
      "  done: false\n",
      "  episode_len_mean: 70.21985815602837\n",
      "  episode_reward_max: 387.9379093958951\n",
      "  episode_reward_mean: 19.963240025490236\n",
      "  episode_reward_min: -164.7184808263445\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 56428\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3674.667\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 4620000\n",
      "    num_steps_trained: 4620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6227996945381165\n",
      "      kl: 0.01703663356602192\n",
      "      policy_loss: 0.0018179109320044518\n",
      "      total_loss: 54.11107635498047\n",
      "      vf_explained_var: 0.9034226536750793\n",
      "      vf_loss: 54.10698318481445\n",
      "    sample_time_ms: 18200.671\n",
      "    update_time_ms: 5.495\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.98162001274512\n",
      "  time_since_restore: 10186.515100479126\n",
      "  time_this_iter_s: 21.658543825149536\n",
      "  time_total_s: 10186.515100479126\n",
      "  timestamp: 1553132000\n",
      "  timesteps_since_restore: 4620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4620000\n",
      "  training_iteration: 462\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10186 s, 462 iter, 4620000 ts, 20 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-33-42\n",
      "  done: false\n",
      "  episode_len_mean: 70.65034965034965\n",
      "  episode_reward_max: 387.7565513727495\n",
      "  episode_reward_mean: 25.380021507147415\n",
      "  episode_reward_min: -162.66033082458017\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 56571\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.583\n",
      "    load_time_ms: 1.779\n",
      "    num_steps_sampled: 4630000\n",
      "    num_steps_trained: 4630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6156718730926514\n",
      "      kl: 0.01772286556661129\n",
      "      policy_loss: 0.0030921567231416702\n",
      "      total_loss: 47.27102279663086\n",
      "      vf_explained_var: 0.9166828989982605\n",
      "      vf_loss: 47.26554489135742\n",
      "    sample_time_ms: 18159.612\n",
      "    update_time_ms: 5.845\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.690010753573706\n",
      "  time_since_restore: 10208.236169099808\n",
      "  time_this_iter_s: 21.721068620681763\n",
      "  time_total_s: 10208.236169099808\n",
      "  timestamp: 1553132022\n",
      "  timesteps_since_restore: 4630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4630000\n",
      "  training_iteration: 463\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10208 s, 463 iter, 4630000 ts, 25.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-34-04\n",
      "  done: false\n",
      "  episode_len_mean: 74.19402985074628\n",
      "  episode_reward_max: 385.43906876930356\n",
      "  episode_reward_mean: 44.32838744485727\n",
      "  episode_reward_min: -165.1592867292428\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 56705\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.547\n",
      "    load_time_ms: 1.805\n",
      "    num_steps_sampled: 4640000\n",
      "    num_steps_trained: 4640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6257975697517395\n",
      "      kl: 0.02091020531952381\n",
      "      policy_loss: 0.0032193975057452917\n",
      "      total_loss: 51.32801055908203\n",
      "      vf_explained_var: 0.897344172000885\n",
      "      vf_loss: 51.32199478149414\n",
      "    sample_time_ms: 18094.621\n",
      "    update_time_ms: 6.003\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.164193722428628\n",
      "  time_since_restore: 10229.876941204071\n",
      "  time_this_iter_s: 21.640772104263306\n",
      "  time_total_s: 10229.876941204071\n",
      "  timestamp: 1553132044\n",
      "  timesteps_since_restore: 4640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4640000\n",
      "  training_iteration: 464\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10229 s, 464 iter, 4640000 ts, 44.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-34-26\n",
      "  done: false\n",
      "  episode_len_mean: 72.15217391304348\n",
      "  episode_reward_max: 384.4538594775815\n",
      "  episode_reward_mean: 30.25959424141306\n",
      "  episode_reward_min: -166.73980341836452\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 56843\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.085\n",
      "    load_time_ms: 1.81\n",
      "    num_steps_sampled: 4650000\n",
      "    num_steps_trained: 4650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6227757334709167\n",
      "      kl: 0.02902836725115776\n",
      "      policy_loss: 0.006861501839011908\n",
      "      total_loss: 66.46967315673828\n",
      "      vf_explained_var: 0.8774995803833008\n",
      "      vf_loss: 66.45893096923828\n",
      "    sample_time_ms: 18051.079\n",
      "    update_time_ms: 5.952\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.129797120706518\n",
      "  time_since_restore: 10251.908301830292\n",
      "  time_this_iter_s: 22.031360626220703\n",
      "  time_total_s: 10251.908301830292\n",
      "  timestamp: 1553132066\n",
      "  timesteps_since_restore: 4650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4650000\n",
      "  training_iteration: 465\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10251 s, 465 iter, 4650000 ts, 30.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-34-48\n",
      "  done: false\n",
      "  episode_len_mean: 72.60431654676259\n",
      "  episode_reward_max: 387.8951409375352\n",
      "  episode_reward_mean: 36.96797307106045\n",
      "  episode_reward_min: -168.75857543608188\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 56982\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.784\n",
      "    load_time_ms: 1.773\n",
      "    num_steps_sampled: 4660000\n",
      "    num_steps_trained: 4660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6337622404098511\n",
      "      kl: 0.032395392656326294\n",
      "      policy_loss: 0.0073277829214930534\n",
      "      total_loss: 53.81070327758789\n",
      "      vf_explained_var: 0.9018545150756836\n",
      "      vf_loss: 53.799041748046875\n",
      "    sample_time_ms: 18086.809\n",
      "    update_time_ms: 6.009\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.48398653553023\n",
      "  time_since_restore: 10273.961923599243\n",
      "  time_this_iter_s: 22.053621768951416\n",
      "  time_total_s: 10273.961923599243\n",
      "  timestamp: 1553132088\n",
      "  timesteps_since_restore: 4660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4660000\n",
      "  training_iteration: 466\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10273 s, 466 iter, 4660000 ts, 37 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-35-09\n",
      "  done: false\n",
      "  episode_len_mean: 77.63565891472868\n",
      "  episode_reward_max: 387.9429611277818\n",
      "  episode_reward_mean: 74.28533283758377\n",
      "  episode_reward_min: -168.7659663487339\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 57111\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.76\n",
      "    load_time_ms: 1.708\n",
      "    num_steps_sampled: 4670000\n",
      "    num_steps_trained: 4670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5995087027549744\n",
      "      kl: 0.026205331087112427\n",
      "      policy_loss: 0.0044313715770840645\n",
      "      total_loss: 59.06663131713867\n",
      "      vf_explained_var: 0.8793559670448303\n",
      "      vf_loss: 59.058692932128906\n",
      "    sample_time_ms: 17996.87\n",
      "    update_time_ms: 5.913\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.142666418791876\n",
      "  time_since_restore: 10295.54005074501\n",
      "  time_this_iter_s: 21.578127145767212\n",
      "  time_total_s: 10295.54005074501\n",
      "  timestamp: 1553132109\n",
      "  timesteps_since_restore: 4670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4670000\n",
      "  training_iteration: 467\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10295 s, 467 iter, 4670000 ts, 74.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-35-32\n",
      "  done: false\n",
      "  episode_len_mean: 72.81751824817518\n",
      "  episode_reward_max: 386.94048076878863\n",
      "  episode_reward_mean: 41.629243769859976\n",
      "  episode_reward_min: -166.85201520165444\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 57248\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.41\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 4680000\n",
      "    num_steps_trained: 4680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6130752563476562\n",
      "      kl: 0.021720558404922485\n",
      "      policy_loss: 0.0032429539132863283\n",
      "      total_loss: 57.91727828979492\n",
      "      vf_explained_var: 0.8890783786773682\n",
      "      vf_loss: 57.91112518310547\n",
      "    sample_time_ms: 18068.393\n",
      "    update_time_ms: 6.411\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.814621884929984\n",
      "  time_since_restore: 10317.806102275848\n",
      "  time_this_iter_s: 22.266051530838013\n",
      "  time_total_s: 10317.806102275848\n",
      "  timestamp: 1553132132\n",
      "  timesteps_since_restore: 4680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4680000\n",
      "  training_iteration: 468\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10317 s, 468 iter, 4680000 ts, 41.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-35-54\n",
      "  done: false\n",
      "  episode_len_mean: 70.95035460992908\n",
      "  episode_reward_max: 382.12578662848847\n",
      "  episode_reward_mean: 27.941769128535004\n",
      "  episode_reward_min: -168.80590387269496\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 57389\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.658\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 4690000\n",
      "    num_steps_trained: 4690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6280502676963806\n",
      "      kl: 0.021463027223944664\n",
      "      policy_loss: 0.00431395648047328\n",
      "      total_loss: 49.74149703979492\n",
      "      vf_explained_var: 0.907878577709198\n",
      "      vf_loss: 49.73431396484375\n",
      "    sample_time_ms: 18062.728\n",
      "    update_time_ms: 6.183\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 13.970884564267504\n",
      "  time_since_restore: 10339.595025539398\n",
      "  time_this_iter_s: 21.788923263549805\n",
      "  time_total_s: 10339.595025539398\n",
      "  timestamp: 1553132154\n",
      "  timesteps_since_restore: 4690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4690000\n",
      "  training_iteration: 469\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10339 s, 469 iter, 4690000 ts, 27.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-36-15\n",
      "  done: false\n",
      "  episode_len_mean: 72.62773722627738\n",
      "  episode_reward_max: 385.2362097651689\n",
      "  episode_reward_mean: 33.505195424304326\n",
      "  episode_reward_min: -166.86854267498492\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 57526\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.65\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 4700000\n",
      "    num_steps_trained: 4700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6187812685966492\n",
      "      kl: 0.02518012933433056\n",
      "      policy_loss: 0.001886723912321031\n",
      "      total_loss: 64.3946304321289\n",
      "      vf_explained_var: 0.8788332939147949\n",
      "      vf_loss: 64.38937377929688\n",
      "    sample_time_ms: 18048.52\n",
      "    update_time_ms: 6.252\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.75259771215216\n",
      "  time_since_restore: 10361.368483543396\n",
      "  time_this_iter_s: 21.773458003997803\n",
      "  time_total_s: 10361.368483543396\n",
      "  timestamp: 1553132175\n",
      "  timesteps_since_restore: 4700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4700000\n",
      "  training_iteration: 470\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10361 s, 470 iter, 4700000 ts, 33.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-36-38\n",
      "  done: false\n",
      "  episode_len_mean: 73.37226277372262\n",
      "  episode_reward_max: 384.69894949266575\n",
      "  episode_reward_mean: 44.177113552028686\n",
      "  episode_reward_min: -164.70452883168696\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 57663\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.306\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 4710000\n",
      "    num_steps_trained: 4710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6053745746612549\n",
      "      kl: 0.024578671902418137\n",
      "      policy_loss: 0.0032451367005705833\n",
      "      total_loss: 60.10279083251953\n",
      "      vf_explained_var: 0.8841224312782288\n",
      "      vf_loss: 60.09626007080078\n",
      "    sample_time_ms: 18145.041\n",
      "    update_time_ms: 6.134\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.088556776014343\n",
      "  time_since_restore: 10383.700988054276\n",
      "  time_this_iter_s: 22.332504510879517\n",
      "  time_total_s: 10383.700988054276\n",
      "  timestamp: 1553132198\n",
      "  timesteps_since_restore: 4710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4710000\n",
      "  training_iteration: 471\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10383 s, 471 iter, 4710000 ts, 44.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-37-00\n",
      "  done: false\n",
      "  episode_len_mean: 70.42957746478874\n",
      "  episode_reward_max: 386.77007677980134\n",
      "  episode_reward_mean: 13.15476119927516\n",
      "  episode_reward_min: -168.77023308202266\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 57805\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.733\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 4720000\n",
      "    num_steps_trained: 4720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6342931985855103\n",
      "      kl: 0.019879331812262535\n",
      "      policy_loss: 0.00687017198652029\n",
      "      total_loss: 60.43220901489258\n",
      "      vf_explained_var: 0.8914039731025696\n",
      "      vf_loss: 60.42267608642578\n",
      "    sample_time_ms: 18209.567\n",
      "    update_time_ms: 6.038\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.5773805996375785\n",
      "  time_since_restore: 10406.031171560287\n",
      "  time_this_iter_s: 22.330183506011963\n",
      "  time_total_s: 10406.031171560287\n",
      "  timestamp: 1553132220\n",
      "  timesteps_since_restore: 4720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4720000\n",
      "  training_iteration: 472\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10406 s, 472 iter, 4720000 ts, 13.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-37-23\n",
      "  done: false\n",
      "  episode_len_mean: 72.80147058823529\n",
      "  episode_reward_max: 384.966363088418\n",
      "  episode_reward_mean: 34.89162309873286\n",
      "  episode_reward_min: -165.33377255615233\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 57941\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.887\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 4730000\n",
      "    num_steps_trained: 4730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6476728916168213\n",
      "      kl: 0.021960314363241196\n",
      "      policy_loss: 0.0023518765810877085\n",
      "      total_loss: 69.37750244140625\n",
      "      vf_explained_var: 0.8701266050338745\n",
      "      vf_loss: 69.37220764160156\n",
      "    sample_time_ms: 18295.944\n",
      "    update_time_ms: 5.777\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.44581154936643\n",
      "  time_since_restore: 10428.373903989792\n",
      "  time_this_iter_s: 22.342732429504395\n",
      "  time_total_s: 10428.373903989792\n",
      "  timestamp: 1553132243\n",
      "  timesteps_since_restore: 4730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4730000\n",
      "  training_iteration: 473\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10428 s, 473 iter, 4730000 ts, 34.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-37-44\n",
      "  done: false\n",
      "  episode_len_mean: 70.13194444444444\n",
      "  episode_reward_max: 387.37344897672983\n",
      "  episode_reward_mean: 19.626421117656093\n",
      "  episode_reward_min: -164.69292773529529\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 58085\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.66\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 4740000\n",
      "    num_steps_trained: 4740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6701950430870056\n",
      "      kl: 0.03615511208772659\n",
      "      policy_loss: 0.009082118980586529\n",
      "      total_loss: 65.3081283569336\n",
      "      vf_explained_var: 0.8840633034706116\n",
      "      vf_loss: 65.2942123413086\n",
      "    sample_time_ms: 18297.411\n",
      "    update_time_ms: 5.797\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.813210558828041\n",
      "  time_since_restore: 10450.046746730804\n",
      "  time_this_iter_s: 21.672842741012573\n",
      "  time_total_s: 10450.046746730804\n",
      "  timestamp: 1553132264\n",
      "  timesteps_since_restore: 4740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4740000\n",
      "  training_iteration: 474\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10450 s, 474 iter, 4740000 ts, 19.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-38-06\n",
      "  done: false\n",
      "  episode_len_mean: 69.21830985915493\n",
      "  episode_reward_max: 387.99639602408297\n",
      "  episode_reward_mean: 18.61967681812786\n",
      "  episode_reward_min: -166.86041279157638\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 58227\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.881\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 4750000\n",
      "    num_steps_trained: 4750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6481414437294006\n",
      "      kl: 0.026041073724627495\n",
      "      policy_loss: 0.0040032691322267056\n",
      "      total_loss: 68.40850067138672\n",
      "      vf_explained_var: 0.8787000775337219\n",
      "      vf_loss: 68.4010009765625\n",
      "    sample_time_ms: 18288.115\n",
      "    update_time_ms: 5.712\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.309838409063925\n",
      "  time_since_restore: 10471.977478981018\n",
      "  time_this_iter_s: 21.930732250213623\n",
      "  time_total_s: 10471.977478981018\n",
      "  timestamp: 1553132286\n",
      "  timesteps_since_restore: 4750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4750000\n",
      "  training_iteration: 475\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10471 s, 475 iter, 4750000 ts, 18.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-38-28\n",
      "  done: false\n",
      "  episode_len_mean: 76.6590909090909\n",
      "  episode_reward_max: 387.46836767001713\n",
      "  episode_reward_mean: 62.30887503921896\n",
      "  episode_reward_min: -165.1427921485567\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 58359\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.006\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 4760000\n",
      "    num_steps_trained: 4760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5870294570922852\n",
      "      kl: 0.016849255189299583\n",
      "      policy_loss: 0.0024067405611276627\n",
      "      total_loss: 51.47285079956055\n",
      "      vf_explained_var: 0.8971226811408997\n",
      "      vf_loss: 51.46818542480469\n",
      "    sample_time_ms: 18285.567\n",
      "    update_time_ms: 5.677\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.154437519609473\n",
      "  time_since_restore: 10493.958158016205\n",
      "  time_this_iter_s: 21.980679035186768\n",
      "  time_total_s: 10493.958158016205\n",
      "  timestamp: 1553132308\n",
      "  timesteps_since_restore: 4760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4760000\n",
      "  training_iteration: 476\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10493 s, 476 iter, 4760000 ts, 62.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-38-50\n",
      "  done: false\n",
      "  episode_len_mean: 76.7175572519084\n",
      "  episode_reward_max: 387.7924095618344\n",
      "  episode_reward_mean: 68.08605257375311\n",
      "  episode_reward_min: -164.97446166309356\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 58490\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.559\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 4770000\n",
      "    num_steps_trained: 4770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5775212645530701\n",
      "      kl: 0.01872061938047409\n",
      "      policy_loss: 0.0010954516474157572\n",
      "      total_loss: 56.38700485229492\n",
      "      vf_explained_var: 0.8818482756614685\n",
      "      vf_loss: 56.38340759277344\n",
      "    sample_time_ms: 18301.112\n",
      "    update_time_ms: 5.491\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.04302628687654\n",
      "  time_since_restore: 10515.633345127106\n",
      "  time_this_iter_s: 21.67518711090088\n",
      "  time_total_s: 10515.633345127106\n",
      "  timestamp: 1553132330\n",
      "  timesteps_since_restore: 4770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4770000\n",
      "  training_iteration: 477\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10515 s, 477 iter, 4770000 ts, 68.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-39-12\n",
      "  done: false\n",
      "  episode_len_mean: 72.3840579710145\n",
      "  episode_reward_max: 392.69711471862183\n",
      "  episode_reward_mean: 35.79994468200853\n",
      "  episode_reward_min: -166.75572624465465\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 58628\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.258\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 4780000\n",
      "    num_steps_trained: 4780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6110143661499023\n",
      "      kl: 0.017502008005976677\n",
      "      policy_loss: 0.002962193451821804\n",
      "      total_loss: 58.794471740722656\n",
      "      vf_explained_var: 0.8908158540725708\n",
      "      vf_loss: 58.789161682128906\n",
      "    sample_time_ms: 18278.051\n",
      "    update_time_ms: 5.279\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.89997234100426\n",
      "  time_since_restore: 10537.872809410095\n",
      "  time_this_iter_s: 22.239464282989502\n",
      "  time_total_s: 10537.872809410095\n",
      "  timestamp: 1553132352\n",
      "  timesteps_since_restore: 4780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4780000\n",
      "  training_iteration: 478\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10537 s, 478 iter, 4780000 ts, 35.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-39-34\n",
      "  done: false\n",
      "  episode_len_mean: 71.96350364963503\n",
      "  episode_reward_max: 389.3107472996344\n",
      "  episode_reward_mean: 33.563654219516565\n",
      "  episode_reward_min: -167.1771368943119\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 58765\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.373\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 4790000\n",
      "    num_steps_trained: 4790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.598159670829773\n",
      "      kl: 0.02268795482814312\n",
      "      policy_loss: 0.0063684550113976\n",
      "      total_loss: 52.708194732666016\n",
      "      vf_explained_var: 0.9028230309486389\n",
      "      vf_loss: 52.69879150390625\n",
      "    sample_time_ms: 18275.817\n",
      "    update_time_ms: 5.417\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.781827109758282\n",
      "  time_since_restore: 10559.655358076096\n",
      "  time_this_iter_s: 21.782548666000366\n",
      "  time_total_s: 10559.655358076096\n",
      "  timestamp: 1553132374\n",
      "  timesteps_since_restore: 4790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4790000\n",
      "  training_iteration: 479\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10559 s, 479 iter, 4790000 ts, 33.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-39-56\n",
      "  done: false\n",
      "  episode_len_mean: 68.13422818791946\n",
      "  episode_reward_max: 386.2276432313205\n",
      "  episode_reward_mean: -0.5189614378903253\n",
      "  episode_reward_min: -168.75186152860164\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 58914\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.582\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 4800000\n",
      "    num_steps_trained: 4800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.634703516960144\n",
      "      kl: 0.027662748470902443\n",
      "      policy_loss: 0.00316182360984385\n",
      "      total_loss: 67.31855010986328\n",
      "      vf_explained_var: 0.8869078159332275\n",
      "      vf_loss: 67.31168365478516\n",
      "    sample_time_ms: 18299.759\n",
      "    update_time_ms: 5.396\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -0.25948071894516267\n",
      "  time_since_restore: 10581.648190498352\n",
      "  time_this_iter_s: 21.99283242225647\n",
      "  time_total_s: 10581.648190498352\n",
      "  timestamp: 1553132396\n",
      "  timesteps_since_restore: 4800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4800000\n",
      "  training_iteration: 480\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10581 s, 480 iter, 4800000 ts, -0.519 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-40-18\n",
      "  done: false\n",
      "  episode_len_mean: 71.07801418439716\n",
      "  episode_reward_max: 389.39043686995547\n",
      "  episode_reward_mean: 24.108492968193165\n",
      "  episode_reward_min: -164.67961341663838\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 59055\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.241\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 4810000\n",
      "    num_steps_trained: 4810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6034490466117859\n",
      "      kl: 0.01728849671781063\n",
      "      policy_loss: 0.0012069264193996787\n",
      "      total_loss: 70.02623748779297\n",
      "      vf_explained_var: 0.8733767867088318\n",
      "      vf_loss: 70.02272033691406\n",
      "    sample_time_ms: 18293.179\n",
      "    update_time_ms: 5.505\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.054246484096588\n",
      "  time_since_restore: 10603.93756723404\n",
      "  time_this_iter_s: 22.289376735687256\n",
      "  time_total_s: 10603.93756723404\n",
      "  timestamp: 1553132418\n",
      "  timesteps_since_restore: 4810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4810000\n",
      "  training_iteration: 481\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10603 s, 481 iter, 4810000 ts, 24.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-40-41\n",
      "  done: false\n",
      "  episode_len_mean: 70.50714285714285\n",
      "  episode_reward_max: 383.7382563646141\n",
      "  episode_reward_mean: 23.214040374503092\n",
      "  episode_reward_min: -166.79453305467604\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 59195\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.498\n",
      "    load_time_ms: 1.5\n",
      "    num_steps_sampled: 4820000\n",
      "    num_steps_trained: 4820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6213334202766418\n",
      "      kl: 0.017418403178453445\n",
      "      policy_loss: 0.001818469725549221\n",
      "      total_loss: 61.60834884643555\n",
      "      vf_explained_var: 0.8879930377006531\n",
      "      vf_loss: 61.604190826416016\n",
      "    sample_time_ms: 18290.509\n",
      "    update_time_ms: 5.504\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.607020187251543\n",
      "  time_since_restore: 10626.30717921257\n",
      "  time_this_iter_s: 22.369611978530884\n",
      "  time_total_s: 10626.30717921257\n",
      "  timestamp: 1553132441\n",
      "  timesteps_since_restore: 4820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4820000\n",
      "  training_iteration: 482\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10626 s, 482 iter, 4820000 ts, 23.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-41-03\n",
      "  done: false\n",
      "  episode_len_mean: 73.96323529411765\n",
      "  episode_reward_max: 385.13164276572337\n",
      "  episode_reward_mean: 41.80197698600638\n",
      "  episode_reward_min: -168.77738998326302\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 59331\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.699\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 4830000\n",
      "    num_steps_trained: 4830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6054415702819824\n",
      "      kl: 0.022084364667534828\n",
      "      policy_loss: 0.003624772885814309\n",
      "      total_loss: 61.393409729003906\n",
      "      vf_explained_var: 0.882748544216156\n",
      "      vf_loss: 61.38683319091797\n",
      "    sample_time_ms: 18267.659\n",
      "    update_time_ms: 5.615\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.900988493003194\n",
      "  time_since_restore: 10648.43190073967\n",
      "  time_this_iter_s: 22.12472152709961\n",
      "  time_total_s: 10648.43190073967\n",
      "  timestamp: 1553132463\n",
      "  timesteps_since_restore: 4830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4830000\n",
      "  training_iteration: 483\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10648 s, 483 iter, 4830000 ts, 41.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-41-25\n",
      "  done: false\n",
      "  episode_len_mean: 71.87050359712231\n",
      "  episode_reward_max: 387.05099959465156\n",
      "  episode_reward_mean: 30.026550345130595\n",
      "  episode_reward_min: -166.84111976167202\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 59470\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.301\n",
      "    load_time_ms: 1.392\n",
      "    num_steps_sampled: 4840000\n",
      "    num_steps_trained: 4840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6131794452667236\n",
      "      kl: 0.01641317456960678\n",
      "      policy_loss: 0.005049742758274078\n",
      "      total_loss: 52.2442512512207\n",
      "      vf_explained_var: 0.904510498046875\n",
      "      vf_loss: 52.23699951171875\n",
      "    sample_time_ms: 18287.153\n",
      "    update_time_ms: 5.509\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.01327517256529\n",
      "  time_since_restore: 10670.304584980011\n",
      "  time_this_iter_s: 21.872684240341187\n",
      "  time_total_s: 10670.304584980011\n",
      "  timestamp: 1553132485\n",
      "  timesteps_since_restore: 4840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4840000\n",
      "  training_iteration: 484\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10670 s, 484 iter, 4840000 ts, 30 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-41-46\n",
      "  done: false\n",
      "  episode_len_mean: 73.91176470588235\n",
      "  episode_reward_max: 389.30770668845383\n",
      "  episode_reward_mean: 40.09776196446755\n",
      "  episode_reward_min: -166.72918106218816\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 59606\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.999\n",
      "    load_time_ms: 1.398\n",
      "    num_steps_sampled: 4850000\n",
      "    num_steps_trained: 4850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6119078397750854\n",
      "      kl: 0.022804085165262222\n",
      "      policy_loss: 0.004490281455218792\n",
      "      total_loss: 54.04750061035156\n",
      "      vf_explained_var: 0.896722137928009\n",
      "      vf_loss: 54.03995895385742\n",
      "    sample_time_ms: 18238.06\n",
      "    update_time_ms: 5.53\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.048880982233776\n",
      "  time_since_restore: 10691.781409740448\n",
      "  time_this_iter_s: 21.47682476043701\n",
      "  time_total_s: 10691.781409740448\n",
      "  timestamp: 1553132506\n",
      "  timesteps_since_restore: 4850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4850000\n",
      "  training_iteration: 485\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10691 s, 485 iter, 4850000 ts, 40.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-42-08\n",
      "  done: false\n",
      "  episode_len_mean: 70.65\n",
      "  episode_reward_max: 387.9332747834844\n",
      "  episode_reward_mean: 24.60187585993449\n",
      "  episode_reward_min: -167.06633143207074\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 59746\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.466\n",
      "    load_time_ms: 1.391\n",
      "    num_steps_sampled: 4860000\n",
      "    num_steps_trained: 4860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6208969950675964\n",
      "      kl: 0.018380718305706978\n",
      "      policy_loss: 0.003658524714410305\n",
      "      total_loss: 51.559444427490234\n",
      "      vf_explained_var: 0.9065866470336914\n",
      "      vf_loss: 51.553321838378906\n",
      "    sample_time_ms: 18167.112\n",
      "    update_time_ms: 5.687\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.300937929967246\n",
      "  time_since_restore: 10713.058739185333\n",
      "  time_this_iter_s: 21.277329444885254\n",
      "  time_total_s: 10713.058739185333\n",
      "  timestamp: 1553132528\n",
      "  timesteps_since_restore: 4860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4860000\n",
      "  training_iteration: 486\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10713 s, 486 iter, 4860000 ts, 24.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-42-29\n",
      "  done: false\n",
      "  episode_len_mean: 73.9051094890511\n",
      "  episode_reward_max: 390.2938872759902\n",
      "  episode_reward_mean: 46.175248472198035\n",
      "  episode_reward_min: -167.03639320894717\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 59883\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.389\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 4870000\n",
      "    num_steps_trained: 4870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5905147194862366\n",
      "      kl: 0.022214427590370178\n",
      "      policy_loss: 0.0045057786628603935\n",
      "      total_loss: 54.875457763671875\n",
      "      vf_explained_var: 0.8958038687705994\n",
      "      vf_loss: 54.867977142333984\n",
      "    sample_time_ms: 18168.108\n",
      "    update_time_ms: 5.768\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.087624236099018\n",
      "  time_since_restore: 10734.768981456757\n",
      "  time_this_iter_s: 21.71024227142334\n",
      "  time_total_s: 10734.768981456757\n",
      "  timestamp: 1553132549\n",
      "  timesteps_since_restore: 4870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4870000\n",
      "  training_iteration: 487\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10734 s, 487 iter, 4870000 ts, 46.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-42-51\n",
      "  done: false\n",
      "  episode_len_mean: 73.43382352941177\n",
      "  episode_reward_max: 385.53101694198193\n",
      "  episode_reward_mean: 37.05505052642556\n",
      "  episode_reward_min: -167.2820392508769\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 60019\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.851\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 4880000\n",
      "    num_steps_trained: 4880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6193522810935974\n",
      "      kl: 0.025571579113602638\n",
      "      policy_loss: 0.005390486214309931\n",
      "      total_loss: 61.554473876953125\n",
      "      vf_explained_var: 0.8838760256767273\n",
      "      vf_loss: 61.54566192626953\n",
      "    sample_time_ms: 18145.76\n",
      "    update_time_ms: 5.423\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.527525263212777\n",
      "  time_since_restore: 10756.565841674805\n",
      "  time_this_iter_s: 21.796860218048096\n",
      "  time_total_s: 10756.565841674805\n",
      "  timestamp: 1553132571\n",
      "  timesteps_since_restore: 4880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4880000\n",
      "  training_iteration: 488\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10756 s, 488 iter, 4880000 ts, 37.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-43-13\n",
      "  done: false\n",
      "  episode_len_mean: 76.0\n",
      "  episode_reward_max: 386.11701281281404\n",
      "  episode_reward_mean: 57.63797185548343\n",
      "  episode_reward_min: -166.7685757069254\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 60149\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.574\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 4890000\n",
      "    num_steps_trained: 4890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5808920860290527\n",
      "      kl: 0.01975700445473194\n",
      "      policy_loss: 0.0035352855920791626\n",
      "      total_loss: 57.63387680053711\n",
      "      vf_explained_var: 0.8830819725990295\n",
      "      vf_loss: 57.62769317626953\n",
      "    sample_time_ms: 18119.356\n",
      "    update_time_ms: 5.792\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.818985927741707\n",
      "  time_since_restore: 10778.285057067871\n",
      "  time_this_iter_s: 21.719215393066406\n",
      "  time_total_s: 10778.285057067871\n",
      "  timestamp: 1553132593\n",
      "  timesteps_since_restore: 4890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4890000\n",
      "  training_iteration: 489\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10778 s, 489 iter, 4890000 ts, 57.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-43-34\n",
      "  done: false\n",
      "  episode_len_mean: 68.73287671232876\n",
      "  episode_reward_max: 386.6406223684348\n",
      "  episode_reward_mean: 8.309459356387903\n",
      "  episode_reward_min: -164.74989497789383\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 60295\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.243\n",
      "    load_time_ms: 1.401\n",
      "    num_steps_sampled: 4900000\n",
      "    num_steps_trained: 4900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6427303552627563\n",
      "      kl: 0.027200499549508095\n",
      "      policy_loss: 0.006330435164272785\n",
      "      total_loss: 60.42992401123047\n",
      "      vf_explained_var: 0.8938337564468384\n",
      "      vf_loss: 60.419960021972656\n",
      "    sample_time_ms: 18044.18\n",
      "    update_time_ms: 5.751\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 4.154729678193951\n",
      "  time_since_restore: 10799.550325393677\n",
      "  time_this_iter_s: 21.265268325805664\n",
      "  time_total_s: 10799.550325393677\n",
      "  timestamp: 1553132614\n",
      "  timesteps_since_restore: 4900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4900000\n",
      "  training_iteration: 490\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10799 s, 490 iter, 4900000 ts, 8.31 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-43-56\n",
      "  done: false\n",
      "  episode_len_mean: 73.50735294117646\n",
      "  episode_reward_max: 386.6195651023372\n",
      "  episode_reward_mean: 42.31013818607233\n",
      "  episode_reward_min: -168.72520603772642\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 60431\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.674\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 4910000\n",
      "    num_steps_trained: 4910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6062822341918945\n",
      "      kl: 0.01661902293562889\n",
      "      policy_loss: 0.0023409638088196516\n",
      "      total_loss: 43.61623001098633\n",
      "      vf_explained_var: 0.9171775579452515\n",
      "      vf_loss: 43.61166763305664\n",
      "    sample_time_ms: 17985.27\n",
      "    update_time_ms: 5.877\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.155069093036158\n",
      "  time_since_restore: 10821.2219851017\n",
      "  time_this_iter_s: 21.67165970802307\n",
      "  time_total_s: 10821.2219851017\n",
      "  timestamp: 1553132636\n",
      "  timesteps_since_restore: 4910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4910000\n",
      "  training_iteration: 491\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10821 s, 491 iter, 4910000 ts, 42.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-44-18\n",
      "  done: false\n",
      "  episode_len_mean: 72.28571428571429\n",
      "  episode_reward_max: 392.7957300265691\n",
      "  episode_reward_mean: 35.307839839205634\n",
      "  episode_reward_min: -166.90019594129564\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 60571\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.022\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 4920000\n",
      "    num_steps_trained: 4920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.613220751285553\n",
      "      kl: 0.037064071744680405\n",
      "      policy_loss: 0.009650154039263725\n",
      "      total_loss: 64.1341781616211\n",
      "      vf_explained_var: 0.8798652291297913\n",
      "      vf_loss: 64.11956024169922\n",
      "    sample_time_ms: 17951.744\n",
      "    update_time_ms: 5.841\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.653919919602817\n",
      "  time_since_restore: 10843.159947156906\n",
      "  time_this_iter_s: 21.9379620552063\n",
      "  time_total_s: 10843.159947156906\n",
      "  timestamp: 1553132658\n",
      "  timesteps_since_restore: 4920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4920000\n",
      "  training_iteration: 492\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10843 s, 492 iter, 4920000 ts, 35.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-44-40\n",
      "  done: false\n",
      "  episode_len_mean: 67.9041095890411\n",
      "  episode_reward_max: 388.0730532833692\n",
      "  episode_reward_mean: -0.8070401120182135\n",
      "  episode_reward_min: -166.8062361023092\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 60717\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.429\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 4930000\n",
      "    num_steps_trained: 4930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6370700001716614\n",
      "      kl: 0.015769897028803825\n",
      "      policy_loss: 0.004383672494441271\n",
      "      total_loss: 58.44203186035156\n",
      "      vf_explained_var: 0.9005418419837952\n",
      "      vf_loss: 58.4355354309082\n",
      "    sample_time_ms: 17939.674\n",
      "    update_time_ms: 5.73\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -0.40352005600911256\n",
      "  time_since_restore: 10865.259148359299\n",
      "  time_this_iter_s: 22.099201202392578\n",
      "  time_total_s: 10865.259148359299\n",
      "  timestamp: 1553132680\n",
      "  timesteps_since_restore: 4930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4930000\n",
      "  training_iteration: 493\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10865 s, 493 iter, 4930000 ts, -0.807 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-45-02\n",
      "  done: false\n",
      "  episode_len_mean: 69.61805555555556\n",
      "  episode_reward_max: 388.0750278768928\n",
      "  episode_reward_mean: 18.769030107537553\n",
      "  episode_reward_min: -165.35558254918098\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 60861\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.24\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 4940000\n",
      "    num_steps_trained: 4940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6183599829673767\n",
      "      kl: 0.0289626307785511\n",
      "      policy_loss: 0.006058236584067345\n",
      "      total_loss: 60.35670852661133\n",
      "      vf_explained_var: 0.8942417502403259\n",
      "      vf_loss: 60.34677505493164\n",
      "    sample_time_ms: 17887.821\n",
      "    update_time_ms: 5.705\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.384515053768778\n",
      "  time_since_restore: 10886.618393421173\n",
      "  time_this_iter_s: 21.35924506187439\n",
      "  time_total_s: 10886.618393421173\n",
      "  timestamp: 1553132702\n",
      "  timesteps_since_restore: 4940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4940000\n",
      "  training_iteration: 494\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10886 s, 494 iter, 4940000 ts, 18.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-45-23\n",
      "  done: false\n",
      "  episode_len_mean: 71.37142857142857\n",
      "  episode_reward_max: 386.2228030198849\n",
      "  episode_reward_mean: 22.96488656371222\n",
      "  episode_reward_min: -164.69101587995527\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 61001\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.74\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 4950000\n",
      "    num_steps_trained: 4950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6019389033317566\n",
      "      kl: 0.02601976878941059\n",
      "      policy_loss: 0.0037224208936095238\n",
      "      total_loss: 66.17276000976562\n",
      "      vf_explained_var: 0.8775410056114197\n",
      "      vf_loss: 66.1655502319336\n",
      "    sample_time_ms: 17912.404\n",
      "    update_time_ms: 5.795\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.482443281856114\n",
      "  time_since_restore: 10908.297393798828\n",
      "  time_this_iter_s: 21.67900037765503\n",
      "  time_total_s: 10908.297393798828\n",
      "  timestamp: 1553132723\n",
      "  timesteps_since_restore: 4950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4950000\n",
      "  training_iteration: 495\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10908 s, 495 iter, 4950000 ts, 23 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-45-46\n",
      "  done: false\n",
      "  episode_len_mean: 69.61805555555556\n",
      "  episode_reward_max: 387.62219180892225\n",
      "  episode_reward_mean: 10.328013801096777\n",
      "  episode_reward_min: -166.83952356621265\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 61145\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.865\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 4960000\n",
      "    num_steps_trained: 4960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5993769764900208\n",
      "      kl: 0.022676171734929085\n",
      "      policy_loss: 0.00191589689347893\n",
      "      total_loss: 50.100379943847656\n",
      "      vf_explained_var: 0.9122992157936096\n",
      "      vf_loss: 50.095428466796875\n",
      "    sample_time_ms: 18001.397\n",
      "    update_time_ms: 5.797\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 5.16400690054838\n",
      "  time_since_restore: 10930.480331659317\n",
      "  time_this_iter_s: 22.18293786048889\n",
      "  time_total_s: 10930.480331659317\n",
      "  timestamp: 1553132746\n",
      "  timesteps_since_restore: 4960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4960000\n",
      "  training_iteration: 496\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10930 s, 496 iter, 4960000 ts, 10.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-46-08\n",
      "  done: false\n",
      "  episode_len_mean: 70.94326241134752\n",
      "  episode_reward_max: 389.59068487176734\n",
      "  episode_reward_mean: 25.824351364625326\n",
      "  episode_reward_min: -164.68168055674076\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 61286\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.415\n",
      "    load_time_ms: 1.441\n",
      "    num_steps_sampled: 4970000\n",
      "    num_steps_trained: 4970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6161227822303772\n",
      "      kl: 0.020604511722922325\n",
      "      policy_loss: 0.002509630750864744\n",
      "      total_loss: 63.42678451538086\n",
      "      vf_explained_var: 0.883367657661438\n",
      "      vf_loss: 63.421512603759766\n",
      "    sample_time_ms: 18052.134\n",
      "    update_time_ms: 5.805\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.912175682312663\n",
      "  time_since_restore: 10952.690265655518\n",
      "  time_this_iter_s: 22.20993399620056\n",
      "  time_total_s: 10952.690265655518\n",
      "  timestamp: 1553132768\n",
      "  timesteps_since_restore: 4970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4970000\n",
      "  training_iteration: 497\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10952 s, 497 iter, 4970000 ts, 25.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-46-30\n",
      "  done: false\n",
      "  episode_len_mean: 71.59285714285714\n",
      "  episode_reward_max: 386.5165938681594\n",
      "  episode_reward_mean: 34.05377857277197\n",
      "  episode_reward_min: -166.77734662088395\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 61426\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.905\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 4980000\n",
      "    num_steps_trained: 4980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6098211407661438\n",
      "      kl: 0.026468835771083832\n",
      "      policy_loss: 0.005004000384360552\n",
      "      total_loss: 52.91721725463867\n",
      "      vf_explained_var: 0.9046321511268616\n",
      "      vf_loss: 52.90867233276367\n",
      "    sample_time_ms: 18113.87\n",
      "    update_time_ms: 5.832\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.026889286385984\n",
      "  time_since_restore: 10975.112322568893\n",
      "  time_this_iter_s: 22.422056913375854\n",
      "  time_total_s: 10975.112322568893\n",
      "  timestamp: 1553132790\n",
      "  timesteps_since_restore: 4980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4980000\n",
      "  training_iteration: 498\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10975 s, 498 iter, 4980000 ts, 34.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-46-52\n",
      "  done: false\n",
      "  episode_len_mean: 71.66906474820144\n",
      "  episode_reward_max: 387.72355416415115\n",
      "  episode_reward_mean: 28.715103320443642\n",
      "  episode_reward_min: -163.8493983167672\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 61565\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.406\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 4990000\n",
      "    num_steps_trained: 4990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5966092348098755\n",
      "      kl: 0.020931215956807137\n",
      "      policy_loss: 0.0030276828911155462\n",
      "      total_loss: 61.625675201416016\n",
      "      vf_explained_var: 0.8868618607521057\n",
      "      vf_loss: 61.61984634399414\n",
      "    sample_time_ms: 18136.688\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.357551660221821\n",
      "  time_since_restore: 10996.848520040512\n",
      "  time_this_iter_s: 21.736197471618652\n",
      "  time_total_s: 10996.848520040512\n",
      "  timestamp: 1553132812\n",
      "  timesteps_since_restore: 4990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4990000\n",
      "  training_iteration: 499\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 10996 s, 499 iter, 4990000 ts, 28.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-47-14\n",
      "  done: false\n",
      "  episode_len_mean: 71.66428571428571\n",
      "  episode_reward_max: 385.68876474642343\n",
      "  episode_reward_mean: 22.826485098644916\n",
      "  episode_reward_min: -166.85301765176297\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 61705\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.075\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 5000000\n",
      "    num_steps_trained: 5000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5925413370132446\n",
      "      kl: 0.021525032818317413\n",
      "      policy_loss: 0.005681017879396677\n",
      "      total_loss: 62.062198638916016\n",
      "      vf_explained_var: 0.8877500891685486\n",
      "      vf_loss: 62.05363464355469\n",
      "    sample_time_ms: 18236.004\n",
      "    update_time_ms: 5.442\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.413242549322451\n",
      "  time_since_restore: 11019.10273385048\n",
      "  time_this_iter_s: 22.25421380996704\n",
      "  time_total_s: 11019.10273385048\n",
      "  timestamp: 1553132834\n",
      "  timesteps_since_restore: 5000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5000000\n",
      "  training_iteration: 500\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11019 s, 500 iter, 5000000 ts, 22.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-47-36\n",
      "  done: false\n",
      "  episode_len_mean: 71.69064748201438\n",
      "  episode_reward_max: 387.68396135810394\n",
      "  episode_reward_mean: 29.012771776013142\n",
      "  episode_reward_min: -166.9081399355793\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 61844\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.334\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 5010000\n",
      "    num_steps_trained: 5010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5892264246940613\n",
      "      kl: 0.01985485479235649\n",
      "      policy_loss: 0.005260426085442305\n",
      "      total_loss: 61.941532135009766\n",
      "      vf_explained_var: 0.8865284323692322\n",
      "      vf_loss: 61.93361282348633\n",
      "    sample_time_ms: 18254.585\n",
      "    update_time_ms: 5.205\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.506385888006575\n",
      "  time_since_restore: 11040.952336072922\n",
      "  time_this_iter_s: 21.849602222442627\n",
      "  time_total_s: 11040.952336072922\n",
      "  timestamp: 1553132856\n",
      "  timesteps_since_restore: 5010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5010000\n",
      "  training_iteration: 501\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11040 s, 501 iter, 5010000 ts, 29 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-47-59\n",
      "  done: false\n",
      "  episode_len_mean: 75.2406015037594\n",
      "  episode_reward_max: 387.84080835934424\n",
      "  episode_reward_mean: 51.40703384099732\n",
      "  episode_reward_min: -160.50094039114953\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 61977\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.005\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 5020000\n",
      "    num_steps_trained: 5020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.582756519317627\n",
      "      kl: 0.026014037430286407\n",
      "      policy_loss: 0.005549097433686256\n",
      "      total_loss: 62.65079879760742\n",
      "      vf_explained_var: 0.8773449659347534\n",
      "      vf_loss: 62.64175796508789\n",
      "    sample_time_ms: 18301.749\n",
      "    update_time_ms: 5.252\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.703516920498664\n",
      "  time_since_restore: 11063.369769096375\n",
      "  time_this_iter_s: 22.41743302345276\n",
      "  time_total_s: 11063.369769096375\n",
      "  timestamp: 1553132879\n",
      "  timesteps_since_restore: 5020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5020000\n",
      "  training_iteration: 502\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11063 s, 502 iter, 5020000 ts, 51.4 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-48-20\n",
      "  done: false\n",
      "  episode_len_mean: 72.86029411764706\n",
      "  episode_reward_max: 386.5123428221352\n",
      "  episode_reward_mean: 35.596480768119996\n",
      "  episode_reward_min: -166.89806855103015\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 62113\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.241\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 5030000\n",
      "    num_steps_trained: 5030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5967482328414917\n",
      "      kl: 0.020129982382059097\n",
      "      policy_loss: 0.00308609614148736\n",
      "      total_loss: 65.06221008300781\n",
      "      vf_explained_var: 0.8754522800445557\n",
      "      vf_loss: 65.05642700195312\n",
      "    sample_time_ms: 18253.46\n",
      "    update_time_ms: 5.328\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.798240384059994\n",
      "  time_since_restore: 11084.889333486557\n",
      "  time_this_iter_s: 21.519564390182495\n",
      "  time_total_s: 11084.889333486557\n",
      "  timestamp: 1553132900\n",
      "  timesteps_since_restore: 5030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5030000\n",
      "  training_iteration: 503\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11084 s, 503 iter, 5030000 ts, 35.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-48-42\n",
      "  done: false\n",
      "  episode_len_mean: 72.87050359712231\n",
      "  episode_reward_max: 386.63784801657806\n",
      "  episode_reward_mean: 32.85721048448571\n",
      "  episode_reward_min: -166.8264473141098\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 62252\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.58\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 5040000\n",
      "    num_steps_trained: 5040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.562614917755127\n",
      "      kl: 0.015806520357728004\n",
      "      policy_loss: 0.0028849767986685038\n",
      "      total_loss: 46.02756118774414\n",
      "      vf_explained_var: 0.9138990640640259\n",
      "      vf_loss: 46.022560119628906\n",
      "    sample_time_ms: 18318.345\n",
      "    update_time_ms: 5.521\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.428605242242856\n",
      "  time_since_restore: 11107.051475048065\n",
      "  time_this_iter_s: 22.16214156150818\n",
      "  time_total_s: 11107.051475048065\n",
      "  timestamp: 1553132922\n",
      "  timesteps_since_restore: 5040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5040000\n",
      "  training_iteration: 504\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11107 s, 504 iter, 5040000 ts, 32.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-49-05\n",
      "  done: false\n",
      "  episode_len_mean: 71.05035971223022\n",
      "  episode_reward_max: 390.3956015283891\n",
      "  episode_reward_mean: 25.58770859896712\n",
      "  episode_reward_min: -166.76025089046001\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 62391\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.535\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 5050000\n",
      "    num_steps_trained: 5050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5895586013793945\n",
      "      kl: 0.018604835495352745\n",
      "      policy_loss: 0.004004067741334438\n",
      "      total_loss: 56.22188186645508\n",
      "      vf_explained_var: 0.8991957306861877\n",
      "      vf_loss: 56.21538162231445\n",
      "    sample_time_ms: 18399.046\n",
      "    update_time_ms: 5.442\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.793854299483547\n",
      "  time_since_restore: 11129.595805168152\n",
      "  time_this_iter_s: 22.54433012008667\n",
      "  time_total_s: 11129.595805168152\n",
      "  timestamp: 1553132945\n",
      "  timesteps_since_restore: 5050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5050000\n",
      "  training_iteration: 505\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11129 s, 505 iter, 5050000 ts, 25.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-49-27\n",
      "  done: false\n",
      "  episode_len_mean: 71.67375886524823\n",
      "  episode_reward_max: 386.9977877604663\n",
      "  episode_reward_mean: 28.648890608904814\n",
      "  episode_reward_min: -166.768874581542\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 62532\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.84\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 5060000\n",
      "    num_steps_trained: 5060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5710638165473938\n",
      "      kl: 0.022470660507678986\n",
      "      policy_loss: 0.003998244181275368\n",
      "      total_loss: 55.55065155029297\n",
      "      vf_explained_var: 0.8985299468040466\n",
      "      vf_loss: 55.543643951416016\n",
      "    sample_time_ms: 18420.603\n",
      "    update_time_ms: 5.199\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.324445304452402\n",
      "  time_since_restore: 11151.982597589493\n",
      "  time_this_iter_s: 22.386792421340942\n",
      "  time_total_s: 11151.982597589493\n",
      "  timestamp: 1553132967\n",
      "  timesteps_since_restore: 5060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5060000\n",
      "  training_iteration: 506\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11151 s, 506 iter, 5060000 ts, 28.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-49-50\n",
      "  done: false\n",
      "  episode_len_mean: 72.8529411764706\n",
      "  episode_reward_max: 386.47479348525144\n",
      "  episode_reward_mean: 38.324539784247335\n",
      "  episode_reward_min: -166.75589817341805\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 62668\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.717\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 5070000\n",
      "    num_steps_trained: 5070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5431002378463745\n",
      "      kl: 0.01894451677799225\n",
      "      policy_loss: 0.0037207312416285276\n",
      "      total_loss: 55.14168930053711\n",
      "      vf_explained_var: 0.8967193365097046\n",
      "      vf_loss: 55.13542175292969\n",
      "    sample_time_ms: 18453.04\n",
      "    update_time_ms: 5.15\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.162269892123664\n",
      "  time_since_restore: 11174.506791114807\n",
      "  time_this_iter_s: 22.52419352531433\n",
      "  time_total_s: 11174.506791114807\n",
      "  timestamp: 1553132990\n",
      "  timesteps_since_restore: 5070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5070000\n",
      "  training_iteration: 507\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11174 s, 507 iter, 5070000 ts, 38.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-50-12\n",
      "  done: false\n",
      "  episode_len_mean: 71.87142857142857\n",
      "  episode_reward_max: 385.966804765363\n",
      "  episode_reward_mean: 29.29115243861433\n",
      "  episode_reward_min: -167.06903830828904\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 62808\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.065\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 5080000\n",
      "    num_steps_trained: 5080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5653764009475708\n",
      "      kl: 0.015142208896577358\n",
      "      policy_loss: 0.002922794781625271\n",
      "      total_loss: 64.85784912109375\n",
      "      vf_explained_var: 0.8818271160125732\n",
      "      vf_loss: 64.85289764404297\n",
      "    sample_time_ms: 18369.87\n",
      "    update_time_ms: 5.131\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.645576219307161\n",
      "  time_since_restore: 11196.296189785004\n",
      "  time_this_iter_s: 21.789398670196533\n",
      "  time_total_s: 11196.296189785004\n",
      "  timestamp: 1553133012\n",
      "  timesteps_since_restore: 5080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5080000\n",
      "  training_iteration: 508\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11196 s, 508 iter, 5080000 ts, 29.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-50-33\n",
      "  done: false\n",
      "  episode_len_mean: 67.79054054054055\n",
      "  episode_reward_max: 385.27113837520284\n",
      "  episode_reward_mean: 1.8552062161363427\n",
      "  episode_reward_min: -168.79791877016066\n",
      "  episodes_this_iter: 148\n",
      "  episodes_total: 62956\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3725.846\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 5090000\n",
      "    num_steps_trained: 5090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5810316205024719\n",
      "      kl: 0.018301401287317276\n",
      "      policy_loss: 0.0023434124886989594\n",
      "      total_loss: 68.4156723022461\n",
      "      vf_explained_var: 0.8829516172409058\n",
      "      vf_loss: 68.41087341308594\n",
      "    sample_time_ms: 18356.262\n",
      "    update_time_ms: 4.981\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 0.9276031080681698\n",
      "  time_since_restore: 11217.91426372528\n",
      "  time_this_iter_s: 21.6180739402771\n",
      "  time_total_s: 11217.91426372528\n",
      "  timestamp: 1553133033\n",
      "  timesteps_since_restore: 5090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5090000\n",
      "  training_iteration: 509\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11217 s, 509 iter, 5090000 ts, 1.86 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-50-55\n",
      "  done: false\n",
      "  episode_len_mean: 66.84563758389261\n",
      "  episode_reward_max: 385.8668421751115\n",
      "  episode_reward_mean: -4.9665663751991245\n",
      "  episode_reward_min: -168.73228369494916\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 63105\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.919\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 5100000\n",
      "    num_steps_trained: 5100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5950472950935364\n",
      "      kl: 0.027175916358828545\n",
      "      policy_loss: 0.006642581429332495\n",
      "      total_loss: 59.71826934814453\n",
      "      vf_explained_var: 0.8985185027122498\n",
      "      vf_loss: 59.70798873901367\n",
      "    sample_time_ms: 18288.759\n",
      "    update_time_ms: 5.04\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -2.4832831875995693\n",
      "  time_since_restore: 11239.476078033447\n",
      "  time_this_iter_s: 21.561814308166504\n",
      "  time_total_s: 11239.476078033447\n",
      "  timestamp: 1553133055\n",
      "  timesteps_since_restore: 5100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5100000\n",
      "  training_iteration: 510\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11239 s, 510 iter, 5100000 ts, -4.97 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-51-17\n",
      "  done: false\n",
      "  episode_len_mean: 71.92805755395683\n",
      "  episode_reward_max: 388.5554011299981\n",
      "  episode_reward_mean: 30.66299474200249\n",
      "  episode_reward_min: -166.9731234391594\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 63244\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3725.174\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 5110000\n",
      "    num_steps_trained: 5110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5748160481452942\n",
      "      kl: 0.02925363928079605\n",
      "      policy_loss: 0.004044367931783199\n",
      "      total_loss: 58.77205276489258\n",
      "      vf_explained_var: 0.8913218379020691\n",
      "      vf_loss: 58.76409149169922\n",
      "    sample_time_ms: 18272.873\n",
      "    update_time_ms: 5.083\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.331497371001237\n",
      "  time_since_restore: 11261.179239988327\n",
      "  time_this_iter_s: 21.70316195487976\n",
      "  time_total_s: 11261.179239988327\n",
      "  timestamp: 1553133077\n",
      "  timesteps_since_restore: 5110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5110000\n",
      "  training_iteration: 511\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11261 s, 511 iter, 5110000 ts, 30.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-51-39\n",
      "  done: false\n",
      "  episode_len_mean: 71.73571428571428\n",
      "  episode_reward_max: 387.16733453002666\n",
      "  episode_reward_mean: 28.378611730871306\n",
      "  episode_reward_min: -168.79886462351323\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 63384\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.504\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 5120000\n",
      "    num_steps_trained: 5120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5726093649864197\n",
      "      kl: 0.02169552445411682\n",
      "      policy_loss: 0.0027807520236819983\n",
      "      total_loss: 64.65616607666016\n",
      "      vf_explained_var: 0.8820134401321411\n",
      "      vf_loss: 64.65047454833984\n",
      "    sample_time_ms: 18233.9\n",
      "    update_time_ms: 5.215\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.189305865435653\n",
      "  time_since_restore: 11283.320284366608\n",
      "  time_this_iter_s: 22.14104437828064\n",
      "  time_total_s: 11283.320284366608\n",
      "  timestamp: 1553133099\n",
      "  timesteps_since_restore: 5120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5120000\n",
      "  training_iteration: 512\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11283 s, 512 iter, 5120000 ts, 28.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-52-01\n",
      "  done: false\n",
      "  episode_len_mean: 70.67142857142858\n",
      "  episode_reward_max: 385.14742803495307\n",
      "  episode_reward_mean: 14.889329383457447\n",
      "  episode_reward_min: -166.79802314146997\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 63524\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3737.275\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 5130000\n",
      "    num_steps_trained: 5130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5859873294830322\n",
      "      kl: 0.01943601481616497\n",
      "      policy_loss: 0.003966060001403093\n",
      "      total_loss: 75.47682189941406\n",
      "      vf_explained_var: 0.8616212010383606\n",
      "      vf_loss: 75.47024536132812\n",
      "    sample_time_ms: 18306.106\n",
      "    update_time_ms: 5.072\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.444664691728719\n",
      "  time_since_restore: 11305.568352937698\n",
      "  time_this_iter_s: 22.2480685710907\n",
      "  time_total_s: 11305.568352937698\n",
      "  timestamp: 1553133121\n",
      "  timesteps_since_restore: 5130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5130000\n",
      "  training_iteration: 513\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11305 s, 513 iter, 5130000 ts, 14.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-52-24\n",
      "  done: false\n",
      "  episode_len_mean: 72.15\n",
      "  episode_reward_max: 388.14367142201047\n",
      "  episode_reward_mean: 27.815080015688736\n",
      "  episode_reward_min: -168.81619456204413\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 63664\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.047\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 5140000\n",
      "    num_steps_trained: 5140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5853085517883301\n",
      "      kl: 0.019758369773626328\n",
      "      policy_loss: 0.0036170894745737314\n",
      "      total_loss: 54.144630432128906\n",
      "      vf_explained_var: 0.900146484375\n",
      "      vf_loss: 54.138370513916016\n",
      "    sample_time_ms: 18398.808\n",
      "    update_time_ms: 5.066\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 13.90754000784436\n",
      "  time_since_restore: 11328.495562314987\n",
      "  time_this_iter_s: 22.92720937728882\n",
      "  time_total_s: 11328.495562314987\n",
      "  timestamp: 1553133144\n",
      "  timesteps_since_restore: 5140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5140000\n",
      "  training_iteration: 514\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11328 s, 514 iter, 5140000 ts, 27.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-52-46\n",
      "  done: false\n",
      "  episode_len_mean: 72.3913043478261\n",
      "  episode_reward_max: 387.0474106565068\n",
      "  episode_reward_mean: 36.99264192684059\n",
      "  episode_reward_min: -166.83644152494907\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 63802\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.317\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 5150000\n",
      "    num_steps_trained: 5150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5853390097618103\n",
      "      kl: 0.022558704018592834\n",
      "      policy_loss: 0.004576473496854305\n",
      "      total_loss: 56.07004165649414\n",
      "      vf_explained_var: 0.893360435962677\n",
      "      vf_loss: 56.06245803833008\n",
      "    sample_time_ms: 18335.552\n",
      "    update_time_ms: 5.013\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.49632096342029\n",
      "  time_since_restore: 11350.362273454666\n",
      "  time_this_iter_s: 21.866711139678955\n",
      "  time_total_s: 11350.362273454666\n",
      "  timestamp: 1553133166\n",
      "  timesteps_since_restore: 5150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5150000\n",
      "  training_iteration: 515\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11350 s, 515 iter, 5150000 ts, 37 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-53-09\n",
      "  done: false\n",
      "  episode_len_mean: 71.32857142857142\n",
      "  episode_reward_max: 387.0977912003234\n",
      "  episode_reward_mean: 25.57877927704601\n",
      "  episode_reward_min: -166.76014382585527\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 63942\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.466\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 5160000\n",
      "    num_steps_trained: 5160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5800116062164307\n",
      "      kl: 0.018027281388640404\n",
      "      policy_loss: 0.002856323029845953\n",
      "      total_loss: 57.52139663696289\n",
      "      vf_explained_var: 0.8951739072799683\n",
      "      vf_loss: 57.5161247253418\n",
      "    sample_time_ms: 18326.163\n",
      "    update_time_ms: 5.093\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.78938963852301\n",
      "  time_since_restore: 11372.674540758133\n",
      "  time_this_iter_s: 22.312267303466797\n",
      "  time_total_s: 11372.674540758133\n",
      "  timestamp: 1553133189\n",
      "  timesteps_since_restore: 5160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5160000\n",
      "  training_iteration: 516\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11372 s, 516 iter, 5160000 ts, 25.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-53-30\n",
      "  done: false\n",
      "  episode_len_mean: 72.6231884057971\n",
      "  episode_reward_max: 385.32637236217147\n",
      "  episode_reward_mean: 32.43895953927817\n",
      "  episode_reward_min: -166.90413315555097\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 64080\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.5\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 5170000\n",
      "    num_steps_trained: 5170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5780373811721802\n",
      "      kl: 0.01887565478682518\n",
      "      policy_loss: 0.002647720044478774\n",
      "      total_loss: 60.59545135498047\n",
      "      vf_explained_var: 0.8850581645965576\n",
      "      vf_loss: 60.590274810791016\n",
      "    sample_time_ms: 18231.867\n",
      "    update_time_ms: 5.083\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.219479769639083\n",
      "  time_since_restore: 11394.275158166885\n",
      "  time_this_iter_s: 21.60061740875244\n",
      "  time_total_s: 11394.275158166885\n",
      "  timestamp: 1553133210\n",
      "  timesteps_since_restore: 5170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5170000\n",
      "  training_iteration: 517\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11394 s, 517 iter, 5170000 ts, 32.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-53-52\n",
      "  done: false\n",
      "  episode_len_mean: 70.31914893617021\n",
      "  episode_reward_max: 388.26670349545174\n",
      "  episode_reward_mean: 23.109751901815056\n",
      "  episode_reward_min: -168.9724067877197\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 64221\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.293\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 5180000\n",
      "    num_steps_trained: 5180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6030229330062866\n",
      "      kl: 0.02048674039542675\n",
      "      policy_loss: 0.003840399906039238\n",
      "      total_loss: 66.62566375732422\n",
      "      vf_explained_var: 0.8807553052902222\n",
      "      vf_loss: 66.61907958984375\n",
      "    sample_time_ms: 18277.551\n",
      "    update_time_ms: 5.067\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.554875950907523\n",
      "  time_since_restore: 11416.304542779922\n",
      "  time_this_iter_s: 22.02938461303711\n",
      "  time_total_s: 11416.304542779922\n",
      "  timestamp: 1553133232\n",
      "  timesteps_since_restore: 5180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5180000\n",
      "  training_iteration: 518\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11416 s, 518 iter, 5180000 ts, 23.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-54-14\n",
      "  done: false\n",
      "  episode_len_mean: 74.125\n",
      "  episode_reward_max: 388.54109990817426\n",
      "  episode_reward_mean: 46.51672211659067\n",
      "  episode_reward_min: -163.99387896462918\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 64357\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.272\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 5190000\n",
      "    num_steps_trained: 5190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5583502650260925\n",
      "      kl: 0.015491616912186146\n",
      "      policy_loss: 0.0029627601616084576\n",
      "      total_loss: 54.37173080444336\n",
      "      vf_explained_var: 0.896242082118988\n",
      "      vf_loss: 54.36669158935547\n",
      "    sample_time_ms: 18305.081\n",
      "    update_time_ms: 5.323\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.258361058295325\n",
      "  time_since_restore: 11438.209509849548\n",
      "  time_this_iter_s: 21.904967069625854\n",
      "  time_total_s: 11438.209509849548\n",
      "  timestamp: 1553133254\n",
      "  timesteps_since_restore: 5190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5190000\n",
      "  training_iteration: 519\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11438 s, 519 iter, 5190000 ts, 46.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-54-36\n",
      "  done: false\n",
      "  episode_len_mean: 70.14084507042253\n",
      "  episode_reward_max: 387.2127543722523\n",
      "  episode_reward_mean: 21.716736262287945\n",
      "  episode_reward_min: -167.01599941798688\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 64499\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.762\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 5200000\n",
      "    num_steps_trained: 5200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6253242492675781\n",
      "      kl: 0.018328119069337845\n",
      "      policy_loss: 0.0008869002922438085\n",
      "      total_loss: 69.50414276123047\n",
      "      vf_explained_var: 0.8766908645629883\n",
      "      vf_loss: 69.50080108642578\n",
      "    sample_time_ms: 18358.344\n",
      "    update_time_ms: 5.365\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 10.858368131143973\n",
      "  time_since_restore: 11460.310945034027\n",
      "  time_this_iter_s: 22.10143518447876\n",
      "  time_total_s: 11460.310945034027\n",
      "  timestamp: 1553133276\n",
      "  timesteps_since_restore: 5200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5200000\n",
      "  training_iteration: 520\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11460 s, 520 iter, 5200000 ts, 21.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-54-58\n",
      "  done: false\n",
      "  episode_len_mean: 72.56521739130434\n",
      "  episode_reward_max: 384.6107728184286\n",
      "  episode_reward_mean: 33.67185043549178\n",
      "  episode_reward_min: -165.73353157630206\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 64637\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.2\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 5210000\n",
      "    num_steps_trained: 5210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5674336552619934\n",
      "      kl: 0.022277064621448517\n",
      "      policy_loss: 0.00468301260843873\n",
      "      total_loss: 50.85378646850586\n",
      "      vf_explained_var: 0.9041673541069031\n",
      "      vf_loss: 50.84612274169922\n",
      "    sample_time_ms: 18348.637\n",
      "    update_time_ms: 5.4\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.83592521774589\n",
      "  time_since_restore: 11481.900504112244\n",
      "  time_this_iter_s: 21.589559078216553\n",
      "  time_total_s: 11481.900504112244\n",
      "  timestamp: 1553133298\n",
      "  timesteps_since_restore: 5210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5210000\n",
      "  training_iteration: 521\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11481 s, 521 iter, 5210000 ts, 33.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 69.875\n",
      "  episode_reward_max: 385.27312303405546\n",
      "  episode_reward_mean: 15.055070918389301\n",
      "  episode_reward_min: -168.75997063919544\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 64781\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.463\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 5220000\n",
      "    num_steps_trained: 5220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.60770583152771\n",
      "      kl: 0.01914803870022297\n",
      "      policy_loss: 0.0027624336071312428\n",
      "      total_loss: 56.13024139404297\n",
      "      vf_explained_var: 0.9046401977539062\n",
      "      vf_loss: 56.12491226196289\n",
      "    sample_time_ms: 18377.781\n",
      "    update_time_ms: 5.228\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 7.527535459194651\n",
      "  time_since_restore: 11504.19370007515\n",
      "  time_this_iter_s: 22.293195962905884\n",
      "  time_total_s: 11504.19370007515\n",
      "  timestamp: 1553133320\n",
      "  timesteps_since_restore: 5220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5220000\n",
      "  training_iteration: 522\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11504 s, 522 iter, 5220000 ts, 15.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 77.25581395348837\n",
      "  episode_reward_max: 386.95225702517604\n",
      "  episode_reward_mean: 74.68704267710291\n",
      "  episode_reward_min: -167.09816263588905\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 64910\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.766\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 5230000\n",
      "    num_steps_trained: 5230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5790522694587708\n",
      "      kl: 0.015825586393475533\n",
      "      policy_loss: 0.002619748702272773\n",
      "      total_loss: 47.589839935302734\n",
      "      vf_explained_var: 0.9009191989898682\n",
      "      vf_loss: 47.58509826660156\n",
      "    sample_time_ms: 18353.506\n",
      "    update_time_ms: 5.738\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.343521338551454\n",
      "  time_since_restore: 11526.356367349625\n",
      "  time_this_iter_s: 22.162667274475098\n",
      "  time_total_s: 11526.356367349625\n",
      "  timestamp: 1553133343\n",
      "  timesteps_since_restore: 5230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5230000\n",
      "  training_iteration: 523\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11526 s, 523 iter, 5230000 ts, 74.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-56-04\n",
      "  done: false\n",
      "  episode_len_mean: 72.34057971014492\n",
      "  episode_reward_max: 387.3742900994089\n",
      "  episode_reward_mean: 34.84621920465002\n",
      "  episode_reward_min: -166.86868187734126\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 65048\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.108\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 5240000\n",
      "    num_steps_trained: 5240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.576720654964447\n",
      "      kl: 0.02839626930654049\n",
      "      policy_loss: 0.005716891027987003\n",
      "      total_loss: 49.49812316894531\n",
      "      vf_explained_var: 0.9078858494758606\n",
      "      vf_loss: 49.48860549926758\n",
      "    sample_time_ms: 18245.751\n",
      "    update_time_ms: 5.526\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.42310960232501\n",
      "  time_since_restore: 11548.217175483704\n",
      "  time_this_iter_s: 21.86080813407898\n",
      "  time_total_s: 11548.217175483704\n",
      "  timestamp: 1553133364\n",
      "  timesteps_since_restore: 5240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5240000\n",
      "  training_iteration: 524\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11548 s, 524 iter, 5240000 ts, 34.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-56-27\n",
      "  done: false\n",
      "  episode_len_mean: 71.69565217391305\n",
      "  episode_reward_max: 387.45730063672283\n",
      "  episode_reward_mean: 32.75799770104094\n",
      "  episode_reward_min: -166.80717325982093\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 65186\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.655\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 5250000\n",
      "    num_steps_trained: 5250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5909813046455383\n",
      "      kl: 0.01766931638121605\n",
      "      policy_loss: 0.002166913589462638\n",
      "      total_loss: 56.24252700805664\n",
      "      vf_explained_var: 0.8979139924049377\n",
      "      vf_loss: 56.23799514770508\n",
      "    sample_time_ms: 18280.982\n",
      "    update_time_ms: 5.603\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.378998850520475\n",
      "  time_since_restore: 11570.441291093826\n",
      "  time_this_iter_s: 22.22411561012268\n",
      "  time_total_s: 11570.441291093826\n",
      "  timestamp: 1553133387\n",
      "  timesteps_since_restore: 5250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5250000\n",
      "  training_iteration: 525\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11570 s, 525 iter, 5250000 ts, 32.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-56-48\n",
      "  done: false\n",
      "  episode_len_mean: 74.71851851851852\n",
      "  episode_reward_max: 386.59781173522464\n",
      "  episode_reward_mean: 44.41070652701245\n",
      "  episode_reward_min: -164.73536662682534\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 65321\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.208\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 5260000\n",
      "    num_steps_trained: 5260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5583691000938416\n",
      "      kl: 0.021677063778042793\n",
      "      policy_loss: 0.004688914865255356\n",
      "      total_loss: 53.422306060791016\n",
      "      vf_explained_var: 0.8973609805107117\n",
      "      vf_loss: 53.41471862792969\n",
      "    sample_time_ms: 18210.308\n",
      "    update_time_ms: 5.6\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.20535326350622\n",
      "  time_since_restore: 11592.054336071014\n",
      "  time_this_iter_s: 21.61304497718811\n",
      "  time_total_s: 11592.054336071014\n",
      "  timestamp: 1553133408\n",
      "  timesteps_since_restore: 5260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5260000\n",
      "  training_iteration: 526\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11592 s, 526 iter, 5260000 ts, 44.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-57-11\n",
      "  done: false\n",
      "  episode_len_mean: 70.35915492957747\n",
      "  episode_reward_max: 387.57941448828194\n",
      "  episode_reward_mean: 17.319902578113698\n",
      "  episode_reward_min: -166.90860787400246\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 65463\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.208\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 5270000\n",
      "    num_steps_trained: 5270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5951917767524719\n",
      "      kl: 0.02058562822639942\n",
      "      policy_loss: 0.002974997041746974\n",
      "      total_loss: 53.22746276855469\n",
      "      vf_explained_var: 0.9050103425979614\n",
      "      vf_loss: 53.22172927856445\n",
      "    sample_time_ms: 18270.443\n",
      "    update_time_ms: 5.684\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 8.659951289056846\n",
      "  time_since_restore: 11614.34676527977\n",
      "  time_this_iter_s: 22.292429208755493\n",
      "  time_total_s: 11614.34676527977\n",
      "  timestamp: 1553133431\n",
      "  timesteps_since_restore: 5270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5270000\n",
      "  training_iteration: 527\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11614 s, 527 iter, 5270000 ts, 17.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-57-33\n",
      "  done: false\n",
      "  episode_len_mean: 74.45185185185186\n",
      "  episode_reward_max: 387.56080872423644\n",
      "  episode_reward_mean: 47.77441198013345\n",
      "  episode_reward_min: -164.75225330206393\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 65598\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.125\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 5280000\n",
      "    num_steps_trained: 5280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5715053677558899\n",
      "      kl: 0.025091173127293587\n",
      "      policy_loss: 0.004570581950247288\n",
      "      total_loss: 53.31270217895508\n",
      "      vf_explained_var: 0.8986493349075317\n",
      "      vf_loss: 53.30477523803711\n",
      "    sample_time_ms: 18270.077\n",
      "    update_time_ms: 5.662\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.887205990066732\n",
      "  time_since_restore: 11636.397283315659\n",
      "  time_this_iter_s: 22.050518035888672\n",
      "  time_total_s: 11636.397283315659\n",
      "  timestamp: 1553133453\n",
      "  timesteps_since_restore: 5280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5280000\n",
      "  training_iteration: 528\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11636 s, 528 iter, 5280000 ts, 47.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-57-55\n",
      "  done: false\n",
      "  episode_len_mean: 66.73154362416108\n",
      "  episode_reward_max: 389.07849366692807\n",
      "  episode_reward_mean: -9.397437389496217\n",
      "  episode_reward_min: -164.68690999051572\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 65747\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.219\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 5290000\n",
      "    num_steps_trained: 5290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6124495267868042\n",
      "      kl: 0.026180533692240715\n",
      "      policy_loss: 0.00251774862408638\n",
      "      total_loss: 57.4916877746582\n",
      "      vf_explained_var: 0.9055702090263367\n",
      "      vf_loss: 57.48567199707031\n",
      "    sample_time_ms: 18312.178\n",
      "    update_time_ms: 5.42\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: -4.698718694748114\n",
      "  time_since_restore: 11658.682748794556\n",
      "  time_this_iter_s: 22.285465478897095\n",
      "  time_total_s: 11658.682748794556\n",
      "  timestamp: 1553133475\n",
      "  timesteps_since_restore: 5290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5290000\n",
      "  training_iteration: 529\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11658 s, 529 iter, 5290000 ts, -9.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-58-17\n",
      "  done: false\n",
      "  episode_len_mean: 68.32191780821918\n",
      "  episode_reward_max: 387.08630299510673\n",
      "  episode_reward_mean: 8.396479651830399\n",
      "  episode_reward_min: -166.97066705295086\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 65893\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.662\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 5300000\n",
      "    num_steps_trained: 5300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5966346859931946\n",
      "      kl: 0.017426347360014915\n",
      "      policy_loss: 0.0026680321898311377\n",
      "      total_loss: 68.18548583984375\n",
      "      vf_explained_var: 0.8825636506080627\n",
      "      vf_loss: 68.18048095703125\n",
      "    sample_time_ms: 18289.756\n",
      "    update_time_ms: 5.256\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 4.198239825915203\n",
      "  time_since_restore: 11680.542627096176\n",
      "  time_this_iter_s: 21.859878301620483\n",
      "  time_total_s: 11680.542627096176\n",
      "  timestamp: 1553133497\n",
      "  timesteps_since_restore: 5300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5300000\n",
      "  training_iteration: 530\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11680 s, 530 iter, 5300000 ts, 8.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-58-39\n",
      "  done: false\n",
      "  episode_len_mean: 72.71532846715328\n",
      "  episode_reward_max: 386.715551355242\n",
      "  episode_reward_mean: 36.48251462434672\n",
      "  episode_reward_min: -168.8064754358196\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 66030\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.145\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 5310000\n",
      "    num_steps_trained: 5310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5635026097297668\n",
      "      kl: 0.017113562673330307\n",
      "      policy_loss: 0.0017636952688917518\n",
      "      total_loss: 53.25415802001953\n",
      "      vf_explained_var: 0.9022637605667114\n",
      "      vf_loss: 53.250099182128906\n",
      "    sample_time_ms: 18350.796\n",
      "    update_time_ms: 5.41\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.241257312173364\n",
      "  time_since_restore: 11702.780826091766\n",
      "  time_this_iter_s: 22.23819899559021\n",
      "  time_total_s: 11702.780826091766\n",
      "  timestamp: 1553133519\n",
      "  timesteps_since_restore: 5310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5310000\n",
      "  training_iteration: 531\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11702 s, 531 iter, 5310000 ts, 36.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-59-01\n",
      "  done: false\n",
      "  episode_len_mean: 74.93333333333334\n",
      "  episode_reward_max: 387.54887322967573\n",
      "  episode_reward_mean: 53.2367343799749\n",
      "  episode_reward_min: -166.9841417617464\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 66165\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.817\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 5320000\n",
      "    num_steps_trained: 5320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5548499822616577\n",
      "      kl: 0.01366518996655941\n",
      "      policy_loss: 0.0022698964457958937\n",
      "      total_loss: 57.99845886230469\n",
      "      vf_explained_var: 0.8880789279937744\n",
      "      vf_loss: 57.99435806274414\n",
      "    sample_time_ms: 18269.948\n",
      "    update_time_ms: 5.53\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.618367189987445\n",
      "  time_since_restore: 11724.333294153214\n",
      "  time_this_iter_s: 21.552468061447144\n",
      "  time_total_s: 11724.333294153214\n",
      "  timestamp: 1553133541\n",
      "  timesteps_since_restore: 5320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5320000\n",
      "  training_iteration: 532\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11724 s, 532 iter, 5320000 ts, 53.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-59-23\n",
      "  done: false\n",
      "  episode_len_mean: 74.6044776119403\n",
      "  episode_reward_max: 387.5386909055664\n",
      "  episode_reward_mean: 52.28146008357081\n",
      "  episode_reward_min: -160.79001774358392\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 66299\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.026\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 5330000\n",
      "    num_steps_trained: 5330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5540090799331665\n",
      "      kl: 0.029036641120910645\n",
      "      policy_loss: 0.008676636964082718\n",
      "      total_loss: 49.50759506225586\n",
      "      vf_explained_var: 0.9046280980110168\n",
      "      vf_loss: 49.49502944946289\n",
      "    sample_time_ms: 18291.8\n",
      "    update_time_ms: 5.061\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.140730041785407\n",
      "  time_since_restore: 11746.522819519043\n",
      "  time_this_iter_s: 22.189525365829468\n",
      "  time_total_s: 11746.522819519043\n",
      "  timestamp: 1553133563\n",
      "  timesteps_since_restore: 5330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5330000\n",
      "  training_iteration: 533\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11746 s, 533 iter, 5330000 ts, 52.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_02-59-45\n",
      "  done: false\n",
      "  episode_len_mean: 72.0431654676259\n",
      "  episode_reward_max: 386.4606683678549\n",
      "  episode_reward_mean: 24.34662720009841\n",
      "  episode_reward_min: -166.76023761579037\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 66438\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.224\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 5340000\n",
      "    num_steps_trained: 5340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5591614246368408\n",
      "      kl: 0.020715512335300446\n",
      "      policy_loss: 0.0024596990551799536\n",
      "      total_loss: 53.42097473144531\n",
      "      vf_explained_var: 0.9025180339813232\n",
      "      vf_loss: 53.415740966796875\n",
      "    sample_time_ms: 18277.817\n",
      "    update_time_ms: 5.379\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.173313600049205\n",
      "  time_since_restore: 11768.231372594833\n",
      "  time_this_iter_s: 21.708553075790405\n",
      "  time_total_s: 11768.231372594833\n",
      "  timestamp: 1553133585\n",
      "  timesteps_since_restore: 5340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5340000\n",
      "  training_iteration: 534\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11768 s, 534 iter, 5340000 ts, 24.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-00-07\n",
      "  done: false\n",
      "  episode_len_mean: 72.4963503649635\n",
      "  episode_reward_max: 387.8298151042373\n",
      "  episode_reward_mean: 29.464675465227003\n",
      "  episode_reward_min: -161.4340922711754\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 66575\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.448\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 5350000\n",
      "    num_steps_trained: 5350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5848609805107117\n",
      "      kl: 0.01682853326201439\n",
      "      policy_loss: 0.0010019972687587142\n",
      "      total_loss: 62.58595657348633\n",
      "      vf_explained_var: 0.8836843967437744\n",
      "      vf_loss: 62.58270263671875\n",
      "    sample_time_ms: 18229.736\n",
      "    update_time_ms: 5.407\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.732337732613498\n",
      "  time_since_restore: 11789.997208356857\n",
      "  time_this_iter_s: 21.765835762023926\n",
      "  time_total_s: 11789.997208356857\n",
      "  timestamp: 1553133607\n",
      "  timesteps_since_restore: 5350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5350000\n",
      "  training_iteration: 535\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11789 s, 535 iter, 5350000 ts, 29.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-00-29\n",
      "  done: false\n",
      "  episode_len_mean: 71.26241134751773\n",
      "  episode_reward_max: 388.26666463082535\n",
      "  episode_reward_mean: 22.086865250864165\n",
      "  episode_reward_min: -162.82944004913807\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 66716\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.584\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 5360000\n",
      "    num_steps_trained: 5360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5668986439704895\n",
      "      kl: 0.022907422855496407\n",
      "      policy_loss: 0.004678069613873959\n",
      "      total_loss: 59.220157623291016\n",
      "      vf_explained_var: 0.8907179236412048\n",
      "      vf_loss: 59.2124137878418\n",
      "    sample_time_ms: 18264.892\n",
      "    update_time_ms: 5.465\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.043432625432082\n",
      "  time_since_restore: 11811.943242311478\n",
      "  time_this_iter_s: 21.94603395462036\n",
      "  time_total_s: 11811.943242311478\n",
      "  timestamp: 1553133629\n",
      "  timesteps_since_restore: 5360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5360000\n",
      "  training_iteration: 536\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11811 s, 536 iter, 5360000 ts, 22.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-00-51\n",
      "  done: false\n",
      "  episode_len_mean: 74.45522388059702\n",
      "  episode_reward_max: 387.32364405714\n",
      "  episode_reward_mean: 55.61056308469862\n",
      "  episode_reward_min: -166.81313957008362\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 66850\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.61\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 5370000\n",
      "    num_steps_trained: 5370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5669740438461304\n",
      "      kl: 0.02657790668308735\n",
      "      policy_loss: 0.0054717883467674255\n",
      "      total_loss: 56.94610595703125\n",
      "      vf_explained_var: 0.8887693881988525\n",
      "      vf_loss: 56.93707275390625\n",
      "    sample_time_ms: 18263.764\n",
      "    update_time_ms: 5.349\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.80528154234931\n",
      "  time_since_restore: 11834.113689661026\n",
      "  time_this_iter_s: 22.17044734954834\n",
      "  time_total_s: 11834.113689661026\n",
      "  timestamp: 1553133651\n",
      "  timesteps_since_restore: 5370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5370000\n",
      "  training_iteration: 537\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11834 s, 537 iter, 5370000 ts, 55.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-01-13\n",
      "  done: false\n",
      "  episode_len_mean: 72.44117647058823\n",
      "  episode_reward_max: 387.8170374179926\n",
      "  episode_reward_mean: 26.568371328944814\n",
      "  episode_reward_min: -166.77322424921036\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 66986\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.417\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 5380000\n",
      "    num_steps_trained: 5380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5626892447471619\n",
      "      kl: 0.018116287887096405\n",
      "      policy_loss: 0.006027046591043472\n",
      "      total_loss: 51.48175811767578\n",
      "      vf_explained_var: 0.9056782722473145\n",
      "      vf_loss: 51.47330093383789\n",
      "    sample_time_ms: 18265.177\n",
      "    update_time_ms: 5.477\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 13.284185664472403\n",
      "  time_since_restore: 11856.309134483337\n",
      "  time_this_iter_s: 22.1954448223114\n",
      "  time_total_s: 11856.309134483337\n",
      "  timestamp: 1553133673\n",
      "  timesteps_since_restore: 5380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5380000\n",
      "  training_iteration: 538\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11856 s, 538 iter, 5380000 ts, 26.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-01-35\n",
      "  done: false\n",
      "  episode_len_mean: 75.4\n",
      "  episode_reward_max: 389.9406771020513\n",
      "  episode_reward_mean: 54.17037988982422\n",
      "  episode_reward_min: -165.5042391241455\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 67121\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.077\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 5390000\n",
      "    num_steps_trained: 5390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5397929549217224\n",
      "      kl: 0.018602725118398666\n",
      "      policy_loss: 0.004323708824813366\n",
      "      total_loss: 58.86529541015625\n",
      "      vf_explained_var: 0.8820527195930481\n",
      "      vf_loss: 58.85848617553711\n",
      "    sample_time_ms: 18224.136\n",
      "    update_time_ms: 5.606\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.085189944912102\n",
      "  time_since_restore: 11878.221365213394\n",
      "  time_this_iter_s: 21.912230730056763\n",
      "  time_total_s: 11878.221365213394\n",
      "  timestamp: 1553133695\n",
      "  timesteps_since_restore: 5390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5390000\n",
      "  training_iteration: 539\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11878 s, 539 iter, 5390000 ts, 54.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-01-57\n",
      "  done: false\n",
      "  episode_len_mean: 72.63235294117646\n",
      "  episode_reward_max: 386.85714974278864\n",
      "  episode_reward_mean: 19.829736654877884\n",
      "  episode_reward_min: -168.86265320130826\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 67257\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.509\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 5400000\n",
      "    num_steps_trained: 5400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5537845492362976\n",
      "      kl: 0.0337393544614315\n",
      "      policy_loss: 0.008026053197681904\n",
      "      total_loss: 51.553443908691406\n",
      "      vf_explained_var: 0.9066247940063477\n",
      "      vf_loss: 51.54090118408203\n",
      "    sample_time_ms: 18203.346\n",
      "    update_time_ms: 5.726\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.914868327438938\n",
      "  time_since_restore: 11899.887731075287\n",
      "  time_this_iter_s: 21.6663658618927\n",
      "  time_total_s: 11899.887731075287\n",
      "  timestamp: 1553133717\n",
      "  timesteps_since_restore: 5400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5400000\n",
      "  training_iteration: 540\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11899 s, 540 iter, 5400000 ts, 19.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-02-19\n",
      "  done: false\n",
      "  episode_len_mean: 69.10958904109589\n",
      "  episode_reward_max: 390.3174917200567\n",
      "  episode_reward_mean: 4.887367127734055\n",
      "  episode_reward_min: -168.82070987531185\n",
      "  episodes_this_iter: 146\n",
      "  episodes_total: 67403\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.287\n",
      "    load_time_ms: 1.545\n",
      "    num_steps_sampled: 5410000\n",
      "    num_steps_trained: 5410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5734618902206421\n",
      "      kl: 0.022357283160090446\n",
      "      policy_loss: 0.004572926554828882\n",
      "      total_loss: 57.663230895996094\n",
      "      vf_explained_var: 0.9019805788993835\n",
      "      vf_loss: 57.655662536621094\n",
      "    sample_time_ms: 18182.507\n",
      "    update_time_ms: 5.504\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 2.443683563867029\n",
      "  time_since_restore: 11921.882978200912\n",
      "  time_this_iter_s: 21.99524712562561\n",
      "  time_total_s: 11921.882978200912\n",
      "  timestamp: 1553133739\n",
      "  timesteps_since_restore: 5410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5410000\n",
      "  training_iteration: 541\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11921 s, 541 iter, 5410000 ts, 4.89 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-02-40\n",
      "  done: false\n",
      "  episode_len_mean: 75.42105263157895\n",
      "  episode_reward_max: 389.5276031869994\n",
      "  episode_reward_mean: 57.01449933260433\n",
      "  episode_reward_min: -166.76881454428673\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 67536\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.131\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 5420000\n",
      "    num_steps_trained: 5420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5564581751823425\n",
      "      kl: 0.017904294654726982\n",
      "      policy_loss: 0.002959487261250615\n",
      "      total_loss: 53.54303741455078\n",
      "      vf_explained_var: 0.8945817351341248\n",
      "      vf_loss: 53.53768539428711\n",
      "    sample_time_ms: 18177.597\n",
      "    update_time_ms: 5.756\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.50724966630216\n",
      "  time_since_restore: 11943.438782691956\n",
      "  time_this_iter_s: 21.55580449104309\n",
      "  time_total_s: 11943.438782691956\n",
      "  timestamp: 1553133760\n",
      "  timesteps_since_restore: 5420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5420000\n",
      "  training_iteration: 542\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11943 s, 542 iter, 5420000 ts, 57 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-03-03\n",
      "  done: false\n",
      "  episode_len_mean: 73.16788321167883\n",
      "  episode_reward_max: 387.39216957731\n",
      "  episode_reward_mean: 38.65516021723545\n",
      "  episode_reward_min: -162.66165550097466\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 67673\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.744\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 5430000\n",
      "    num_steps_trained: 5430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5465056896209717\n",
      "      kl: 0.0251507256180048\n",
      "      policy_loss: 0.007059822324663401\n",
      "      total_loss: 62.162986755371094\n",
      "      vf_explained_var: 0.8814759850502014\n",
      "      vf_loss: 62.15256881713867\n",
      "    sample_time_ms: 18190.626\n",
      "    update_time_ms: 5.789\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.327580108617724\n",
      "  time_since_restore: 11965.793508529663\n",
      "  time_this_iter_s: 22.35472583770752\n",
      "  time_total_s: 11965.793508529663\n",
      "  timestamp: 1553133783\n",
      "  timesteps_since_restore: 5430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5430000\n",
      "  training_iteration: 543\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11965 s, 543 iter, 5430000 ts, 38.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-03-24\n",
      "  done: false\n",
      "  episode_len_mean: 73.21323529411765\n",
      "  episode_reward_max: 385.8331877306878\n",
      "  episode_reward_mean: 41.83386545903623\n",
      "  episode_reward_min: -166.77770467385292\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 67809\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.859\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 5440000\n",
      "    num_steps_trained: 5440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5580054521560669\n",
      "      kl: 0.017861247062683105\n",
      "      policy_loss: 0.0023959034588187933\n",
      "      total_loss: 48.35406494140625\n",
      "      vf_explained_var: 0.9081552028656006\n",
      "      vf_loss: 48.349281311035156\n",
      "    sample_time_ms: 18179.227\n",
      "    update_time_ms: 5.49\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.916932729518113\n",
      "  time_since_restore: 11987.375728607178\n",
      "  time_this_iter_s: 21.58222007751465\n",
      "  time_total_s: 11987.375728607178\n",
      "  timestamp: 1553133804\n",
      "  timesteps_since_restore: 5440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5440000\n",
      "  training_iteration: 544\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 11987 s, 544 iter, 5440000 ts, 41.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-03-46\n",
      "  done: false\n",
      "  episode_len_mean: 79.14285714285714\n",
      "  episode_reward_max: 387.4990088755465\n",
      "  episode_reward_mean: 79.27079043263576\n",
      "  episode_reward_min: -167.0717500123644\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 67935\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.348\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 5450000\n",
      "    num_steps_trained: 5450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5696156620979309\n",
      "      kl: 0.020600106567144394\n",
      "      policy_loss: 0.001967577962204814\n",
      "      total_loss: 55.56556701660156\n",
      "      vf_explained_var: 0.8766630291938782\n",
      "      vf_loss: 55.560848236083984\n",
      "    sample_time_ms: 18200.661\n",
      "    update_time_ms: 5.471\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.63539521631787\n",
      "  time_since_restore: 12009.338835954666\n",
      "  time_this_iter_s: 21.963107347488403\n",
      "  time_total_s: 12009.338835954666\n",
      "  timestamp: 1553133826\n",
      "  timesteps_since_restore: 5450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5450000\n",
      "  training_iteration: 545\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12009 s, 545 iter, 5450000 ts, 79.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-04-08\n",
      "  done: false\n",
      "  episode_len_mean: 75.85606060606061\n",
      "  episode_reward_max: 385.9744707400528\n",
      "  episode_reward_mean: 58.726235169453716\n",
      "  episode_reward_min: -168.88225563141344\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 68067\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.403\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 5460000\n",
      "    num_steps_trained: 5460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.531294584274292\n",
      "      kl: 0.01720476895570755\n",
      "      policy_loss: 0.0016745436005294323\n",
      "      total_loss: 52.90205764770508\n",
      "      vf_explained_var: 0.8936912417411804\n",
      "      vf_loss: 52.89807891845703\n",
      "    sample_time_ms: 18192.486\n",
      "    update_time_ms: 5.476\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.363117584726854\n",
      "  time_since_restore: 12031.244049072266\n",
      "  time_this_iter_s: 21.905213117599487\n",
      "  time_total_s: 12031.244049072266\n",
      "  timestamp: 1553133848\n",
      "  timesteps_since_restore: 5460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5460000\n",
      "  training_iteration: 546\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12031 s, 546 iter, 5460000 ts, 58.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-04-30\n",
      "  done: false\n",
      "  episode_len_mean: 69.54166666666667\n",
      "  episode_reward_max: 391.1921225008272\n",
      "  episode_reward_mean: 18.1932820962672\n",
      "  episode_reward_min: -166.9886055030489\n",
      "  episodes_this_iter: 144\n",
      "  episodes_total: 68211\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.375\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 5470000\n",
      "    num_steps_trained: 5470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6000790596008301\n",
      "      kl: 0.02339364029467106\n",
      "      policy_loss: 0.005017556250095367\n",
      "      total_loss: 67.48880004882812\n",
      "      vf_explained_var: 0.8768692016601562\n",
      "      vf_loss: 67.48065948486328\n",
      "    sample_time_ms: 18142.65\n",
      "    update_time_ms: 5.523\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.0966410481336\n",
      "  time_since_restore: 12052.905670404434\n",
      "  time_this_iter_s: 21.66162133216858\n",
      "  time_total_s: 12052.905670404434\n",
      "  timestamp: 1553133870\n",
      "  timesteps_since_restore: 5470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5470000\n",
      "  training_iteration: 547\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12052 s, 547 iter, 5470000 ts, 18.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-04-52\n",
      "  done: false\n",
      "  episode_len_mean: 75.42424242424242\n",
      "  episode_reward_max: 387.3038425427224\n",
      "  episode_reward_mean: 57.94380341332359\n",
      "  episode_reward_min: -164.97787435075284\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 68343\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.638\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 5480000\n",
      "    num_steps_trained: 5480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5693444609642029\n",
      "      kl: 0.02058395743370056\n",
      "      policy_loss: 0.0011576181277632713\n",
      "      total_loss: 54.50143814086914\n",
      "      vf_explained_var: 0.8899641633033752\n",
      "      vf_loss: 54.497520446777344\n",
      "    sample_time_ms: 18165.129\n",
      "    update_time_ms: 5.36\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.971901706661797\n",
      "  time_since_restore: 12075.1702542305\n",
      "  time_this_iter_s: 22.264583826065063\n",
      "  time_total_s: 12075.1702542305\n",
      "  timestamp: 1553133892\n",
      "  timesteps_since_restore: 5480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5480000\n",
      "  training_iteration: 548\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12075 s, 548 iter, 5480000 ts, 57.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-05-14\n",
      "  done: false\n",
      "  episode_len_mean: 69.83216783216783\n",
      "  episode_reward_max: 382.1568566880003\n",
      "  episode_reward_mean: 13.63354327023403\n",
      "  episode_reward_min: -168.75909444591045\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 68486\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.124\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 5490000\n",
      "    num_steps_trained: 5490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5776777267456055\n",
      "      kl: 0.02079840376973152\n",
      "      policy_loss: 0.0013965771067887545\n",
      "      total_loss: 51.838172912597656\n",
      "      vf_explained_var: 0.9080458283424377\n",
      "      vf_loss: 51.833984375\n",
      "    sample_time_ms: 18187.579\n",
      "    update_time_ms: 5.185\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.816771635117012\n",
      "  time_since_restore: 12097.289627552032\n",
      "  time_this_iter_s: 22.119373321533203\n",
      "  time_total_s: 12097.289627552032\n",
      "  timestamp: 1553133914\n",
      "  timesteps_since_restore: 5490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5490000\n",
      "  training_iteration: 549\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12097 s, 549 iter, 5490000 ts, 13.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-05-36\n",
      "  done: false\n",
      "  episode_len_mean: 75.54887218045113\n",
      "  episode_reward_max: 389.6941897600441\n",
      "  episode_reward_mean: 58.395755672047265\n",
      "  episode_reward_min: -168.69622627123832\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 68619\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.114\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 5500000\n",
      "    num_steps_trained: 5500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5767344832420349\n",
      "      kl: 0.027464695274829865\n",
      "      policy_loss: 0.0072322990745306015\n",
      "      total_loss: 48.999473571777344\n",
      "      vf_explained_var: 0.9020845293998718\n",
      "      vf_loss: 48.988563537597656\n",
      "    sample_time_ms: 18184.764\n",
      "    update_time_ms: 5.099\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.197877836023633\n",
      "  time_since_restore: 12118.905558347702\n",
      "  time_this_iter_s: 21.615930795669556\n",
      "  time_total_s: 12118.905558347702\n",
      "  timestamp: 1553133936\n",
      "  timesteps_since_restore: 5500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5500000\n",
      "  training_iteration: 550\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12118 s, 550 iter, 5500000 ts, 58.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-05-58\n",
      "  done: false\n",
      "  episode_len_mean: 72.69565217391305\n",
      "  episode_reward_max: 390.14385431665374\n",
      "  episode_reward_mean: 39.828748045880246\n",
      "  episode_reward_min: -166.71172282752036\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 68757\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.57\n",
      "    load_time_ms: 1.545\n",
      "    num_steps_sampled: 5510000\n",
      "    num_steps_trained: 5510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6039972305297852\n",
      "      kl: 0.02280239202082157\n",
      "      policy_loss: 0.006293763872236013\n",
      "      total_loss: 68.79322814941406\n",
      "      vf_explained_var: 0.868389904499054\n",
      "      vf_loss: 68.78388977050781\n",
      "    sample_time_ms: 18195.683\n",
      "    update_time_ms: 5.106\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.914374022940116\n",
      "  time_since_restore: 12141.03372168541\n",
      "  time_this_iter_s: 22.12816333770752\n",
      "  time_total_s: 12141.03372168541\n",
      "  timestamp: 1553133958\n",
      "  timesteps_since_restore: 5510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5510000\n",
      "  training_iteration: 551\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12141 s, 551 iter, 5510000 ts, 39.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-06-20\n",
      "  done: false\n",
      "  episode_len_mean: 75.4090909090909\n",
      "  episode_reward_max: 389.3378878276223\n",
      "  episode_reward_mean: 61.36655399612439\n",
      "  episode_reward_min: -167.06317021378516\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 68889\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.358\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 5520000\n",
      "    num_steps_trained: 5520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5729617476463318\n",
      "      kl: 0.018669219687581062\n",
      "      policy_loss: 0.004776832181960344\n",
      "      total_loss: 54.34044647216797\n",
      "      vf_explained_var: 0.8898202776908875\n",
      "      vf_loss: 54.33317184448242\n",
      "    sample_time_ms: 18228.013\n",
      "    update_time_ms: 4.742\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.68327699806218\n",
      "  time_since_restore: 12162.815726995468\n",
      "  time_this_iter_s: 21.782005310058594\n",
      "  time_total_s: 12162.815726995468\n",
      "  timestamp: 1553133980\n",
      "  timesteps_since_restore: 5520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5520000\n",
      "  training_iteration: 552\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12162 s, 552 iter, 5520000 ts, 61.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-06-41\n",
      "  done: false\n",
      "  episode_len_mean: 72.07913669064749\n",
      "  episode_reward_max: 386.60655818162877\n",
      "  episode_reward_mean: 32.871406838724994\n",
      "  episode_reward_min: -164.75750996097565\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 69028\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.428\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 5530000\n",
      "    num_steps_trained: 5530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6010774374008179\n",
      "      kl: 0.02904420904815197\n",
      "      policy_loss: 0.005983494222164154\n",
      "      total_loss: 51.92544174194336\n",
      "      vf_explained_var: 0.9042471647262573\n",
      "      vf_loss: 51.91556930541992\n",
      "    sample_time_ms: 18085.367\n",
      "    update_time_ms: 4.938\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.435703419362497\n",
      "  time_since_restore: 12183.926028490067\n",
      "  time_this_iter_s: 21.11030149459839\n",
      "  time_total_s: 12183.926028490067\n",
      "  timestamp: 1553134001\n",
      "  timesteps_since_restore: 5530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5530000\n",
      "  training_iteration: 553\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12183 s, 553 iter, 5530000 ts, 32.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-07-03\n",
      "  done: false\n",
      "  episode_len_mean: 72.71532846715328\n",
      "  episode_reward_max: 388.3913666572026\n",
      "  episode_reward_mean: 39.67429845698712\n",
      "  episode_reward_min: -165.188147546556\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 69165\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.006\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 5540000\n",
      "    num_steps_trained: 5540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6034407019615173\n",
      "      kl: 0.015420293435454369\n",
      "      policy_loss: 0.004760431591421366\n",
      "      total_loss: 57.90044021606445\n",
      "      vf_explained_var: 0.8911148309707642\n",
      "      vf_loss: 57.89361572265625\n",
      "    sample_time_ms: 18064.933\n",
      "    update_time_ms: 4.855\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.83714922849356\n",
      "  time_since_restore: 12205.297975301743\n",
      "  time_this_iter_s: 21.371946811676025\n",
      "  time_total_s: 12205.297975301743\n",
      "  timestamp: 1553134023\n",
      "  timesteps_since_restore: 5540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5540000\n",
      "  training_iteration: 554\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12205 s, 554 iter, 5540000 ts, 39.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-07-24\n",
      "  done: false\n",
      "  episode_len_mean: 75.18656716417911\n",
      "  episode_reward_max: 389.4449195719049\n",
      "  episode_reward_mean: 58.62213786278857\n",
      "  episode_reward_min: -166.71134629138948\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 69299\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.221\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 5550000\n",
      "    num_steps_trained: 5550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5834950804710388\n",
      "      kl: 0.01831694319844246\n",
      "      policy_loss: 0.003009295556694269\n",
      "      total_loss: 49.55094528198242\n",
      "      vf_explained_var: 0.8996507525444031\n",
      "      vf_loss: 49.54548645019531\n",
      "    sample_time_ms: 18040.686\n",
      "    update_time_ms: 4.885\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.311068931394267\n",
      "  time_since_restore: 12227.012681484222\n",
      "  time_this_iter_s: 21.71470618247986\n",
      "  time_total_s: 12227.012681484222\n",
      "  timestamp: 1553134044\n",
      "  timesteps_since_restore: 5550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5550000\n",
      "  training_iteration: 555\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12227 s, 555 iter, 5550000 ts, 58.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-07-46\n",
      "  done: false\n",
      "  episode_len_mean: 72.43382352941177\n",
      "  episode_reward_max: 386.37521462429845\n",
      "  episode_reward_mean: 37.36304509435328\n",
      "  episode_reward_min: -164.72113553198815\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 69435\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.899\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 5560000\n",
      "    num_steps_trained: 5560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6134863495826721\n",
      "      kl: 0.017375873401761055\n",
      "      policy_loss: 0.003549824468791485\n",
      "      total_loss: 54.10190200805664\n",
      "      vf_explained_var: 0.8974501490592957\n",
      "      vf_loss: 54.09602355957031\n",
      "    sample_time_ms: 18031.065\n",
      "    update_time_ms: 5.087\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.681522547176645\n",
      "  time_since_restore: 12248.769199371338\n",
      "  time_this_iter_s: 21.75651788711548\n",
      "  time_total_s: 12248.769199371338\n",
      "  timestamp: 1553134066\n",
      "  timesteps_since_restore: 5560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5560000\n",
      "  training_iteration: 556\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12248 s, 556 iter, 5560000 ts, 37.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-08-08\n",
      "  done: false\n",
      "  episode_len_mean: 72.52857142857142\n",
      "  episode_reward_max: 387.7391401091911\n",
      "  episode_reward_mean: 39.326874744087974\n",
      "  episode_reward_min: -167.0464464529419\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 69575\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.179\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 5570000\n",
      "    num_steps_trained: 5570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6139993667602539\n",
      "      kl: 0.015283343382179737\n",
      "      policy_loss: 0.004574645776301622\n",
      "      total_loss: 53.318973541259766\n",
      "      vf_explained_var: 0.8994674682617188\n",
      "      vf_loss: 53.312355041503906\n",
      "    sample_time_ms: 17993.303\n",
      "    update_time_ms: 5.023\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.663437372043983\n",
      "  time_since_restore: 12270.08844947815\n",
      "  time_this_iter_s: 21.319250106811523\n",
      "  time_total_s: 12270.08844947815\n",
      "  timestamp: 1553134088\n",
      "  timesteps_since_restore: 5570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5570000\n",
      "  training_iteration: 557\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12270 s, 557 iter, 5570000 ts, 39.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-08-29\n",
      "  done: false\n",
      "  episode_len_mean: 79.3015873015873\n",
      "  episode_reward_max: 388.81016097915244\n",
      "  episode_reward_mean: 86.8480372692363\n",
      "  episode_reward_min: -162.65345758780478\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 69701\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.234\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 5580000\n",
      "    num_steps_trained: 5580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5827911496162415\n",
      "      kl: 0.017314394935965538\n",
      "      policy_loss: 0.0033721684012562037\n",
      "      total_loss: 48.49134063720703\n",
      "      vf_explained_var: 0.8927473425865173\n",
      "      vf_loss: 48.485652923583984\n",
      "    sample_time_ms: 17908.446\n",
      "    update_time_ms: 5.089\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.42401863461815\n",
      "  time_since_restore: 12291.529901742935\n",
      "  time_this_iter_s: 21.441452264785767\n",
      "  time_total_s: 12291.529901742935\n",
      "  timestamp: 1553134109\n",
      "  timesteps_since_restore: 5580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5580000\n",
      "  training_iteration: 558\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12291 s, 558 iter, 5580000 ts, 86.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-08-51\n",
      "  done: false\n",
      "  episode_len_mean: 79.24\n",
      "  episode_reward_max: 388.3690638934891\n",
      "  episode_reward_mean: 84.49431298933666\n",
      "  episode_reward_min: -166.74675128563882\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 69826\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.926\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 5590000\n",
      "    num_steps_trained: 5590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.596569836139679\n",
      "      kl: 0.023084981366991997\n",
      "      policy_loss: 0.0038446523249149323\n",
      "      total_loss: 68.14842224121094\n",
      "      vf_explained_var: 0.8484618067741394\n",
      "      vf_loss: 68.1414794921875\n",
      "    sample_time_ms: 17913.695\n",
      "    update_time_ms: 5.065\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.247156494668324\n",
      "  time_since_restore: 12313.707637310028\n",
      "  time_this_iter_s: 22.177735567092896\n",
      "  time_total_s: 12313.707637310028\n",
      "  timestamp: 1553134131\n",
      "  timesteps_since_restore: 5590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5590000\n",
      "  training_iteration: 559\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12313 s, 559 iter, 5590000 ts, 84.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-09-14\n",
      "  done: false\n",
      "  episode_len_mean: 70.69718309859155\n",
      "  episode_reward_max: 389.05958868519843\n",
      "  episode_reward_mean: 23.907046977504457\n",
      "  episode_reward_min: -166.74253996762275\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 69968\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.267\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 5600000\n",
      "    num_steps_trained: 5600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6218149065971375\n",
      "      kl: 0.018837938085198402\n",
      "      policy_loss: 0.002898715902119875\n",
      "      total_loss: 58.73429870605469\n",
      "      vf_explained_var: 0.8924185037612915\n",
      "      vf_loss: 58.728878021240234\n",
      "    sample_time_ms: 17988.387\n",
      "    update_time_ms: 5.051\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.953523488752229\n",
      "  time_since_restore: 12336.10238814354\n",
      "  time_this_iter_s: 22.394750833511353\n",
      "  time_total_s: 12336.10238814354\n",
      "  timestamp: 1553134154\n",
      "  timesteps_since_restore: 5600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5600000\n",
      "  training_iteration: 560\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12336 s, 560 iter, 5600000 ts, 23.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-09-36\n",
      "  done: false\n",
      "  episode_len_mean: 70.7605633802817\n",
      "  episode_reward_max: 386.38686559840346\n",
      "  episode_reward_mean: 24.007162205189683\n",
      "  episode_reward_min: -168.91424750324725\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 70110\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.427\n",
      "    load_time_ms: 1.421\n",
      "    num_steps_sampled: 5610000\n",
      "    num_steps_trained: 5610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6166151762008667\n",
      "      kl: 0.023783139884471893\n",
      "      policy_loss: 0.002226248849183321\n",
      "      total_loss: 53.76830291748047\n",
      "      vf_explained_var: 0.9040505886077881\n",
      "      vf_loss: 53.76289749145508\n",
      "    sample_time_ms: 17982.164\n",
      "    update_time_ms: 5.117\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.003581102594842\n",
      "  time_since_restore: 12358.15789604187\n",
      "  time_this_iter_s: 22.05550789833069\n",
      "  time_total_s: 12358.15789604187\n",
      "  timestamp: 1553134176\n",
      "  timesteps_since_restore: 5610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5610000\n",
      "  training_iteration: 561\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12358 s, 561 iter, 5610000 ts, 24 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-09-58\n",
      "  done: false\n",
      "  episode_len_mean: 74.04444444444445\n",
      "  episode_reward_max: 387.4076844488742\n",
      "  episode_reward_mean: 49.42170919887379\n",
      "  episode_reward_min: -166.6951051195526\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 70245\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.767\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 5620000\n",
      "    num_steps_trained: 5620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6160628199577332\n",
      "      kl: 0.016935303807258606\n",
      "      policy_loss: 0.003728182753548026\n",
      "      total_loss: 53.04821014404297\n",
      "      vf_explained_var: 0.8953373432159424\n",
      "      vf_loss: 53.04220962524414\n",
      "    sample_time_ms: 17989.396\n",
      "    update_time_ms: 5.253\n",
      "  iterations_since_restore: 562\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.7108545994369\n",
      "  time_since_restore: 12380.028988599777\n",
      "  time_this_iter_s: 21.871092557907104\n",
      "  time_total_s: 12380.028988599777\n",
      "  timestamp: 1553134198\n",
      "  timesteps_since_restore: 5620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5620000\n",
      "  training_iteration: 562\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12380 s, 562 iter, 5620000 ts, 49.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-10-20\n",
      "  done: false\n",
      "  episode_len_mean: 74.15671641791045\n",
      "  episode_reward_max: 387.378278056538\n",
      "  episode_reward_mean: 46.982357207813784\n",
      "  episode_reward_min: -166.83488849648475\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 70379\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.316\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 5630000\n",
      "    num_steps_trained: 5630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5922528505325317\n",
      "      kl: 0.018758269026875496\n",
      "      policy_loss: 0.0038004510570317507\n",
      "      total_loss: 48.12907028198242\n",
      "      vf_explained_var: 0.9064178466796875\n",
      "      vf_loss: 48.12275314331055\n",
      "    sample_time_ms: 18081.575\n",
      "    update_time_ms: 5.027\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.491178603906885\n",
      "  time_since_restore: 12401.866143226624\n",
      "  time_this_iter_s: 21.837154626846313\n",
      "  time_total_s: 12401.866143226624\n",
      "  timestamp: 1553134220\n",
      "  timesteps_since_restore: 5630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5630000\n",
      "  training_iteration: 563\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12401 s, 563 iter, 5630000 ts, 47 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 72.76086956521739\n",
      "  episode_reward_max: 385.79234770769784\n",
      "  episode_reward_mean: 39.886848614920254\n",
      "  episode_reward_min: -168.7373906222248\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 70517\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.486\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 5640000\n",
      "    num_steps_trained: 5640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.628566324710846\n",
      "      kl: 0.03133806958794594\n",
      "      policy_loss: 0.005282750353217125\n",
      "      total_loss: 59.54636001586914\n",
      "      vf_explained_var: 0.8887792825698853\n",
      "      vf_loss: 59.53687286376953\n",
      "    sample_time_ms: 18121.289\n",
      "    update_time_ms: 5.707\n",
      "  iterations_since_restore: 564\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.94342430746013\n",
      "  time_since_restore: 12423.764798641205\n",
      "  time_this_iter_s: 21.8986554145813\n",
      "  time_total_s: 12423.764798641205\n",
      "  timestamp: 1553134242\n",
      "  timesteps_since_restore: 5640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5640000\n",
      "  training_iteration: 564\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12423 s, 564 iter, 5640000 ts, 39.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-11-04\n",
      "  done: false\n",
      "  episode_len_mean: 75.78030303030303\n",
      "  episode_reward_max: 386.9466981019976\n",
      "  episode_reward_mean: 61.85024097105376\n",
      "  episode_reward_min: -164.73790430435182\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 70649\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.622\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 5650000\n",
      "    num_steps_trained: 5650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5960653424263\n",
      "      kl: 0.024560268968343735\n",
      "      policy_loss: 0.002200567163527012\n",
      "      total_loss: 52.0617790222168\n",
      "      vf_explained_var: 0.8966232538223267\n",
      "      vf_loss: 52.05628967285156\n",
      "    sample_time_ms: 18168.884\n",
      "    update_time_ms: 5.733\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.925120485526875\n",
      "  time_since_restore: 12445.998182535172\n",
      "  time_this_iter_s: 22.233383893966675\n",
      "  time_total_s: 12445.998182535172\n",
      "  timestamp: 1553134264\n",
      "  timesteps_since_restore: 5650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5650000\n",
      "  training_iteration: 565\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12445 s, 565 iter, 5650000 ts, 61.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 74.42537313432835\n",
      "  episode_reward_max: 386.95933132548925\n",
      "  episode_reward_mean: 52.003661485683935\n",
      "  episode_reward_min: -164.67040735527516\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 70783\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.51\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 5660000\n",
      "    num_steps_trained: 5660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5929513573646545\n",
      "      kl: 0.022520868107676506\n",
      "      policy_loss: 0.005326693877577782\n",
      "      total_loss: 63.864070892333984\n",
      "      vf_explained_var: 0.872031569480896\n",
      "      vf_loss: 63.85573196411133\n",
      "    sample_time_ms: 18210.014\n",
      "    update_time_ms: 5.476\n",
      "  iterations_since_restore: 566\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.001830742841964\n",
      "  time_since_restore: 12468.163756370544\n",
      "  time_this_iter_s: 22.165573835372925\n",
      "  time_total_s: 12468.163756370544\n",
      "  timestamp: 1553134286\n",
      "  timesteps_since_restore: 5660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5660000\n",
      "  training_iteration: 566\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12468 s, 566 iter, 5660000 ts, 52 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-11-48\n",
      "  done: false\n",
      "  episode_len_mean: 81.73770491803279\n",
      "  episode_reward_max: 387.89477598355563\n",
      "  episode_reward_mean: 104.38254401295855\n",
      "  episode_reward_min: -166.79189338311195\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 70905\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.363\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 5670000\n",
      "    num_steps_trained: 5670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5778515934944153\n",
      "      kl: 0.018542427569627762\n",
      "      policy_loss: 0.0021977499127388\n",
      "      total_loss: 43.22071838378906\n",
      "      vf_explained_var: 0.8994401097297668\n",
      "      vf_loss: 43.21603775024414\n",
      "    sample_time_ms: 18310.782\n",
      "    update_time_ms: 5.475\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.19127200647928\n",
      "  time_since_restore: 12490.494195699692\n",
      "  time_this_iter_s: 22.33043932914734\n",
      "  time_total_s: 12490.494195699692\n",
      "  timestamp: 1553134308\n",
      "  timesteps_since_restore: 5670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5670000\n",
      "  training_iteration: 567\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12490 s, 567 iter, 5670000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-12-10\n",
      "  done: false\n",
      "  episode_len_mean: 83.14166666666667\n",
      "  episode_reward_max: 387.647174299398\n",
      "  episode_reward_mean: 113.70267145847104\n",
      "  episode_reward_min: -166.71706899782657\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 71025\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.725\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 5680000\n",
      "    num_steps_trained: 5680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5650984048843384\n",
      "      kl: 0.019996924325823784\n",
      "      policy_loss: 0.001318043447099626\n",
      "      total_loss: 45.44203567504883\n",
      "      vf_explained_var: 0.8906573057174683\n",
      "      vf_loss: 45.43803405761719\n",
      "    sample_time_ms: 18307.537\n",
      "    update_time_ms: 5.723\n",
      "  iterations_since_restore: 568\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.85133572923552\n",
      "  time_since_restore: 12512.038461208344\n",
      "  time_this_iter_s: 21.544265508651733\n",
      "  time_total_s: 12512.038461208344\n",
      "  timestamp: 1553134330\n",
      "  timesteps_since_restore: 5680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5680000\n",
      "  training_iteration: 568\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12512 s, 568 iter, 5680000 ts, 114 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-12-32\n",
      "  done: false\n",
      "  episode_len_mean: 75.47014925373135\n",
      "  episode_reward_max: 387.47948881283645\n",
      "  episode_reward_mean: 60.870388686355184\n",
      "  episode_reward_min: -165.10902202221394\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 71159\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.444\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 5690000\n",
      "    num_steps_trained: 5690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5942179560661316\n",
      "      kl: 0.02203063853085041\n",
      "      policy_loss: 0.0038505096454173326\n",
      "      total_loss: 47.78412628173828\n",
      "      vf_explained_var: 0.9073494076728821\n",
      "      vf_loss: 47.77732849121094\n",
      "    sample_time_ms: 18272.454\n",
      "    update_time_ms: 5.888\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.435194343177596\n",
      "  time_since_restore: 12533.854204893112\n",
      "  time_this_iter_s: 21.815743684768677\n",
      "  time_total_s: 12533.854204893112\n",
      "  timestamp: 1553134352\n",
      "  timesteps_since_restore: 5690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5690000\n",
      "  training_iteration: 569\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12533 s, 569 iter, 5690000 ts, 60.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-12-54\n",
      "  done: false\n",
      "  episode_len_mean: 73.5925925925926\n",
      "  episode_reward_max: 384.7152943312004\n",
      "  episode_reward_mean: 41.40012854023988\n",
      "  episode_reward_min: -168.7574243628645\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 71294\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.909\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 5700000\n",
      "    num_steps_trained: 5700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5933042764663696\n",
      "      kl: 0.020799588412046432\n",
      "      policy_loss: 0.005112883169203997\n",
      "      total_loss: 55.35391616821289\n",
      "      vf_explained_var: 0.8952929973602295\n",
      "      vf_loss: 55.34601593017578\n",
      "    sample_time_ms: 18254.14\n",
      "    update_time_ms: 5.921\n",
      "  iterations_since_restore: 570\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.700064270119935\n",
      "  time_since_restore: 12556.065655469894\n",
      "  time_this_iter_s: 22.211450576782227\n",
      "  time_total_s: 12556.065655469894\n",
      "  timestamp: 1553134374\n",
      "  timesteps_since_restore: 5700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5700000\n",
      "  training_iteration: 570\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12556 s, 570 iter, 5700000 ts, 41.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-13-16\n",
      "  done: false\n",
      "  episode_len_mean: 73.75735294117646\n",
      "  episode_reward_max: 387.95983146311573\n",
      "  episode_reward_mean: 48.371298083973954\n",
      "  episode_reward_min: -165.54588203724862\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 71430\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.171\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 5710000\n",
      "    num_steps_trained: 5710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5956422686576843\n",
      "      kl: 0.017344309017062187\n",
      "      policy_loss: 0.0019481804920360446\n",
      "      total_loss: 60.42411422729492\n",
      "      vf_explained_var: 0.883345365524292\n",
      "      vf_loss: 60.41984558105469\n",
      "    sample_time_ms: 18277.635\n",
      "    update_time_ms: 5.945\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.185649041986977\n",
      "  time_since_restore: 12578.352667331696\n",
      "  time_this_iter_s: 22.287011861801147\n",
      "  time_total_s: 12578.352667331696\n",
      "  timestamp: 1553134396\n",
      "  timesteps_since_restore: 5710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5710000\n",
      "  training_iteration: 571\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12578 s, 571 iter, 5710000 ts, 48.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-13-38\n",
      "  done: false\n",
      "  episode_len_mean: 73.88235294117646\n",
      "  episode_reward_max: 385.56579630970685\n",
      "  episode_reward_mean: 51.12260344098394\n",
      "  episode_reward_min: -166.72398007580279\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 71566\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.242\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 5720000\n",
      "    num_steps_trained: 5720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5736459493637085\n",
      "      kl: 0.018591051921248436\n",
      "      policy_loss: 0.00402029836550355\n",
      "      total_loss: 50.594993591308594\n",
      "      vf_explained_var: 0.9017766118049622\n",
      "      vf_loss: 50.58848190307617\n",
      "    sample_time_ms: 18255.93\n",
      "    update_time_ms: 5.889\n",
      "  iterations_since_restore: 572\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.561301720491965\n",
      "  time_since_restore: 12600.074914216995\n",
      "  time_this_iter_s: 21.722246885299683\n",
      "  time_total_s: 12600.074914216995\n",
      "  timestamp: 1553134418\n",
      "  timesteps_since_restore: 5720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5720000\n",
      "  training_iteration: 572\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12600 s, 572 iter, 5720000 ts, 51.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-14-00\n",
      "  done: false\n",
      "  episode_len_mean: 77.24031007751938\n",
      "  episode_reward_max: 385.2238269761038\n",
      "  episode_reward_mean: 75.20452062410948\n",
      "  episode_reward_min: -168.69634707507134\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 71695\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.95\n",
      "    load_time_ms: 1.451\n",
      "    num_steps_sampled: 5730000\n",
      "    num_steps_trained: 5730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5518490076065063\n",
      "      kl: 0.020070580765604973\n",
      "      policy_loss: 0.0028362704906612635\n",
      "      total_loss: 49.19801712036133\n",
      "      vf_explained_var: 0.8964341282844543\n",
      "      vf_loss: 49.19249725341797\n",
      "    sample_time_ms: 18261.684\n",
      "    update_time_ms: 5.919\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.60226031205474\n",
      "  time_since_restore: 12621.965480566025\n",
      "  time_this_iter_s: 21.89056634902954\n",
      "  time_total_s: 12621.965480566025\n",
      "  timestamp: 1553134440\n",
      "  timesteps_since_restore: 5730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5730000\n",
      "  training_iteration: 573\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12621 s, 573 iter, 5730000 ts, 75.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-14-22\n",
      "  done: false\n",
      "  episode_len_mean: 74.40298507462687\n",
      "  episode_reward_max: 386.3528901931331\n",
      "  episode_reward_mean: 48.923382741313716\n",
      "  episode_reward_min: -166.80614800569057\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 71829\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.607\n",
      "    load_time_ms: 1.447\n",
      "    num_steps_sampled: 5740000\n",
      "    num_steps_trained: 5740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5776321887969971\n",
      "      kl: 0.015054146759212017\n",
      "      policy_loss: 0.00021482307056430727\n",
      "      total_loss: 51.52560806274414\n",
      "      vf_explained_var: 0.8994624018669128\n",
      "      vf_loss: 51.52337646484375\n",
      "    sample_time_ms: 18258.41\n",
      "    update_time_ms: 5.323\n",
      "  iterations_since_restore: 574\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.461691370656848\n",
      "  time_since_restore: 12643.671519756317\n",
      "  time_this_iter_s: 21.70603919029236\n",
      "  time_total_s: 12643.671519756317\n",
      "  timestamp: 1553134462\n",
      "  timesteps_since_restore: 5740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5740000\n",
      "  training_iteration: 574\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12643 s, 574 iter, 5740000 ts, 48.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 76.75384615384615\n",
      "  episode_reward_max: 391.3857706138115\n",
      "  episode_reward_mean: 66.96517360202627\n",
      "  episode_reward_min: -162.60581502315046\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 71959\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.445\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 5750000\n",
      "    num_steps_trained: 5750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.583366334438324\n",
      "      kl: 0.018159184604883194\n",
      "      policy_loss: 0.003411884419620037\n",
      "      total_loss: 51.88974380493164\n",
      "      vf_explained_var: 0.8907159566879272\n",
      "      vf_loss: 51.88390350341797\n",
      "    sample_time_ms: 18199.885\n",
      "    update_time_ms: 5.655\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.48258680101314\n",
      "  time_since_restore: 12665.292891979218\n",
      "  time_this_iter_s: 21.62137222290039\n",
      "  time_total_s: 12665.292891979218\n",
      "  timestamp: 1553134484\n",
      "  timesteps_since_restore: 5750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5750000\n",
      "  training_iteration: 575\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12665 s, 575 iter, 5750000 ts, 67 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 77.97674418604652\n",
      "  episode_reward_max: 390.7261013056906\n",
      "  episode_reward_mean: 81.87737329189926\n",
      "  episode_reward_min: -166.74216394099236\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 72088\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.752\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 5760000\n",
      "    num_steps_trained: 5760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5470666885375977\n",
      "      kl: 0.015644963830709457\n",
      "      policy_loss: 0.003965387586504221\n",
      "      total_loss: 44.46638107299805\n",
      "      vf_explained_var: 0.905854344367981\n",
      "      vf_loss: 44.46031951904297\n",
      "    sample_time_ms: 18181.408\n",
      "    update_time_ms: 5.716\n",
      "  iterations_since_restore: 576\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.93868664594962\n",
      "  time_since_restore: 12687.266845226288\n",
      "  time_this_iter_s: 21.973953247070312\n",
      "  time_total_s: 12687.266845226288\n",
      "  timestamp: 1553134506\n",
      "  timesteps_since_restore: 5760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5760000\n",
      "  training_iteration: 576\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12687 s, 576 iter, 5760000 ts, 81.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-15-28\n",
      "  done: false\n",
      "  episode_len_mean: 76.66153846153846\n",
      "  episode_reward_max: 386.42070566638125\n",
      "  episode_reward_mean: 72.67725322191461\n",
      "  episode_reward_min: -166.81569856091977\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 72218\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.843\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 5770000\n",
      "    num_steps_trained: 5770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5593551993370056\n",
      "      kl: 0.019158262759447098\n",
      "      policy_loss: 0.003674375591799617\n",
      "      total_loss: 49.68114471435547\n",
      "      vf_explained_var: 0.8946024775505066\n",
      "      vf_loss: 49.674903869628906\n",
      "    sample_time_ms: 18152.554\n",
      "    update_time_ms: 5.87\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.338626610957306\n",
      "  time_since_restore: 12709.301098585129\n",
      "  time_this_iter_s: 22.034253358840942\n",
      "  time_total_s: 12709.301098585129\n",
      "  timestamp: 1553134528\n",
      "  timesteps_since_restore: 5770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5770000\n",
      "  training_iteration: 577\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12709 s, 577 iter, 5770000 ts, 72.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-15-50\n",
      "  done: false\n",
      "  episode_len_mean: 76.89147286821705\n",
      "  episode_reward_max: 384.7624855866395\n",
      "  episode_reward_mean: 70.24991269701592\n",
      "  episode_reward_min: -166.8641656882429\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 72347\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.511\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 5780000\n",
      "    num_steps_trained: 5780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5732336640357971\n",
      "      kl: 0.02063344605267048\n",
      "      policy_loss: 0.0020351309794932604\n",
      "      total_loss: 55.28291702270508\n",
      "      vf_explained_var: 0.8847613334655762\n",
      "      vf_loss: 55.27811813354492\n",
      "    sample_time_ms: 18205.159\n",
      "    update_time_ms: 5.707\n",
      "  iterations_since_restore: 578\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.12495634850796\n",
      "  time_since_restore: 12731.21757555008\n",
      "  time_this_iter_s: 21.91647696495056\n",
      "  time_total_s: 12731.21757555008\n",
      "  timestamp: 1553134550\n",
      "  timesteps_since_restore: 5780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5780000\n",
      "  training_iteration: 578\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12731 s, 578 iter, 5780000 ts, 70.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-16-12\n",
      "  done: false\n",
      "  episode_len_mean: 71.39716312056737\n",
      "  episode_reward_max: 388.06158441812494\n",
      "  episode_reward_mean: 30.34602520964261\n",
      "  episode_reward_min: -166.94327076956273\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 72488\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.756\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 5790000\n",
      "    num_steps_trained: 5790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5907478332519531\n",
      "      kl: 0.0194327961653471\n",
      "      policy_loss: 0.0028895565774291754\n",
      "      total_loss: 58.82081985473633\n",
      "      vf_explained_var: 0.8908074498176575\n",
      "      vf_loss: 58.815330505371094\n",
      "    sample_time_ms: 18207.739\n",
      "    update_time_ms: 5.699\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.173012604821317\n",
      "  time_since_restore: 12753.203778982162\n",
      "  time_this_iter_s: 21.98620343208313\n",
      "  time_total_s: 12753.203778982162\n",
      "  timestamp: 1553134572\n",
      "  timesteps_since_restore: 5790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5790000\n",
      "  training_iteration: 579\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12753 s, 579 iter, 5790000 ts, 30.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-16-33\n",
      "  done: false\n",
      "  episode_len_mean: 74.73134328358209\n",
      "  episode_reward_max: 386.44485780327767\n",
      "  episode_reward_mean: 52.63162416575468\n",
      "  episode_reward_min: -166.753619107213\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 72622\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.327\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 5800000\n",
      "    num_steps_trained: 5800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5735148787498474\n",
      "      kl: 0.02073473110795021\n",
      "      policy_loss: 0.0020032089669257402\n",
      "      total_loss: 55.781944274902344\n",
      "      vf_explained_var: 0.8910387754440308\n",
      "      vf_loss: 55.77716827392578\n",
      "    sample_time_ms: 18102.702\n",
      "    update_time_ms: 5.642\n",
      "  iterations_since_restore: 580\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.31581208287734\n",
      "  time_since_restore: 12774.365529537201\n",
      "  time_this_iter_s: 21.161750555038452\n",
      "  time_total_s: 12774.365529537201\n",
      "  timestamp: 1553134593\n",
      "  timesteps_since_restore: 5800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5800000\n",
      "  training_iteration: 580\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12774 s, 580 iter, 5800000 ts, 52.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-16-55\n",
      "  done: false\n",
      "  episode_len_mean: 76.7\n",
      "  episode_reward_max: 389.04256074310854\n",
      "  episode_reward_mean: 66.31050804723895\n",
      "  episode_reward_min: -166.84570184871197\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 72752\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.225\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 5810000\n",
      "    num_steps_trained: 5810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5787330269813538\n",
      "      kl: 0.021682649850845337\n",
      "      policy_loss: 0.002134090755134821\n",
      "      total_loss: 50.00536346435547\n",
      "      vf_explained_var: 0.8984543085098267\n",
      "      vf_loss: 50.00032043457031\n",
      "    sample_time_ms: 18106.513\n",
      "    update_time_ms: 5.647\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.155254023619484\n",
      "  time_since_restore: 12796.668363809586\n",
      "  time_this_iter_s: 22.302834272384644\n",
      "  time_total_s: 12796.668363809586\n",
      "  timestamp: 1553134615\n",
      "  timesteps_since_restore: 5810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5810000\n",
      "  training_iteration: 581\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12796 s, 581 iter, 5810000 ts, 66.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-17-17\n",
      "  done: false\n",
      "  episode_len_mean: 80.56451612903226\n",
      "  episode_reward_max: 389.9452760706155\n",
      "  episode_reward_mean: 101.03615741644262\n",
      "  episode_reward_min: -164.70045960184575\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 72876\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.312\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 5820000\n",
      "    num_steps_trained: 5820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5252417922019958\n",
      "      kl: 0.017946993932127953\n",
      "      policy_loss: 0.003924049437046051\n",
      "      total_loss: 51.15727615356445\n",
      "      vf_explained_var: 0.8809890747070312\n",
      "      vf_loss: 51.15095138549805\n",
      "    sample_time_ms: 18138.36\n",
      "    update_time_ms: 5.555\n",
      "  iterations_since_restore: 582\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.5180787082213\n",
      "  time_since_restore: 12818.630587816238\n",
      "  time_this_iter_s: 21.962224006652832\n",
      "  time_total_s: 12818.630587816238\n",
      "  timestamp: 1553134637\n",
      "  timesteps_since_restore: 5820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5820000\n",
      "  training_iteration: 582\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12818 s, 582 iter, 5820000 ts, 101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-17-39\n",
      "  done: false\n",
      "  episode_len_mean: 81.51219512195122\n",
      "  episode_reward_max: 387.762831469766\n",
      "  episode_reward_mean: 106.28295853443858\n",
      "  episode_reward_min: -164.6854756844902\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 72999\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.444\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 5830000\n",
      "    num_steps_trained: 5830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5358108878135681\n",
      "      kl: 0.018096784129738808\n",
      "      policy_loss: 0.007690558675676584\n",
      "      total_loss: 49.27086639404297\n",
      "      vf_explained_var: 0.8809376955032349\n",
      "      vf_loss: 49.26074981689453\n",
      "    sample_time_ms: 18117.491\n",
      "    update_time_ms: 5.755\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.14147926721928\n",
      "  time_since_restore: 12840.3669860363\n",
      "  time_this_iter_s: 21.736398220062256\n",
      "  time_total_s: 12840.3669860363\n",
      "  timestamp: 1553134659\n",
      "  timesteps_since_restore: 5830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5830000\n",
      "  training_iteration: 583\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12840 s, 583 iter, 5830000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-18-01\n",
      "  done: false\n",
      "  episode_len_mean: 78.11023622047244\n",
      "  episode_reward_max: 387.7863829178216\n",
      "  episode_reward_mean: 78.36464183978724\n",
      "  episode_reward_min: -168.75731607874872\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 73126\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.581\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 5840000\n",
      "    num_steps_trained: 5840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5515158176422119\n",
      "      kl: 0.022061806172132492\n",
      "      policy_loss: 0.004356484394520521\n",
      "      total_loss: 40.30202102661133\n",
      "      vf_explained_var: 0.913638174533844\n",
      "      vf_loss: 40.294715881347656\n",
      "    sample_time_ms: 18133.971\n",
      "    update_time_ms: 5.734\n",
      "  iterations_since_restore: 584\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.18232091989361\n",
      "  time_since_restore: 12862.310736179352\n",
      "  time_this_iter_s: 21.943750143051147\n",
      "  time_total_s: 12862.310736179352\n",
      "  timestamp: 1553134681\n",
      "  timesteps_since_restore: 5840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5840000\n",
      "  training_iteration: 584\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12862 s, 584 iter, 5840000 ts, 78.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-18-23\n",
      "  done: false\n",
      "  episode_len_mean: 75.87121212121212\n",
      "  episode_reward_max: 386.27672042929765\n",
      "  episode_reward_mean: 66.4337939155557\n",
      "  episode_reward_min: -166.72591178139686\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 73258\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.751\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 5850000\n",
      "    num_steps_trained: 5850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.566568911075592\n",
      "      kl: 0.015192453749477863\n",
      "      policy_loss: 0.004411752335727215\n",
      "      total_loss: 42.89708709716797\n",
      "      vf_explained_var: 0.9130920767784119\n",
      "      vf_loss: 42.89064025878906\n",
      "    sample_time_ms: 18184.717\n",
      "    update_time_ms: 5.338\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.21689695777784\n",
      "  time_since_restore: 12884.445471048355\n",
      "  time_this_iter_s: 22.134734869003296\n",
      "  time_total_s: 12884.445471048355\n",
      "  timestamp: 1553134703\n",
      "  timesteps_since_restore: 5850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5850000\n",
      "  training_iteration: 585\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12884 s, 585 iter, 5850000 ts, 66.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-18-45\n",
      "  done: false\n",
      "  episode_len_mean: 75.7218045112782\n",
      "  episode_reward_max: 387.66997304404583\n",
      "  episode_reward_mean: 65.59126443111151\n",
      "  episode_reward_min: -166.7934686456585\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 73391\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.406\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 5860000\n",
      "    num_steps_trained: 5860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5520073175430298\n",
      "      kl: 0.019263001158833504\n",
      "      policy_loss: 0.004106587264686823\n",
      "      total_loss: 50.76163864135742\n",
      "      vf_explained_var: 0.8986237645149231\n",
      "      vf_loss: 50.75495147705078\n",
      "    sample_time_ms: 18124.186\n",
      "    update_time_ms: 5.234\n",
      "  iterations_since_restore: 586\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.795632215555756\n",
      "  time_since_restore: 12905.828961610794\n",
      "  time_this_iter_s: 21.383490562438965\n",
      "  time_total_s: 12905.828961610794\n",
      "  timestamp: 1553134725\n",
      "  timesteps_since_restore: 5860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5860000\n",
      "  training_iteration: 586\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12905 s, 586 iter, 5860000 ts, 65.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-19-06\n",
      "  done: false\n",
      "  episode_len_mean: 77.15384615384616\n",
      "  episode_reward_max: 388.4993674931224\n",
      "  episode_reward_mean: 75.209680481432\n",
      "  episode_reward_min: -164.75308274802208\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 73521\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.543\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 5870000\n",
      "    num_steps_trained: 5870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5212575197219849\n",
      "      kl: 0.014791137538850307\n",
      "      policy_loss: 0.003545309416949749\n",
      "      total_loss: 44.86309814453125\n",
      "      vf_explained_var: 0.9065057039260864\n",
      "      vf_loss: 44.85757064819336\n",
      "    sample_time_ms: 18114.48\n",
      "    update_time_ms: 5.082\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.604840240716\n",
      "  time_since_restore: 12927.737817049026\n",
      "  time_this_iter_s: 21.908855438232422\n",
      "  time_total_s: 12927.737817049026\n",
      "  timestamp: 1553134746\n",
      "  timesteps_since_restore: 5870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5870000\n",
      "  training_iteration: 587\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12927 s, 587 iter, 5870000 ts, 75.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-19-29\n",
      "  done: false\n",
      "  episode_len_mean: 73.75735294117646\n",
      "  episode_reward_max: 387.55039870255547\n",
      "  episode_reward_mean: 58.47793293302338\n",
      "  episode_reward_min: -166.68314295324325\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 73657\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.415\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 5880000\n",
      "    num_steps_trained: 5880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5808143615722656\n",
      "      kl: 0.018230313435196877\n",
      "      policy_loss: 0.001680124318227172\n",
      "      total_loss: 51.80345153808594\n",
      "      vf_explained_var: 0.8986212015151978\n",
      "      vf_loss: 51.79932403564453\n",
      "    sample_time_ms: 18152.347\n",
      "    update_time_ms: 4.878\n",
      "  iterations_since_restore: 588\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.238966466511684\n",
      "  time_since_restore: 12950.022219657898\n",
      "  time_this_iter_s: 22.28440260887146\n",
      "  time_total_s: 12950.022219657898\n",
      "  timestamp: 1553134769\n",
      "  timesteps_since_restore: 5880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5880000\n",
      "  training_iteration: 588\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12950 s, 588 iter, 5880000 ts, 58.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-19-51\n",
      "  done: false\n",
      "  episode_len_mean: 71.05755395683454\n",
      "  episode_reward_max: 390.68644922005814\n",
      "  episode_reward_mean: 30.30196287740116\n",
      "  episode_reward_min: -166.7547304336691\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 73796\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.51\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 5890000\n",
      "    num_steps_trained: 5890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6012133955955505\n",
      "      kl: 0.020145434886217117\n",
      "      policy_loss: 0.0053965747356414795\n",
      "      total_loss: 57.00307846069336\n",
      "      vf_explained_var: 0.8935893177986145\n",
      "      vf_loss: 56.99498748779297\n",
      "    sample_time_ms: 18217.109\n",
      "    update_time_ms: 4.886\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 15.15098143870058\n",
      "  time_since_restore: 12972.530080080032\n",
      "  time_this_iter_s: 22.5078604221344\n",
      "  time_total_s: 12972.530080080032\n",
      "  timestamp: 1553134791\n",
      "  timesteps_since_restore: 5890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5890000\n",
      "  training_iteration: 589\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12972 s, 589 iter, 5890000 ts, 30.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-20-13\n",
      "  done: false\n",
      "  episode_len_mean: 77.2442748091603\n",
      "  episode_reward_max: 386.45010119711804\n",
      "  episode_reward_mean: 75.51847838552989\n",
      "  episode_reward_min: -166.8220857462549\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 73927\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.85\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 5900000\n",
      "    num_steps_trained: 5900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5502435564994812\n",
      "      kl: 0.02055427059531212\n",
      "      policy_loss: 0.003105984767898917\n",
      "      total_loss: 44.22060775756836\n",
      "      vf_explained_var: 0.9074325561523438\n",
      "      vf_loss: 44.21474838256836\n",
      "    sample_time_ms: 18305.32\n",
      "    update_time_ms: 5.136\n",
      "  iterations_since_restore: 590\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.759239192764944\n",
      "  time_since_restore: 12994.592609405518\n",
      "  time_this_iter_s: 22.06252932548523\n",
      "  time_total_s: 12994.592609405518\n",
      "  timestamp: 1553134813\n",
      "  timesteps_since_restore: 5900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5900000\n",
      "  training_iteration: 590\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 12994 s, 590 iter, 5900000 ts, 75.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-20-35\n",
      "  done: false\n",
      "  episode_len_mean: 76.18320610687023\n",
      "  episode_reward_max: 387.6741997778589\n",
      "  episode_reward_mean: 67.51291467713064\n",
      "  episode_reward_min: -164.67812704977035\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 74058\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.287\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 5910000\n",
      "    num_steps_trained: 5910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.561142086982727\n",
      "      kl: 0.019521255046129227\n",
      "      policy_loss: 0.0036900753621011972\n",
      "      total_loss: 41.75278091430664\n",
      "      vf_explained_var: 0.9127996563911438\n",
      "      vf_loss: 41.746482849121094\n",
      "    sample_time_ms: 18213.798\n",
      "    update_time_ms: 5.04\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.756457338565305\n",
      "  time_since_restore: 13016.014286756516\n",
      "  time_this_iter_s: 21.421677350997925\n",
      "  time_total_s: 13016.014286756516\n",
      "  timestamp: 1553134835\n",
      "  timesteps_since_restore: 5910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5910000\n",
      "  training_iteration: 591\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13016 s, 591 iter, 5910000 ts, 67.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-20-57\n",
      "  done: false\n",
      "  episode_len_mean: 77.8046875\n",
      "  episode_reward_max: 388.07328146171125\n",
      "  episode_reward_mean: 78.63732757844966\n",
      "  episode_reward_min: -168.755369676795\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 74186\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.737\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 5920000\n",
      "    num_steps_trained: 5920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5510202050209045\n",
      "      kl: 0.01682448759675026\n",
      "      policy_loss: 0.0026107188314199448\n",
      "      total_loss: 58.39201354980469\n",
      "      vf_explained_var: 0.8746934533119202\n",
      "      vf_loss: 58.387149810791016\n",
      "    sample_time_ms: 18256.806\n",
      "    update_time_ms: 5.176\n",
      "  iterations_since_restore: 592\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.31866378922482\n",
      "  time_since_restore: 13038.392114400864\n",
      "  time_this_iter_s: 22.377827644348145\n",
      "  time_total_s: 13038.392114400864\n",
      "  timestamp: 1553134857\n",
      "  timesteps_since_restore: 5920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5920000\n",
      "  training_iteration: 592\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13038 s, 592 iter, 5920000 ts, 78.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-21-19\n",
      "  done: false\n",
      "  episode_len_mean: 74.62962962962963\n",
      "  episode_reward_max: 387.1359778270769\n",
      "  episode_reward_mean: 58.55842411946543\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 74321\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.691\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 5930000\n",
      "    num_steps_trained: 5930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5893109440803528\n",
      "      kl: 0.01902235485613346\n",
      "      policy_loss: 0.006071142386645079\n",
      "      total_loss: 50.18386459350586\n",
      "      vf_explained_var: 0.8987078666687012\n",
      "      vf_loss: 50.17524337768555\n",
      "    sample_time_ms: 18279.092\n",
      "    update_time_ms: 5.022\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.27921205973271\n",
      "  time_since_restore: 13060.298957824707\n",
      "  time_this_iter_s: 21.906843423843384\n",
      "  time_total_s: 13060.298957824707\n",
      "  timestamp: 1553134879\n",
      "  timesteps_since_restore: 5930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5930000\n",
      "  training_iteration: 593\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13060 s, 593 iter, 5930000 ts, 58.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-21-41\n",
      "  done: false\n",
      "  episode_len_mean: 76.8125\n",
      "  episode_reward_max: 385.83385750841796\n",
      "  episode_reward_mean: 71.11177931990855\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 74449\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.945\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 5940000\n",
      "    num_steps_trained: 5940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5640032291412354\n",
      "      kl: 0.016989899799227715\n",
      "      policy_loss: 0.004386354703456163\n",
      "      total_loss: 47.295166015625\n",
      "      vf_explained_var: 0.8999766707420349\n",
      "      vf_loss: 47.28850555419922\n",
      "    sample_time_ms: 18257.808\n",
      "    update_time_ms: 5.027\n",
      "  iterations_since_restore: 594\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.55588965995428\n",
      "  time_since_restore: 13082.300847053528\n",
      "  time_this_iter_s: 22.0018892288208\n",
      "  time_total_s: 13082.300847053528\n",
      "  timestamp: 1553134901\n",
      "  timesteps_since_restore: 5940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5940000\n",
      "  training_iteration: 594\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13082 s, 594 iter, 5940000 ts, 71.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-22-03\n",
      "  done: false\n",
      "  episode_len_mean: 78.21705426356588\n",
      "  episode_reward_max: 388.3148497210612\n",
      "  episode_reward_mean: 83.32396315806757\n",
      "  episode_reward_min: -166.75219843145848\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 74578\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.624\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 5950000\n",
      "    num_steps_trained: 5950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.581146240234375\n",
      "      kl: 0.021767569705843925\n",
      "      policy_loss: 0.0018605866935104132\n",
      "      total_loss: 49.91548538208008\n",
      "      vf_explained_var: 0.8933736085891724\n",
      "      vf_loss: 49.910709381103516\n",
      "    sample_time_ms: 18167.36\n",
      "    update_time_ms: 4.993\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.661981579033785\n",
      "  time_since_restore: 13103.495748758316\n",
      "  time_this_iter_s: 21.194901704788208\n",
      "  time_total_s: 13103.495748758316\n",
      "  timestamp: 1553134923\n",
      "  timesteps_since_restore: 5950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5950000\n",
      "  training_iteration: 595\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13103 s, 595 iter, 5950000 ts, 83.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-22-24\n",
      "  done: false\n",
      "  episode_len_mean: 78.109375\n",
      "  episode_reward_max: 387.4259898486897\n",
      "  episode_reward_mean: 85.29639159486617\n",
      "  episode_reward_min: -165.06489887174607\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 74706\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.454\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 5960000\n",
      "    num_steps_trained: 5960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5770347714424133\n",
      "      kl: 0.016355877742171288\n",
      "      policy_loss: 0.003362113842740655\n",
      "      total_loss: 46.50764083862305\n",
      "      vf_explained_var: 0.8995521664619446\n",
      "      vf_loss: 46.5020866394043\n",
      "    sample_time_ms: 18172.075\n",
      "    update_time_ms: 4.999\n",
      "  iterations_since_restore: 596\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.64819579743309\n",
      "  time_since_restore: 13124.925378084183\n",
      "  time_this_iter_s: 21.4296293258667\n",
      "  time_total_s: 13124.925378084183\n",
      "  timestamp: 1553134944\n",
      "  timesteps_since_restore: 5960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5960000\n",
      "  training_iteration: 596\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13124 s, 596 iter, 5960000 ts, 85.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 73.66666666666667\n",
      "  episode_reward_max: 389.3805070590192\n",
      "  episode_reward_mean: 53.92359932992115\n",
      "  episode_reward_min: -166.7346958217287\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 74841\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.291\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 5970000\n",
      "    num_steps_trained: 5970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5917608141899109\n",
      "      kl: 0.022466881200671196\n",
      "      policy_loss: 0.005475796293467283\n",
      "      total_loss: 52.3448486328125\n",
      "      vf_explained_var: 0.8965850472450256\n",
      "      vf_loss: 52.33636474609375\n",
      "    sample_time_ms: 18210.318\n",
      "    update_time_ms: 5.064\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.961799664960576\n",
      "  time_since_restore: 13147.237393379211\n",
      "  time_this_iter_s: 22.312015295028687\n",
      "  time_total_s: 13147.237393379211\n",
      "  timestamp: 1553134966\n",
      "  timesteps_since_restore: 5970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5970000\n",
      "  training_iteration: 597\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13147 s, 597 iter, 5970000 ts, 53.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-23-07\n",
      "  done: false\n",
      "  episode_len_mean: 80.53968253968254\n",
      "  episode_reward_max: 391.1602944147354\n",
      "  episode_reward_mean: 94.25578529767549\n",
      "  episode_reward_min: -166.74868743010998\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 74967\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.059\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 5980000\n",
      "    num_steps_trained: 5980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5578569769859314\n",
      "      kl: 0.013997514732182026\n",
      "      policy_loss: 0.0015428602928295732\n",
      "      total_loss: 47.90274429321289\n",
      "      vf_explained_var: 0.8902655243873596\n",
      "      vf_loss: 47.89932632446289\n",
      "    sample_time_ms: 18079.087\n",
      "    update_time_ms: 5.144\n",
      "  iterations_since_restore: 598\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.127892648837744\n",
      "  time_since_restore: 13168.216853618622\n",
      "  time_this_iter_s: 20.9794602394104\n",
      "  time_total_s: 13168.216853618622\n",
      "  timestamp: 1553134987\n",
      "  timesteps_since_restore: 5980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5980000\n",
      "  training_iteration: 598\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13168 s, 598 iter, 5980000 ts, 94.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-23-29\n",
      "  done: false\n",
      "  episode_len_mean: 77.97637795275591\n",
      "  episode_reward_max: 385.49554231899265\n",
      "  episode_reward_mean: 74.3068309807706\n",
      "  episode_reward_min: -164.9763052200937\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 75094\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.557\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 5990000\n",
      "    num_steps_trained: 5990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.587683916091919\n",
      "      kl: 0.027035465463995934\n",
      "      policy_loss: 0.006315581500530243\n",
      "      total_loss: 46.79563522338867\n",
      "      vf_explained_var: 0.8980004787445068\n",
      "      vf_loss: 46.785701751708984\n",
      "    sample_time_ms: 17980.85\n",
      "    update_time_ms: 5.136\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.1534154903853\n",
      "  time_since_restore: 13189.722725391388\n",
      "  time_this_iter_s: 21.505871772766113\n",
      "  time_total_s: 13189.722725391388\n",
      "  timestamp: 1553135009\n",
      "  timesteps_since_restore: 5990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5990000\n",
      "  training_iteration: 599\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13189 s, 599 iter, 5990000 ts, 74.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-23-51\n",
      "  done: false\n",
      "  episode_len_mean: 79.4920634920635\n",
      "  episode_reward_max: 390.2093403032588\n",
      "  episode_reward_mean: 94.24930578470752\n",
      "  episode_reward_min: -168.74414048048496\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 75220\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.357\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 6000000\n",
      "    num_steps_trained: 6000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5601205229759216\n",
      "      kl: 0.018413299694657326\n",
      "      policy_loss: 0.002655142219737172\n",
      "      total_loss: 40.963653564453125\n",
      "      vf_explained_var: 0.9089791774749756\n",
      "      vf_loss: 40.958534240722656\n",
      "    sample_time_ms: 17969.326\n",
      "    update_time_ms: 4.863\n",
      "  iterations_since_restore: 600\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.12465289235375\n",
      "  time_since_restore: 13211.635871887207\n",
      "  time_this_iter_s: 21.913146495819092\n",
      "  time_total_s: 13211.635871887207\n",
      "  timestamp: 1553135031\n",
      "  timesteps_since_restore: 6000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6000000\n",
      "  training_iteration: 600\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13211 s, 600 iter, 6000000 ts, 94.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-24-13\n",
      "  done: false\n",
      "  episode_len_mean: 72.73722627737226\n",
      "  episode_reward_max: 382.1182131169299\n",
      "  episode_reward_mean: 43.92926400398364\n",
      "  episode_reward_min: -166.71654538198948\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 75357\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.775\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 6010000\n",
      "    num_steps_trained: 6010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5820992588996887\n",
      "      kl: 0.025060376152396202\n",
      "      policy_loss: 0.005065592937171459\n",
      "      total_loss: 49.30611038208008\n",
      "      vf_explained_var: 0.9055199027061462\n",
      "      vf_loss: 49.29768753051758\n",
      "    sample_time_ms: 18056.8\n",
      "    update_time_ms: 5.143\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.96463200199182\n",
      "  time_since_restore: 13233.948018074036\n",
      "  time_this_iter_s: 22.312146186828613\n",
      "  time_total_s: 13233.948018074036\n",
      "  timestamp: 1553135053\n",
      "  timesteps_since_restore: 6010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6010000\n",
      "  training_iteration: 601\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13233 s, 601 iter, 6010000 ts, 43.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-24-35\n",
      "  done: false\n",
      "  episode_len_mean: 77.63846153846154\n",
      "  episode_reward_max: 387.4650897915725\n",
      "  episode_reward_mean: 81.10806597341637\n",
      "  episode_reward_min: -164.70832308348656\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 75487\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.12\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 6020000\n",
      "    num_steps_trained: 6020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5964846611022949\n",
      "      kl: 0.016393529251217842\n",
      "      policy_loss: 0.004742647521197796\n",
      "      total_loss: 60.717323303222656\n",
      "      vf_explained_var: 0.8701112270355225\n",
      "      vf_loss: 60.71038055419922\n",
      "    sample_time_ms: 18017.244\n",
      "    update_time_ms: 5.0\n",
      "  iterations_since_restore: 602\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.554032986708194\n",
      "  time_since_restore: 13255.940360307693\n",
      "  time_this_iter_s: 21.992342233657837\n",
      "  time_total_s: 13255.940360307693\n",
      "  timestamp: 1553135075\n",
      "  timesteps_since_restore: 6020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6020000\n",
      "  training_iteration: 602\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13255 s, 602 iter, 6020000 ts, 81.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-24-58\n",
      "  done: false\n",
      "  episode_len_mean: 76.12213740458016\n",
      "  episode_reward_max: 386.51619602564136\n",
      "  episode_reward_mean: 67.98758301916524\n",
      "  episode_reward_min: -167.0285614587927\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 75618\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.423\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 6030000\n",
      "    num_steps_trained: 6030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5807417631149292\n",
      "      kl: 0.02533375471830368\n",
      "      policy_loss: 0.005390289705246687\n",
      "      total_loss: 56.0388298034668\n",
      "      vf_explained_var: 0.8844499588012695\n",
      "      vf_loss: 56.0300407409668\n",
      "    sample_time_ms: 18060.467\n",
      "    update_time_ms: 5.045\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.993791509582614\n",
      "  time_since_restore: 13278.284942865372\n",
      "  time_this_iter_s: 22.344582557678223\n",
      "  time_total_s: 13278.284942865372\n",
      "  timestamp: 1553135098\n",
      "  timesteps_since_restore: 6030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6030000\n",
      "  training_iteration: 603\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13278 s, 603 iter, 6030000 ts, 68 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-25-20\n",
      "  done: false\n",
      "  episode_len_mean: 76.41221374045801\n",
      "  episode_reward_max: 386.01243608436033\n",
      "  episode_reward_mean: 67.1053072587761\n",
      "  episode_reward_min: -168.80837392517566\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 75749\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.573\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 6040000\n",
      "    num_steps_trained: 6040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5967769026756287\n",
      "      kl: 0.019556421786546707\n",
      "      policy_loss: 0.0016241177218034863\n",
      "      total_loss: 54.5439567565918\n",
      "      vf_explained_var: 0.8892620801925659\n",
      "      vf_loss: 54.53971481323242\n",
      "    sample_time_ms: 18137.375\n",
      "    update_time_ms: 5.015\n",
      "  iterations_since_restore: 604\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.55265362938803\n",
      "  time_since_restore: 13300.768788576126\n",
      "  time_this_iter_s: 22.483845710754395\n",
      "  time_total_s: 13300.768788576126\n",
      "  timestamp: 1553135120\n",
      "  timesteps_since_restore: 6040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6040000\n",
      "  training_iteration: 604\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13300 s, 604 iter, 6040000 ts, 67.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-25-42\n",
      "  done: false\n",
      "  episode_len_mean: 80.16\n",
      "  episode_reward_max: 387.9092004973642\n",
      "  episode_reward_mean: 93.33959765248208\n",
      "  episode_reward_min: -160.43563321336745\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 75874\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.015\n",
      "    load_time_ms: 1.656\n",
      "    num_steps_sampled: 6050000\n",
      "    num_steps_trained: 6050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5950236320495605\n",
      "      kl: 0.018287552520632744\n",
      "      policy_loss: 0.004204655531793833\n",
      "      total_loss: 55.1892204284668\n",
      "      vf_explained_var: 0.8730213642120361\n",
      "      vf_loss: 55.18256759643555\n",
      "    sample_time_ms: 18226.399\n",
      "    update_time_ms: 5.183\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.66979882624105\n",
      "  time_since_restore: 13322.988776445389\n",
      "  time_this_iter_s: 22.219987869262695\n",
      "  time_total_s: 13322.988776445389\n",
      "  timestamp: 1553135142\n",
      "  timesteps_since_restore: 6050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6050000\n",
      "  training_iteration: 605\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13322 s, 605 iter, 6050000 ts, 93.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-26-04\n",
      "  done: false\n",
      "  episode_len_mean: 78.18110236220473\n",
      "  episode_reward_max: 387.4849523674595\n",
      "  episode_reward_mean: 81.4527249976325\n",
      "  episode_reward_min: -164.71346698829174\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 76001\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.325\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 6060000\n",
      "    num_steps_trained: 6060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6029678583145142\n",
      "      kl: 0.016333719715476036\n",
      "      policy_loss: 0.00526648061349988\n",
      "      total_loss: 45.82893371582031\n",
      "      vf_explained_var: 0.8990097045898438\n",
      "      vf_loss: 45.82148361206055\n",
      "    sample_time_ms: 18268.238\n",
      "    update_time_ms: 5.279\n",
      "  iterations_since_restore: 606\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.726362498816236\n",
      "  time_since_restore: 13344.83188867569\n",
      "  time_this_iter_s: 21.843112230300903\n",
      "  time_total_s: 13344.83188867569\n",
      "  timestamp: 1553135164\n",
      "  timesteps_since_restore: 6060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6060000\n",
      "  training_iteration: 606\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13344 s, 606 iter, 6060000 ts, 81.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-26-26\n",
      "  done: false\n",
      "  episode_len_mean: 80.25806451612904\n",
      "  episode_reward_max: 387.9889018410914\n",
      "  episode_reward_mean: 103.89431973823439\n",
      "  episode_reward_min: -168.7137486675644\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 76125\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.51\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 6070000\n",
      "    num_steps_trained: 6070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.547692596912384\n",
      "      kl: 0.01992245391011238\n",
      "      policy_loss: 0.004645378328859806\n",
      "      total_loss: 59.22706985473633\n",
      "      vf_explained_var: 0.859237790107727\n",
      "      vf_loss: 59.219757080078125\n",
      "    sample_time_ms: 18221.32\n",
      "    update_time_ms: 5.309\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.94715986911718\n",
      "  time_since_restore: 13366.653254270554\n",
      "  time_this_iter_s: 21.82136559486389\n",
      "  time_total_s: 13366.653254270554\n",
      "  timestamp: 1553135186\n",
      "  timesteps_since_restore: 6070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6070000\n",
      "  training_iteration: 607\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13366 s, 607 iter, 6070000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-26-48\n",
      "  done: false\n",
      "  episode_len_mean: 71.57142857142857\n",
      "  episode_reward_max: 387.9997240611476\n",
      "  episode_reward_mean: 40.398067187682884\n",
      "  episode_reward_min: -164.6753978838587\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 76265\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.176\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 6080000\n",
      "    num_steps_trained: 6080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6026491522789001\n",
      "      kl: 0.016146162524819374\n",
      "      policy_loss: 0.0037614558823406696\n",
      "      total_loss: 52.943721771240234\n",
      "      vf_explained_var: 0.9008235335350037\n",
      "      vf_loss: 52.937801361083984\n",
      "    sample_time_ms: 18322.188\n",
      "    update_time_ms: 5.318\n",
      "  iterations_since_restore: 608\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.19903359384144\n",
      "  time_since_restore: 13388.625437498093\n",
      "  time_this_iter_s: 21.972183227539062\n",
      "  time_total_s: 13388.625437498093\n",
      "  timestamp: 1553135208\n",
      "  timesteps_since_restore: 6080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6080000\n",
      "  training_iteration: 608\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13388 s, 608 iter, 6080000 ts, 40.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-27-10\n",
      "  done: false\n",
      "  episode_len_mean: 75.81954887218045\n",
      "  episode_reward_max: 388.02307712934686\n",
      "  episode_reward_mean: 68.38874273326267\n",
      "  episode_reward_min: -164.72935741111277\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 76398\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.183\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 6090000\n",
      "    num_steps_trained: 6090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5863374471664429\n",
      "      kl: 0.022173259407281876\n",
      "      policy_loss: 0.004081905819475651\n",
      "      total_loss: 51.98470687866211\n",
      "      vf_explained_var: 0.8942419290542603\n",
      "      vf_loss: 51.977657318115234\n",
      "    sample_time_ms: 18371.661\n",
      "    update_time_ms: 5.478\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.19437136663133\n",
      "  time_since_restore: 13410.747658491135\n",
      "  time_this_iter_s: 22.122220993041992\n",
      "  time_total_s: 13410.747658491135\n",
      "  timestamp: 1553135230\n",
      "  timesteps_since_restore: 6090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6090000\n",
      "  training_iteration: 609\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13410 s, 609 iter, 6090000 ts, 68.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-27-32\n",
      "  done: false\n",
      "  episode_len_mean: 72.10071942446044\n",
      "  episode_reward_max: 388.0179451262628\n",
      "  episode_reward_mean: 43.42024245762768\n",
      "  episode_reward_min: -168.82969947704316\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 76537\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.359\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 6100000\n",
      "    num_steps_trained: 6100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6132031679153442\n",
      "      kl: 0.018718285486102104\n",
      "      policy_loss: 0.0037628328427672386\n",
      "      total_loss: 61.518741607666016\n",
      "      vf_explained_var: 0.8824967741966248\n",
      "      vf_loss: 61.51247024536133\n",
      "    sample_time_ms: 18335.193\n",
      "    update_time_ms: 5.549\n",
      "  iterations_since_restore: 610\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.710121228813836\n",
      "  time_since_restore: 13432.307208776474\n",
      "  time_this_iter_s: 21.559550285339355\n",
      "  time_total_s: 13432.307208776474\n",
      "  timestamp: 1553135252\n",
      "  timesteps_since_restore: 6100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6100000\n",
      "  training_iteration: 610\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13432 s, 610 iter, 6100000 ts, 43.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-27-54\n",
      "  done: false\n",
      "  episode_len_mean: 77.703125\n",
      "  episode_reward_max: 387.96337456458843\n",
      "  episode_reward_mean: 83.12813633109258\n",
      "  episode_reward_min: -166.7167020980978\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 76665\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.476\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 6110000\n",
      "    num_steps_trained: 6110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.57366544008255\n",
      "      kl: 0.021553659811615944\n",
      "      policy_loss: 0.009262465871870518\n",
      "      total_loss: 62.88389587402344\n",
      "      vf_explained_var: 0.8618054389953613\n",
      "      vf_loss: 62.87174606323242\n",
      "    sample_time_ms: 18331.129\n",
      "    update_time_ms: 5.333\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.5640681655463\n",
      "  time_since_restore: 13454.547855615616\n",
      "  time_this_iter_s: 22.240646839141846\n",
      "  time_total_s: 13454.547855615616\n",
      "  timestamp: 1553135274\n",
      "  timesteps_since_restore: 6110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6110000\n",
      "  training_iteration: 611\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13454 s, 611 iter, 6110000 ts, 83.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-28-16\n",
      "  done: false\n",
      "  episode_len_mean: 75.87786259541984\n",
      "  episode_reward_max: 385.352010981276\n",
      "  episode_reward_mean: 67.1259160821324\n",
      "  episode_reward_min: -162.69003458830355\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 76796\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.014\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 6120000\n",
      "    num_steps_trained: 6120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5773769617080688\n",
      "      kl: 0.01757325977087021\n",
      "      policy_loss: 0.001704078633338213\n",
      "      total_loss: 53.75446319580078\n",
      "      vf_explained_var: 0.8875604271888733\n",
      "      vf_loss: 53.75040817260742\n",
      "    sample_time_ms: 18330.447\n",
      "    update_time_ms: 5.507\n",
      "  iterations_since_restore: 612\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.5629580410662\n",
      "  time_since_restore: 13476.545113325119\n",
      "  time_this_iter_s: 21.997257709503174\n",
      "  time_total_s: 13476.545113325119\n",
      "  timestamp: 1553135296\n",
      "  timesteps_since_restore: 6120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6120000\n",
      "  training_iteration: 612\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13476 s, 612 iter, 6120000 ts, 67.1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-28-38\n",
      "  done: false\n",
      "  episode_len_mean: 77.37209302325581\n",
      "  episode_reward_max: 387.56881171390495\n",
      "  episode_reward_mean: 75.2268197742511\n",
      "  episode_reward_min: -168.7724656057024\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 76925\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.561\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 6130000\n",
      "    num_steps_trained: 6130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6008560657501221\n",
      "      kl: 0.023525012657046318\n",
      "      policy_loss: 0.0035606634337455034\n",
      "      total_loss: 49.11646270751953\n",
      "      vf_explained_var: 0.897987961769104\n",
      "      vf_loss: 49.10974884033203\n",
      "    sample_time_ms: 18268.194\n",
      "    update_time_ms: 5.403\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.61340988712555\n",
      "  time_since_restore: 13498.289233446121\n",
      "  time_this_iter_s: 21.744120121002197\n",
      "  time_total_s: 13498.289233446121\n",
      "  timestamp: 1553135318\n",
      "  timesteps_since_restore: 6130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6130000\n",
      "  training_iteration: 613\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13498 s, 613 iter, 6130000 ts, 75.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-29-00\n",
      "  done: false\n",
      "  episode_len_mean: 74.33582089552239\n",
      "  episode_reward_max: 387.8570045936228\n",
      "  episode_reward_mean: 62.50552483303533\n",
      "  episode_reward_min: -166.80602369996546\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 77059\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.467\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 6140000\n",
      "    num_steps_trained: 6140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5729137063026428\n",
      "      kl: 0.015117486007511616\n",
      "      policy_loss: 0.003011060878634453\n",
      "      total_loss: 56.48706817626953\n",
      "      vf_explained_var: 0.887033224105835\n",
      "      vf_loss: 56.482032775878906\n",
      "    sample_time_ms: 18243.23\n",
      "    update_time_ms: 5.406\n",
      "  iterations_since_restore: 614\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.252762416517673\n",
      "  time_since_restore: 13520.531262159348\n",
      "  time_this_iter_s: 22.24202871322632\n",
      "  time_total_s: 13520.531262159348\n",
      "  timestamp: 1553135340\n",
      "  timesteps_since_restore: 6140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6140000\n",
      "  training_iteration: 614\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13520 s, 614 iter, 6140000 ts, 62.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-29-22\n",
      "  done: false\n",
      "  episode_len_mean: 81.184\n",
      "  episode_reward_max: 387.74859986313606\n",
      "  episode_reward_mean: 110.54440210947277\n",
      "  episode_reward_min: -168.85315094121933\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 77184\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.906\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 6150000\n",
      "    num_steps_trained: 6150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5601310729980469\n",
      "      kl: 0.019338469952344894\n",
      "      policy_loss: 0.005463744048029184\n",
      "      total_loss: 44.025291442871094\n",
      "      vf_explained_var: 0.8962492346763611\n",
      "      vf_loss: 44.017234802246094\n",
      "    sample_time_ms: 18237.66\n",
      "    update_time_ms: 5.395\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.27220105473637\n",
      "  time_since_restore: 13542.601795434952\n",
      "  time_this_iter_s: 22.070533275604248\n",
      "  time_total_s: 13542.601795434952\n",
      "  timestamp: 1553135362\n",
      "  timesteps_since_restore: 6150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6150000\n",
      "  training_iteration: 615\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13542 s, 615 iter, 6150000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-29-44\n",
      "  done: false\n",
      "  episode_len_mean: 76.93023255813954\n",
      "  episode_reward_max: 385.1424920875835\n",
      "  episode_reward_mean: 74.04250673839942\n",
      "  episode_reward_min: -166.78102166434766\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 77313\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.755\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 6160000\n",
      "    num_steps_trained: 6160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5946908593177795\n",
      "      kl: 0.02100335992872715\n",
      "      policy_loss: 0.006821479648351669\n",
      "      total_loss: 43.40633010864258\n",
      "      vf_explained_var: 0.90763920545578\n",
      "      vf_loss: 43.396690368652344\n",
      "    sample_time_ms: 18165.353\n",
      "    update_time_ms: 5.322\n",
      "  iterations_since_restore: 616\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.02125336919971\n",
      "  time_since_restore: 13563.742112159729\n",
      "  time_this_iter_s: 21.14031672477722\n",
      "  time_total_s: 13563.742112159729\n",
      "  timestamp: 1553135384\n",
      "  timesteps_since_restore: 6160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6160000\n",
      "  training_iteration: 616\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13563 s, 616 iter, 6160000 ts, 74 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-30-05\n",
      "  done: false\n",
      "  episode_len_mean: 76.79389312977099\n",
      "  episode_reward_max: 393.15724084135445\n",
      "  episode_reward_mean: 76.36872803156388\n",
      "  episode_reward_min: -167.0585513158703\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 77444\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.161\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 6170000\n",
      "    num_steps_trained: 6170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5988593697547913\n",
      "      kl: 0.02971835620701313\n",
      "      policy_loss: 0.004067594185471535\n",
      "      total_loss: 53.85758590698242\n",
      "      vf_explained_var: 0.8868829607963562\n",
      "      vf_loss: 53.84952926635742\n",
      "    sample_time_ms: 18159.821\n",
      "    update_time_ms: 5.259\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.18436401578194\n",
      "  time_since_restore: 13585.563599586487\n",
      "  time_this_iter_s: 21.821487426757812\n",
      "  time_total_s: 13585.563599586487\n",
      "  timestamp: 1553135405\n",
      "  timesteps_since_restore: 6170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6170000\n",
      "  training_iteration: 617\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13585 s, 617 iter, 6170000 ts, 76.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-30-28\n",
      "  done: false\n",
      "  episode_len_mean: 73.91044776119404\n",
      "  episode_reward_max: 387.38938378750856\n",
      "  episode_reward_mean: 51.61575397434443\n",
      "  episode_reward_min: -168.70116422053815\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 77578\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.392\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 6180000\n",
      "    num_steps_trained: 6180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5936703681945801\n",
      "      kl: 0.019448090344667435\n",
      "      policy_loss: 0.004100281745195389\n",
      "      total_loss: 55.5622673034668\n",
      "      vf_explained_var: 0.8897783160209656\n",
      "      vf_loss: 55.555564880371094\n",
      "    sample_time_ms: 18164.379\n",
      "    update_time_ms: 5.33\n",
      "  iterations_since_restore: 618\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.80787698717221\n",
      "  time_since_restore: 13607.605785369873\n",
      "  time_this_iter_s: 22.04218578338623\n",
      "  time_total_s: 13607.605785369873\n",
      "  timestamp: 1553135428\n",
      "  timesteps_since_restore: 6180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6180000\n",
      "  training_iteration: 618\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13607 s, 618 iter, 6180000 ts, 51.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-30-49\n",
      "  done: false\n",
      "  episode_len_mean: 73.72058823529412\n",
      "  episode_reward_max: 387.79556038871107\n",
      "  episode_reward_mean: 52.52411666244541\n",
      "  episode_reward_min: -165.28104897662638\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 77714\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.016\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 6190000\n",
      "    num_steps_trained: 6190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5829249024391174\n",
      "      kl: 0.017859479412436485\n",
      "      policy_loss: 0.0026462057139724493\n",
      "      total_loss: 57.91358184814453\n",
      "      vf_explained_var: 0.8866592645645142\n",
      "      vf_loss: 57.90854263305664\n",
      "    sample_time_ms: 18147.647\n",
      "    update_time_ms: 5.096\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.262058331222708\n",
      "  time_since_restore: 13629.465598583221\n",
      "  time_this_iter_s: 21.85981321334839\n",
      "  time_total_s: 13629.465598583221\n",
      "  timestamp: 1553135449\n",
      "  timesteps_since_restore: 6190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6190000\n",
      "  training_iteration: 619\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13629 s, 619 iter, 6190000 ts, 52.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-31-12\n",
      "  done: false\n",
      "  episode_len_mean: 78.0077519379845\n",
      "  episode_reward_max: 386.5178114892849\n",
      "  episode_reward_mean: 82.49009182505175\n",
      "  episode_reward_min: -163.10736700912952\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 77843\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.322\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 6200000\n",
      "    num_steps_trained: 6200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5653829574584961\n",
      "      kl: 0.019457532092928886\n",
      "      policy_loss: 0.004968057852238417\n",
      "      total_loss: 45.158077239990234\n",
      "      vf_explained_var: 0.9038183689117432\n",
      "      vf_loss: 45.150508880615234\n",
      "    sample_time_ms: 18187.328\n",
      "    update_time_ms: 5.058\n",
      "  iterations_since_restore: 620\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.245045912525875\n",
      "  time_since_restore: 13651.603199005127\n",
      "  time_this_iter_s: 22.137600421905518\n",
      "  time_total_s: 13651.603199005127\n",
      "  timestamp: 1553135472\n",
      "  timesteps_since_restore: 6200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6200000\n",
      "  training_iteration: 620\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13651 s, 620 iter, 6200000 ts, 82.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-31-33\n",
      "  done: false\n",
      "  episode_len_mean: 75.01503759398496\n",
      "  episode_reward_max: 387.96462225216027\n",
      "  episode_reward_mean: 57.34811316723567\n",
      "  episode_reward_min: -166.73768987521171\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 77976\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.487\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 6210000\n",
      "    num_steps_trained: 6210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5696275234222412\n",
      "      kl: 0.016555076465010643\n",
      "      policy_loss: 0.0020924173295497894\n",
      "      total_loss: 52.65846633911133\n",
      "      vf_explained_var: 0.8935768008232117\n",
      "      vf_loss: 52.65415954589844\n",
      "    sample_time_ms: 18112.018\n",
      "    update_time_ms: 5.052\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.67405658361783\n",
      "  time_since_restore: 13673.103478193283\n",
      "  time_this_iter_s: 21.500279188156128\n",
      "  time_total_s: 13673.103478193283\n",
      "  timestamp: 1553135493\n",
      "  timesteps_since_restore: 6210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6210000\n",
      "  training_iteration: 621\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13673 s, 621 iter, 6210000 ts, 57.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-31-55\n",
      "  done: false\n",
      "  episode_len_mean: 82.47933884297521\n",
      "  episode_reward_max: 385.1096368759855\n",
      "  episode_reward_mean: 113.16437323180523\n",
      "  episode_reward_min: -162.68392653640745\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 78097\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.969\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 6220000\n",
      "    num_steps_trained: 6220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5410966277122498\n",
      "      kl: 0.016472473740577698\n",
      "      policy_loss: 0.0062702372670173645\n",
      "      total_loss: 48.917049407958984\n",
      "      vf_explained_var: 0.8811099529266357\n",
      "      vf_loss: 48.908573150634766\n",
      "    sample_time_ms: 18080.287\n",
      "    update_time_ms: 4.865\n",
      "  iterations_since_restore: 622\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.5821866159026\n",
      "  time_since_restore: 13694.764667272568\n",
      "  time_this_iter_s: 21.661189079284668\n",
      "  time_total_s: 13694.764667272568\n",
      "  timestamp: 1553135515\n",
      "  timesteps_since_restore: 6220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6220000\n",
      "  training_iteration: 622\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13694 s, 622 iter, 6220000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-32-16\n",
      "  done: false\n",
      "  episode_len_mean: 75.22727272727273\n",
      "  episode_reward_max: 388.40674901480895\n",
      "  episode_reward_mean: 53.81679963980729\n",
      "  episode_reward_min: -164.68540221890447\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 78229\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.581\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 6230000\n",
      "    num_steps_trained: 6230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.587513267993927\n",
      "      kl: 0.01401565968990326\n",
      "      policy_loss: 0.0015777784865349531\n",
      "      total_loss: 62.87488555908203\n",
      "      vf_explained_var: 0.873261570930481\n",
      "      vf_loss: 62.87143325805664\n",
      "    sample_time_ms: 18060.14\n",
      "    update_time_ms: 4.88\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.908399819903646\n",
      "  time_since_restore: 13716.27452325821\n",
      "  time_this_iter_s: 21.50985598564148\n",
      "  time_total_s: 13716.27452325821\n",
      "  timestamp: 1553135536\n",
      "  timesteps_since_restore: 6230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6230000\n",
      "  training_iteration: 623\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13716 s, 623 iter, 6230000 ts, 53.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-32-38\n",
      "  done: false\n",
      "  episode_len_mean: 76.04545454545455\n",
      "  episode_reward_max: 385.64983556817816\n",
      "  episode_reward_mean: 69.18007371753916\n",
      "  episode_reward_min: -166.73238131400586\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 78361\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.241\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 6240000\n",
      "    num_steps_trained: 6240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5830312967300415\n",
      "      kl: 0.017275473102927208\n",
      "      policy_loss: 0.004110538866370916\n",
      "      total_loss: 46.673370361328125\n",
      "      vf_explained_var: 0.9050355553627014\n",
      "      vf_loss: 46.66695022583008\n",
      "    sample_time_ms: 17981.247\n",
      "    update_time_ms: 5.018\n",
      "  iterations_since_restore: 624\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.59003685876958\n",
      "  time_since_restore: 13737.706863164902\n",
      "  time_this_iter_s: 21.432339906692505\n",
      "  time_total_s: 13737.706863164902\n",
      "  timestamp: 1553135558\n",
      "  timesteps_since_restore: 6240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6240000\n",
      "  training_iteration: 624\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13737 s, 624 iter, 6240000 ts, 69.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-33-00\n",
      "  done: false\n",
      "  episode_len_mean: 78.3828125\n",
      "  episode_reward_max: 388.09428202889677\n",
      "  episode_reward_mean: 80.97033968082911\n",
      "  episode_reward_min: -166.75132541259765\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 78489\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.221\n",
      "    load_time_ms: 1.625\n",
      "    num_steps_sampled: 6250000\n",
      "    num_steps_trained: 6250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5823803544044495\n",
      "      kl: 0.024125536903738976\n",
      "      policy_loss: 0.006928673945367336\n",
      "      total_loss: 53.92233657836914\n",
      "      vf_explained_var: 0.8824660181999207\n",
      "      vf_loss: 53.91217803955078\n",
      "    sample_time_ms: 17940.386\n",
      "    update_time_ms: 4.99\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.485169840414564\n",
      "  time_since_restore: 13759.34814453125\n",
      "  time_this_iter_s: 21.641281366348267\n",
      "  time_total_s: 13759.34814453125\n",
      "  timestamp: 1553135580\n",
      "  timesteps_since_restore: 6250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6250000\n",
      "  training_iteration: 625\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13759 s, 625 iter, 6250000 ts, 81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-33-22\n",
      "  done: false\n",
      "  episode_len_mean: 79.31496062992126\n",
      "  episode_reward_max: 386.2957311845796\n",
      "  episode_reward_mean: 87.36305253124857\n",
      "  episode_reward_min: -164.66252160188196\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 78616\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.896\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 6260000\n",
      "    num_steps_trained: 6260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5765300393104553\n",
      "      kl: 0.024988459423184395\n",
      "      policy_loss: 0.008500703610479832\n",
      "      total_loss: 51.19045639038086\n",
      "      vf_explained_var: 0.8847630023956299\n",
      "      vf_loss: 51.17861557006836\n",
      "    sample_time_ms: 18017.576\n",
      "    update_time_ms: 4.992\n",
      "  iterations_since_restore: 626\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.68152626562428\n",
      "  time_since_restore: 13781.246058702469\n",
      "  time_this_iter_s: 21.897914171218872\n",
      "  time_total_s: 13781.246058702469\n",
      "  timestamp: 1553135602\n",
      "  timesteps_since_restore: 6260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6260000\n",
      "  training_iteration: 626\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13781 s, 626 iter, 6260000 ts, 87.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-33-43\n",
      "  done: false\n",
      "  episode_len_mean: 79.07936507936508\n",
      "  episode_reward_max: 383.4915443168156\n",
      "  episode_reward_mean: 85.02089985073023\n",
      "  episode_reward_min: -166.77126419338225\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 78742\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.382\n",
      "    load_time_ms: 1.671\n",
      "    num_steps_sampled: 6270000\n",
      "    num_steps_trained: 6270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5709246397018433\n",
      "      kl: 0.015337069518864155\n",
      "      policy_loss: 0.003607431659474969\n",
      "      total_loss: 47.85536193847656\n",
      "      vf_explained_var: 0.894363284111023\n",
      "      vf_loss: 47.84970474243164\n",
      "    sample_time_ms: 17964.374\n",
      "    update_time_ms: 5.39\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.51044992536513\n",
      "  time_since_restore: 13802.643797636032\n",
      "  time_this_iter_s: 21.397738933563232\n",
      "  time_total_s: 13802.643797636032\n",
      "  timestamp: 1553135623\n",
      "  timesteps_since_restore: 6270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6270000\n",
      "  training_iteration: 627\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13802 s, 627 iter, 6270000 ts, 85 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-34-04\n",
      "  done: false\n",
      "  episode_len_mean: 76.63565891472868\n",
      "  episode_reward_max: 388.3444617883079\n",
      "  episode_reward_mean: 67.38507253150401\n",
      "  episode_reward_min: -166.89364308878422\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 78871\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.946\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 6280000\n",
      "    num_steps_trained: 6280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5769920349121094\n",
      "      kl: 0.02022520639002323\n",
      "      policy_loss: 0.004011393524706364\n",
      "      total_loss: 52.0131950378418\n",
      "      vf_explained_var: 0.8916842937469482\n",
      "      vf_loss: 52.00647735595703\n",
      "    sample_time_ms: 17882.976\n",
      "    update_time_ms: 5.265\n",
      "  iterations_since_restore: 628\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.692536265752004\n",
      "  time_since_restore: 13823.866167783737\n",
      "  time_this_iter_s: 21.222370147705078\n",
      "  time_total_s: 13823.866167783737\n",
      "  timestamp: 1553135644\n",
      "  timesteps_since_restore: 6280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6280000\n",
      "  training_iteration: 628\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13823 s, 628 iter, 6280000 ts, 67.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-34-26\n",
      "  done: false\n",
      "  episode_len_mean: 79.22047244094489\n",
      "  episode_reward_max: 387.7360374502783\n",
      "  episode_reward_mean: 92.48152798775534\n",
      "  episode_reward_min: -164.69658403631686\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 78998\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.162\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 6290000\n",
      "    num_steps_trained: 6290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5703335404396057\n",
      "      kl: 0.016003793105483055\n",
      "      policy_loss: 0.0011799451895058155\n",
      "      total_loss: 41.65988540649414\n",
      "      vf_explained_var: 0.9058324098587036\n",
      "      vf_loss: 41.65656280517578\n",
      "    sample_time_ms: 17879.026\n",
      "    update_time_ms: 5.25\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.24076399387767\n",
      "  time_since_restore: 13845.666377067566\n",
      "  time_this_iter_s: 21.800209283828735\n",
      "  time_total_s: 13845.666377067566\n",
      "  timestamp: 1553135666\n",
      "  timesteps_since_restore: 6290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6290000\n",
      "  training_iteration: 629\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13845 s, 629 iter, 6290000 ts, 92.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-34-48\n",
      "  done: false\n",
      "  episode_len_mean: 83.19166666666666\n",
      "  episode_reward_max: 389.9708885570657\n",
      "  episode_reward_mean: 116.29512554422075\n",
      "  episode_reward_min: -166.8353527540827\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 79118\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.616\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 6300000\n",
      "    num_steps_trained: 6300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5586126446723938\n",
      "      kl: 0.018518105149269104\n",
      "      policy_loss: 0.007086785044521093\n",
      "      total_loss: 43.84353256225586\n",
      "      vf_explained_var: 0.8907119631767273\n",
      "      vf_loss: 43.83396530151367\n",
      "    sample_time_ms: 17875.328\n",
      "    update_time_ms: 5.32\n",
      "  iterations_since_restore: 630\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.14756277211039\n",
      "  time_since_restore: 13867.565351247787\n",
      "  time_this_iter_s: 21.898974180221558\n",
      "  time_total_s: 13867.565351247787\n",
      "  timestamp: 1553135688\n",
      "  timesteps_since_restore: 6300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6300000\n",
      "  training_iteration: 630\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13867 s, 630 iter, 6300000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-35-10\n",
      "  done: false\n",
      "  episode_len_mean: 76.5909090909091\n",
      "  episode_reward_max: 389.88588727150835\n",
      "  episode_reward_mean: 70.47985484020008\n",
      "  episode_reward_min: -164.8008412190342\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 79250\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.65\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 6310000\n",
      "    num_steps_trained: 6310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.602232813835144\n",
      "      kl: 0.01727922447025776\n",
      "      policy_loss: 0.0017813894664868712\n",
      "      total_loss: 55.41610336303711\n",
      "      vf_explained_var: 0.8858466744422913\n",
      "      vf_loss: 55.412010192871094\n",
      "    sample_time_ms: 17913.024\n",
      "    update_time_ms: 5.414\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.23992742010004\n",
      "  time_since_restore: 13889.565521001816\n",
      "  time_this_iter_s: 22.00016975402832\n",
      "  time_total_s: 13889.565521001816\n",
      "  timestamp: 1553135710\n",
      "  timesteps_since_restore: 6310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6310000\n",
      "  training_iteration: 631\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13889 s, 631 iter, 6310000 ts, 70.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-35-32\n",
      "  done: false\n",
      "  episode_len_mean: 81.63636363636364\n",
      "  episode_reward_max: 384.73677537069455\n",
      "  episode_reward_mean: 108.64793882936299\n",
      "  episode_reward_min: -166.76966030189038\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 79371\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.973\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 6320000\n",
      "    num_steps_trained: 6320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5749831795692444\n",
      "      kl: 0.021379956975579262\n",
      "      policy_loss: 0.00606575608253479\n",
      "      total_loss: 60.305721282958984\n",
      "      vf_explained_var: 0.8532708287239075\n",
      "      vf_loss: 60.29678726196289\n",
      "    sample_time_ms: 17916.889\n",
      "    update_time_ms: 5.397\n",
      "  iterations_since_restore: 632\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.323969414681486\n",
      "  time_since_restore: 13911.267968416214\n",
      "  time_this_iter_s: 21.702447414398193\n",
      "  time_total_s: 13911.267968416214\n",
      "  timestamp: 1553135732\n",
      "  timesteps_since_restore: 6320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6320000\n",
      "  training_iteration: 632\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13911 s, 632 iter, 6320000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-35-54\n",
      "  done: false\n",
      "  episode_len_mean: 75.18796992481202\n",
      "  episode_reward_max: 388.0301831381902\n",
      "  episode_reward_mean: 61.4914636948527\n",
      "  episode_reward_min: -166.84724037298201\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 79504\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.319\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 6330000\n",
      "    num_steps_trained: 6330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6182281374931335\n",
      "      kl: 0.029270997270941734\n",
      "      policy_loss: 0.007104585412889719\n",
      "      total_loss: 56.09234619140625\n",
      "      vf_explained_var: 0.884756326675415\n",
      "      vf_loss: 56.081329345703125\n",
      "    sample_time_ms: 17966.947\n",
      "    update_time_ms: 5.439\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.74573184742635\n",
      "  time_since_restore: 13933.279898166656\n",
      "  time_this_iter_s: 22.011929750442505\n",
      "  time_total_s: 13933.279898166656\n",
      "  timestamp: 1553135754\n",
      "  timesteps_since_restore: 6330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6330000\n",
      "  training_iteration: 633\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13933 s, 633 iter, 6330000 ts, 61.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-36-16\n",
      "  done: false\n",
      "  episode_len_mean: 67.40268456375838\n",
      "  episode_reward_max: 387.98625355497563\n",
      "  episode_reward_mean: 3.2721399601399916\n",
      "  episode_reward_min: -164.68743851562976\n",
      "  episodes_this_iter: 149\n",
      "  episodes_total: 79653\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.917\n",
      "    load_time_ms: 1.396\n",
      "    num_steps_sampled: 6340000\n",
      "    num_steps_trained: 6340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6632812023162842\n",
      "      kl: 0.027053870260715485\n",
      "      policy_loss: 0.006687812972813845\n",
      "      total_loss: 70.29098510742188\n",
      "      vf_explained_var: 0.8804429173469543\n",
      "      vf_loss: 70.28067779541016\n",
      "    sample_time_ms: 18006.666\n",
      "    update_time_ms: 5.455\n",
      "  iterations_since_restore: 634\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 1.6360699800699896\n",
      "  time_since_restore: 13955.113556146622\n",
      "  time_this_iter_s: 21.83365797996521\n",
      "  time_total_s: 13955.113556146622\n",
      "  timestamp: 1553135776\n",
      "  timesteps_since_restore: 6340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6340000\n",
      "  training_iteration: 634\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13955 s, 634 iter, 6340000 ts, 3.27 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-36-38\n",
      "  done: false\n",
      "  episode_len_mean: 75.92481203007519\n",
      "  episode_reward_max: 387.84459997897966\n",
      "  episode_reward_mean: 63.78226966534166\n",
      "  episode_reward_min: -166.8832407254839\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 79786\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.276\n",
      "    load_time_ms: 1.417\n",
      "    num_steps_sampled: 6350000\n",
      "    num_steps_trained: 6350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6245220899581909\n",
      "      kl: 0.019183406606316566\n",
      "      policy_loss: 0.0037909429520368576\n",
      "      total_loss: 56.452980041503906\n",
      "      vf_explained_var: 0.8855963349342346\n",
      "      vf_loss: 56.44662857055664\n",
      "    sample_time_ms: 18031.617\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.891134832670836\n",
      "  time_since_restore: 13976.977124929428\n",
      "  time_this_iter_s: 21.863568782806396\n",
      "  time_total_s: 13976.977124929428\n",
      "  timestamp: 1553135798\n",
      "  timesteps_since_restore: 6350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6350000\n",
      "  training_iteration: 635\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13976 s, 635 iter, 6350000 ts, 63.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-36-59\n",
      "  done: false\n",
      "  episode_len_mean: 79.87096774193549\n",
      "  episode_reward_max: 388.0023499329433\n",
      "  episode_reward_mean: 93.49471867731647\n",
      "  episode_reward_min: -168.86864140733718\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 79910\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.268\n",
      "    load_time_ms: 1.369\n",
      "    num_steps_sampled: 6360000\n",
      "    num_steps_trained: 6360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5791403651237488\n",
      "      kl: 0.02204875834286213\n",
      "      policy_loss: 0.007403532043099403\n",
      "      total_loss: 43.8599853515625\n",
      "      vf_explained_var: 0.898688018321991\n",
      "      vf_loss: 43.84962844848633\n",
      "    sample_time_ms: 17993.285\n",
      "    update_time_ms: 5.334\n",
      "  iterations_since_restore: 636\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.747359338658235\n",
      "  time_since_restore: 13998.527291059494\n",
      "  time_this_iter_s: 21.550166130065918\n",
      "  time_total_s: 13998.527291059494\n",
      "  timestamp: 1553135819\n",
      "  timesteps_since_restore: 6360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6360000\n",
      "  training_iteration: 636\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 13998 s, 636 iter, 6360000 ts, 93.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-37-21\n",
      "  done: false\n",
      "  episode_len_mean: 72.39568345323741\n",
      "  episode_reward_max: 389.32289986083975\n",
      "  episode_reward_mean: 48.63632163239024\n",
      "  episode_reward_min: -163.00559535345076\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 80049\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.318\n",
      "    load_time_ms: 1.401\n",
      "    num_steps_sampled: 6370000\n",
      "    num_steps_trained: 6370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6269251704216003\n",
      "      kl: 0.014634363353252411\n",
      "      policy_loss: 0.0018608811078593135\n",
      "      total_loss: 46.30234146118164\n",
      "      vf_explained_var: 0.9112433195114136\n",
      "      vf_loss: 46.29852294921875\n",
      "    sample_time_ms: 18024.076\n",
      "    update_time_ms: 5.025\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.318160816195125\n",
      "  time_since_restore: 14020.091997385025\n",
      "  time_this_iter_s: 21.564706325531006\n",
      "  time_total_s: 14020.091997385025\n",
      "  timestamp: 1553135841\n",
      "  timesteps_since_restore: 6370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6370000\n",
      "  training_iteration: 637\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14020 s, 637 iter, 6370000 ts, 48.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-37-43\n",
      "  done: false\n",
      "  episode_len_mean: 74.07462686567165\n",
      "  episode_reward_max: 388.4255847973745\n",
      "  episode_reward_mean: 54.84180296872154\n",
      "  episode_reward_min: -168.95163891800883\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 80183\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.546\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 6380000\n",
      "    num_steps_trained: 6380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6300733685493469\n",
      "      kl: 0.02219640649855137\n",
      "      policy_loss: 0.0037376582622528076\n",
      "      total_loss: 56.16566467285156\n",
      "      vf_explained_var: 0.8910131454467773\n",
      "      vf_loss: 56.15895462036133\n",
      "    sample_time_ms: 18133.936\n",
      "    update_time_ms: 5.803\n",
      "  iterations_since_restore: 638\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.420901484360776\n",
      "  time_since_restore: 14042.504055023193\n",
      "  time_this_iter_s: 22.412057638168335\n",
      "  time_total_s: 14042.504055023193\n",
      "  timestamp: 1553135863\n",
      "  timesteps_since_restore: 6380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6380000\n",
      "  training_iteration: 638\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14042 s, 638 iter, 6380000 ts, 54.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-38-05\n",
      "  done: false\n",
      "  episode_len_mean: 78.85826771653544\n",
      "  episode_reward_max: 386.2697716058408\n",
      "  episode_reward_mean: 85.63365052925712\n",
      "  episode_reward_min: -167.13082867064713\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 80310\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.398\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 6390000\n",
      "    num_steps_trained: 6390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5886067152023315\n",
      "      kl: 0.020204905420541763\n",
      "      policy_loss: 0.002069988986477256\n",
      "      total_loss: 45.53608322143555\n",
      "      vf_explained_var: 0.901799738407135\n",
      "      vf_loss: 45.531307220458984\n",
      "    sample_time_ms: 18154.841\n",
      "    update_time_ms: 5.824\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.81682526462858\n",
      "  time_since_restore: 14064.524664402008\n",
      "  time_this_iter_s: 22.020609378814697\n",
      "  time_total_s: 14064.524664402008\n",
      "  timestamp: 1553135885\n",
      "  timesteps_since_restore: 6390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6390000\n",
      "  training_iteration: 639\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14064 s, 639 iter, 6390000 ts, 85.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-38-28\n",
      "  done: false\n",
      "  episode_len_mean: 74.8731343283582\n",
      "  episode_reward_max: 387.0751763989232\n",
      "  episode_reward_mean: 57.84192967073194\n",
      "  episode_reward_min: -166.87301769646646\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 80444\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.038\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 6400000\n",
      "    num_steps_trained: 6400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6128128170967102\n",
      "      kl: 0.024429479613900185\n",
      "      policy_loss: 0.005994867067784071\n",
      "      total_loss: 52.58308792114258\n",
      "      vf_explained_var: 0.8955531716346741\n",
      "      vf_loss: 52.57381820678711\n",
      "    sample_time_ms: 18190.236\n",
      "    update_time_ms: 5.824\n",
      "  iterations_since_restore: 640\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.920964835365965\n",
      "  time_since_restore: 14086.771745204926\n",
      "  time_this_iter_s: 22.24708080291748\n",
      "  time_total_s: 14086.771745204926\n",
      "  timestamp: 1553135908\n",
      "  timesteps_since_restore: 6400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6400000\n",
      "  training_iteration: 640\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14086 s, 640 iter, 6400000 ts, 57.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-38-49\n",
      "  done: false\n",
      "  episode_len_mean: 76.30534351145039\n",
      "  episode_reward_max: 386.61605366158517\n",
      "  episode_reward_mean: 72.81361104490517\n",
      "  episode_reward_min: -166.88556360908984\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 80575\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.7\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 6410000\n",
      "    num_steps_trained: 6410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6407678127288818\n",
      "      kl: 0.01872163824737072\n",
      "      policy_loss: 0.004973019007593393\n",
      "      total_loss: 49.37486267089844\n",
      "      vf_explained_var: 0.8980551362037659\n",
      "      vf_loss: 49.36738204956055\n",
      "    sample_time_ms: 18173.808\n",
      "    update_time_ms: 5.701\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.40680552245259\n",
      "  time_since_restore: 14108.459026098251\n",
      "  time_this_iter_s: 21.687280893325806\n",
      "  time_total_s: 14108.459026098251\n",
      "  timestamp: 1553135929\n",
      "  timesteps_since_restore: 6410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6410000\n",
      "  training_iteration: 641\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14108 s, 641 iter, 6410000 ts, 72.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-39-11\n",
      "  done: false\n",
      "  episode_len_mean: 72.53623188405797\n",
      "  episode_reward_max: 383.36992056797123\n",
      "  episode_reward_mean: 41.52343411706047\n",
      "  episode_reward_min: -166.83813901623725\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 80713\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.285\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 6420000\n",
      "    num_steps_trained: 6420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6336721181869507\n",
      "      kl: 0.020423246547579765\n",
      "      policy_loss: 0.005194392055273056\n",
      "      total_loss: 50.86477279663086\n",
      "      vf_explained_var: 0.903645932674408\n",
      "      vf_loss: 50.85684585571289\n",
      "    sample_time_ms: 18173.747\n",
      "    update_time_ms: 5.958\n",
      "  iterations_since_restore: 642\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.761717058530227\n",
      "  time_since_restore: 14130.349514722824\n",
      "  time_this_iter_s: 21.890488624572754\n",
      "  time_total_s: 14130.349514722824\n",
      "  timestamp: 1553135951\n",
      "  timesteps_since_restore: 6420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6420000\n",
      "  training_iteration: 642\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14130 s, 642 iter, 6420000 ts, 41.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-39-33\n",
      "  done: false\n",
      "  episode_len_mean: 76.82945736434108\n",
      "  episode_reward_max: 387.6450335628449\n",
      "  episode_reward_mean: 72.85250350792755\n",
      "  episode_reward_min: -168.88951753648757\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 80842\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.283\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 6430000\n",
      "    num_steps_trained: 6430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6421632766723633\n",
      "      kl: 0.020010391250252724\n",
      "      policy_loss: 0.0023043949622660875\n",
      "      total_loss: 54.12255096435547\n",
      "      vf_explained_var: 0.8923439383506775\n",
      "      vf_loss: 54.11756896972656\n",
      "    sample_time_ms: 18129.038\n",
      "    update_time_ms: 5.964\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.426251753963776\n",
      "  time_since_restore: 14151.886953830719\n",
      "  time_this_iter_s: 21.537439107894897\n",
      "  time_total_s: 14151.886953830719\n",
      "  timestamp: 1553135973\n",
      "  timesteps_since_restore: 6430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6430000\n",
      "  training_iteration: 643\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14151 s, 643 iter, 6430000 ts, 72.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-39-55\n",
      "  done: false\n",
      "  episode_len_mean: 76.63636363636364\n",
      "  episode_reward_max: 385.0090808524822\n",
      "  episode_reward_mean: 71.51364369547058\n",
      "  episode_reward_min: -166.76345934709548\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 80974\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.336\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 6440000\n",
      "    num_steps_trained: 6440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6377087831497192\n",
      "      kl: 0.023525426164269447\n",
      "      policy_loss: 0.0023343972861766815\n",
      "      total_loss: 58.34563446044922\n",
      "      vf_explained_var: 0.8771207928657532\n",
      "      vf_loss: 58.340145111083984\n",
      "    sample_time_ms: 18133.721\n",
      "    update_time_ms: 5.869\n",
      "  iterations_since_restore: 644\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.75682184773529\n",
      "  time_since_restore: 14173.749440193176\n",
      "  time_this_iter_s: 21.862486362457275\n",
      "  time_total_s: 14173.749440193176\n",
      "  timestamp: 1553135995\n",
      "  timesteps_since_restore: 6440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6440000\n",
      "  training_iteration: 644\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14173 s, 644 iter, 6440000 ts, 71.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-40-17\n",
      "  done: false\n",
      "  episode_len_mean: 75.41666666666667\n",
      "  episode_reward_max: 387.8863642019158\n",
      "  episode_reward_mean: 61.92820698335743\n",
      "  episode_reward_min: -168.7813448725605\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 81106\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.957\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 6450000\n",
      "    num_steps_trained: 6450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6193588376045227\n",
      "      kl: 0.018780210986733437\n",
      "      policy_loss: 0.004909547511488199\n",
      "      total_loss: 49.594017028808594\n",
      "      vf_explained_var: 0.8984086513519287\n",
      "      vf_loss: 49.586585998535156\n",
      "    sample_time_ms: 18150.088\n",
      "    update_time_ms: 5.823\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.96410349167871\n",
      "  time_since_restore: 14195.783771276474\n",
      "  time_this_iter_s: 22.03433108329773\n",
      "  time_total_s: 14195.783771276474\n",
      "  timestamp: 1553136017\n",
      "  timesteps_since_restore: 6450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6450000\n",
      "  training_iteration: 645\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14195 s, 645 iter, 6450000 ts, 61.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-40-38\n",
      "  done: false\n",
      "  episode_len_mean: 71.79285714285714\n",
      "  episode_reward_max: 386.59098298912744\n",
      "  episode_reward_mean: 41.26923681323568\n",
      "  episode_reward_min: -166.8164986763859\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 81246\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.445\n",
      "    load_time_ms: 1.722\n",
      "    num_steps_sampled: 6460000\n",
      "    num_steps_trained: 6460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6246812343597412\n",
      "      kl: 0.019006671383976936\n",
      "      policy_loss: 0.005624137353152037\n",
      "      total_loss: 51.830116271972656\n",
      "      vf_explained_var: 0.9031004309654236\n",
      "      vf_loss: 51.82194519042969\n",
      "    sample_time_ms: 18155.823\n",
      "    update_time_ms: 5.828\n",
      "  iterations_since_restore: 646\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.63461840661784\n",
      "  time_since_restore: 14217.347396373749\n",
      "  time_this_iter_s: 21.56362509727478\n",
      "  time_total_s: 14217.347396373749\n",
      "  timestamp: 1553136038\n",
      "  timesteps_since_restore: 6460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6460000\n",
      "  training_iteration: 646\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14217 s, 646 iter, 6460000 ts, 41.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-41-00\n",
      "  done: false\n",
      "  episode_len_mean: 80.53225806451613\n",
      "  episode_reward_max: 390.9629038217804\n",
      "  episode_reward_mean: 101.48381260988249\n",
      "  episode_reward_min: -164.78600778540613\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 81370\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.524\n",
      "    load_time_ms: 1.766\n",
      "    num_steps_sampled: 6470000\n",
      "    num_steps_trained: 6470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13389132916927338\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6270532011985779\n",
      "      kl: 0.04371389374136925\n",
      "      policy_loss: 0.010573774576187134\n",
      "      total_loss: 52.0682258605957\n",
      "      vf_explained_var: 0.8810895085334778\n",
      "      vf_loss: 52.05179977416992\n",
      "    sample_time_ms: 18161.914\n",
      "    update_time_ms: 5.801\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.74190630494124\n",
      "  time_since_restore: 14239.004308462143\n",
      "  time_this_iter_s: 21.656912088394165\n",
      "  time_total_s: 14239.004308462143\n",
      "  timestamp: 1553136060\n",
      "  timesteps_since_restore: 6470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6470000\n",
      "  training_iteration: 647\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14239 s, 647 iter, 6470000 ts, 101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-41-22\n",
      "  done: false\n",
      "  episode_len_mean: 77.0546875\n",
      "  episode_reward_max: 388.431678866747\n",
      "  episode_reward_mean: 75.46688873950539\n",
      "  episode_reward_min: -166.83857473691938\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 81498\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.21\n",
      "    load_time_ms: 1.772\n",
      "    num_steps_sampled: 6480000\n",
      "    num_steps_trained: 6480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6145467758178711\n",
      "      kl: 0.017586050555109978\n",
      "      policy_loss: 0.002386595355346799\n",
      "      total_loss: 42.768218994140625\n",
      "      vf_explained_var: 0.9078092575073242\n",
      "      vf_loss: 42.762306213378906\n",
      "    sample_time_ms: 18094.325\n",
      "    update_time_ms: 5.041\n",
      "  iterations_since_restore: 648\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.73344436975269\n",
      "  time_since_restore: 14260.659573316574\n",
      "  time_this_iter_s: 21.655264854431152\n",
      "  time_total_s: 14260.659573316574\n",
      "  timestamp: 1553136082\n",
      "  timesteps_since_restore: 6480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6480000\n",
      "  training_iteration: 648\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14260 s, 648 iter, 6480000 ts, 75.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-41-44\n",
      "  done: false\n",
      "  episode_len_mean: 81.40650406504065\n",
      "  episode_reward_max: 388.4372523250998\n",
      "  episode_reward_mean: 105.33789838373562\n",
      "  episode_reward_min: -166.86834002276896\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 81621\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.876\n",
      "    load_time_ms: 1.784\n",
      "    num_steps_sampled: 6490000\n",
      "    num_steps_trained: 6490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6181443929672241\n",
      "      kl: 0.02318955957889557\n",
      "      policy_loss: 0.00924157164990902\n",
      "      total_loss: 44.21401596069336\n",
      "      vf_explained_var: 0.8979028463363647\n",
      "      vf_loss: 44.20011901855469\n",
      "    sample_time_ms: 18096.548\n",
      "    update_time_ms: 5.139\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.66894919186781\n",
      "  time_since_restore: 14282.700659275055\n",
      "  time_this_iter_s: 22.041085958480835\n",
      "  time_total_s: 14282.700659275055\n",
      "  timestamp: 1553136104\n",
      "  timesteps_since_restore: 6490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6490000\n",
      "  training_iteration: 649\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14282 s, 649 iter, 6490000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-42-05\n",
      "  done: false\n",
      "  episode_len_mean: 79.8015873015873\n",
      "  episode_reward_max: 389.1717605125426\n",
      "  episode_reward_mean: 95.05139443410667\n",
      "  episode_reward_min: -168.82154584225654\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 81747\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.251\n",
      "    load_time_ms: 1.809\n",
      "    num_steps_sampled: 6500000\n",
      "    num_steps_trained: 6500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6058685183525085\n",
      "      kl: 0.023059329017996788\n",
      "      policy_loss: 0.005366335157305002\n",
      "      total_loss: 45.43049621582031\n",
      "      vf_explained_var: 0.8970637321472168\n",
      "      vf_loss: 45.42049789428711\n",
      "    sample_time_ms: 18008.882\n",
      "    update_time_ms: 5.112\n",
      "  iterations_since_restore: 650\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.525697217053334\n",
      "  time_since_restore: 14304.11635351181\n",
      "  time_this_iter_s: 21.41569423675537\n",
      "  time_total_s: 14304.11635351181\n",
      "  timestamp: 1553136125\n",
      "  timesteps_since_restore: 6500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6500000\n",
      "  training_iteration: 650\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14304 s, 650 iter, 6500000 ts, 95.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-42-27\n",
      "  done: false\n",
      "  episode_len_mean: 76.6\n",
      "  episode_reward_max: 388.3575231559784\n",
      "  episode_reward_mean: 76.70206521690336\n",
      "  episode_reward_min: -168.80786966749667\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 81877\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.945\n",
      "    load_time_ms: 1.805\n",
      "    num_steps_sampled: 6510000\n",
      "    num_steps_trained: 6510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5976876616477966\n",
      "      kl: 0.015336201526224613\n",
      "      policy_loss: 0.0019858283922076225\n",
      "      total_loss: 45.76163101196289\n",
      "      vf_explained_var: 0.9021797180175781\n",
      "      vf_loss: 45.756561279296875\n",
      "    sample_time_ms: 18027.999\n",
      "    update_time_ms: 5.132\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.351032608451675\n",
      "  time_since_restore: 14325.991111516953\n",
      "  time_this_iter_s: 21.874758005142212\n",
      "  time_total_s: 14325.991111516953\n",
      "  timestamp: 1553136147\n",
      "  timesteps_since_restore: 6510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6510000\n",
      "  training_iteration: 651\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14325 s, 651 iter, 6510000 ts, 76.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-42-49\n",
      "  done: false\n",
      "  episode_len_mean: 80.456\n",
      "  episode_reward_max: 388.38131855964815\n",
      "  episode_reward_mean: 104.24900540552092\n",
      "  episode_reward_min: -168.70276634022235\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 82002\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3678.495\n",
      "    load_time_ms: 1.828\n",
      "    num_steps_sampled: 6520000\n",
      "    num_steps_trained: 6520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6150224208831787\n",
      "      kl: 0.01599491760134697\n",
      "      policy_loss: 0.0026507354341447353\n",
      "      total_loss: 59.47443389892578\n",
      "      vf_explained_var: 0.8601580858230591\n",
      "      vf_loss: 59.468563079833984\n",
      "    sample_time_ms: 18024.984\n",
      "    update_time_ms: 4.903\n",
      "  iterations_since_restore: 652\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.12450270276045\n",
      "  time_since_restore: 14347.633620977402\n",
      "  time_this_iter_s: 21.64250946044922\n",
      "  time_total_s: 14347.633620977402\n",
      "  timestamp: 1553136169\n",
      "  timesteps_since_restore: 6520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6520000\n",
      "  training_iteration: 652\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14347 s, 652 iter, 6520000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-43-10\n",
      "  done: false\n",
      "  episode_len_mean: 74.96268656716418\n",
      "  episode_reward_max: 387.2061849549544\n",
      "  episode_reward_mean: 52.49833138144278\n",
      "  episode_reward_min: -167.08542559036255\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 82136\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.659\n",
      "    load_time_ms: 1.92\n",
      "    num_steps_sampled: 6530000\n",
      "    num_steps_trained: 6530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6450329422950745\n",
      "      kl: 0.023160967975854874\n",
      "      policy_loss: 0.006769594270735979\n",
      "      total_loss: 63.26960754394531\n",
      "      vf_explained_var: 0.8748385906219482\n",
      "      vf_loss: 63.258174896240234\n",
      "    sample_time_ms: 17979.97\n",
      "    update_time_ms: 4.946\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.249165690721384\n",
      "  time_since_restore: 14368.834470510483\n",
      "  time_this_iter_s: 21.200849533081055\n",
      "  time_total_s: 14368.834470510483\n",
      "  timestamp: 1553136190\n",
      "  timesteps_since_restore: 6530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6530000\n",
      "  training_iteration: 653\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14368 s, 653 iter, 6530000 ts, 52.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-43-32\n",
      "  done: false\n",
      "  episode_len_mean: 75.37121212121212\n",
      "  episode_reward_max: 388.2564690257517\n",
      "  episode_reward_mean: 60.115861135180694\n",
      "  episode_reward_min: -168.89360030576228\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 82268\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.784\n",
      "    load_time_ms: 1.83\n",
      "    num_steps_sampled: 6540000\n",
      "    num_steps_trained: 6540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6173733472824097\n",
      "      kl: 0.016439028084278107\n",
      "      policy_loss: 0.0013489603297784925\n",
      "      total_loss: 45.927764892578125\n",
      "      vf_explained_var: 0.907863199710846\n",
      "      vf_loss: 45.92311477661133\n",
      "    sample_time_ms: 17984.358\n",
      "    update_time_ms: 5.318\n",
      "  iterations_since_restore: 654\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.057930567590343\n",
      "  time_since_restore: 14390.723425388336\n",
      "  time_this_iter_s: 21.888954877853394\n",
      "  time_total_s: 14390.723425388336\n",
      "  timestamp: 1553136212\n",
      "  timesteps_since_restore: 6540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6540000\n",
      "  training_iteration: 654\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14390 s, 654 iter, 6540000 ts, 60.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-43-54\n",
      "  done: false\n",
      "  episode_len_mean: 75.69924812030075\n",
      "  episode_reward_max: 388.1241534928002\n",
      "  episode_reward_mean: 62.01420253851133\n",
      "  episode_reward_min: -164.98584891411303\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 82401\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.977\n",
      "    load_time_ms: 1.801\n",
      "    num_steps_sampled: 6550000\n",
      "    num_steps_trained: 6550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6184104681015015\n",
      "      kl: 0.01953827403485775\n",
      "      policy_loss: 0.0019241106929257512\n",
      "      total_loss: 49.63827896118164\n",
      "      vf_explained_var: 0.8988357782363892\n",
      "      vf_loss: 49.63243103027344\n",
      "    sample_time_ms: 18012.295\n",
      "    update_time_ms: 5.259\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.007101269255664\n",
      "  time_since_restore: 14413.028230905533\n",
      "  time_this_iter_s: 22.304805517196655\n",
      "  time_total_s: 14413.028230905533\n",
      "  timestamp: 1553136234\n",
      "  timesteps_since_restore: 6550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6550000\n",
      "  training_iteration: 655\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14413 s, 655 iter, 6550000 ts, 62 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-44-16\n",
      "  done: false\n",
      "  episode_len_mean: 76.84615384615384\n",
      "  episode_reward_max: 387.87830811008536\n",
      "  episode_reward_mean: 72.83486995808012\n",
      "  episode_reward_min: -162.62165281054018\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 82531\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.359\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 6560000\n",
      "    num_steps_trained: 6560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6138331890106201\n",
      "      kl: 0.017507702112197876\n",
      "      policy_loss: 0.0010254326043650508\n",
      "      total_loss: 51.24418258666992\n",
      "      vf_explained_var: 0.890627920627594\n",
      "      vf_loss: 51.23963928222656\n",
      "    sample_time_ms: 18012.242\n",
      "    update_time_ms: 5.471\n",
      "  iterations_since_restore: 656\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.41743497904006\n",
      "  time_since_restore: 14434.588016033173\n",
      "  time_this_iter_s: 21.55978512763977\n",
      "  time_total_s: 14434.588016033173\n",
      "  timestamp: 1553136256\n",
      "  timesteps_since_restore: 6560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6560000\n",
      "  training_iteration: 656\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14434 s, 656 iter, 6560000 ts, 72.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-44-38\n",
      "  done: false\n",
      "  episode_len_mean: 80.6178861788618\n",
      "  episode_reward_max: 388.49832889789144\n",
      "  episode_reward_mean: 98.22932427895731\n",
      "  episode_reward_min: -166.9069996237421\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 82654\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3679.264\n",
      "    load_time_ms: 1.673\n",
      "    num_steps_sampled: 6570000\n",
      "    num_steps_trained: 6570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5912708640098572\n",
      "      kl: 0.026215657591819763\n",
      "      policy_loss: 0.007188859861344099\n",
      "      total_loss: 57.29545974731445\n",
      "      vf_explained_var: 0.8665266036987305\n",
      "      vf_loss: 57.28300857543945\n",
      "    sample_time_ms: 18021.099\n",
      "    update_time_ms: 5.385\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.114662139478654\n",
      "  time_since_restore: 14456.258952856064\n",
      "  time_this_iter_s: 21.670936822891235\n",
      "  time_total_s: 14456.258952856064\n",
      "  timestamp: 1553136278\n",
      "  timesteps_since_restore: 6570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6570000\n",
      "  training_iteration: 657\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14456 s, 657 iter, 6570000 ts, 98.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-45-00\n",
      "  done: false\n",
      "  episode_len_mean: 75.1203007518797\n",
      "  episode_reward_max: 385.38049535278043\n",
      "  episode_reward_mean: 56.959328740999524\n",
      "  episode_reward_min: -168.79749363311765\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 82787\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3680.138\n",
      "    load_time_ms: 1.641\n",
      "    num_steps_sampled: 6580000\n",
      "    num_steps_trained: 6580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6143642067909241\n",
      "      kl: 0.018093116581439972\n",
      "      policy_loss: 0.004306877497583628\n",
      "      total_loss: 52.90774154663086\n",
      "      vf_explained_var: 0.8915963768959045\n",
      "      vf_loss: 52.899803161621094\n",
      "    sample_time_ms: 18047.208\n",
      "    update_time_ms: 5.49\n",
      "  iterations_since_restore: 658\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.479664370499755\n",
      "  time_since_restore: 14478.183780193329\n",
      "  time_this_iter_s: 21.924827337265015\n",
      "  time_total_s: 14478.183780193329\n",
      "  timestamp: 1553136300\n",
      "  timesteps_since_restore: 6580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6580000\n",
      "  training_iteration: 658\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14478 s, 658 iter, 6580000 ts, 57 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-45-22\n",
      "  done: false\n",
      "  episode_len_mean: 84.5546218487395\n",
      "  episode_reward_max: 388.5668278803008\n",
      "  episode_reward_mean: 129.389575788973\n",
      "  episode_reward_min: -164.724508510437\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 82906\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3676.863\n",
      "    load_time_ms: 1.562\n",
      "    num_steps_sampled: 6590000\n",
      "    num_steps_trained: 6590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5721211433410645\n",
      "      kl: 0.01699511520564556\n",
      "      policy_loss: 0.005196460988372564\n",
      "      total_loss: 49.23745346069336\n",
      "      vf_explained_var: 0.871031641960144\n",
      "      vf_loss: 49.22884750366211\n",
      "    sample_time_ms: 18070.704\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.69478789448648\n",
      "  time_since_restore: 14500.421299934387\n",
      "  time_this_iter_s: 22.23751974105835\n",
      "  time_total_s: 14500.421299934387\n",
      "  timestamp: 1553136322\n",
      "  timesteps_since_restore: 6590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6590000\n",
      "  training_iteration: 659\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14500 s, 659 iter, 6590000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-45-45\n",
      "  done: false\n",
      "  episode_len_mean: 78.328125\n",
      "  episode_reward_max: 386.8306709578656\n",
      "  episode_reward_mean: 85.67999833972218\n",
      "  episode_reward_min: -164.84180232795717\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 83034\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3672.829\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 6600000\n",
      "    num_steps_trained: 6600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5893497467041016\n",
      "      kl: 0.019834233447909355\n",
      "      policy_loss: 0.006868584081530571\n",
      "      total_loss: 48.18836975097656\n",
      "      vf_explained_var: 0.892910897731781\n",
      "      vf_loss: 48.17751693725586\n",
      "    sample_time_ms: 18183.888\n",
      "    update_time_ms: 5.411\n",
      "  iterations_since_restore: 660\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.839999169861095\n",
      "  time_since_restore: 14522.92560839653\n",
      "  time_this_iter_s: 22.504308462142944\n",
      "  time_total_s: 14522.92560839653\n",
      "  timestamp: 1553136345\n",
      "  timesteps_since_restore: 6600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6600000\n",
      "  training_iteration: 660\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14522 s, 660 iter, 6600000 ts, 85.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-46-07\n",
      "  done: false\n",
      "  episode_len_mean: 73.77037037037037\n",
      "  episode_reward_max: 387.45354483179534\n",
      "  episode_reward_mean: 46.3111075821794\n",
      "  episode_reward_min: -162.71827458026647\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 83169\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3673.888\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 6610000\n",
      "    num_steps_trained: 6610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6190705895423889\n",
      "      kl: 0.01819218136370182\n",
      "      policy_loss: 0.0033058433327823877\n",
      "      total_loss: 57.90953063964844\n",
      "      vf_explained_var: 0.8886098861694336\n",
      "      vf_loss: 57.90256881713867\n",
      "    sample_time_ms: 18193.943\n",
      "    update_time_ms: 5.449\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.155553791089698\n",
      "  time_since_restore: 14544.915014982224\n",
      "  time_this_iter_s: 21.98940658569336\n",
      "  time_total_s: 14544.915014982224\n",
      "  timestamp: 1553136367\n",
      "  timesteps_since_restore: 6610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6610000\n",
      "  training_iteration: 661\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14544 s, 661 iter, 6610000 ts, 46.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-46-28\n",
      "  done: false\n",
      "  episode_len_mean: 72.60144927536231\n",
      "  episode_reward_max: 384.0061482945385\n",
      "  episode_reward_mean: 37.96421453302179\n",
      "  episode_reward_min: -166.95760419961454\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 83307\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3675.8\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 6620000\n",
      "    num_steps_trained: 6620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6179817914962769\n",
      "      kl: 0.016563253477215767\n",
      "      policy_loss: 0.002929204609245062\n",
      "      total_loss: 40.09832763671875\n",
      "      vf_explained_var: 0.9245002865791321\n",
      "      vf_loss: 40.09206771850586\n",
      "    sample_time_ms: 18208.706\n",
      "    update_time_ms: 5.562\n",
      "  iterations_since_restore: 662\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.982107266510894\n",
      "  time_since_restore: 14566.725260019302\n",
      "  time_this_iter_s: 21.810245037078857\n",
      "  time_total_s: 14566.725260019302\n",
      "  timestamp: 1553136388\n",
      "  timesteps_since_restore: 6620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6620000\n",
      "  training_iteration: 662\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14566 s, 662 iter, 6620000 ts, 38 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-46-51\n",
      "  done: false\n",
      "  episode_len_mean: 73.66666666666667\n",
      "  episode_reward_max: 388.30684455694734\n",
      "  episode_reward_mean: 48.894910386200316\n",
      "  episode_reward_min: -166.84469008585452\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 83442\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3667.216\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 6630000\n",
      "    num_steps_trained: 6630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6191436648368835\n",
      "      kl: 0.017309656366705894\n",
      "      policy_loss: 0.0031992774456739426\n",
      "      total_loss: 57.43031311035156\n",
      "      vf_explained_var: 0.8899911046028137\n",
      "      vf_loss: 57.423641204833984\n",
      "    sample_time_ms: 18309.165\n",
      "    update_time_ms: 5.552\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.447455193100147\n",
      "  time_since_restore: 14588.84525847435\n",
      "  time_this_iter_s: 22.119998455047607\n",
      "  time_total_s: 14588.84525847435\n",
      "  timestamp: 1553136411\n",
      "  timesteps_since_restore: 6630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6630000\n",
      "  training_iteration: 663\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14588 s, 663 iter, 6630000 ts, 48.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-47-12\n",
      "  done: false\n",
      "  episode_len_mean: 81.8130081300813\n",
      "  episode_reward_max: 387.7877261798276\n",
      "  episode_reward_mean: 112.59003612994695\n",
      "  episode_reward_min: -168.8201349770689\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 83565\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.955\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 6640000\n",
      "    num_steps_trained: 6640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5713760256767273\n",
      "      kl: 0.014589652419090271\n",
      "      policy_loss: 0.0046612718142569065\n",
      "      total_loss: 54.194679260253906\n",
      "      vf_explained_var: 0.8702954053878784\n",
      "      vf_loss: 54.18708801269531\n",
      "    sample_time_ms: 18258.116\n",
      "    update_time_ms: 5.239\n",
      "  iterations_since_restore: 664\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.295018064973455\n",
      "  time_since_restore: 14610.416275978088\n",
      "  time_this_iter_s: 21.571017503738403\n",
      "  time_total_s: 14610.416275978088\n",
      "  timestamp: 1553136432\n",
      "  timesteps_since_restore: 6640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6640000\n",
      "  training_iteration: 664\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14610 s, 664 iter, 6640000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 77.26923076923077\n",
      "  episode_reward_max: 387.1465190656084\n",
      "  episode_reward_mean: 77.12963161424483\n",
      "  episode_reward_min: -166.7943180679941\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 83695\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.028\n",
      "    load_time_ms: 1.5\n",
      "    num_steps_sampled: 6650000\n",
      "    num_steps_trained: 6650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5979258418083191\n",
      "      kl: 0.013880398124456406\n",
      "      policy_loss: 0.0012413009535521269\n",
      "      total_loss: 43.65034103393555\n",
      "      vf_explained_var: 0.9074151515960693\n",
      "      vf_loss: 43.64630889892578\n",
      "    sample_time_ms: 18188.455\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.5648158071224\n",
      "  time_since_restore: 14632.012254953384\n",
      "  time_this_iter_s: 21.59597897529602\n",
      "  time_total_s: 14632.012254953384\n",
      "  timestamp: 1553136454\n",
      "  timesteps_since_restore: 6650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6650000\n",
      "  training_iteration: 665\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14632 s, 665 iter, 6650000 ts, 77.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-47-55\n",
      "  done: false\n",
      "  episode_len_mean: 73.32592592592593\n",
      "  episode_reward_max: 390.42840973843306\n",
      "  episode_reward_mean: 47.54114437418501\n",
      "  episode_reward_min: -166.8073982624674\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 83830\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.92\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 6660000\n",
      "    num_steps_trained: 6660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6310267448425293\n",
      "      kl: 0.01590469852089882\n",
      "      policy_loss: 0.0026977453380823135\n",
      "      total_loss: 57.86790084838867\n",
      "      vf_explained_var: 0.8892431259155273\n",
      "      vf_loss: 57.86201095581055\n",
      "    sample_time_ms: 18188.31\n",
      "    update_time_ms: 5.254\n",
      "  iterations_since_restore: 666\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.770572187092498\n",
      "  time_since_restore: 14653.588012456894\n",
      "  time_this_iter_s: 21.57575750350952\n",
      "  time_total_s: 14653.588012456894\n",
      "  timestamp: 1553136475\n",
      "  timesteps_since_restore: 6660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6660000\n",
      "  training_iteration: 666\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14653 s, 666 iter, 6660000 ts, 47.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-48-17\n",
      "  done: false\n",
      "  episode_len_mean: 76.45038167938931\n",
      "  episode_reward_max: 388.4032402638709\n",
      "  episode_reward_mean: 73.85266911640747\n",
      "  episode_reward_min: -159.60474672188997\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 83961\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.879\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 6670000\n",
      "    num_steps_trained: 6670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5924220085144043\n",
      "      kl: 0.014449321664869785\n",
      "      policy_loss: 0.0035810654517263174\n",
      "      total_loss: 52.956172943115234\n",
      "      vf_explained_var: 0.8865252733230591\n",
      "      vf_loss: 52.9496955871582\n",
      "    sample_time_ms: 18213.256\n",
      "    update_time_ms: 5.36\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.92633455820373\n",
      "  time_since_restore: 14675.579064846039\n",
      "  time_this_iter_s: 21.991052389144897\n",
      "  time_total_s: 14675.579064846039\n",
      "  timestamp: 1553136497\n",
      "  timesteps_since_restore: 6670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6670000\n",
      "  training_iteration: 667\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14675 s, 667 iter, 6670000 ts, 73.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-48-39\n",
      "  done: false\n",
      "  episode_len_mean: 78.74015748031496\n",
      "  episode_reward_max: 387.3757202442849\n",
      "  episode_reward_mean: 86.21265451185194\n",
      "  episode_reward_min: -168.76033845397473\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 84088\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.905\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 6680000\n",
      "    num_steps_trained: 6680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5767840147018433\n",
      "      kl: 0.01619655266404152\n",
      "      policy_loss: 0.0018812638008967042\n",
      "      total_loss: 52.64321517944336\n",
      "      vf_explained_var: 0.8826076984405518\n",
      "      vf_loss: 52.638084411621094\n",
      "    sample_time_ms: 18149.462\n",
      "    update_time_ms: 5.322\n",
      "  iterations_since_restore: 668\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.10632725592596\n",
      "  time_since_restore: 14696.850285291672\n",
      "  time_this_iter_s: 21.271220445632935\n",
      "  time_total_s: 14696.850285291672\n",
      "  timestamp: 1553136519\n",
      "  timesteps_since_restore: 6680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6680000\n",
      "  training_iteration: 668\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14696 s, 668 iter, 6680000 ts, 86.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-49-01\n",
      "  done: false\n",
      "  episode_len_mean: 77.9609375\n",
      "  episode_reward_max: 388.1788784476915\n",
      "  episode_reward_mean: 82.02680909875315\n",
      "  episode_reward_min: -166.99736178144454\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 84216\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.887\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 6690000\n",
      "    num_steps_trained: 6690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5907029509544373\n",
      "      kl: 0.014177053235471249\n",
      "      policy_loss: 0.003338550217449665\n",
      "      total_loss: 55.62936782836914\n",
      "      vf_explained_var: 0.8816121220588684\n",
      "      vf_loss: 55.62318420410156\n",
      "    sample_time_ms: 18117.061\n",
      "    update_time_ms: 5.337\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.013404549376574\n",
      "  time_since_restore: 14718.838278770447\n",
      "  time_this_iter_s: 21.987993478775024\n",
      "  time_total_s: 14718.838278770447\n",
      "  timestamp: 1553136541\n",
      "  timesteps_since_restore: 6690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6690000\n",
      "  training_iteration: 669\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14718 s, 669 iter, 6690000 ts, 82 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-49-22\n",
      "  done: false\n",
      "  episode_len_mean: 78.73228346456693\n",
      "  episode_reward_max: 388.36280070645137\n",
      "  episode_reward_mean: 89.39889017582995\n",
      "  episode_reward_min: -166.98888984533787\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 84343\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.927\n",
      "    load_time_ms: 1.61\n",
      "    num_steps_sampled: 6700000\n",
      "    num_steps_trained: 6700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5672186613082886\n",
      "      kl: 0.015129147097468376\n",
      "      policy_loss: 0.0021055734250694513\n",
      "      total_loss: 45.76617431640625\n",
      "      vf_explained_var: 0.8980364799499512\n",
      "      vf_loss: 45.76102828979492\n",
      "    sample_time_ms: 18030.572\n",
      "    update_time_ms: 5.379\n",
      "  iterations_since_restore: 670\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.69944508791498\n",
      "  time_since_restore: 14740.479417562485\n",
      "  time_this_iter_s: 21.641138792037964\n",
      "  time_total_s: 14740.479417562485\n",
      "  timestamp: 1553136562\n",
      "  timesteps_since_restore: 6700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6700000\n",
      "  training_iteration: 670\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14740 s, 670 iter, 6700000 ts, 89.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-49-44\n",
      "  done: false\n",
      "  episode_len_mean: 76.5530303030303\n",
      "  episode_reward_max: 390.8557397244868\n",
      "  episode_reward_mean: 71.7284421531811\n",
      "  episode_reward_min: -166.86191542061806\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 84475\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.475\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 6710000\n",
      "    num_steps_trained: 6710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6045111417770386\n",
      "      kl: 0.013665327802300453\n",
      "      policy_loss: 0.00325082428753376\n",
      "      total_loss: 52.90243911743164\n",
      "      vf_explained_var: 0.8907243013381958\n",
      "      vf_loss: 52.89644241333008\n",
      "    sample_time_ms: 18023.49\n",
      "    update_time_ms: 5.293\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.864221076590546\n",
      "  time_since_restore: 14762.37339258194\n",
      "  time_this_iter_s: 21.893975019454956\n",
      "  time_total_s: 14762.37339258194\n",
      "  timestamp: 1553136584\n",
      "  timesteps_since_restore: 6710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6710000\n",
      "  training_iteration: 671\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14762 s, 671 iter, 6710000 ts, 71.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-50-06\n",
      "  done: false\n",
      "  episode_len_mean: 71.84892086330935\n",
      "  episode_reward_max: 387.76496676056894\n",
      "  episode_reward_mean: 42.65225677958884\n",
      "  episode_reward_min: -166.89931884881497\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 84614\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.221\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 6720000\n",
      "    num_steps_trained: 6720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6017868518829346\n",
      "      kl: 0.018425030633807182\n",
      "      policy_loss: 0.0030807703733444214\n",
      "      total_loss: 58.83929443359375\n",
      "      vf_explained_var: 0.8892973065376282\n",
      "      vf_loss: 58.83251953125\n",
      "    sample_time_ms: 18011.59\n",
      "    update_time_ms: 5.387\n",
      "  iterations_since_restore: 672\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.32612838979442\n",
      "  time_since_restore: 14784.05348944664\n",
      "  time_this_iter_s: 21.680096864700317\n",
      "  time_total_s: 14784.05348944664\n",
      "  timestamp: 1553136606\n",
      "  timesteps_since_restore: 6720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6720000\n",
      "  training_iteration: 672\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14784 s, 672 iter, 6720000 ts, 42.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-50-27\n",
      "  done: false\n",
      "  episode_len_mean: 78.38582677165354\n",
      "  episode_reward_max: 381.7069511867225\n",
      "  episode_reward_mean: 77.36069309444079\n",
      "  episode_reward_min: -166.86499678071976\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 84741\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.306\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 6730000\n",
      "    num_steps_trained: 6730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5674665570259094\n",
      "      kl: 0.01596667245030403\n",
      "      policy_loss: 0.004132871050387621\n",
      "      total_loss: 45.317169189453125\n",
      "      vf_explained_var: 0.9005954265594482\n",
      "      vf_loss: 45.309837341308594\n",
      "    sample_time_ms: 17931.36\n",
      "    update_time_ms: 5.282\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.68034654722038\n",
      "  time_since_restore: 14805.350115537643\n",
      "  time_this_iter_s: 21.296626091003418\n",
      "  time_total_s: 14805.350115537643\n",
      "  timestamp: 1553136627\n",
      "  timesteps_since_restore: 6730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6730000\n",
      "  training_iteration: 673\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14805 s, 673 iter, 6730000 ts, 77.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-50-49\n",
      "  done: false\n",
      "  episode_len_mean: 77.85271317829458\n",
      "  episode_reward_max: 386.57638017810905\n",
      "  episode_reward_mean: 82.22630911832677\n",
      "  episode_reward_min: -166.78415830883026\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 84870\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3676.69\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 6740000\n",
      "    num_steps_trained: 6740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5774391293525696\n",
      "      kl: 0.01634146086871624\n",
      "      policy_loss: 0.002003772184252739\n",
      "      total_loss: 50.770755767822266\n",
      "      vf_explained_var: 0.8907891511917114\n",
      "      vf_loss: 50.76546859741211\n",
      "    sample_time_ms: 17963.155\n",
      "    update_time_ms: 5.094\n",
      "  iterations_since_restore: 674\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.11315455916339\n",
      "  time_since_restore: 14827.06330704689\n",
      "  time_this_iter_s: 21.713191509246826\n",
      "  time_total_s: 14827.06330704689\n",
      "  timestamp: 1553136649\n",
      "  timesteps_since_restore: 6740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6740000\n",
      "  training_iteration: 674\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14827 s, 674 iter, 6740000 ts, 82.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-51-11\n",
      "  done: false\n",
      "  episode_len_mean: 74.63157894736842\n",
      "  episode_reward_max: 387.7385729518898\n",
      "  episode_reward_mean: 56.981124949610994\n",
      "  episode_reward_min: -166.68162051769733\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 85003\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.891\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 6750000\n",
      "    num_steps_trained: 6750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5770150423049927\n",
      "      kl: 0.016699280589818954\n",
      "      policy_loss: 0.001306523336097598\n",
      "      total_loss: 44.812198638916016\n",
      "      vf_explained_var: 0.9086083769798279\n",
      "      vf_loss: 44.80754089355469\n",
      "    sample_time_ms: 17945.736\n",
      "    update_time_ms: 5.387\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.490562474805497\n",
      "  time_since_restore: 14848.674107313156\n",
      "  time_this_iter_s: 21.61080026626587\n",
      "  time_total_s: 14848.674107313156\n",
      "  timestamp: 1553136671\n",
      "  timesteps_since_restore: 6750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6750000\n",
      "  training_iteration: 675\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14848 s, 675 iter, 6750000 ts, 57 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-51-32\n",
      "  done: false\n",
      "  episode_len_mean: 75.13533834586467\n",
      "  episode_reward_max: 386.4935677770946\n",
      "  episode_reward_mean: 63.089826911062914\n",
      "  episode_reward_min: -166.76428725501538\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 85136\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.408\n",
      "    load_time_ms: 1.696\n",
      "    num_steps_sampled: 6760000\n",
      "    num_steps_trained: 6760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5647006034851074\n",
      "      kl: 0.011892268434166908\n",
      "      policy_loss: 0.0021398465614765882\n",
      "      total_loss: 47.350955963134766\n",
      "      vf_explained_var: 0.9024930000305176\n",
      "      vf_loss: 47.3464241027832\n",
      "    sample_time_ms: 17902.85\n",
      "    update_time_ms: 5.254\n",
      "  iterations_since_restore: 676\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.544913455531457\n",
      "  time_since_restore: 14869.793829917908\n",
      "  time_this_iter_s: 21.119722604751587\n",
      "  time_total_s: 14869.793829917908\n",
      "  timestamp: 1553136692\n",
      "  timesteps_since_restore: 6760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6760000\n",
      "  training_iteration: 676\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14869 s, 676 iter, 6760000 ts, 63.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-51-54\n",
      "  done: false\n",
      "  episode_len_mean: 81.44354838709677\n",
      "  episode_reward_max: 387.51378978812545\n",
      "  episode_reward_mean: 103.17144670714163\n",
      "  episode_reward_min: -166.83150479694842\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 85260\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.618\n",
      "    load_time_ms: 1.695\n",
      "    num_steps_sampled: 6770000\n",
      "    num_steps_trained: 6770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5380920171737671\n",
      "      kl: 0.01935633271932602\n",
      "      policy_loss: 0.005393031518906355\n",
      "      total_loss: 48.6074104309082\n",
      "      vf_explained_var: 0.8863660097122192\n",
      "      vf_loss: 48.5981330871582\n",
      "    sample_time_ms: 17865.821\n",
      "    update_time_ms: 5.302\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.5857233535708\n",
      "  time_since_restore: 14891.348512887955\n",
      "  time_this_iter_s: 21.554682970046997\n",
      "  time_total_s: 14891.348512887955\n",
      "  timestamp: 1553136714\n",
      "  timesteps_since_restore: 6770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6770000\n",
      "  training_iteration: 677\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14891 s, 677 iter, 6770000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-52-15\n",
      "  done: false\n",
      "  episode_len_mean: 77.8671875\n",
      "  episode_reward_max: 388.74925320598277\n",
      "  episode_reward_mean: 82.63400844655595\n",
      "  episode_reward_min: -168.87884839400292\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 85388\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.303\n",
      "    load_time_ms: 1.594\n",
      "    num_steps_sampled: 6780000\n",
      "    num_steps_trained: 6780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5476387739181519\n",
      "      kl: 0.01637091487646103\n",
      "      policy_loss: 0.002884532790631056\n",
      "      total_loss: 44.88875198364258\n",
      "      vf_explained_var: 0.8999773859977722\n",
      "      vf_loss: 44.8825798034668\n",
      "    sample_time_ms: 17898.506\n",
      "    update_time_ms: 5.468\n",
      "  iterations_since_restore: 678\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.31700422327797\n",
      "  time_since_restore: 14912.960728406906\n",
      "  time_this_iter_s: 21.612215518951416\n",
      "  time_total_s: 14912.960728406906\n",
      "  timestamp: 1553136735\n",
      "  timesteps_since_restore: 6780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6780000\n",
      "  training_iteration: 678\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14912 s, 678 iter, 6780000 ts, 82.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-52-37\n",
      "  done: false\n",
      "  episode_len_mean: 71.12765957446808\n",
      "  episode_reward_max: 387.52829671522517\n",
      "  episode_reward_mean: 29.100715415305313\n",
      "  episode_reward_min: -162.9454288956785\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 85529\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.85\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 6790000\n",
      "    num_steps_trained: 6790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5771449208259583\n",
      "      kl: 0.013141360133886337\n",
      "      policy_loss: 0.0027974951080977917\n",
      "      total_loss: 62.93280029296875\n",
      "      vf_explained_var: 0.8845265507698059\n",
      "      vf_loss: 62.92736053466797\n",
      "    sample_time_ms: 17893.423\n",
      "    update_time_ms: 5.468\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.55035770765266\n",
      "  time_since_restore: 14934.850872278214\n",
      "  time_this_iter_s: 21.890143871307373\n",
      "  time_total_s: 14934.850872278214\n",
      "  timestamp: 1553136757\n",
      "  timesteps_since_restore: 6790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6790000\n",
      "  training_iteration: 679\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14934 s, 679 iter, 6790000 ts, 29.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 74.71969696969697\n",
      "  episode_reward_max: 389.6328451086943\n",
      "  episode_reward_mean: 62.841564301804794\n",
      "  episode_reward_min: -166.849868195858\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 85661\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.297\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 6800000\n",
      "    num_steps_trained: 6800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5688431859016418\n",
      "      kl: 0.01858590915799141\n",
      "      policy_loss: 0.0015680619981139898\n",
      "      total_loss: 47.267433166503906\n",
      "      vf_explained_var: 0.9045707583427429\n",
      "      vf_loss: 47.26213455200195\n",
      "    sample_time_ms: 17935.786\n",
      "    update_time_ms: 5.375\n",
      "  iterations_since_restore: 680\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.420782150902397\n",
      "  time_since_restore: 14956.952434062958\n",
      "  time_this_iter_s: 22.101561784744263\n",
      "  time_total_s: 14956.952434062958\n",
      "  timestamp: 1553136779\n",
      "  timesteps_since_restore: 6800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6800000\n",
      "  training_iteration: 680\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14956 s, 680 iter, 6800000 ts, 62.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-53-21\n",
      "  done: false\n",
      "  episode_len_mean: 81.99186991869918\n",
      "  episode_reward_max: 387.58359609069987\n",
      "  episode_reward_mean: 105.88537240947635\n",
      "  episode_reward_min: -164.71114426609518\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 85784\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.436\n",
      "    load_time_ms: 1.631\n",
      "    num_steps_sampled: 6810000\n",
      "    num_steps_trained: 6810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.544648289680481\n",
      "      kl: 0.012939400970935822\n",
      "      policy_loss: 0.002008527982980013\n",
      "      total_loss: 45.154537200927734\n",
      "      vf_explained_var: 0.8925694227218628\n",
      "      vf_loss: 45.14992904663086\n",
      "    sample_time_ms: 17916.31\n",
      "    update_time_ms: 5.405\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.94268620473819\n",
      "  time_since_restore: 14978.673550844193\n",
      "  time_this_iter_s: 21.72111678123474\n",
      "  time_total_s: 14978.673550844193\n",
      "  timestamp: 1553136801\n",
      "  timesteps_since_restore: 6810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6810000\n",
      "  training_iteration: 681\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 14978 s, 681 iter, 6810000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-53-43\n",
      "  done: false\n",
      "  episode_len_mean: 79.01574803149606\n",
      "  episode_reward_max: 388.02931777210307\n",
      "  episode_reward_mean: 88.18729377161974\n",
      "  episode_reward_min: -166.69196467706203\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 85911\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.58\n",
      "    load_time_ms: 1.594\n",
      "    num_steps_sampled: 6820000\n",
      "    num_steps_trained: 6820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5583122372627258\n",
      "      kl: 0.012954024598002434\n",
      "      policy_loss: 0.002653779461979866\n",
      "      total_loss: 55.6667594909668\n",
      "      vf_explained_var: 0.8745025396347046\n",
      "      vf_loss: 55.661502838134766\n",
      "    sample_time_ms: 17926.658\n",
      "    update_time_ms: 5.552\n",
      "  iterations_since_restore: 682\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.09364688580987\n",
      "  time_since_restore: 15000.647191762924\n",
      "  time_this_iter_s: 21.97364091873169\n",
      "  time_total_s: 15000.647191762924\n",
      "  timestamp: 1553136823\n",
      "  timesteps_since_restore: 6820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6820000\n",
      "  training_iteration: 682\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15000 s, 682 iter, 6820000 ts, 88.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-54-05\n",
      "  done: false\n",
      "  episode_len_mean: 82.44628099173553\n",
      "  episode_reward_max: 386.937286381831\n",
      "  episode_reward_mean: 110.3830487131868\n",
      "  episode_reward_min: -166.7844202731514\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 86032\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.718\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 6830000\n",
      "    num_steps_trained: 6830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5357348918914795\n",
      "      kl: 0.015864834189414978\n",
      "      policy_loss: 0.0036806482821702957\n",
      "      total_loss: 39.99131774902344\n",
      "      vf_explained_var: 0.9022758603096008\n",
      "      vf_loss: 39.98445129394531\n",
      "    sample_time_ms: 17940.615\n",
      "    update_time_ms: 5.597\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.19152435659338\n",
      "  time_since_restore: 15022.142211675644\n",
      "  time_this_iter_s: 21.495019912719727\n",
      "  time_total_s: 15022.142211675644\n",
      "  timestamp: 1553136845\n",
      "  timesteps_since_restore: 6830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6830000\n",
      "  training_iteration: 683\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15022 s, 683 iter, 6830000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-54-27\n",
      "  done: false\n",
      "  episode_len_mean: 73.61481481481482\n",
      "  episode_reward_max: 387.5491610052289\n",
      "  episode_reward_mean: 47.93665456560255\n",
      "  episode_reward_min: -166.74710284861564\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 86167\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.159\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 6840000\n",
      "    num_steps_trained: 6840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5843755602836609\n",
      "      kl: 0.015005762688815594\n",
      "      policy_loss: 0.003634574357420206\n",
      "      total_loss: 50.970542907714844\n",
      "      vf_explained_var: 0.8997343182563782\n",
      "      vf_loss: 50.963897705078125\n",
      "    sample_time_ms: 17993.744\n",
      "    update_time_ms: 5.703\n",
      "  iterations_since_restore: 684\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.96832728280127\n",
      "  time_since_restore: 15044.37075829506\n",
      "  time_this_iter_s: 22.228546619415283\n",
      "  time_total_s: 15044.37075829506\n",
      "  timestamp: 1553136867\n",
      "  timesteps_since_restore: 6840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6840000\n",
      "  training_iteration: 684\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15044 s, 684 iter, 6840000 ts, 47.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-54-49\n",
      "  done: false\n",
      "  episode_len_mean: 79.62204724409449\n",
      "  episode_reward_max: 386.3604304890663\n",
      "  episode_reward_mean: 95.47405161508041\n",
      "  episode_reward_min: -164.69301438066006\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 86294\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.394\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 6850000\n",
      "    num_steps_trained: 6850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5492525100708008\n",
      "      kl: 0.01871330663561821\n",
      "      policy_loss: 0.00308289285749197\n",
      "      total_loss: 50.19095993041992\n",
      "      vf_explained_var: 0.8878002762794495\n",
      "      vf_loss: 50.18412399291992\n",
      "    sample_time_ms: 18060.959\n",
      "    update_time_ms: 5.399\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.737025807540206\n",
      "  time_since_restore: 15066.490338087082\n",
      "  time_this_iter_s: 22.119579792022705\n",
      "  time_total_s: 15066.490338087082\n",
      "  timestamp: 1553136889\n",
      "  timesteps_since_restore: 6850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6850000\n",
      "  training_iteration: 685\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15066 s, 685 iter, 6850000 ts, 95.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-55-11\n",
      "  done: false\n",
      "  episode_len_mean: 71.64028776978417\n",
      "  episode_reward_max: 386.6079279147844\n",
      "  episode_reward_mean: 34.857938893906365\n",
      "  episode_reward_min: -166.75849353286264\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 86433\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.618\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 6860000\n",
      "    num_steps_trained: 6860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5824533104896545\n",
      "      kl: 0.019235113635659218\n",
      "      policy_loss: 0.0031558109913021326\n",
      "      total_loss: 57.71204376220703\n",
      "      vf_explained_var: 0.8917590379714966\n",
      "      vf_loss: 57.70502853393555\n",
      "    sample_time_ms: 18122.91\n",
      "    update_time_ms: 5.334\n",
      "  iterations_since_restore: 686\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.42896944695318\n",
      "  time_since_restore: 15088.353647232056\n",
      "  time_this_iter_s: 21.863309144973755\n",
      "  time_total_s: 15088.353647232056\n",
      "  timestamp: 1553136911\n",
      "  timesteps_since_restore: 6860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6860000\n",
      "  training_iteration: 686\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15088 s, 686 iter, 6860000 ts, 34.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-55-32\n",
      "  done: false\n",
      "  episode_len_mean: 81.22764227642277\n",
      "  episode_reward_max: 390.5604909014353\n",
      "  episode_reward_mean: 103.38954913185361\n",
      "  episode_reward_min: -165.20229033538342\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 86556\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.041\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 6870000\n",
      "    num_steps_trained: 6870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5529432892799377\n",
      "      kl: 0.013366170227527618\n",
      "      policy_loss: 0.001059908652678132\n",
      "      total_loss: 49.54587173461914\n",
      "      vf_explained_var: 0.8844487071037292\n",
      "      vf_loss: 49.54212951660156\n",
      "    sample_time_ms: 18052.186\n",
      "    update_time_ms: 5.283\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.69477456592681\n",
      "  time_since_restore: 15109.225606679916\n",
      "  time_this_iter_s: 20.871959447860718\n",
      "  time_total_s: 15109.225606679916\n",
      "  timestamp: 1553136932\n",
      "  timesteps_since_restore: 6870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6870000\n",
      "  training_iteration: 687\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15109 s, 687 iter, 6870000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-55-54\n",
      "  done: false\n",
      "  episode_len_mean: 76.41221374045801\n",
      "  episode_reward_max: 390.8353941676008\n",
      "  episode_reward_mean: 72.0553836657083\n",
      "  episode_reward_min: -166.90545652469635\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 86687\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.014\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 6880000\n",
      "    num_steps_trained: 6880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5692216157913208\n",
      "      kl: 0.015487859025597572\n",
      "      policy_loss: 0.0022525109816342592\n",
      "      total_loss: 49.756568908691406\n",
      "      vf_explained_var: 0.8955805897712708\n",
      "      vf_loss: 49.75120544433594\n",
      "    sample_time_ms: 18066.132\n",
      "    update_time_ms: 5.112\n",
      "  iterations_since_restore: 688\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.02769183285415\n",
      "  time_since_restore: 15130.958926200867\n",
      "  time_this_iter_s: 21.733319520950317\n",
      "  time_total_s: 15130.958926200867\n",
      "  timestamp: 1553136954\n",
      "  timesteps_since_restore: 6880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6880000\n",
      "  training_iteration: 688\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15130 s, 688 iter, 6880000 ts, 72.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-56-16\n",
      "  done: false\n",
      "  episode_len_mean: 79.448\n",
      "  episode_reward_max: 386.1930373754904\n",
      "  episode_reward_mean: 98.62419701776162\n",
      "  episode_reward_min: -164.7162984069252\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 86812\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.116\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 6890000\n",
      "    num_steps_trained: 6890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5400063991546631\n",
      "      kl: 0.015770668163895607\n",
      "      policy_loss: 0.0028766526374965906\n",
      "      total_loss: 41.75210189819336\n",
      "      vf_explained_var: 0.9068713188171387\n",
      "      vf_loss: 41.746063232421875\n",
      "    sample_time_ms: 18087.626\n",
      "    update_time_ms: 5.154\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.31209850888081\n",
      "  time_since_restore: 15153.055417776108\n",
      "  time_this_iter_s: 22.09649157524109\n",
      "  time_total_s: 15153.055417776108\n",
      "  timestamp: 1553136976\n",
      "  timesteps_since_restore: 6890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6890000\n",
      "  training_iteration: 689\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15153 s, 689 iter, 6890000 ts, 98.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-56-37\n",
      "  done: false\n",
      "  episode_len_mean: 78.140625\n",
      "  episode_reward_max: 390.98616955503985\n",
      "  episode_reward_mean: 86.38733682866615\n",
      "  episode_reward_min: -168.70078453561305\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 86940\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.523\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 6900000\n",
      "    num_steps_trained: 6900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5479949712753296\n",
      "      kl: 0.013364036567509174\n",
      "      policy_loss: 0.0014985402813181281\n",
      "      total_loss: 55.03044128417969\n",
      "      vf_explained_var: 0.8819959759712219\n",
      "      vf_loss: 55.026268005371094\n",
      "    sample_time_ms: 18023.853\n",
      "    update_time_ms: 5.157\n",
      "  iterations_since_restore: 690\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.193668414333075\n",
      "  time_since_restore: 15174.512823104858\n",
      "  time_this_iter_s: 21.45740532875061\n",
      "  time_total_s: 15174.512823104858\n",
      "  timestamp: 1553136997\n",
      "  timesteps_since_restore: 6900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6900000\n",
      "  training_iteration: 690\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15174 s, 690 iter, 6900000 ts, 86.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-57-00\n",
      "  done: false\n",
      "  episode_len_mean: 78.16279069767442\n",
      "  episode_reward_max: 388.49683573685894\n",
      "  episode_reward_mean: 82.80556518842958\n",
      "  episode_reward_min: -162.7243856380844\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 87069\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.966\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 6910000\n",
      "    num_steps_trained: 6910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5592395067214966\n",
      "      kl: 0.013734878972172737\n",
      "      policy_loss: 0.0024988530203700066\n",
      "      total_loss: 39.55411911010742\n",
      "      vf_explained_var: 0.9140636920928955\n",
      "      vf_loss: 39.54886245727539\n",
      "    sample_time_ms: 18097.616\n",
      "    update_time_ms: 5.204\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.40278259421478\n",
      "  time_since_restore: 15196.965605735779\n",
      "  time_this_iter_s: 22.45278263092041\n",
      "  time_total_s: 15196.965605735779\n",
      "  timestamp: 1553137020\n",
      "  timesteps_since_restore: 6910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6910000\n",
      "  training_iteration: 691\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15196 s, 691 iter, 6910000 ts, 82.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-57-22\n",
      "  done: false\n",
      "  episode_len_mean: 73.32352941176471\n",
      "  episode_reward_max: 392.36832785705286\n",
      "  episode_reward_mean: 47.487224930628656\n",
      "  episode_reward_min: -166.74506120141984\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 87205\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.992\n",
      "    load_time_ms: 1.5\n",
      "    num_steps_sampled: 6920000\n",
      "    num_steps_trained: 6920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.59039306640625\n",
      "      kl: 0.013788064010441303\n",
      "      policy_loss: 0.002831692574545741\n",
      "      total_loss: 54.553497314453125\n",
      "      vf_explained_var: 0.8940415978431702\n",
      "      vf_loss: 54.54789352416992\n",
      "    sample_time_ms: 18098.702\n",
      "    update_time_ms: 4.891\n",
      "  iterations_since_restore: 692\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.743612465314325\n",
      "  time_since_restore: 15218.801040172577\n",
      "  time_this_iter_s: 21.835434436798096\n",
      "  time_total_s: 15218.801040172577\n",
      "  timestamp: 1553137042\n",
      "  timesteps_since_restore: 6920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6920000\n",
      "  training_iteration: 692\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15218 s, 692 iter, 6920000 ts, 47.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-57-44\n",
      "  done: false\n",
      "  episode_len_mean: 79.48412698412699\n",
      "  episode_reward_max: 390.8633060647584\n",
      "  episode_reward_mean: 94.65017131315696\n",
      "  episode_reward_min: -166.73381844028472\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 87331\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.503\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 6930000\n",
      "    num_steps_trained: 6930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5420160293579102\n",
      "      kl: 0.011094481684267521\n",
      "      policy_loss: 0.0009987151715904474\n",
      "      total_loss: 38.46270751953125\n",
      "      vf_explained_var: 0.9157742261886597\n",
      "      vf_loss: 38.45947265625\n",
      "    sample_time_ms: 18160.115\n",
      "    update_time_ms: 5.127\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.325085656578466\n",
      "  time_since_restore: 15240.879945278168\n",
      "  time_this_iter_s: 22.07890510559082\n",
      "  time_total_s: 15240.879945278168\n",
      "  timestamp: 1553137064\n",
      "  timesteps_since_restore: 6930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6930000\n",
      "  training_iteration: 693\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15240 s, 693 iter, 6930000 ts, 94.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-58-06\n",
      "  done: false\n",
      "  episode_len_mean: 78.28125\n",
      "  episode_reward_max: 388.2354010609049\n",
      "  episode_reward_mean: 77.48489856016862\n",
      "  episode_reward_min: -166.73934882673262\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 87459\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.735\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 6940000\n",
      "    num_steps_trained: 6940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5516394972801208\n",
      "      kl: 0.01223790179938078\n",
      "      policy_loss: 0.0044549559243023396\n",
      "      total_loss: 54.67762756347656\n",
      "      vf_explained_var: 0.8836596608161926\n",
      "      vf_loss: 54.67071533203125\n",
      "    sample_time_ms: 18113.224\n",
      "    update_time_ms: 5.062\n",
      "  iterations_since_restore: 694\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.7424492800843\n",
      "  time_since_restore: 15262.664019584656\n",
      "  time_this_iter_s: 21.784074306488037\n",
      "  time_total_s: 15262.664019584656\n",
      "  timestamp: 1553137086\n",
      "  timesteps_since_restore: 6940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6940000\n",
      "  training_iteration: 694\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15262 s, 694 iter, 6940000 ts, 77.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-58-28\n",
      "  done: false\n",
      "  episode_len_mean: 78.66141732283465\n",
      "  episode_reward_max: 391.6814801753987\n",
      "  episode_reward_mean: 89.7023418902832\n",
      "  episode_reward_min: -168.7453071844244\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 87586\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.38\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 6950000\n",
      "    num_steps_trained: 6950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5344956517219543\n",
      "      kl: 0.013158280402421951\n",
      "      policy_loss: 7.91733109508641e-05\n",
      "      total_loss: 58.28369140625\n",
      "      vf_explained_var: 0.8687198162078857\n",
      "      vf_loss: 58.28096389770508\n",
      "    sample_time_ms: 18105.052\n",
      "    update_time_ms: 5.095\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.85117094514159\n",
      "  time_since_restore: 15284.719220399857\n",
      "  time_this_iter_s: 22.055200815200806\n",
      "  time_total_s: 15284.719220399857\n",
      "  timestamp: 1553137108\n",
      "  timesteps_since_restore: 6950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6950000\n",
      "  training_iteration: 695\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15284 s, 695 iter, 6950000 ts, 89.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-58-50\n",
      "  done: false\n",
      "  episode_len_mean: 79.28\n",
      "  episode_reward_max: 388.42611471452943\n",
      "  episode_reward_mean: 85.46950665965778\n",
      "  episode_reward_min: -168.6919263058567\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 87711\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3680.941\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 6960000\n",
      "    num_steps_trained: 6960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5249084830284119\n",
      "      kl: 0.016119271516799927\n",
      "      policy_loss: 0.0022782087326049805\n",
      "      total_loss: 48.33523178100586\n",
      "      vf_explained_var: 0.8908349871635437\n",
      "      vf_loss: 48.32971954345703\n",
      "    sample_time_ms: 18139.35\n",
      "    update_time_ms: 5.135\n",
      "  iterations_since_restore: 696\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.73475332982888\n",
      "  time_since_restore: 15306.810955047607\n",
      "  time_this_iter_s: 22.091734647750854\n",
      "  time_total_s: 15306.810955047607\n",
      "  timestamp: 1553137130\n",
      "  timesteps_since_restore: 6960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6960000\n",
      "  training_iteration: 696\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15306 s, 696 iter, 6960000 ts, 85.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-59-12\n",
      "  done: false\n",
      "  episode_len_mean: 79.67716535433071\n",
      "  episode_reward_max: 388.2393703637752\n",
      "  episode_reward_mean: 99.46107827936248\n",
      "  episode_reward_min: -168.68145930537224\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 87838\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.086\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 6970000\n",
      "    num_steps_trained: 6970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5183218717575073\n",
      "      kl: 0.013545351102948189\n",
      "      policy_loss: 0.0022192776668816805\n",
      "      total_loss: 55.13489532470703\n",
      "      vf_explained_var: 0.870750904083252\n",
      "      vf_loss: 55.12995147705078\n",
      "    sample_time_ms: 18226.162\n",
      "    update_time_ms: 5.045\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.73053913968122\n",
      "  time_since_restore: 15328.770320177078\n",
      "  time_this_iter_s: 21.959365129470825\n",
      "  time_total_s: 15328.770320177078\n",
      "  timestamp: 1553137152\n",
      "  timesteps_since_restore: 6970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6970000\n",
      "  training_iteration: 697\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15328 s, 697 iter, 6970000 ts, 99.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-59-34\n",
      "  done: false\n",
      "  episode_len_mean: 73.68656716417911\n",
      "  episode_reward_max: 386.5148994371071\n",
      "  episode_reward_mean: 47.92500639368922\n",
      "  episode_reward_min: -168.68717232951164\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 87972\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.569\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 6980000\n",
      "    num_steps_trained: 6980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5471649169921875\n",
      "      kl: 0.014326817356050014\n",
      "      policy_loss: 0.0014761111233383417\n",
      "      total_loss: 56.488868713378906\n",
      "      vf_explained_var: 0.8891014456748962\n",
      "      vf_loss: 56.484519958496094\n",
      "    sample_time_ms: 18258.125\n",
      "    update_time_ms: 5.072\n",
      "  iterations_since_restore: 698\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.9625031968446\n",
      "  time_since_restore: 15350.807900428772\n",
      "  time_this_iter_s: 22.037580251693726\n",
      "  time_total_s: 15350.807900428772\n",
      "  timestamp: 1553137174\n",
      "  timesteps_since_restore: 6980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6980000\n",
      "  training_iteration: 698\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15350 s, 698 iter, 6980000 ts, 47.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_03-59-56\n",
      "  done: false\n",
      "  episode_len_mean: 79.57142857142857\n",
      "  episode_reward_max: 386.1482357153588\n",
      "  episode_reward_mean: 93.06729035657871\n",
      "  episode_reward_min: -168.73538800868033\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 88098\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.94\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 6990000\n",
      "    num_steps_trained: 6990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5083627104759216\n",
      "      kl: 0.010866350494325161\n",
      "      policy_loss: 0.0014996409881860018\n",
      "      total_loss: 46.577049255371094\n",
      "      vf_explained_var: 0.8967686295509338\n",
      "      vf_loss: 46.5733642578125\n",
      "    sample_time_ms: 18211.881\n",
      "    update_time_ms: 5.094\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.53364517828935\n",
      "  time_since_restore: 15372.418907880783\n",
      "  time_this_iter_s: 21.61100745201111\n",
      "  time_total_s: 15372.418907880783\n",
      "  timestamp: 1553137196\n",
      "  timesteps_since_restore: 6990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6990000\n",
      "  training_iteration: 699\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15372 s, 699 iter, 6990000 ts, 93.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-00-17\n",
      "  done: false\n",
      "  episode_len_mean: 78.63492063492063\n",
      "  episode_reward_max: 386.28380465493717\n",
      "  episode_reward_mean: 84.26068444315865\n",
      "  episode_reward_min: -166.67739423307418\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 88224\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.125\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 7000000\n",
      "    num_steps_trained: 7000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49773505330085754\n",
      "      kl: 0.0162586010992527\n",
      "      policy_loss: 0.001856279675848782\n",
      "      total_loss: 56.638545989990234\n",
      "      vf_explained_var: 0.875049889087677\n",
      "      vf_loss: 56.633419036865234\n",
      "    sample_time_ms: 18227.232\n",
      "    update_time_ms: 5.054\n",
      "  iterations_since_restore: 700\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.13034222157932\n",
      "  time_since_restore: 15394.020247936249\n",
      "  time_this_iter_s: 21.6013400554657\n",
      "  time_total_s: 15394.020247936249\n",
      "  timestamp: 1553137217\n",
      "  timesteps_since_restore: 7000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7000000\n",
      "  training_iteration: 700\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15394 s, 700 iter, 7000000 ts, 84.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-00-39\n",
      "  done: false\n",
      "  episode_len_mean: 80.2936507936508\n",
      "  episode_reward_max: 391.1997175387608\n",
      "  episode_reward_mean: 99.7936357274864\n",
      "  episode_reward_min: -166.70001007911205\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 88350\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.997\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 7010000\n",
      "    num_steps_trained: 7010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5147143006324768\n",
      "      kl: 0.01812547817826271\n",
      "      policy_loss: 0.0028999829664826393\n",
      "      total_loss: 44.76457214355469\n",
      "      vf_explained_var: 0.8942172527313232\n",
      "      vf_loss: 44.75802993774414\n",
      "    sample_time_ms: 18164.38\n",
      "    update_time_ms: 5.093\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.896817863743195\n",
      "  time_since_restore: 15415.881783485413\n",
      "  time_this_iter_s: 21.86153554916382\n",
      "  time_total_s: 15415.881783485413\n",
      "  timestamp: 1553137239\n",
      "  timesteps_since_restore: 7010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7010000\n",
      "  training_iteration: 701\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15415 s, 701 iter, 7010000 ts, 99.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-01-01\n",
      "  done: false\n",
      "  episode_len_mean: 78.04651162790698\n",
      "  episode_reward_max: 388.15972772603544\n",
      "  episode_reward_mean: 78.61860870393295\n",
      "  episode_reward_min: -168.72438324066638\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 88479\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.767\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 7020000\n",
      "    num_steps_trained: 7020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5329049229621887\n",
      "      kl: 0.020696669816970825\n",
      "      policy_loss: 0.004888919647783041\n",
      "      total_loss: 47.06879425048828\n",
      "      vf_explained_var: 0.9011242389678955\n",
      "      vf_loss: 47.059749603271484\n",
      "    sample_time_ms: 18145.728\n",
      "    update_time_ms: 5.125\n",
      "  iterations_since_restore: 702\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.30930435196647\n",
      "  time_since_restore: 15437.528140306473\n",
      "  time_this_iter_s: 21.64635682106018\n",
      "  time_total_s: 15437.528140306473\n",
      "  timestamp: 1553137261\n",
      "  timesteps_since_restore: 7020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7020000\n",
      "  training_iteration: 702\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15437 s, 702 iter, 7020000 ts, 78.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-01-22\n",
      "  done: false\n",
      "  episode_len_mean: 74.29323308270676\n",
      "  episode_reward_max: 386.9487063623626\n",
      "  episode_reward_mean: 56.57600070085678\n",
      "  episode_reward_min: -166.69772761913777\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 88612\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.01\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 7030000\n",
      "    num_steps_trained: 7030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.53369140625\n",
      "      kl: 0.0145501047372818\n",
      "      policy_loss: 0.002541404217481613\n",
      "      total_loss: 58.11507797241211\n",
      "      vf_explained_var: 0.881941556930542\n",
      "      vf_loss: 58.10961151123047\n",
      "    sample_time_ms: 18096.115\n",
      "    update_time_ms: 4.863\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.288000350428383\n",
      "  time_since_restore: 15459.110867977142\n",
      "  time_this_iter_s: 21.582727670669556\n",
      "  time_total_s: 15459.110867977142\n",
      "  timestamp: 1553137282\n",
      "  timesteps_since_restore: 7030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7030000\n",
      "  training_iteration: 703\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15459 s, 703 iter, 7030000 ts, 56.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-01-45\n",
      "  done: false\n",
      "  episode_len_mean: 70.6830985915493\n",
      "  episode_reward_max: 387.65953081495326\n",
      "  episode_reward_mean: 33.078926787883155\n",
      "  episode_reward_min: -164.66513505717757\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 88754\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.689\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 7040000\n",
      "    num_steps_trained: 7040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5458700656890869\n",
      "      kl: 0.015267170034348965\n",
      "      policy_loss: 0.0019110661232843995\n",
      "      total_loss: 60.70987319946289\n",
      "      vf_explained_var: 0.8880147933959961\n",
      "      vf_loss: 60.70489501953125\n",
      "    sample_time_ms: 18133.905\n",
      "    update_time_ms: 5.092\n",
      "  iterations_since_restore: 704\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.539463393941578\n",
      "  time_since_restore: 15481.26870393753\n",
      "  time_this_iter_s: 22.157835960388184\n",
      "  time_total_s: 15481.26870393753\n",
      "  timestamp: 1553137305\n",
      "  timesteps_since_restore: 7040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7040000\n",
      "  training_iteration: 704\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15481 s, 704 iter, 7040000 ts, 33.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-02-07\n",
      "  done: false\n",
      "  episode_len_mean: 79.18110236220473\n",
      "  episode_reward_max: 388.22463167637164\n",
      "  episode_reward_mean: 87.47756364777086\n",
      "  episode_reward_min: -168.70240874763965\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 88881\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.071\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 7050000\n",
      "    num_steps_trained: 7050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5008477568626404\n",
      "      kl: 0.010621117427945137\n",
      "      policy_loss: 0.004126806277781725\n",
      "      total_loss: 38.953758239746094\n",
      "      vf_explained_var: 0.9156543016433716\n",
      "      vf_loss: 38.9474983215332\n",
      "    sample_time_ms: 18145.863\n",
      "    update_time_ms: 5.159\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.738781823885425\n",
      "  time_since_restore: 15503.409401893616\n",
      "  time_this_iter_s: 22.140697956085205\n",
      "  time_total_s: 15503.409401893616\n",
      "  timestamp: 1553137327\n",
      "  timesteps_since_restore: 7050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7050000\n",
      "  training_iteration: 705\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15503 s, 705 iter, 7050000 ts, 87.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-02-29\n",
      "  done: false\n",
      "  episode_len_mean: 76.43846153846154\n",
      "  episode_reward_max: 387.21439341868864\n",
      "  episode_reward_mean: 70.59632542594018\n",
      "  episode_reward_min: -168.84651818570137\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 89011\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.557\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 7060000\n",
      "    num_steps_trained: 7060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5284144282341003\n",
      "      kl: 0.012174785137176514\n",
      "      policy_loss: 0.0006095413700677454\n",
      "      total_loss: 40.36485290527344\n",
      "      vf_explained_var: 0.9185441136360168\n",
      "      vf_loss: 40.36179733276367\n",
      "    sample_time_ms: 18130.873\n",
      "    update_time_ms: 5.227\n",
      "  iterations_since_restore: 706\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.29816271297008\n",
      "  time_since_restore: 15525.345880746841\n",
      "  time_this_iter_s: 21.936478853225708\n",
      "  time_total_s: 15525.345880746841\n",
      "  timestamp: 1553137349\n",
      "  timesteps_since_restore: 7060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7060000\n",
      "  training_iteration: 706\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15525 s, 706 iter, 7060000 ts, 70.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-02-51\n",
      "  done: false\n",
      "  episode_len_mean: 79.16535433070867\n",
      "  episode_reward_max: 387.31587289310033\n",
      "  episode_reward_mean: 86.89022304202533\n",
      "  episode_reward_min: -168.77869663747788\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 89138\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3673.12\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 7070000\n",
      "    num_steps_trained: 7070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5271080136299133\n",
      "      kl: 0.014298142865300179\n",
      "      policy_loss: 0.0033339629881083965\n",
      "      total_loss: 50.04069137573242\n",
      "      vf_explained_var: 0.8889134526252747\n",
      "      vf_loss: 50.034481048583984\n",
      "    sample_time_ms: 18133.254\n",
      "    update_time_ms: 5.319\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.44511152101266\n",
      "  time_since_restore: 15547.088231086731\n",
      "  time_this_iter_s: 21.742350339889526\n",
      "  time_total_s: 15547.088231086731\n",
      "  timestamp: 1553137371\n",
      "  timesteps_since_restore: 7070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7070000\n",
      "  training_iteration: 707\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15547 s, 707 iter, 7070000 ts, 86.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-03-13\n",
      "  done: false\n",
      "  episode_len_mean: 75.6015037593985\n",
      "  episode_reward_max: 389.9689980555074\n",
      "  episode_reward_mean: 67.64878540848065\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 89271\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3680.568\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 7080000\n",
      "    num_steps_trained: 7080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5304526090621948\n",
      "      kl: 0.01715473271906376\n",
      "      policy_loss: 0.0041570113971829414\n",
      "      total_loss: 63.39624786376953\n",
      "      vf_explained_var: 0.8727326989173889\n",
      "      vf_loss: 63.38864517211914\n",
      "    sample_time_ms: 18116.475\n",
      "    update_time_ms: 5.216\n",
      "  iterations_since_restore: 708\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.824392704240324\n",
      "  time_since_restore: 15569.030336380005\n",
      "  time_this_iter_s: 21.942105293273926\n",
      "  time_total_s: 15569.030336380005\n",
      "  timestamp: 1553137393\n",
      "  timesteps_since_restore: 7080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7080000\n",
      "  training_iteration: 708\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15569 s, 708 iter, 7080000 ts, 67.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-03-34\n",
      "  done: false\n",
      "  episode_len_mean: 80.10483870967742\n",
      "  episode_reward_max: 387.34001599344236\n",
      "  episode_reward_mean: 99.48283076987066\n",
      "  episode_reward_min: -166.74695658906936\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 89395\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.26\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 7090000\n",
      "    num_steps_trained: 7090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5187292695045471\n",
      "      kl: 0.017209621146321297\n",
      "      policy_loss: 0.004916003439575434\n",
      "      total_loss: 45.88716125488281\n",
      "      vf_explained_var: 0.8932965397834778\n",
      "      vf_loss: 45.878787994384766\n",
      "    sample_time_ms: 18087.912\n",
      "    update_time_ms: 5.328\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.74141538493533\n",
      "  time_since_restore: 15590.381616830826\n",
      "  time_this_iter_s: 21.351280450820923\n",
      "  time_total_s: 15590.381616830826\n",
      "  timestamp: 1553137414\n",
      "  timesteps_since_restore: 7090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7090000\n",
      "  training_iteration: 709\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15590 s, 709 iter, 7090000 ts, 99.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-03-56\n",
      "  done: false\n",
      "  episode_len_mean: 76.10687022900764\n",
      "  episode_reward_max: 386.27630961618894\n",
      "  episode_reward_mean: 68.84580992420238\n",
      "  episode_reward_min: -166.7131366018915\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 89526\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.894\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 7100000\n",
      "    num_steps_trained: 7100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5250216126441956\n",
      "      kl: 0.012664577923715115\n",
      "      policy_loss: 0.0022636931389570236\n",
      "      total_loss: 45.7993049621582\n",
      "      vf_explained_var: 0.9047659635543823\n",
      "      vf_loss: 45.79449462890625\n",
      "    sample_time_ms: 18166.335\n",
      "    update_time_ms: 5.339\n",
      "  iterations_since_restore: 710\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.42290496210119\n",
      "  time_since_restore: 15612.753833532333\n",
      "  time_this_iter_s: 22.37221670150757\n",
      "  time_total_s: 15612.753833532333\n",
      "  timestamp: 1553137436\n",
      "  timesteps_since_restore: 7100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7100000\n",
      "  training_iteration: 710\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15612 s, 710 iter, 7100000 ts, 68.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 73.18978102189782\n",
      "  episode_reward_max: 387.0694824353542\n",
      "  episode_reward_mean: 45.976390826667064\n",
      "  episode_reward_min: -166.69472764715195\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 89663\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3677.179\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 7110000\n",
      "    num_steps_trained: 7110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5352457761764526\n",
      "      kl: 0.012325291521847248\n",
      "      policy_loss: 0.0001680341811152175\n",
      "      total_loss: 55.891788482666016\n",
      "      vf_explained_var: 0.8915213346481323\n",
      "      vf_loss: 55.88914108276367\n",
      "    sample_time_ms: 18198.871\n",
      "    update_time_ms: 5.252\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.98819541333353\n",
      "  time_since_restore: 15634.894903182983\n",
      "  time_this_iter_s: 22.141069650650024\n",
      "  time_total_s: 15634.894903182983\n",
      "  timestamp: 1553137459\n",
      "  timesteps_since_restore: 7110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7110000\n",
      "  training_iteration: 711\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15634 s, 711 iter, 7110000 ts, 46 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-04-40\n",
      "  done: false\n",
      "  episode_len_mean: 76.48091603053435\n",
      "  episode_reward_max: 390.2657070678396\n",
      "  episode_reward_mean: 67.93186090823328\n",
      "  episode_reward_min: -166.7476541360283\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 89794\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.842\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 7120000\n",
      "    num_steps_trained: 7120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5321604609489441\n",
      "      kl: 0.012635646387934685\n",
      "      policy_loss: 0.0015240315115079284\n",
      "      total_loss: 53.28459167480469\n",
      "      vf_explained_var: 0.8889709711074829\n",
      "      vf_loss: 53.28053665161133\n",
      "    sample_time_ms: 18192.775\n",
      "    update_time_ms: 5.331\n",
      "  iterations_since_restore: 712\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.96593045411663\n",
      "  time_since_restore: 15656.61610865593\n",
      "  time_this_iter_s: 21.721205472946167\n",
      "  time_total_s: 15656.61610865593\n",
      "  timestamp: 1553137480\n",
      "  timesteps_since_restore: 7120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7120000\n",
      "  training_iteration: 712\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15656 s, 712 iter, 7120000 ts, 67.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-05-02\n",
      "  done: false\n",
      "  episode_len_mean: 76.96899224806202\n",
      "  episode_reward_max: 388.03997247640183\n",
      "  episode_reward_mean: 71.85039759741358\n",
      "  episode_reward_min: -168.80930857631205\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 89923\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.496\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 7130000\n",
      "    num_steps_trained: 7130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5269331932067871\n",
      "      kl: 0.017155438661575317\n",
      "      policy_loss: 0.0005427295109257102\n",
      "      total_loss: 45.65159225463867\n",
      "      vf_explained_var: 0.9025388956069946\n",
      "      vf_loss: 45.647605895996094\n",
      "    sample_time_ms: 18205.716\n",
      "    update_time_ms: 5.329\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.92519879870679\n",
      "  time_since_restore: 15678.325836896896\n",
      "  time_this_iter_s: 21.709728240966797\n",
      "  time_total_s: 15678.325836896896\n",
      "  timestamp: 1553137502\n",
      "  timesteps_since_restore: 7130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7130000\n",
      "  training_iteration: 713\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15678 s, 713 iter, 7130000 ts, 71.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-05-24\n",
      "  done: false\n",
      "  episode_len_mean: 70.81818181818181\n",
      "  episode_reward_max: 384.9255493162214\n",
      "  episode_reward_mean: 24.579012429019556\n",
      "  episode_reward_min: -164.66875727781297\n",
      "  episodes_this_iter: 143\n",
      "  episodes_total: 90066\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.622\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 7140000\n",
      "    num_steps_trained: 7140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5705156922340393\n",
      "      kl: 0.012130029499530792\n",
      "      policy_loss: 0.0036974376998841763\n",
      "      total_loss: 57.69740295410156\n",
      "      vf_explained_var: 0.8953446745872498\n",
      "      vf_loss: 57.69126892089844\n",
      "    sample_time_ms: 18163.708\n",
      "    update_time_ms: 5.148\n",
      "  iterations_since_restore: 714\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.289506214509775\n",
      "  time_since_restore: 15700.036520004272\n",
      "  time_this_iter_s: 21.7106831073761\n",
      "  time_total_s: 15700.036520004272\n",
      "  timestamp: 1553137524\n",
      "  timesteps_since_restore: 7140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7140000\n",
      "  training_iteration: 714\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15700 s, 714 iter, 7140000 ts, 24.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-05-46\n",
      "  done: false\n",
      "  episode_len_mean: 76.73076923076923\n",
      "  episode_reward_max: 387.8035840154665\n",
      "  episode_reward_mean: 71.51645589985174\n",
      "  episode_reward_min: -162.61043705150126\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 90196\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.508\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 7150000\n",
      "    num_steps_trained: 7150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.521427571773529\n",
      "      kl: 0.020162086933851242\n",
      "      policy_loss: 0.003914608620107174\n",
      "      total_loss: 51.621700286865234\n",
      "      vf_explained_var: 0.8895384669303894\n",
      "      vf_loss: 51.61373519897461\n",
      "    sample_time_ms: 18161.242\n",
      "    update_time_ms: 5.734\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.75822794992586\n",
      "  time_since_restore: 15722.177026748657\n",
      "  time_this_iter_s: 22.140506744384766\n",
      "  time_total_s: 15722.177026748657\n",
      "  timestamp: 1553137546\n",
      "  timesteps_since_restore: 7150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7150000\n",
      "  training_iteration: 715\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15722 s, 715 iter, 7150000 ts, 71.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-06-07\n",
      "  done: false\n",
      "  episode_len_mean: 72.30434782608695\n",
      "  episode_reward_max: 382.9089962467945\n",
      "  episode_reward_mean: 39.01167754223137\n",
      "  episode_reward_min: -168.67978175696373\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 90334\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.538\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 7160000\n",
      "    num_steps_trained: 7160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5499612092971802\n",
      "      kl: 0.022821031510829926\n",
      "      policy_loss: 0.006533417850732803\n",
      "      total_loss: 55.57096862792969\n",
      "      vf_explained_var: 0.8980892896652222\n",
      "      vf_loss: 55.559852600097656\n",
      "    sample_time_ms: 18078.807\n",
      "    update_time_ms: 5.768\n",
      "  iterations_since_restore: 716\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.505838771115688\n",
      "  time_since_restore: 15743.33053970337\n",
      "  time_this_iter_s: 21.153512954711914\n",
      "  time_total_s: 15743.33053970337\n",
      "  timestamp: 1553137567\n",
      "  timesteps_since_restore: 7160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7160000\n",
      "  training_iteration: 716\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15743 s, 716 iter, 7160000 ts, 39 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-06-29\n",
      "  done: false\n",
      "  episode_len_mean: 73.56296296296296\n",
      "  episode_reward_max: 387.6569991199285\n",
      "  episode_reward_mean: 51.23673070579056\n",
      "  episode_reward_min: -168.8170248131418\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 90469\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.495\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 7170000\n",
      "    num_steps_trained: 7170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5487207174301147\n",
      "      kl: 0.01632804051041603\n",
      "      policy_loss: 0.0033238311298191547\n",
      "      total_loss: 47.11000442504883\n",
      "      vf_explained_var: 0.9083389043807983\n",
      "      vf_loss: 47.10340118408203\n",
      "    sample_time_ms: 18069.408\n",
      "    update_time_ms: 5.815\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.61836535289528\n",
      "  time_since_restore: 15765.02725815773\n",
      "  time_this_iter_s: 21.696718454360962\n",
      "  time_total_s: 15765.02725815773\n",
      "  timestamp: 1553137589\n",
      "  timesteps_since_restore: 7170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7170000\n",
      "  training_iteration: 717\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15765 s, 717 iter, 7170000 ts, 51.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-06-51\n",
      "  done: false\n",
      "  episode_len_mean: 74.55639097744361\n",
      "  episode_reward_max: 389.49171512220516\n",
      "  episode_reward_mean: 57.19912008908769\n",
      "  episode_reward_min: -162.63492896505832\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 90602\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.366\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 7180000\n",
      "    num_steps_trained: 7180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5400815010070801\n",
      "      kl: 0.014243732206523418\n",
      "      policy_loss: 0.0016714864177629352\n",
      "      total_loss: 43.59663009643555\n",
      "      vf_explained_var: 0.9119961857795715\n",
      "      vf_loss: 43.592098236083984\n",
      "    sample_time_ms: 18080.695\n",
      "    update_time_ms: 5.952\n",
      "  iterations_since_restore: 718\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.599560044543843\n",
      "  time_since_restore: 15787.022783994675\n",
      "  time_this_iter_s: 21.99552583694458\n",
      "  time_total_s: 15787.022783994675\n",
      "  timestamp: 1553137611\n",
      "  timesteps_since_restore: 7180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7180000\n",
      "  training_iteration: 718\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15787 s, 718 iter, 7180000 ts, 57.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-07-13\n",
      "  done: false\n",
      "  episode_len_mean: 76.80152671755725\n",
      "  episode_reward_max: 386.87700255107023\n",
      "  episode_reward_mean: 68.47532039938619\n",
      "  episode_reward_min: -168.7098773055935\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 90733\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.57\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 7190000\n",
      "    num_steps_trained: 7190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5184319019317627\n",
      "      kl: 0.014563444070518017\n",
      "      policy_loss: 0.0013223901623860002\n",
      "      total_loss: 52.21373748779297\n",
      "      vf_explained_var: 0.8936120271682739\n",
      "      vf_loss: 52.20949172973633\n",
      "    sample_time_ms: 18158.157\n",
      "    update_time_ms: 5.827\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.23766019969309\n",
      "  time_since_restore: 15809.218029022217\n",
      "  time_this_iter_s: 22.195245027542114\n",
      "  time_total_s: 15809.218029022217\n",
      "  timestamp: 1553137633\n",
      "  timesteps_since_restore: 7190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7190000\n",
      "  training_iteration: 719\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15809 s, 719 iter, 7190000 ts, 68.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-07-34\n",
      "  done: false\n",
      "  episode_len_mean: 73.29710144927536\n",
      "  episode_reward_max: 390.9660318619658\n",
      "  episode_reward_mean: 47.98439317425887\n",
      "  episode_reward_min: -168.70034375688076\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 90871\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.319\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 7200000\n",
      "    num_steps_trained: 7200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5445191860198975\n",
      "      kl: 0.017823901027441025\n",
      "      policy_loss: 0.0031528607942163944\n",
      "      total_loss: 55.645606994628906\n",
      "      vf_explained_var: 0.8929932713508606\n",
      "      vf_loss: 55.638885498046875\n",
      "    sample_time_ms: 18033.694\n",
      "    update_time_ms: 5.807\n",
      "  iterations_since_restore: 720\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.99219658712943\n",
      "  time_since_restore: 15830.373507261276\n",
      "  time_this_iter_s: 21.15547823905945\n",
      "  time_total_s: 15830.373507261276\n",
      "  timestamp: 1553137654\n",
      "  timesteps_since_restore: 7200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7200000\n",
      "  training_iteration: 720\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15830 s, 720 iter, 7200000 ts, 48 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-07-56\n",
      "  done: false\n",
      "  episode_len_mean: 76.61538461538461\n",
      "  episode_reward_max: 388.2775536403646\n",
      "  episode_reward_mean: 69.05393009394504\n",
      "  episode_reward_min: -168.73541407522202\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 91001\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.584\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 7210000\n",
      "    num_steps_trained: 7210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5066850185394287\n",
      "      kl: 0.014784712344408035\n",
      "      policy_loss: 0.0017100286204367876\n",
      "      total_loss: 52.500118255615234\n",
      "      vf_explained_var: 0.8910913467407227\n",
      "      vf_loss: 52.49543762207031\n",
      "    sample_time_ms: 17996.922\n",
      "    update_time_ms: 5.918\n",
      "  iterations_since_restore: 721\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.52696504697251\n",
      "  time_since_restore: 15852.16150546074\n",
      "  time_this_iter_s: 21.78799819946289\n",
      "  time_total_s: 15852.16150546074\n",
      "  timestamp: 1553137676\n",
      "  timesteps_since_restore: 7210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7210000\n",
      "  training_iteration: 721\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15852 s, 721 iter, 7210000 ts, 69.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-08-18\n",
      "  done: false\n",
      "  episode_len_mean: 72.02898550724638\n",
      "  episode_reward_max: 387.3246838887358\n",
      "  episode_reward_mean: 37.27640935070171\n",
      "  episode_reward_min: -168.7934794561529\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 91139\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.209\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 7220000\n",
      "    num_steps_trained: 7220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5224870443344116\n",
      "      kl: 0.011529968120157719\n",
      "      policy_loss: 0.0025246364530175924\n",
      "      total_loss: 49.32444381713867\n",
      "      vf_explained_var: 0.907556414604187\n",
      "      vf_loss: 49.31960678100586\n",
      "    sample_time_ms: 17968.881\n",
      "    update_time_ms: 5.775\n",
      "  iterations_since_restore: 722\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 18.638204675350856\n",
      "  time_since_restore: 15873.448482751846\n",
      "  time_this_iter_s: 21.286977291107178\n",
      "  time_total_s: 15873.448482751846\n",
      "  timestamp: 1553137698\n",
      "  timesteps_since_restore: 7220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7220000\n",
      "  training_iteration: 722\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15873 s, 722 iter, 7220000 ts, 37.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-08-39\n",
      "  done: false\n",
      "  episode_len_mean: 79.5748031496063\n",
      "  episode_reward_max: 389.2519792297312\n",
      "  episode_reward_mean: 93.55711760083956\n",
      "  episode_reward_min: -168.6439673548603\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 91266\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.895\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 7230000\n",
      "    num_steps_trained: 7230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4830560088157654\n",
      "      kl: 0.013947280123829842\n",
      "      policy_loss: 0.0007089804275892675\n",
      "      total_loss: 42.46543884277344\n",
      "      vf_explained_var: 0.9041771292686462\n",
      "      vf_loss: 42.4619255065918\n",
      "    sample_time_ms: 17976.18\n",
      "    update_time_ms: 5.842\n",
      "  iterations_since_restore: 723\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.77855880041977\n",
      "  time_since_restore: 15895.230949401855\n",
      "  time_this_iter_s: 21.782466650009155\n",
      "  time_total_s: 15895.230949401855\n",
      "  timestamp: 1553137719\n",
      "  timesteps_since_restore: 7230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7230000\n",
      "  training_iteration: 723\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15895 s, 723 iter, 7230000 ts, 93.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-09-01\n",
      "  done: false\n",
      "  episode_len_mean: 73.41481481481482\n",
      "  episode_reward_max: 388.02319224346314\n",
      "  episode_reward_mean: 47.11121284739853\n",
      "  episode_reward_min: -168.81952054163457\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 91401\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.895\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 7240000\n",
      "    num_steps_trained: 7240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5279914736747742\n",
      "      kl: 0.01783834584057331\n",
      "      policy_loss: 0.0038596291560679674\n",
      "      total_loss: 45.20820236206055\n",
      "      vf_explained_var: 0.9137710332870483\n",
      "      vf_loss: 45.20076370239258\n",
      "    sample_time_ms: 17975.266\n",
      "    update_time_ms: 6.004\n",
      "  iterations_since_restore: 724\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.555606423699256\n",
      "  time_since_restore: 15916.984489917755\n",
      "  time_this_iter_s: 21.753540515899658\n",
      "  time_total_s: 15916.984489917755\n",
      "  timestamp: 1553137741\n",
      "  timesteps_since_restore: 7240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7240000\n",
      "  training_iteration: 724\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15916 s, 724 iter, 7240000 ts, 47.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-09-23\n",
      "  done: false\n",
      "  episode_len_mean: 74.4\n",
      "  episode_reward_max: 388.3151215177454\n",
      "  episode_reward_mean: 55.67769432205879\n",
      "  episode_reward_min: -166.73189254507065\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 91536\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.036\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 7250000\n",
      "    num_steps_trained: 7250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.518695056438446\n",
      "      kl: 0.01136691402643919\n",
      "      policy_loss: 0.0026353991124778986\n",
      "      total_loss: 52.9367561340332\n",
      "      vf_explained_var: 0.894481360912323\n",
      "      vf_loss: 52.93183517456055\n",
      "    sample_time_ms: 17910.813\n",
      "    update_time_ms: 5.265\n",
      "  iterations_since_restore: 725\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.838847161029395\n",
      "  time_since_restore: 15938.455238342285\n",
      "  time_this_iter_s: 21.47074842453003\n",
      "  time_total_s: 15938.455238342285\n",
      "  timestamp: 1553137763\n",
      "  timesteps_since_restore: 7250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7250000\n",
      "  training_iteration: 725\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15938 s, 725 iter, 7250000 ts, 55.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-09-45\n",
      "  done: false\n",
      "  episode_len_mean: 74.16296296296296\n",
      "  episode_reward_max: 388.0070682355459\n",
      "  episode_reward_mean: 51.94297929209033\n",
      "  episode_reward_min: -164.75764655300617\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 91671\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.62\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 7260000\n",
      "    num_steps_trained: 7260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5046204924583435\n",
      "      kl: 0.01554354652762413\n",
      "      policy_loss: 0.0027858105022460222\n",
      "      total_loss: 52.14737319946289\n",
      "      vf_explained_var: 0.8991613388061523\n",
      "      vf_loss: 52.1414680480957\n",
      "    sample_time_ms: 18027.14\n",
      "    update_time_ms: 5.271\n",
      "  iterations_since_restore: 726\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.97148964604516\n",
      "  time_since_restore: 15960.781805992126\n",
      "  time_this_iter_s: 22.32656764984131\n",
      "  time_total_s: 15960.781805992126\n",
      "  timestamp: 1553137785\n",
      "  timesteps_since_restore: 7260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7260000\n",
      "  training_iteration: 726\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15960 s, 726 iter, 7260000 ts, 51.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-10-07\n",
      "  done: false\n",
      "  episode_len_mean: 76.08461538461539\n",
      "  episode_reward_max: 387.34197262204157\n",
      "  episode_reward_mean: 60.79203598284261\n",
      "  episode_reward_min: -166.78626527639867\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 91801\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.81\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 7270000\n",
      "    num_steps_trained: 7270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5204868912696838\n",
      "      kl: 0.015048794448375702\n",
      "      policy_loss: 0.0034544814843684435\n",
      "      total_loss: 55.28818130493164\n",
      "      vf_explained_var: 0.885500967502594\n",
      "      vf_loss: 55.281700134277344\n",
      "    sample_time_ms: 18068.135\n",
      "    update_time_ms: 5.098\n",
      "  iterations_since_restore: 727\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.396017991421306\n",
      "  time_since_restore: 15982.83617734909\n",
      "  time_this_iter_s: 22.05437135696411\n",
      "  time_total_s: 15982.83617734909\n",
      "  timestamp: 1553137807\n",
      "  timesteps_since_restore: 7270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7270000\n",
      "  training_iteration: 727\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 15982 s, 727 iter, 7270000 ts, 60.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-10-29\n",
      "  done: false\n",
      "  episode_len_mean: 75.30827067669173\n",
      "  episode_reward_max: 387.60848462736845\n",
      "  episode_reward_mean: 60.893220634304875\n",
      "  episode_reward_min: -164.6605181013012\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 91934\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.711\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 7280000\n",
      "    num_steps_trained: 7280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5269378423690796\n",
      "      kl: 0.014139262959361076\n",
      "      policy_loss: 0.002073397161439061\n",
      "      total_loss: 48.62065887451172\n",
      "      vf_explained_var: 0.903654932975769\n",
      "      vf_loss: 48.615745544433594\n",
      "    sample_time_ms: 18050.612\n",
      "    update_time_ms: 5.064\n",
      "  iterations_since_restore: 728\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.446610317152434\n",
      "  time_since_restore: 16004.644666671753\n",
      "  time_this_iter_s: 21.808489322662354\n",
      "  time_total_s: 16004.644666671753\n",
      "  timestamp: 1553137829\n",
      "  timesteps_since_restore: 7280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7280000\n",
      "  training_iteration: 728\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16004 s, 728 iter, 7280000 ts, 60.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-10-52\n",
      "  done: false\n",
      "  episode_len_mean: 73.95620437956204\n",
      "  episode_reward_max: 387.62101219108587\n",
      "  episode_reward_mean: 50.41314070606391\n",
      "  episode_reward_min: -166.7932194745207\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 92071\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3674.95\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 7290000\n",
      "    num_steps_trained: 7290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5061119198799133\n",
      "      kl: 0.013849188573658466\n",
      "      policy_loss: 4.950490620103665e-05\n",
      "      total_loss: 49.68252182006836\n",
      "      vf_explained_var: 0.904972493648529\n",
      "      vf_loss: 49.67969512939453\n",
      "    sample_time_ms: 18105.757\n",
      "    update_time_ms: 5.014\n",
      "  iterations_since_restore: 729\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 25.20657035303195\n",
      "  time_since_restore: 16027.284461259842\n",
      "  time_this_iter_s: 22.63979458808899\n",
      "  time_total_s: 16027.284461259842\n",
      "  timestamp: 1553137852\n",
      "  timesteps_since_restore: 7290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7290000\n",
      "  training_iteration: 729\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16027 s, 729 iter, 7290000 ts, 50.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-11-14\n",
      "  done: false\n",
      "  episode_len_mean: 71.02158273381295\n",
      "  episode_reward_max: 390.4317245233582\n",
      "  episode_reward_mean: 28.991909938752865\n",
      "  episode_reward_min: -166.83363593741893\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 92210\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3671.62\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 7300000\n",
      "    num_steps_trained: 7300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.52577143907547\n",
      "      kl: 0.01165021862834692\n",
      "      policy_loss: 0.003343224059790373\n",
      "      total_loss: 54.140525817871094\n",
      "      vf_explained_var: 0.9002043604850769\n",
      "      vf_loss: 54.13484191894531\n",
      "    sample_time_ms: 18224.41\n",
      "    update_time_ms: 5.18\n",
      "  iterations_since_restore: 730\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.495954969376433\n",
      "  time_since_restore: 16049.594122886658\n",
      "  time_this_iter_s: 22.309661626815796\n",
      "  time_total_s: 16049.594122886658\n",
      "  timestamp: 1553137874\n",
      "  timesteps_since_restore: 7300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7300000\n",
      "  training_iteration: 730\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16049 s, 730 iter, 7300000 ts, 29 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-11-35\n",
      "  done: false\n",
      "  episode_len_mean: 79.93650793650794\n",
      "  episode_reward_max: 390.9231641193931\n",
      "  episode_reward_mean: 97.58897882268363\n",
      "  episode_reward_min: -168.7050160480404\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 92336\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3671.143\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 7310000\n",
      "    num_steps_trained: 7310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4897574484348297\n",
      "      kl: 0.015013160184025764\n",
      "      policy_loss: -0.0010111448355019093\n",
      "      total_loss: 49.00284194946289\n",
      "      vf_explained_var: 0.887531578540802\n",
      "      vf_loss: 49.00084686279297\n",
      "    sample_time_ms: 18164.332\n",
      "    update_time_ms: 5.083\n",
      "  iterations_since_restore: 731\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.7944894113418\n",
      "  time_since_restore: 16070.773707151413\n",
      "  time_this_iter_s: 21.17958426475525\n",
      "  time_total_s: 16070.773707151413\n",
      "  timestamp: 1553137895\n",
      "  timesteps_since_restore: 7310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7310000\n",
      "  training_iteration: 731\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16070 s, 731 iter, 7310000 ts, 97.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-11-58\n",
      "  done: false\n",
      "  episode_len_mean: 78.91338582677166\n",
      "  episode_reward_max: 391.3448197473399\n",
      "  episode_reward_mean: 83.2808841651982\n",
      "  episode_reward_min: -166.8342714316511\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 92463\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3672.242\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 7320000\n",
      "    num_steps_trained: 7320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49993348121643066\n",
      "      kl: 0.011752288788557053\n",
      "      policy_loss: 0.003171210875734687\n",
      "      total_loss: 50.9468879699707\n",
      "      vf_explained_var: 0.8895164132118225\n",
      "      vf_loss: 50.94135665893555\n",
      "    sample_time_ms: 18262.659\n",
      "    update_time_ms: 5.15\n",
      "  iterations_since_restore: 732\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.6404420825991\n",
      "  time_since_restore: 16093.05543255806\n",
      "  time_this_iter_s: 22.28172540664673\n",
      "  time_total_s: 16093.05543255806\n",
      "  timestamp: 1553137918\n",
      "  timesteps_since_restore: 7320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7320000\n",
      "  training_iteration: 732\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16093 s, 732 iter, 7320000 ts, 83.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-12-20\n",
      "  done: false\n",
      "  episode_len_mean: 70.5\n",
      "  episode_reward_max: 386.618866890506\n",
      "  episode_reward_mean: 28.32519252497629\n",
      "  episode_reward_min: -168.82367981776235\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 92605\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3670.033\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 7330000\n",
      "    num_steps_trained: 7330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5404480695724487\n",
      "      kl: 0.011476799845695496\n",
      "      policy_loss: 0.002373938448727131\n",
      "      total_loss: 64.47801208496094\n",
      "      vf_explained_var: 0.8845465183258057\n",
      "      vf_loss: 64.47333526611328\n",
      "    sample_time_ms: 18305.707\n",
      "    update_time_ms: 5.135\n",
      "  iterations_since_restore: 733\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.162596262488146\n",
      "  time_since_restore: 16115.242408275604\n",
      "  time_this_iter_s: 22.186975717544556\n",
      "  time_total_s: 16115.242408275604\n",
      "  timestamp: 1553137940\n",
      "  timesteps_since_restore: 7330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7330000\n",
      "  training_iteration: 733\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16115 s, 733 iter, 7330000 ts, 28.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-12-42\n",
      "  done: false\n",
      "  episode_len_mean: 73.25\n",
      "  episode_reward_max: 387.7056415826844\n",
      "  episode_reward_mean: 48.638592306412704\n",
      "  episode_reward_min: -166.97160244974137\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 92741\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3675.098\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 7340000\n",
      "    num_steps_trained: 7340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5188981890678406\n",
      "      kl: 0.011653545312583447\n",
      "      policy_loss: 0.004111132584512234\n",
      "      total_loss: 46.36370086669922\n",
      "      vf_explained_var: 0.9103906154632568\n",
      "      vf_loss: 46.35724639892578\n",
      "    sample_time_ms: 18343.36\n",
      "    update_time_ms: 5.175\n",
      "  iterations_since_restore: 734\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.319296153206345\n",
      "  time_since_restore: 16137.42066001892\n",
      "  time_this_iter_s: 22.17825174331665\n",
      "  time_total_s: 16137.42066001892\n",
      "  timestamp: 1553137962\n",
      "  timesteps_since_restore: 7340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7340000\n",
      "  training_iteration: 734\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16137 s, 734 iter, 7340000 ts, 48.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-13-04\n",
      "  done: false\n",
      "  episode_len_mean: 75.50757575757575\n",
      "  episode_reward_max: 386.04066593197757\n",
      "  episode_reward_mean: 63.22578595563788\n",
      "  episode_reward_min: -166.99763079675674\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 92873\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3678.147\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 7350000\n",
      "    num_steps_trained: 7350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5185246467590332\n",
      "      kl: 0.012901361100375652\n",
      "      policy_loss: 0.0026543003041297197\n",
      "      total_loss: 47.26118087768555\n",
      "      vf_explained_var: 0.9065141081809998\n",
      "      vf_loss: 47.25593566894531\n",
      "    sample_time_ms: 18430.976\n",
      "    update_time_ms: 5.23\n",
      "  iterations_since_restore: 735\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.612892977818934\n",
      "  time_since_restore: 16159.79786658287\n",
      "  time_this_iter_s: 22.377206563949585\n",
      "  time_total_s: 16159.79786658287\n",
      "  timestamp: 1553137984\n",
      "  timesteps_since_restore: 7350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7350000\n",
      "  training_iteration: 735\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16159 s, 735 iter, 7350000 ts, 63.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-13-27\n",
      "  done: false\n",
      "  episode_len_mean: 80.224\n",
      "  episode_reward_max: 387.66943417919856\n",
      "  episode_reward_mean: 96.99003912897976\n",
      "  episode_reward_min: -166.71958846696853\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 92998\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3675.315\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 7360000\n",
      "    num_steps_trained: 7360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5135671496391296\n",
      "      kl: 0.019111961126327515\n",
      "      policy_loss: 0.0018564248457551003\n",
      "      total_loss: 46.83136749267578\n",
      "      vf_explained_var: 0.894012451171875\n",
      "      vf_loss: 46.82567596435547\n",
      "    sample_time_ms: 18422.611\n",
      "    update_time_ms: 5.248\n",
      "  iterations_since_restore: 736\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.495019564489866\n",
      "  time_since_restore: 16182.007678508759\n",
      "  time_this_iter_s: 22.20981192588806\n",
      "  time_total_s: 16182.007678508759\n",
      "  timestamp: 1553138007\n",
      "  timesteps_since_restore: 7360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7360000\n",
      "  training_iteration: 736\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16182 s, 736 iter, 7360000 ts, 97 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-13-48\n",
      "  done: false\n",
      "  episode_len_mean: 79.912\n",
      "  episode_reward_max: 387.54304912538197\n",
      "  episode_reward_mean: 90.88780114047478\n",
      "  episode_reward_min: -168.7203659500742\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 93123\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3674.818\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 7370000\n",
      "    num_steps_trained: 7370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5264576077461243\n",
      "      kl: 0.013719937764108181\n",
      "      policy_loss: 0.0031378925777971745\n",
      "      total_loss: 48.62764358520508\n",
      "      vf_explained_var: 0.8900586366653442\n",
      "      vf_loss: 48.62174987792969\n",
      "    sample_time_ms: 18397.068\n",
      "    update_time_ms: 5.26\n",
      "  iterations_since_restore: 737\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.44390057023738\n",
      "  time_since_restore: 16203.802072763443\n",
      "  time_this_iter_s: 21.79439425468445\n",
      "  time_total_s: 16203.802072763443\n",
      "  timestamp: 1553138028\n",
      "  timesteps_since_restore: 7370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7370000\n",
      "  training_iteration: 737\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16203 s, 737 iter, 7370000 ts, 90.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-14-11\n",
      "  done: false\n",
      "  episode_len_mean: 77.734375\n",
      "  episode_reward_max: 386.6720235349778\n",
      "  episode_reward_mean: 80.31726678222483\n",
      "  episode_reward_min: -168.67586293872833\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 93251\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.015\n",
      "    load_time_ms: 1.409\n",
      "    num_steps_sampled: 7380000\n",
      "    num_steps_trained: 7380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.532811164855957\n",
      "      kl: 0.014118931256234646\n",
      "      policy_loss: 0.003923520911484957\n",
      "      total_loss: 40.10507583618164\n",
      "      vf_explained_var: 0.9149075746536255\n",
      "      vf_loss: 40.09832000732422\n",
      "    sample_time_ms: 18415.422\n",
      "    update_time_ms: 5.298\n",
      "  iterations_since_restore: 738\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.15863339111242\n",
      "  time_since_restore: 16225.907186985016\n",
      "  time_this_iter_s: 22.105114221572876\n",
      "  time_total_s: 16225.907186985016\n",
      "  timestamp: 1553138051\n",
      "  timesteps_since_restore: 7380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7380000\n",
      "  training_iteration: 738\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16225 s, 738 iter, 7380000 ts, 80.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-14-32\n",
      "  done: false\n",
      "  episode_len_mean: 76.40151515151516\n",
      "  episode_reward_max: 391.67903773019043\n",
      "  episode_reward_mean: 70.07925046446356\n",
      "  episode_reward_min: -166.91610206481457\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 93383\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.938\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 7390000\n",
      "    num_steps_trained: 7390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5715435147285461\n",
      "      kl: 0.022363662719726562\n",
      "      policy_loss: 0.00825063418596983\n",
      "      total_loss: 56.87191390991211\n",
      "      vf_explained_var: 0.884206235408783\n",
      "      vf_loss: 56.85917282104492\n",
      "    sample_time_ms: 18304.478\n",
      "    update_time_ms: 5.266\n",
      "  iterations_since_restore: 739\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.039625232231764\n",
      "  time_since_restore: 16247.486509799957\n",
      "  time_this_iter_s: 21.579322814941406\n",
      "  time_total_s: 16247.486509799957\n",
      "  timestamp: 1553138072\n",
      "  timesteps_since_restore: 7390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7390000\n",
      "  training_iteration: 739\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16247 s, 739 iter, 7390000 ts, 70.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-14-54\n",
      "  done: false\n",
      "  episode_len_mean: 72.85401459854015\n",
      "  episode_reward_max: 390.7505970149984\n",
      "  episode_reward_mean: 49.81595466333101\n",
      "  episode_reward_min: -168.65215267941\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 93520\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.99\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 7400000\n",
      "    num_steps_trained: 7400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5619001388549805\n",
      "      kl: 0.01114351861178875\n",
      "      policy_loss: 0.000786656397394836\n",
      "      total_loss: 44.265987396240234\n",
      "      vf_explained_var: 0.9137827754020691\n",
      "      vf_loss: 44.26296615600586\n",
      "    sample_time_ms: 18216.498\n",
      "    update_time_ms: 5.336\n",
      "  iterations_since_restore: 740\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.907977331665506\n",
      "  time_since_restore: 16268.90902519226\n",
      "  time_this_iter_s: 21.422515392303467\n",
      "  time_total_s: 16268.90902519226\n",
      "  timestamp: 1553138094\n",
      "  timesteps_since_restore: 7400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7400000\n",
      "  training_iteration: 740\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16268 s, 740 iter, 7400000 ts, 49.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-15-15\n",
      "  done: false\n",
      "  episode_len_mean: 74.95488721804512\n",
      "  episode_reward_max: 386.75417125524115\n",
      "  episode_reward_mean: 59.07184491222442\n",
      "  episode_reward_min: -168.73629919775962\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 93653\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.499\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 7410000\n",
      "    num_steps_trained: 7410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5461024641990662\n",
      "      kl: 0.014952316880226135\n",
      "      policy_loss: 0.0024639954790472984\n",
      "      total_loss: 50.81501007080078\n",
      "      vf_explained_var: 0.8963128328323364\n",
      "      vf_loss: 50.80954360961914\n",
      "    sample_time_ms: 18250.554\n",
      "    update_time_ms: 5.376\n",
      "  iterations_since_restore: 741\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.535922456112207\n",
      "  time_since_restore: 16290.423471450806\n",
      "  time_this_iter_s: 21.514446258544922\n",
      "  time_total_s: 16290.423471450806\n",
      "  timestamp: 1553138115\n",
      "  timesteps_since_restore: 7410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7410000\n",
      "  training_iteration: 741\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16290 s, 741 iter, 7410000 ts, 59.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 78.97637795275591\n",
      "  episode_reward_max: 385.8658971448559\n",
      "  episode_reward_mean: 85.014071194847\n",
      "  episode_reward_min: -166.6810014420414\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 93780\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.436\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 7420000\n",
      "    num_steps_trained: 7420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5145782828330994\n",
      "      kl: 0.018222130835056305\n",
      "      policy_loss: 0.0019692094065248966\n",
      "      total_loss: 47.90764236450195\n",
      "      vf_explained_var: 0.8946566581726074\n",
      "      vf_loss: 47.90201187133789\n",
      "    sample_time_ms: 18217.5\n",
      "    update_time_ms: 5.377\n",
      "  iterations_since_restore: 742\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.5070355974235\n",
      "  time_since_restore: 16312.352472305298\n",
      "  time_this_iter_s: 21.929000854492188\n",
      "  time_total_s: 16312.352472305298\n",
      "  timestamp: 1553138137\n",
      "  timesteps_since_restore: 7420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7420000\n",
      "  training_iteration: 742\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16312 s, 742 iter, 7420000 ts, 85 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-15-58\n",
      "  done: false\n",
      "  episode_len_mean: 74.6268656716418\n",
      "  episode_reward_max: 385.69297043077495\n",
      "  episode_reward_mean: 57.58606778226\n",
      "  episode_reward_min: -164.72836888560295\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 93914\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.371\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 7430000\n",
      "    num_steps_trained: 7430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5572260022163391\n",
      "      kl: 0.011846344918012619\n",
      "      policy_loss: 0.002058499725535512\n",
      "      total_loss: 63.24486541748047\n",
      "      vf_explained_var: 0.874512791633606\n",
      "      vf_loss: 63.24042892456055\n",
      "    sample_time_ms: 18117.681\n",
      "    update_time_ms: 5.297\n",
      "  iterations_since_restore: 743\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.79303389113001\n",
      "  time_since_restore: 16333.539820432663\n",
      "  time_this_iter_s: 21.187348127365112\n",
      "  time_total_s: 16333.539820432663\n",
      "  timestamp: 1553138158\n",
      "  timesteps_since_restore: 7430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7430000\n",
      "  training_iteration: 743\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16333 s, 743 iter, 7430000 ts, 57.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-16-20\n",
      "  done: false\n",
      "  episode_len_mean: 76.04580152671755\n",
      "  episode_reward_max: 387.9132803868151\n",
      "  episode_reward_mean: 64.80360446412278\n",
      "  episode_reward_min: -164.66434150704384\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 94045\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3678.994\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 7440000\n",
      "    num_steps_trained: 7440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5389695763587952\n",
      "      kl: 0.014707120135426521\n",
      "      policy_loss: 0.0017837882041931152\n",
      "      total_loss: 44.4651985168457\n",
      "      vf_explained_var: 0.9106817841529846\n",
      "      vf_loss: 44.4604606628418\n",
      "    sample_time_ms: 18096.327\n",
      "    update_time_ms: 5.113\n",
      "  iterations_since_restore: 744\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.401802232061385\n",
      "  time_since_restore: 16355.420678138733\n",
      "  time_this_iter_s: 21.880857706069946\n",
      "  time_total_s: 16355.420678138733\n",
      "  timestamp: 1553138180\n",
      "  timesteps_since_restore: 7440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7440000\n",
      "  training_iteration: 744\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16355 s, 744 iter, 7440000 ts, 64.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-16-42\n",
      "  done: false\n",
      "  episode_len_mean: 73.32846715328468\n",
      "  episode_reward_max: 392.03196488519967\n",
      "  episode_reward_mean: 49.36122292410113\n",
      "  episode_reward_min: -162.68280690261363\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 94182\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.959\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 7450000\n",
      "    num_steps_trained: 7450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5533380508422852\n",
      "      kl: 0.017716877162456512\n",
      "      policy_loss: 0.0031870929524302483\n",
      "      total_loss: 55.24440383911133\n",
      "      vf_explained_var: 0.8930670022964478\n",
      "      vf_loss: 55.237667083740234\n",
      "    sample_time_ms: 18042.885\n",
      "    update_time_ms: 5.31\n",
      "  iterations_since_restore: 745\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.680611462050557\n",
      "  time_since_restore: 16377.335745811462\n",
      "  time_this_iter_s: 21.915067672729492\n",
      "  time_total_s: 16377.335745811462\n",
      "  timestamp: 1553138202\n",
      "  timesteps_since_restore: 7450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7450000\n",
      "  training_iteration: 745\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16377 s, 745 iter, 7450000 ts, 49.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-17-04\n",
      "  done: false\n",
      "  episode_len_mean: 77.6640625\n",
      "  episode_reward_max: 391.86424193625874\n",
      "  episode_reward_mean: 75.34128052299238\n",
      "  episode_reward_min: -166.80873675796033\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 94310\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.822\n",
      "    load_time_ms: 1.5\n",
      "    num_steps_sampled: 7460000\n",
      "    num_steps_trained: 7460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5317597985267639\n",
      "      kl: 0.014206351712346077\n",
      "      policy_loss: 0.0034536307211965322\n",
      "      total_loss: 49.469871520996094\n",
      "      vf_explained_var: 0.8925597071647644\n",
      "      vf_loss: 49.46356201171875\n",
      "    sample_time_ms: 17978.194\n",
      "    update_time_ms: 5.236\n",
      "  iterations_since_restore: 746\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.67064026149618\n",
      "  time_since_restore: 16398.90638899803\n",
      "  time_this_iter_s: 21.570643186569214\n",
      "  time_total_s: 16398.90638899803\n",
      "  timestamp: 1553138224\n",
      "  timesteps_since_restore: 7460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7460000\n",
      "  training_iteration: 746\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16398 s, 746 iter, 7460000 ts, 75.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-17-26\n",
      "  done: false\n",
      "  episode_len_mean: 77.9609375\n",
      "  episode_reward_max: 387.97352429870955\n",
      "  episode_reward_mean: 76.56705315848238\n",
      "  episode_reward_min: -166.68681229671478\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 94438\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.002\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 7470000\n",
      "    num_steps_trained: 7470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5235409736633301\n",
      "      kl: 0.015433049760758877\n",
      "      policy_loss: 0.0043671224266290665\n",
      "      total_loss: 47.201080322265625\n",
      "      vf_explained_var: 0.8999345302581787\n",
      "      vf_loss: 47.19361114501953\n",
      "    sample_time_ms: 17953.09\n",
      "    update_time_ms: 5.313\n",
      "  iterations_since_restore: 747\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.2835265792412\n",
      "  time_since_restore: 16420.51583957672\n",
      "  time_this_iter_s: 21.609450578689575\n",
      "  time_total_s: 16420.51583957672\n",
      "  timestamp: 1553138246\n",
      "  timesteps_since_restore: 7470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7470000\n",
      "  training_iteration: 747\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16420 s, 747 iter, 7470000 ts, 76.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-17-48\n",
      "  done: false\n",
      "  episode_len_mean: 80.70161290322581\n",
      "  episode_reward_max: 387.63759585068846\n",
      "  episode_reward_mean: 96.91932251239095\n",
      "  episode_reward_min: -166.7703205855751\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 94562\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.609\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 7480000\n",
      "    num_steps_trained: 7480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5224595069885254\n",
      "      kl: 0.011259769089519978\n",
      "      policy_loss: 0.0024928946513682604\n",
      "      total_loss: 36.01645278930664\n",
      "      vf_explained_var: 0.9146053791046143\n",
      "      vf_loss: 36.011695861816406\n",
      "    sample_time_ms: 17976.889\n",
      "    update_time_ms: 5.282\n",
      "  iterations_since_restore: 748\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.459661256195474\n",
      "  time_since_restore: 16442.76403093338\n",
      "  time_this_iter_s: 22.248191356658936\n",
      "  time_total_s: 16442.76403093338\n",
      "  timestamp: 1553138268\n",
      "  timesteps_since_restore: 7480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7480000\n",
      "  training_iteration: 748\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16442 s, 748 iter, 7480000 ts, 96.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-18-10\n",
      "  done: false\n",
      "  episode_len_mean: 75.13432835820896\n",
      "  episode_reward_max: 386.65412231492996\n",
      "  episode_reward_mean: 59.28426196205268\n",
      "  episode_reward_min: -166.7589580217266\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 94696\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.035\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 7490000\n",
      "    num_steps_trained: 7490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5327572822570801\n",
      "      kl: 0.012104888446629047\n",
      "      policy_loss: 0.0024521006271243095\n",
      "      total_loss: 38.94147491455078\n",
      "      vf_explained_var: 0.9224700927734375\n",
      "      vf_loss: 38.93659210205078\n",
      "    sample_time_ms: 18031.828\n",
      "    update_time_ms: 5.537\n",
      "  iterations_since_restore: 749\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.642130981026337\n",
      "  time_since_restore: 16465.00663805008\n",
      "  time_this_iter_s: 22.24260711669922\n",
      "  time_total_s: 16465.00663805008\n",
      "  timestamp: 1553138290\n",
      "  timesteps_since_restore: 7490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7490000\n",
      "  training_iteration: 749\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16465 s, 749 iter, 7490000 ts, 59.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-18-33\n",
      "  done: false\n",
      "  episode_len_mean: 79.27777777777777\n",
      "  episode_reward_max: 388.45172029906564\n",
      "  episode_reward_mean: 88.18853787831128\n",
      "  episode_reward_min: -164.72154485413074\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 94822\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.577\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 7500000\n",
      "    num_steps_trained: 7500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5362110733985901\n",
      "      kl: 0.018350038677453995\n",
      "      policy_loss: 0.005432183854281902\n",
      "      total_loss: 54.97380828857422\n",
      "      vf_explained_var: 0.8794600367546082\n",
      "      vf_loss: 54.96468734741211\n",
      "    sample_time_ms: 18122.904\n",
      "    update_time_ms: 5.362\n",
      "  iterations_since_restore: 750\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.09426893915563\n",
      "  time_since_restore: 16487.350472927094\n",
      "  time_this_iter_s: 22.34383487701416\n",
      "  time_total_s: 16487.350472927094\n",
      "  timestamp: 1553138313\n",
      "  timesteps_since_restore: 7500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7500000\n",
      "  training_iteration: 750\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16487 s, 750 iter, 7500000 ts, 88.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 74.80597014925372\n",
      "  episode_reward_max: 391.44355198265055\n",
      "  episode_reward_mean: 60.844500372244404\n",
      "  episode_reward_min: -164.75757427712918\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 94956\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.959\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 7510000\n",
      "    num_steps_trained: 7510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5553386807441711\n",
      "      kl: 0.012206918559968472\n",
      "      policy_loss: 0.00030451553175225854\n",
      "      total_loss: 57.1552848815918\n",
      "      vf_explained_var: 0.8848350644111633\n",
      "      vf_loss: 57.152530670166016\n",
      "    sample_time_ms: 18166.072\n",
      "    update_time_ms: 5.286\n",
      "  iterations_since_restore: 751\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.42225018612221\n",
      "  time_since_restore: 16509.318877220154\n",
      "  time_this_iter_s: 21.968404293060303\n",
      "  time_total_s: 16509.318877220154\n",
      "  timestamp: 1553138335\n",
      "  timesteps_since_restore: 7510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7510000\n",
      "  training_iteration: 751\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16509 s, 751 iter, 7510000 ts, 60.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-19-16\n",
      "  done: false\n",
      "  episode_len_mean: 77.76744186046511\n",
      "  episode_reward_max: 387.6582135772207\n",
      "  episode_reward_mean: 72.52150103088627\n",
      "  episode_reward_min: -168.7668976598644\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 95085\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.579\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 7520000\n",
      "    num_steps_trained: 7520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5317975282669067\n",
      "      kl: 0.011252976022660732\n",
      "      policy_loss: 0.0031423289328813553\n",
      "      total_loss: 47.91518020629883\n",
      "      vf_explained_var: 0.8988410830497742\n",
      "      vf_loss: 47.9097785949707\n",
      "    sample_time_ms: 18145.131\n",
      "    update_time_ms: 5.415\n",
      "  iterations_since_restore: 752\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.260750515443135\n",
      "  time_since_restore: 16531.0280046463\n",
      "  time_this_iter_s: 21.70912742614746\n",
      "  time_total_s: 16531.0280046463\n",
      "  timestamp: 1553138356\n",
      "  timesteps_since_restore: 7520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7520000\n",
      "  training_iteration: 752\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16531 s, 752 iter, 7520000 ts, 72.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-19-39\n",
      "  done: false\n",
      "  episode_len_mean: 77.32558139534883\n",
      "  episode_reward_max: 387.05321505718496\n",
      "  episode_reward_mean: 74.14823521919888\n",
      "  episode_reward_min: -163.73504174705982\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 95214\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.338\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 7530000\n",
      "    num_steps_trained: 7530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5135534405708313\n",
      "      kl: 0.016529608517885208\n",
      "      policy_loss: 0.002872306853532791\n",
      "      total_loss: 50.09196853637695\n",
      "      vf_explained_var: 0.8938305974006653\n",
      "      vf_loss: 50.085784912109375\n",
      "    sample_time_ms: 18236.273\n",
      "    update_time_ms: 5.473\n",
      "  iterations_since_restore: 753\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.074117609599426\n",
      "  time_since_restore: 16553.22337079048\n",
      "  time_this_iter_s: 22.195366144180298\n",
      "  time_total_s: 16553.22337079048\n",
      "  timestamp: 1553138379\n",
      "  timesteps_since_restore: 7530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7530000\n",
      "  training_iteration: 753\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16553 s, 753 iter, 7530000 ts, 74.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-20-01\n",
      "  done: false\n",
      "  episode_len_mean: 73.27737226277372\n",
      "  episode_reward_max: 387.60993583822983\n",
      "  episode_reward_mean: 45.13912941268966\n",
      "  episode_reward_min: -166.82257601937295\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 95351\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.477\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 7540000\n",
      "    num_steps_trained: 7540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5280842781066895\n",
      "      kl: 0.012112637050449848\n",
      "      policy_loss: 0.0006970933172851801\n",
      "      total_loss: 43.23384475708008\n",
      "      vf_explained_var: 0.9177954196929932\n",
      "      vf_loss: 43.230712890625\n",
      "    sample_time_ms: 18267.858\n",
      "    update_time_ms: 5.508\n",
      "  iterations_since_restore: 754\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.56956470634483\n",
      "  time_since_restore: 16575.437937259674\n",
      "  time_this_iter_s: 22.214566469192505\n",
      "  time_total_s: 16575.437937259674\n",
      "  timestamp: 1553138401\n",
      "  timesteps_since_restore: 7540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7540000\n",
      "  training_iteration: 754\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16575 s, 754 iter, 7540000 ts, 45.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-20-22\n",
      "  done: false\n",
      "  episode_len_mean: 79.424\n",
      "  episode_reward_max: 385.3536387999112\n",
      "  episode_reward_mean: 90.26722369328736\n",
      "  episode_reward_min: -168.78855593379973\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 95476\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.792\n",
      "    load_time_ms: 1.416\n",
      "    num_steps_sampled: 7550000\n",
      "    num_steps_trained: 7550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5088084936141968\n",
      "      kl: 0.013023000210523605\n",
      "      policy_loss: 0.00448079127818346\n",
      "      total_loss: 47.88684844970703\n",
      "      vf_explained_var: 0.8933488726615906\n",
      "      vf_loss: 47.87975311279297\n",
      "    sample_time_ms: 18249.162\n",
      "    update_time_ms: 5.339\n",
      "  iterations_since_restore: 755\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.133611846643674\n",
      "  time_since_restore: 16597.08775472641\n",
      "  time_this_iter_s: 21.64981746673584\n",
      "  time_total_s: 16597.08775472641\n",
      "  timestamp: 1553138422\n",
      "  timesteps_since_restore: 7550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7550000\n",
      "  training_iteration: 755\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16597 s, 755 iter, 7550000 ts, 90.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-20-45\n",
      "  done: false\n",
      "  episode_len_mean: 76.38461538461539\n",
      "  episode_reward_max: 388.07644381523085\n",
      "  episode_reward_mean: 62.4712415502841\n",
      "  episode_reward_min: -162.59021057483196\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 95606\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.837\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 7560000\n",
      "    num_steps_trained: 7560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5126414895057678\n",
      "      kl: 0.01528496015816927\n",
      "      policy_loss: 0.0038209580816328526\n",
      "      total_loss: 56.35346603393555\n",
      "      vf_explained_var: 0.8828535676002502\n",
      "      vf_loss: 56.34657287597656\n",
      "    sample_time_ms: 18295.078\n",
      "    update_time_ms: 5.433\n",
      "  iterations_since_restore: 756\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.23562077514204\n",
      "  time_since_restore: 16619.097816705704\n",
      "  time_this_iter_s: 22.010061979293823\n",
      "  time_total_s: 16619.097816705704\n",
      "  timestamp: 1553138445\n",
      "  timesteps_since_restore: 7560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7560000\n",
      "  training_iteration: 756\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16619 s, 756 iter, 7560000 ts, 62.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-21-06\n",
      "  done: false\n",
      "  episode_len_mean: 73.14598540145985\n",
      "  episode_reward_max: 381.33280033134383\n",
      "  episode_reward_mean: 43.130770421533924\n",
      "  episode_reward_min: -166.7229867049122\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 95743\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.744\n",
      "    load_time_ms: 1.378\n",
      "    num_steps_sampled: 7570000\n",
      "    num_steps_trained: 7570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5272933840751648\n",
      "      kl: 0.01165122538805008\n",
      "      policy_loss: 0.0023337427992373705\n",
      "      total_loss: 55.16524124145508\n",
      "      vf_explained_var: 0.8961557149887085\n",
      "      vf_loss: 55.16056823730469\n",
      "    sample_time_ms: 18259.93\n",
      "    update_time_ms: 5.37\n",
      "  iterations_since_restore: 757\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.565385210766962\n",
      "  time_since_restore: 16640.331189393997\n",
      "  time_this_iter_s: 21.233372688293457\n",
      "  time_total_s: 16640.331189393997\n",
      "  timestamp: 1553138466\n",
      "  timesteps_since_restore: 7570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7570000\n",
      "  training_iteration: 757\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16640 s, 757 iter, 7570000 ts, 43.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 81.0\n",
      "  episode_reward_max: 387.90460178083475\n",
      "  episode_reward_mean: 105.28520954622198\n",
      "  episode_reward_min: -166.78177007647992\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 95867\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.053\n",
      "    load_time_ms: 1.341\n",
      "    num_steps_sampled: 7580000\n",
      "    num_steps_trained: 7580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5003126859664917\n",
      "      kl: 0.016707463189959526\n",
      "      policy_loss: 0.0029533340130001307\n",
      "      total_loss: 43.739559173583984\n",
      "      vf_explained_var: 0.8989526033401489\n",
      "      vf_loss: 43.73324966430664\n",
      "    sample_time_ms: 18189.308\n",
      "    update_time_ms: 5.321\n",
      "  iterations_since_restore: 758\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.64260477311096\n",
      "  time_since_restore: 16661.882880449295\n",
      "  time_this_iter_s: 21.55169105529785\n",
      "  time_total_s: 16661.882880449295\n",
      "  timestamp: 1553138487\n",
      "  timesteps_since_restore: 7580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7580000\n",
      "  training_iteration: 758\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16661 s, 758 iter, 7580000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-21-49\n",
      "  done: false\n",
      "  episode_len_mean: 74.55555555555556\n",
      "  episode_reward_max: 385.4720546359036\n",
      "  episode_reward_mean: 60.452580368228666\n",
      "  episode_reward_min: -168.7663386565113\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 96002\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.759\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 7590000\n",
      "    num_steps_trained: 7590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49771714210510254\n",
      "      kl: 0.01442648470401764\n",
      "      policy_loss: 0.0018954059341922402\n",
      "      total_loss: 49.60849380493164\n",
      "      vf_explained_var: 0.9006950259208679\n",
      "      vf_loss: 49.603702545166016\n",
      "    sample_time_ms: 18155.329\n",
      "    update_time_ms: 5.474\n",
      "  iterations_since_restore: 759\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.226290184114326\n",
      "  time_since_restore: 16683.6690659523\n",
      "  time_this_iter_s: 21.78618550300598\n",
      "  time_total_s: 16683.6690659523\n",
      "  timestamp: 1553138509\n",
      "  timesteps_since_restore: 7590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7590000\n",
      "  training_iteration: 759\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16683 s, 759 iter, 7590000 ts, 60.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-22-11\n",
      "  done: false\n",
      "  episode_len_mean: 79.87096774193549\n",
      "  episode_reward_max: 391.46245252301594\n",
      "  episode_reward_mean: 98.07379961401445\n",
      "  episode_reward_min: -166.75566599866391\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 96126\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.665\n",
      "    load_time_ms: 1.409\n",
      "    num_steps_sampled: 7600000\n",
      "    num_steps_trained: 7600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5167238712310791\n",
      "      kl: 0.012353114783763885\n",
      "      policy_loss: 0.0038068003486841917\n",
      "      total_loss: 44.820369720458984\n",
      "      vf_explained_var: 0.895634114742279\n",
      "      vf_loss: 44.814083099365234\n",
      "    sample_time_ms: 18124.214\n",
      "    update_time_ms: 5.521\n",
      "  iterations_since_restore: 760\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.03689980700724\n",
      "  time_since_restore: 16705.831301689148\n",
      "  time_this_iter_s: 22.162235736846924\n",
      "  time_total_s: 16705.831301689148\n",
      "  timestamp: 1553138531\n",
      "  timesteps_since_restore: 7600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7600000\n",
      "  training_iteration: 760\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16705 s, 760 iter, 7600000 ts, 98.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-22-33\n",
      "  done: false\n",
      "  episode_len_mean: 75.46616541353383\n",
      "  episode_reward_max: 387.52483417142747\n",
      "  episode_reward_mean: 58.752157394962246\n",
      "  episode_reward_min: -168.7270066610241\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 96259\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.881\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 7610000\n",
      "    num_steps_trained: 7610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4998512268066406\n",
      "      kl: 0.017352422699332237\n",
      "      policy_loss: 0.004619586747139692\n",
      "      total_loss: 43.15826416015625\n",
      "      vf_explained_var: 0.9152857661247253\n",
      "      vf_loss: 43.1501579284668\n",
      "    sample_time_ms: 18111.449\n",
      "    update_time_ms: 5.607\n",
      "  iterations_since_restore: 761\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.376078697481123\n",
      "  time_since_restore: 16727.658502578735\n",
      "  time_this_iter_s: 21.827200889587402\n",
      "  time_total_s: 16727.658502578735\n",
      "  timestamp: 1553138553\n",
      "  timesteps_since_restore: 7610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7610000\n",
      "  training_iteration: 761\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16727 s, 761 iter, 7610000 ts, 58.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-22-55\n",
      "  done: false\n",
      "  episode_len_mean: 75.60902255639098\n",
      "  episode_reward_max: 387.9952024052537\n",
      "  episode_reward_mean: 58.81182653535529\n",
      "  episode_reward_min: -168.78284080621245\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 96392\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.355\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 7620000\n",
      "    num_steps_trained: 7620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5228574872016907\n",
      "      kl: 0.019947731867432594\n",
      "      policy_loss: 0.0037883883342146873\n",
      "      total_loss: 46.33640670776367\n",
      "      vf_explained_var: 0.9078856110572815\n",
      "      vf_loss: 46.32861328125\n",
      "    sample_time_ms: 18149.435\n",
      "    update_time_ms: 5.416\n",
      "  iterations_since_restore: 762\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.405913267677633\n",
      "  time_since_restore: 16749.741077661514\n",
      "  time_this_iter_s: 22.08257508277893\n",
      "  time_total_s: 16749.741077661514\n",
      "  timestamp: 1553138575\n",
      "  timesteps_since_restore: 7620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7620000\n",
      "  training_iteration: 762\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16749 s, 762 iter, 7620000 ts, 58.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-23-18\n",
      "  done: false\n",
      "  episode_len_mean: 75.0\n",
      "  episode_reward_max: 391.81169366271774\n",
      "  episode_reward_mean: 58.63993872387357\n",
      "  episode_reward_min: -166.7570552968645\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 96524\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.356\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 7630000\n",
      "    num_steps_trained: 7630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.502232015132904\n",
      "      kl: 0.013333520852029324\n",
      "      policy_loss: 0.00042681433842517436\n",
      "      total_loss: 53.62615203857422\n",
      "      vf_explained_var: 0.8926153182983398\n",
      "      vf_loss: 53.623046875\n",
      "    sample_time_ms: 18161.618\n",
      "    update_time_ms: 5.345\n",
      "  iterations_since_restore: 763\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.31996936193678\n",
      "  time_since_restore: 16771.98971247673\n",
      "  time_this_iter_s: 22.248634815216064\n",
      "  time_total_s: 16771.98971247673\n",
      "  timestamp: 1553138598\n",
      "  timesteps_since_restore: 7630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7630000\n",
      "  training_iteration: 763\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16771 s, 763 iter, 7630000 ts, 58.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-23-39\n",
      "  done: false\n",
      "  episode_len_mean: 79.21428571428571\n",
      "  episode_reward_max: 388.1719031744893\n",
      "  episode_reward_mean: 89.18309916584455\n",
      "  episode_reward_min: -160.16077471696974\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 96650\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.247\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 7640000\n",
      "    num_steps_trained: 7640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5156570672988892\n",
      "      kl: 0.014813294634222984\n",
      "      policy_loss: 0.0032662535086274147\n",
      "      total_loss: 50.52962875366211\n",
      "      vf_explained_var: 0.8856580853462219\n",
      "      vf_loss: 50.52339553833008\n",
      "    sample_time_ms: 18041.113\n",
      "    update_time_ms: 5.665\n",
      "  iterations_since_restore: 764\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.59154958292227\n",
      "  time_since_restore: 16793.054161548615\n",
      "  time_this_iter_s: 21.064449071884155\n",
      "  time_total_s: 16793.054161548615\n",
      "  timestamp: 1553138619\n",
      "  timesteps_since_restore: 7640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7640000\n",
      "  training_iteration: 764\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16793 s, 764 iter, 7640000 ts, 89.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-24-01\n",
      "  done: false\n",
      "  episode_len_mean: 75.87121212121212\n",
      "  episode_reward_max: 387.97166860275047\n",
      "  episode_reward_mean: 66.99076555971895\n",
      "  episode_reward_min: -162.94459860619546\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 96782\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.982\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 7650000\n",
      "    num_steps_trained: 7650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5233098268508911\n",
      "      kl: 0.015139548107981682\n",
      "      policy_loss: 0.005182175897061825\n",
      "      total_loss: 52.83869934082031\n",
      "      vf_explained_var: 0.8890243172645569\n",
      "      vf_loss: 52.83047866821289\n",
      "    sample_time_ms: 18072.005\n",
      "    update_time_ms: 5.78\n",
      "  iterations_since_restore: 765\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.495382779859476\n",
      "  time_since_restore: 16815.037106990814\n",
      "  time_this_iter_s: 21.982945442199707\n",
      "  time_total_s: 16815.037106990814\n",
      "  timestamp: 1553138641\n",
      "  timesteps_since_restore: 7650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7650000\n",
      "  training_iteration: 765\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16815 s, 765 iter, 7650000 ts, 67 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-24-22\n",
      "  done: false\n",
      "  episode_len_mean: 76.19083969465649\n",
      "  episode_reward_max: 387.89858748648464\n",
      "  episode_reward_mean: 66.52833815866434\n",
      "  episode_reward_min: -166.76203945061206\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 96913\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.696\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 7660000\n",
      "    num_steps_trained: 7660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5171768665313721\n",
      "      kl: 0.01830318570137024\n",
      "      policy_loss: 0.0024056206457316875\n",
      "      total_loss: 42.14662170410156\n",
      "      vf_explained_var: 0.914883553981781\n",
      "      vf_loss: 42.14054489135742\n",
      "    sample_time_ms: 18022.47\n",
      "    update_time_ms: 5.622\n",
      "  iterations_since_restore: 766\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.26416907933217\n",
      "  time_since_restore: 16836.56073617935\n",
      "  time_this_iter_s: 21.523629188537598\n",
      "  time_total_s: 16836.56073617935\n",
      "  timestamp: 1553138662\n",
      "  timesteps_since_restore: 7660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7660000\n",
      "  training_iteration: 766\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16836 s, 766 iter, 7660000 ts, 66.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-24-44\n",
      "  done: false\n",
      "  episode_len_mean: 74.73333333333333\n",
      "  episode_reward_max: 392.41671866024745\n",
      "  episode_reward_mean: 54.09024594174681\n",
      "  episode_reward_min: -165.0940050367975\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 97048\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.99\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 7670000\n",
      "    num_steps_trained: 7670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5269076824188232\n",
      "      kl: 0.01310561690479517\n",
      "      policy_loss: 0.0035612911451607943\n",
      "      total_loss: 45.83586883544922\n",
      "      vf_explained_var: 0.9096026420593262\n",
      "      vf_loss: 45.82967758178711\n",
      "    sample_time_ms: 18092.632\n",
      "    update_time_ms: 5.763\n",
      "  iterations_since_restore: 767\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.045122970873397\n",
      "  time_since_restore: 16858.501255989075\n",
      "  time_this_iter_s: 21.9405198097229\n",
      "  time_total_s: 16858.501255989075\n",
      "  timestamp: 1553138684\n",
      "  timesteps_since_restore: 7670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7670000\n",
      "  training_iteration: 767\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16858 s, 767 iter, 7670000 ts, 54.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-25-06\n",
      "  done: false\n",
      "  episode_len_mean: 73.43382352941177\n",
      "  episode_reward_max: 387.633776863491\n",
      "  episode_reward_mean: 46.2491207341873\n",
      "  episode_reward_min: -166.7039815412426\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 97184\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.164\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 7680000\n",
      "    num_steps_trained: 7680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5355035662651062\n",
      "      kl: 0.015602007508277893\n",
      "      policy_loss: 0.002059794729575515\n",
      "      total_loss: 46.54835891723633\n",
      "      vf_explained_var: 0.9116610288619995\n",
      "      vf_loss: 46.54316711425781\n",
      "    sample_time_ms: 18140.091\n",
      "    update_time_ms: 5.743\n",
      "  iterations_since_restore: 768\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.124560367093643\n",
      "  time_since_restore: 16880.490778446198\n",
      "  time_this_iter_s: 21.989522457122803\n",
      "  time_total_s: 16880.490778446198\n",
      "  timestamp: 1553138706\n",
      "  timesteps_since_restore: 7680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7680000\n",
      "  training_iteration: 768\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16880 s, 768 iter, 7680000 ts, 46.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-25-29\n",
      "  done: false\n",
      "  episode_len_mean: 78.36220472440945\n",
      "  episode_reward_max: 388.76647001802144\n",
      "  episode_reward_mean: 81.70843269648363\n",
      "  episode_reward_min: -165.08560968455313\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 97311\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.688\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 7690000\n",
      "    num_steps_trained: 7690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48779296875\n",
      "      kl: 0.013050887733697891\n",
      "      policy_loss: 0.002523742150515318\n",
      "      total_loss: 56.16188430786133\n",
      "      vf_explained_var: 0.8791190981864929\n",
      "      vf_loss: 56.15673828125\n",
      "    sample_time_ms: 18241.952\n",
      "    update_time_ms: 5.282\n",
      "  iterations_since_restore: 769\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.854216348241806\n",
      "  time_since_restore: 16903.298485040665\n",
      "  time_this_iter_s: 22.807706594467163\n",
      "  time_total_s: 16903.298485040665\n",
      "  timestamp: 1553138729\n",
      "  timesteps_since_restore: 7690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7690000\n",
      "  training_iteration: 769\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16903 s, 769 iter, 7690000 ts, 81.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-25-52\n",
      "  done: false\n",
      "  episode_len_mean: 73.77372262773723\n",
      "  episode_reward_max: 389.72050621691767\n",
      "  episode_reward_mean: 54.636140203003045\n",
      "  episode_reward_min: -168.69500703307628\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 97448\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.885\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 7700000\n",
      "    num_steps_trained: 7700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4949999451637268\n",
      "      kl: 0.01368714589625597\n",
      "      policy_loss: 0.003662187373265624\n",
      "      total_loss: 55.30648422241211\n",
      "      vf_explained_var: 0.8906907439231873\n",
      "      vf_loss: 55.30007553100586\n",
      "    sample_time_ms: 18274.71\n",
      "    update_time_ms: 5.244\n",
      "  iterations_since_restore: 770\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.31807010150152\n",
      "  time_since_restore: 16925.659883737564\n",
      "  time_this_iter_s: 22.361398696899414\n",
      "  time_total_s: 16925.659883737564\n",
      "  timestamp: 1553138752\n",
      "  timesteps_since_restore: 7700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7700000\n",
      "  training_iteration: 770\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16925 s, 770 iter, 7700000 ts, 54.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-26-14\n",
      "  done: false\n",
      "  episode_len_mean: 73.34074074074074\n",
      "  episode_reward_max: 390.33240787220535\n",
      "  episode_reward_mean: 40.77480836082653\n",
      "  episode_reward_min: -166.7722200430298\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 97583\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.9\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 7710000\n",
      "    num_steps_trained: 7710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5212413668632507\n",
      "      kl: 0.014920896850526333\n",
      "      policy_loss: 0.0015758138615638018\n",
      "      total_loss: 51.9031982421875\n",
      "      vf_explained_var: 0.8989852666854858\n",
      "      vf_loss: 51.898624420166016\n",
      "    sample_time_ms: 18321.729\n",
      "    update_time_ms: 5.298\n",
      "  iterations_since_restore: 771\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.387404180413267\n",
      "  time_since_restore: 16947.96534228325\n",
      "  time_this_iter_s: 22.305458545684814\n",
      "  time_total_s: 16947.96534228325\n",
      "  timestamp: 1553138774\n",
      "  timesteps_since_restore: 7710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7710000\n",
      "  training_iteration: 771\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16947 s, 771 iter, 7710000 ts, 40.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-26-36\n",
      "  done: false\n",
      "  episode_len_mean: 76.59848484848484\n",
      "  episode_reward_max: 391.1111107436354\n",
      "  episode_reward_mean: 64.53888182980747\n",
      "  episode_reward_min: -166.86613806375505\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 97715\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.021\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 7720000\n",
      "    num_steps_trained: 7720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.486778199672699\n",
      "      kl: 0.016016369685530663\n",
      "      policy_loss: 0.0036893831565976143\n",
      "      total_loss: 47.701541900634766\n",
      "      vf_explained_var: 0.9012579321861267\n",
      "      vf_loss: 47.694637298583984\n",
      "    sample_time_ms: 18306.106\n",
      "    update_time_ms: 5.393\n",
      "  iterations_since_restore: 772\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.26944091490373\n",
      "  time_since_restore: 16969.94420814514\n",
      "  time_this_iter_s: 21.9788658618927\n",
      "  time_total_s: 16969.94420814514\n",
      "  timestamp: 1553138796\n",
      "  timesteps_since_restore: 7720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7720000\n",
      "  training_iteration: 772\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16969 s, 772 iter, 7720000 ts, 64.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-26-58\n",
      "  done: false\n",
      "  episode_len_mean: 76.48461538461538\n",
      "  episode_reward_max: 392.13683181299496\n",
      "  episode_reward_mean: 72.72235680807277\n",
      "  episode_reward_min: -166.79552054926395\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 97845\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.904\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 7730000\n",
      "    num_steps_trained: 7730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4742012023925781\n",
      "      kl: 0.011700516566634178\n",
      "      policy_loss: 0.0032845032401382923\n",
      "      total_loss: 47.8701171875\n",
      "      vf_explained_var: 0.8996511697769165\n",
      "      vf_loss: 47.86447525024414\n",
      "    sample_time_ms: 18301.585\n",
      "    update_time_ms: 5.476\n",
      "  iterations_since_restore: 773\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.36117840403637\n",
      "  time_since_restore: 16992.136409521103\n",
      "  time_this_iter_s: 22.192201375961304\n",
      "  time_total_s: 16992.136409521103\n",
      "  timestamp: 1553138818\n",
      "  timesteps_since_restore: 7730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7730000\n",
      "  training_iteration: 773\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 16992 s, 773 iter, 7730000 ts, 72.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-27-20\n",
      "  done: false\n",
      "  episode_len_mean: 70.44366197183099\n",
      "  episode_reward_max: 387.3799037023264\n",
      "  episode_reward_mean: 24.080297462389463\n",
      "  episode_reward_min: -164.67849243399144\n",
      "  episodes_this_iter: 142\n",
      "  episodes_total: 97987\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.465\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 7740000\n",
      "    num_steps_trained: 7740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5322189331054688\n",
      "      kl: 0.014678646810352802\n",
      "      policy_loss: 0.0021629470866173506\n",
      "      total_loss: 59.4106330871582\n",
      "      vf_explained_var: 0.8941398859024048\n",
      "      vf_loss: 59.4055290222168\n",
      "    sample_time_ms: 18400.709\n",
      "    update_time_ms: 5.174\n",
      "  iterations_since_restore: 774\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.040148731194728\n",
      "  time_since_restore: 17014.173699617386\n",
      "  time_this_iter_s: 22.03729009628296\n",
      "  time_total_s: 17014.173699617386\n",
      "  timestamp: 1553138840\n",
      "  timesteps_since_restore: 7740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7740000\n",
      "  training_iteration: 774\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17014 s, 774 iter, 7740000 ts, 24.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-27-43\n",
      "  done: false\n",
      "  episode_len_mean: 73.01459854014598\n",
      "  episode_reward_max: 387.5107575541415\n",
      "  episode_reward_mean: 41.39151313805608\n",
      "  episode_reward_min: -166.7099845401907\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 98124\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.03\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 7750000\n",
      "    num_steps_trained: 7750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5350445508956909\n",
      "      kl: 0.015718569979071617\n",
      "      policy_loss: 0.003475813427940011\n",
      "      total_loss: 54.124454498291016\n",
      "      vf_explained_var: 0.8955963253974915\n",
      "      vf_loss: 54.11782455444336\n",
      "    sample_time_ms: 18425.616\n",
      "    update_time_ms: 5.196\n",
      "  iterations_since_restore: 775\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.695756569028035\n",
      "  time_since_restore: 17036.585582971573\n",
      "  time_this_iter_s: 22.41188335418701\n",
      "  time_total_s: 17036.585582971573\n",
      "  timestamp: 1553138863\n",
      "  timesteps_since_restore: 7750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7750000\n",
      "  training_iteration: 775\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17036 s, 775 iter, 7750000 ts, 41.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-28-05\n",
      "  done: false\n",
      "  episode_len_mean: 75.78787878787878\n",
      "  episode_reward_max: 388.0856155760914\n",
      "  episode_reward_mean: 69.12077410367442\n",
      "  episode_reward_min: -166.78499920484066\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 98256\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.41\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 7760000\n",
      "    num_steps_trained: 7760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49250784516334534\n",
      "      kl: 0.012265386991202831\n",
      "      policy_loss: 0.002865690505132079\n",
      "      total_loss: 48.274871826171875\n",
      "      vf_explained_var: 0.902166485786438\n",
      "      vf_loss: 48.26953887939453\n",
      "    sample_time_ms: 18445.682\n",
      "    update_time_ms: 5.253\n",
      "  iterations_since_restore: 776\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.560387051837196\n",
      "  time_since_restore: 17058.393770456314\n",
      "  time_this_iter_s: 21.80818748474121\n",
      "  time_total_s: 17058.393770456314\n",
      "  timestamp: 1553138885\n",
      "  timesteps_since_restore: 7760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7760000\n",
      "  training_iteration: 776\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17058 s, 776 iter, 7760000 ts, 69.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-28-27\n",
      "  done: false\n",
      "  episode_len_mean: 74.2910447761194\n",
      "  episode_reward_max: 387.74543120586986\n",
      "  episode_reward_mean: 52.056597648543026\n",
      "  episode_reward_min: -164.7647281995678\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 98390\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.692\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 7770000\n",
      "    num_steps_trained: 7770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5142419338226318\n",
      "      kl: 0.013951371423900127\n",
      "      policy_loss: 0.0007500178762711585\n",
      "      total_loss: 44.491729736328125\n",
      "      vf_explained_var: 0.9109236598014832\n",
      "      vf_loss: 44.48817443847656\n",
      "    sample_time_ms: 18465.287\n",
      "    update_time_ms: 5.094\n",
      "  iterations_since_restore: 777\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.02829882427151\n",
      "  time_since_restore: 17080.520671844482\n",
      "  time_this_iter_s: 22.126901388168335\n",
      "  time_total_s: 17080.520671844482\n",
      "  timestamp: 1553138907\n",
      "  timesteps_since_restore: 7770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7770000\n",
      "  training_iteration: 777\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17080 s, 777 iter, 7770000 ts, 52.1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-28-49\n",
      "  done: false\n",
      "  episode_len_mean: 80.08\n",
      "  episode_reward_max: 387.1266192651868\n",
      "  episode_reward_mean: 92.45216556002093\n",
      "  episode_reward_min: -164.77985896357535\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 98515\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.517\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 7780000\n",
      "    num_steps_trained: 7780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4509107172489166\n",
      "      kl: 0.01216500997543335\n",
      "      policy_loss: 0.0007566536660306156\n",
      "      total_loss: 41.482913970947266\n",
      "      vf_explained_var: 0.9058845639228821\n",
      "      vf_loss: 41.47971725463867\n",
      "    sample_time_ms: 18475.261\n",
      "    update_time_ms: 5.038\n",
      "  iterations_since_restore: 778\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.22608278001045\n",
      "  time_since_restore: 17102.616543293\n",
      "  time_this_iter_s: 22.095871448516846\n",
      "  time_total_s: 17102.616543293\n",
      "  timestamp: 1553138929\n",
      "  timesteps_since_restore: 7780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7780000\n",
      "  training_iteration: 778\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17102 s, 778 iter, 7780000 ts, 92.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-29-11\n",
      "  done: false\n",
      "  episode_len_mean: 75.9469696969697\n",
      "  episode_reward_max: 387.5498253952114\n",
      "  episode_reward_mean: 55.00227337377555\n",
      "  episode_reward_min: -166.9086550218725\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 98647\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.735\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 7790000\n",
      "    num_steps_trained: 7790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47298574447631836\n",
      "      kl: 0.014556817710399628\n",
      "      policy_loss: -0.0003259212535340339\n",
      "      total_loss: 45.97334671020508\n",
      "      vf_explained_var: 0.9078419804573059\n",
      "      vf_loss: 45.97074508666992\n",
      "    sample_time_ms: 18403.31\n",
      "    update_time_ms: 5.273\n",
      "  iterations_since_restore: 779\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.501136686887776\n",
      "  time_since_restore: 17124.80299592018\n",
      "  time_this_iter_s: 22.186452627182007\n",
      "  time_total_s: 17124.80299592018\n",
      "  timestamp: 1553138951\n",
      "  timesteps_since_restore: 7790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7790000\n",
      "  training_iteration: 779\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17124 s, 779 iter, 7790000 ts, 55 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-29-33\n",
      "  done: false\n",
      "  episode_len_mean: 71.12056737588652\n",
      "  episode_reward_max: 387.61330466562083\n",
      "  episode_reward_mean: 32.334950559290895\n",
      "  episode_reward_min: -164.68351354810238\n",
      "  episodes_this_iter: 141\n",
      "  episodes_total: 98788\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.412\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 7800000\n",
      "    num_steps_trained: 7800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.490913987159729\n",
      "      kl: 0.012287468649446964\n",
      "      policy_loss: 0.003410417353734374\n",
      "      total_loss: 38.33673858642578\n",
      "      vf_explained_var: 0.931812584400177\n",
      "      vf_loss: 38.33086395263672\n",
      "    sample_time_ms: 18351.178\n",
      "    update_time_ms: 5.17\n",
      "  iterations_since_restore: 780\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.167475279645448\n",
      "  time_since_restore: 17146.647535800934\n",
      "  time_this_iter_s: 21.844539880752563\n",
      "  time_total_s: 17146.647535800934\n",
      "  timestamp: 1553138973\n",
      "  timesteps_since_restore: 7800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7800000\n",
      "  training_iteration: 780\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17146 s, 780 iter, 7800000 ts, 32.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 73.48529411764706\n",
      "  episode_reward_max: 388.0825349012239\n",
      "  episode_reward_mean: 45.62594718571616\n",
      "  episode_reward_min: -166.77494431563855\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 98924\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.986\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 7810000\n",
      "    num_steps_trained: 7810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4994758665561676\n",
      "      kl: 0.017830584198236465\n",
      "      policy_loss: 0.006845866795629263\n",
      "      total_loss: 40.713661193847656\n",
      "      vf_explained_var: 0.9212075471878052\n",
      "      vf_loss: 40.70323181152344\n",
      "    sample_time_ms: 18337.973\n",
      "    update_time_ms: 5.049\n",
      "  iterations_since_restore: 781\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.812973592858075\n",
      "  time_since_restore: 17168.824151277542\n",
      "  time_this_iter_s: 22.176615476608276\n",
      "  time_total_s: 17168.824151277542\n",
      "  timestamp: 1553138995\n",
      "  timesteps_since_restore: 7810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7810000\n",
      "  training_iteration: 781\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17168 s, 781 iter, 7810000 ts, 45.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-30-18\n",
      "  done: false\n",
      "  episode_len_mean: 76.66923076923077\n",
      "  episode_reward_max: 393.0291653313817\n",
      "  episode_reward_mean: 69.23696276716872\n",
      "  episode_reward_min: -168.73071030887604\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 99054\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.508\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 7820000\n",
      "    num_steps_trained: 7820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48192644119262695\n",
      "      kl: 0.016269030049443245\n",
      "      policy_loss: 0.0036706114187836647\n",
      "      total_loss: 42.78050994873047\n",
      "      vf_explained_var: 0.9130280613899231\n",
      "      vf_loss: 42.77356719970703\n",
      "    sample_time_ms: 18371.673\n",
      "    update_time_ms: 4.894\n",
      "  iterations_since_restore: 782\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.61848138358437\n",
      "  time_since_restore: 17191.123127937317\n",
      "  time_this_iter_s: 22.29897665977478\n",
      "  time_total_s: 17191.123127937317\n",
      "  timestamp: 1553139018\n",
      "  timesteps_since_restore: 7820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7820000\n",
      "  training_iteration: 782\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17191 s, 782 iter, 7820000 ts, 69.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-30-40\n",
      "  done: false\n",
      "  episode_len_mean: 74.05185185185185\n",
      "  episode_reward_max: 388.17672918766203\n",
      "  episode_reward_mean: 55.20356321776042\n",
      "  episode_reward_min: -168.85266118833064\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 99189\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3737.826\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 7830000\n",
      "    num_steps_trained: 7830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.491973340511322\n",
      "      kl: 0.010492847301065922\n",
      "      policy_loss: 0.0011549525661394\n",
      "      total_loss: 44.95315170288086\n",
      "      vf_explained_var: 0.9126618504524231\n",
      "      vf_loss: 44.94989013671875\n",
      "    sample_time_ms: 18378.716\n",
      "    update_time_ms: 4.874\n",
      "  iterations_since_restore: 783\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.60178160888021\n",
      "  time_since_restore: 17213.540600538254\n",
      "  time_this_iter_s: 22.41747260093689\n",
      "  time_total_s: 17213.540600538254\n",
      "  timestamp: 1553139040\n",
      "  timesteps_since_restore: 7830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7830000\n",
      "  training_iteration: 783\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17213 s, 783 iter, 7830000 ts, 55.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-31-02\n",
      "  done: false\n",
      "  episode_len_mean: 74.08208955223881\n",
      "  episode_reward_max: 385.7517822018441\n",
      "  episode_reward_mean: 55.94648960078672\n",
      "  episode_reward_min: -166.96541922399044\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 99323\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3737.217\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 7840000\n",
      "    num_steps_trained: 7840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4592531621456146\n",
      "      kl: 0.010903647169470787\n",
      "      policy_loss: 0.0023893527686595917\n",
      "      total_loss: 56.615203857421875\n",
      "      vf_explained_var: 0.8856865167617798\n",
      "      vf_loss: 56.610626220703125\n",
      "    sample_time_ms: 18361.353\n",
      "    update_time_ms: 4.762\n",
      "  iterations_since_restore: 784\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.973244800393353\n",
      "  time_since_restore: 17235.397070884705\n",
      "  time_this_iter_s: 21.856470346450806\n",
      "  time_total_s: 17235.397070884705\n",
      "  timestamp: 1553139062\n",
      "  timesteps_since_restore: 7840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7840000\n",
      "  training_iteration: 784\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17235 s, 784 iter, 7840000 ts, 55.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-31-24\n",
      "  done: false\n",
      "  episode_len_mean: 78.64566929133858\n",
      "  episode_reward_max: 382.9180685332915\n",
      "  episode_reward_mean: 87.95044401217433\n",
      "  episode_reward_min: -164.68709770175457\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 99450\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.546\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 7850000\n",
      "    num_steps_trained: 7850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4526754915714264\n",
      "      kl: 0.0125341871753335\n",
      "      policy_loss: 0.0011809024726971984\n",
      "      total_loss: 45.82646942138672\n",
      "      vf_explained_var: 0.8965790867805481\n",
      "      vf_loss: 45.82277297973633\n",
      "    sample_time_ms: 18390.162\n",
      "    update_time_ms: 5.01\n",
      "  iterations_since_restore: 785\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.97522200608718\n",
      "  time_since_restore: 17257.910527467728\n",
      "  time_this_iter_s: 22.51345658302307\n",
      "  time_total_s: 17257.910527467728\n",
      "  timestamp: 1553139084\n",
      "  timesteps_since_restore: 7850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7850000\n",
      "  training_iteration: 785\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17257 s, 785 iter, 7850000 ts, 88 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-31-46\n",
      "  done: false\n",
      "  episode_len_mean: 76.54545454545455\n",
      "  episode_reward_max: 392.4340216063359\n",
      "  episode_reward_mean: 74.05807528487638\n",
      "  episode_reward_min: -168.64396927770616\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 99582\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.46\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 7860000\n",
      "    num_steps_trained: 7860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20083697140216827\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4940488636493683\n",
      "      kl: 0.008281291462481022\n",
      "      policy_loss: 0.0015822044806554914\n",
      "      total_loss: 48.22200393676758\n",
      "      vf_explained_var: 0.8973689079284668\n",
      "      vf_loss: 48.21875762939453\n",
      "    sample_time_ms: 18378.182\n",
      "    update_time_ms: 5.104\n",
      "  iterations_since_restore: 786\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.0290376424382\n",
      "  time_since_restore: 17279.539220571518\n",
      "  time_this_iter_s: 21.628693103790283\n",
      "  time_total_s: 17279.539220571518\n",
      "  timestamp: 1553139106\n",
      "  timesteps_since_restore: 7860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7860000\n",
      "  training_iteration: 786\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17279 s, 786 iter, 7860000 ts, 74.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-32-08\n",
      "  done: false\n",
      "  episode_len_mean: 74.84210526315789\n",
      "  episode_reward_max: 387.378074935003\n",
      "  episode_reward_mean: 53.77246110518389\n",
      "  episode_reward_min: -166.74181114360331\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 99715\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.427\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 7870000\n",
      "    num_steps_trained: 7870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5164223313331604\n",
      "      kl: 0.016009284183382988\n",
      "      policy_loss: 0.0042388769797980785\n",
      "      total_loss: 49.587039947509766\n",
      "      vf_explained_var: 0.8996216058731079\n",
      "      vf_loss: 49.58119201660156\n",
      "    sample_time_ms: 18380.051\n",
      "    update_time_ms: 5.113\n",
      "  iterations_since_restore: 787\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.886230552591933\n",
      "  time_since_restore: 17301.68784213066\n",
      "  time_this_iter_s: 22.148621559143066\n",
      "  time_total_s: 17301.68784213066\n",
      "  timestamp: 1553139128\n",
      "  timesteps_since_restore: 7870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7870000\n",
      "  training_iteration: 787\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17301 s, 787 iter, 7870000 ts, 53.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-32-30\n",
      "  done: false\n",
      "  episode_len_mean: 76.70992366412214\n",
      "  episode_reward_max: 383.0695894917029\n",
      "  episode_reward_mean: 71.57956639175723\n",
      "  episode_reward_min: -166.92701544376848\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 99846\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.574\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 7880000\n",
      "    num_steps_trained: 7880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4814651608467102\n",
      "      kl: 0.02050021104514599\n",
      "      policy_loss: 0.004571089521050453\n",
      "      total_loss: 47.18999481201172\n",
      "      vf_explained_var: 0.9039890766143799\n",
      "      vf_loss: 47.1833610534668\n",
      "    sample_time_ms: 18315.807\n",
      "    update_time_ms: 5.13\n",
      "  iterations_since_restore: 788\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.7897831958786\n",
      "  time_since_restore: 17323.19702911377\n",
      "  time_this_iter_s: 21.50918698310852\n",
      "  time_total_s: 17323.19702911377\n",
      "  timestamp: 1553139150\n",
      "  timesteps_since_restore: 7880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7880000\n",
      "  training_iteration: 788\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17323 s, 788 iter, 7880000 ts, 71.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-32-52\n",
      "  done: false\n",
      "  episode_len_mean: 79.05555555555556\n",
      "  episode_reward_max: 392.35668433183673\n",
      "  episode_reward_mean: 87.17319554632816\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 99972\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.163\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 7890000\n",
      "    num_steps_trained: 7890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48561859130859375\n",
      "      kl: 0.01763453148305416\n",
      "      policy_loss: 0.0008280195179395378\n",
      "      total_loss: 48.792091369628906\n",
      "      vf_explained_var: 0.892545759677887\n",
      "      vf_loss: 48.789493560791016\n",
      "    sample_time_ms: 18291.772\n",
      "    update_time_ms: 4.967\n",
      "  iterations_since_restore: 789\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.586597773164094\n",
      "  time_since_restore: 17345.048589468002\n",
      "  time_this_iter_s: 21.851560354232788\n",
      "  time_total_s: 17345.048589468002\n",
      "  timestamp: 1553139172\n",
      "  timesteps_since_restore: 7890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7890000\n",
      "  training_iteration: 789\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17345 s, 789 iter, 7890000 ts, 87.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-33-14\n",
      "  done: false\n",
      "  episode_len_mean: 80.656\n",
      "  episode_reward_max: 392.4279109340435\n",
      "  episode_reward_mean: 97.48596256826936\n",
      "  episode_reward_min: -166.80732482143878\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 100097\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.007\n",
      "    load_time_ms: 1.96\n",
      "    num_steps_sampled: 7900000\n",
      "    num_steps_trained: 7900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4970996677875519\n",
      "      kl: 0.0166609026491642\n",
      "      policy_loss: 0.005645823199301958\n",
      "      total_loss: 44.20041275024414\n",
      "      vf_explained_var: 0.8955215215682983\n",
      "      vf_loss: 44.19309997558594\n",
      "    sample_time_ms: 18314.672\n",
      "    update_time_ms: 5.271\n",
      "  iterations_since_restore: 790\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.742981284134686\n",
      "  time_since_restore: 17367.1479511261\n",
      "  time_this_iter_s: 22.099361658096313\n",
      "  time_total_s: 17367.1479511261\n",
      "  timestamp: 1553139194\n",
      "  timesteps_since_restore: 7900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7900000\n",
      "  training_iteration: 790\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17367 s, 790 iter, 7900000 ts, 97.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-33-35\n",
      "  done: false\n",
      "  episode_len_mean: 71.09285714285714\n",
      "  episode_reward_max: 392.6216693410606\n",
      "  episode_reward_mean: 29.45740391112605\n",
      "  episode_reward_min: -166.7401195563936\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 100237\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.756\n",
      "    load_time_ms: 1.976\n",
      "    num_steps_sampled: 7910000\n",
      "    num_steps_trained: 7910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5534115433692932\n",
      "      kl: 0.018677325919270515\n",
      "      policy_loss: 0.005930693354457617\n",
      "      total_loss: 55.92024612426758\n",
      "      vf_explained_var: 0.8990341424942017\n",
      "      vf_loss: 55.91244125366211\n",
      "    sample_time_ms: 18231.934\n",
      "    update_time_ms: 5.335\n",
      "  iterations_since_restore: 791\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.728701955563029\n",
      "  time_since_restore: 17388.50722694397\n",
      "  time_this_iter_s: 21.359275817871094\n",
      "  time_total_s: 17388.50722694397\n",
      "  timestamp: 1553139215\n",
      "  timesteps_since_restore: 7910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7910000\n",
      "  training_iteration: 791\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17388 s, 791 iter, 7910000 ts, 29.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-33-58\n",
      "  done: false\n",
      "  episode_len_mean: 78.55118110236221\n",
      "  episode_reward_max: 387.9401382994064\n",
      "  episode_reward_mean: 87.91257014954344\n",
      "  episode_reward_min: -166.81945756277085\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 100364\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.06\n",
      "    load_time_ms: 1.956\n",
      "    num_steps_sampled: 7920000\n",
      "    num_steps_trained: 7920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5216282606124878\n",
      "      kl: 0.02873694896697998\n",
      "      policy_loss: 0.003627720521762967\n",
      "      total_loss: 44.8107795715332\n",
      "      vf_explained_var: 0.9013131856918335\n",
      "      vf_loss: 44.80426025390625\n",
      "    sample_time_ms: 18229.985\n",
      "    update_time_ms: 5.464\n",
      "  iterations_since_restore: 792\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.95628507477173\n",
      "  time_since_restore: 17410.76968717575\n",
      "  time_this_iter_s: 22.262460231781006\n",
      "  time_total_s: 17410.76968717575\n",
      "  timestamp: 1553139238\n",
      "  timesteps_since_restore: 7920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7920000\n",
      "  training_iteration: 792\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17410 s, 792 iter, 7920000 ts, 87.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-34-20\n",
      "  done: false\n",
      "  episode_len_mean: 78.234375\n",
      "  episode_reward_max: 386.6689253070449\n",
      "  episode_reward_mean: 80.06403820963246\n",
      "  episode_reward_min: -160.43563321336745\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 100492\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.359\n",
      "    load_time_ms: 1.89\n",
      "    num_steps_sampled: 7930000\n",
      "    num_steps_trained: 7930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5165676474571228\n",
      "      kl: 0.01384181808680296\n",
      "      policy_loss: 0.002405240200459957\n",
      "      total_loss: 54.18978500366211\n",
      "      vf_explained_var: 0.882498025894165\n",
      "      vf_loss: 54.18598556518555\n",
      "    sample_time_ms: 18225.589\n",
      "    update_time_ms: 5.356\n",
      "  iterations_since_restore: 793\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.032019104816214\n",
      "  time_since_restore: 17432.98131585121\n",
      "  time_this_iter_s: 22.211628675460815\n",
      "  time_total_s: 17432.98131585121\n",
      "  timestamp: 1553139260\n",
      "  timesteps_since_restore: 7930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7930000\n",
      "  training_iteration: 793\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17432 s, 793 iter, 7930000 ts, 80.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-34-42\n",
      "  done: false\n",
      "  episode_len_mean: 75.79545454545455\n",
      "  episode_reward_max: 387.9642008258574\n",
      "  episode_reward_mean: 64.54991948308086\n",
      "  episode_reward_min: -164.67974476560593\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 100624\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.763\n",
      "    load_time_ms: 1.878\n",
      "    num_steps_sampled: 7940000\n",
      "    num_steps_trained: 7940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5137994885444641\n",
      "      kl: 0.015492384321987629\n",
      "      policy_loss: 0.0025508147664368153\n",
      "      total_loss: 50.22595977783203\n",
      "      vf_explained_var: 0.8983092904090881\n",
      "      vf_loss: 50.22185516357422\n",
      "    sample_time_ms: 18217.464\n",
      "    update_time_ms: 5.57\n",
      "  iterations_since_restore: 794\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.27495974154043\n",
      "  time_since_restore: 17454.823887109756\n",
      "  time_this_iter_s: 21.842571258544922\n",
      "  time_total_s: 17454.823887109756\n",
      "  timestamp: 1553139282\n",
      "  timesteps_since_restore: 7940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7940000\n",
      "  training_iteration: 794\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17454 s, 794 iter, 7940000 ts, 64.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-35-03\n",
      "  done: false\n",
      "  episode_len_mean: 73.01459854014598\n",
      "  episode_reward_max: 386.3674931829257\n",
      "  episode_reward_mean: 46.64321339358071\n",
      "  episode_reward_min: -168.71007235368728\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 100761\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.26\n",
      "    load_time_ms: 1.878\n",
      "    num_steps_sampled: 7950000\n",
      "    num_steps_trained: 7950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5435460209846497\n",
      "      kl: 0.019852757453918457\n",
      "      policy_loss: 0.003995366394519806\n",
      "      total_loss: 56.406925201416016\n",
      "      vf_explained_var: 0.892828643321991\n",
      "      vf_loss: 56.40093994140625\n",
      "    sample_time_ms: 18054.301\n",
      "    update_time_ms: 5.215\n",
      "  iterations_since_restore: 795\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.321606696790354\n",
      "  time_since_restore: 17475.707450151443\n",
      "  time_this_iter_s: 20.88356304168701\n",
      "  time_total_s: 17475.707450151443\n",
      "  timestamp: 1553139303\n",
      "  timesteps_since_restore: 7950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7950000\n",
      "  training_iteration: 795\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17475 s, 795 iter, 7950000 ts, 46.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-35-24\n",
      "  done: false\n",
      "  episode_len_mean: 82.21311475409836\n",
      "  episode_reward_max: 386.66413291488664\n",
      "  episode_reward_mean: 110.84624324210654\n",
      "  episode_reward_min: -162.97966694876195\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 100883\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.086\n",
      "    load_time_ms: 1.927\n",
      "    num_steps_sampled: 7960000\n",
      "    num_steps_trained: 7960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4904632568359375\n",
      "      kl: 0.01734122633934021\n",
      "      policy_loss: 0.0024041165597736835\n",
      "      total_loss: 38.74692153930664\n",
      "      vf_explained_var: 0.9079374670982361\n",
      "      vf_loss: 38.742774963378906\n",
      "    sample_time_ms: 18053.008\n",
      "    update_time_ms: 5.089\n",
      "  iterations_since_restore: 796\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.42312162105325\n",
      "  time_since_restore: 17497.30128645897\n",
      "  time_this_iter_s: 21.593836307525635\n",
      "  time_total_s: 17497.30128645897\n",
      "  timestamp: 1553139324\n",
      "  timesteps_since_restore: 7960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7960000\n",
      "  training_iteration: 796\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17497 s, 796 iter, 7960000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-35-46\n",
      "  done: false\n",
      "  episode_len_mean: 74.13432835820896\n",
      "  episode_reward_max: 387.42068118194044\n",
      "  episode_reward_mean: 56.13986850668539\n",
      "  episode_reward_min: -166.74756573161125\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 101017\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.312\n",
      "    load_time_ms: 1.884\n",
      "    num_steps_sampled: 7970000\n",
      "    num_steps_trained: 7970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5371884107589722\n",
      "      kl: 0.020749377086758614\n",
      "      policy_loss: 0.005268544424325228\n",
      "      total_loss: 49.74308395385742\n",
      "      vf_explained_var: 0.9013545513153076\n",
      "      vf_loss: 49.73573303222656\n",
      "    sample_time_ms: 18040.296\n",
      "    update_time_ms: 5.099\n",
      "  iterations_since_restore: 797\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.06993425334269\n",
      "  time_since_restore: 17519.30055975914\n",
      "  time_this_iter_s: 21.9992733001709\n",
      "  time_total_s: 17519.30055975914\n",
      "  timestamp: 1553139346\n",
      "  timesteps_since_restore: 7970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7970000\n",
      "  training_iteration: 797\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17519 s, 797 iter, 7970000 ts, 56.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-36-08\n",
      "  done: false\n",
      "  episode_len_mean: 80.80645161290323\n",
      "  episode_reward_max: 391.031850102322\n",
      "  episode_reward_mean: 106.00610467500765\n",
      "  episode_reward_min: -166.72944796535015\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 101141\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.228\n",
      "    load_time_ms: 1.827\n",
      "    num_steps_sampled: 7980000\n",
      "    num_steps_trained: 7980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5148394703865051\n",
      "      kl: 0.012180965393781662\n",
      "      policy_loss: 0.001773799303919077\n",
      "      total_loss: 45.230247497558594\n",
      "      vf_explained_var: 0.8928864598274231\n",
      "      vf_loss: 45.22725296020508\n",
      "    sample_time_ms: 18072.083\n",
      "    update_time_ms: 5.134\n",
      "  iterations_since_restore: 798\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.00305233750383\n",
      "  time_since_restore: 17541.11248755455\n",
      "  time_this_iter_s: 21.811927795410156\n",
      "  time_total_s: 17541.11248755455\n",
      "  timestamp: 1553139368\n",
      "  timesteps_since_restore: 7980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7980000\n",
      "  training_iteration: 798\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17541 s, 798 iter, 7980000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-36-30\n",
      "  done: false\n",
      "  episode_len_mean: 80.6774193548387\n",
      "  episode_reward_max: 387.5276830564313\n",
      "  episode_reward_mean: 102.83313740599525\n",
      "  episode_reward_min: -164.6946741320753\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 101265\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.098\n",
      "    load_time_ms: 1.817\n",
      "    num_steps_sampled: 7990000\n",
      "    num_steps_trained: 7990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.500762939453125\n",
      "      kl: 0.01590924710035324\n",
      "      policy_loss: 0.0013582197716459632\n",
      "      total_loss: 49.487030029296875\n",
      "      vf_explained_var: 0.8872381448745728\n",
      "      vf_loss: 49.48406982421875\n",
      "    sample_time_ms: 18089.021\n",
      "    update_time_ms: 5.131\n",
      "  iterations_since_restore: 799\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.41656870299761\n",
      "  time_since_restore: 17563.114058732986\n",
      "  time_this_iter_s: 22.00157117843628\n",
      "  time_total_s: 17563.114058732986\n",
      "  timestamp: 1553139390\n",
      "  timesteps_since_restore: 7990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7990000\n",
      "  training_iteration: 799\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17563 s, 799 iter, 7990000 ts, 103 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-36-53\n",
      "  done: false\n",
      "  episode_len_mean: 73.24087591240875\n",
      "  episode_reward_max: 387.62384348867977\n",
      "  episode_reward_mean: 47.87662011615527\n",
      "  episode_reward_min: -164.72292286941052\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 101402\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.772\n",
      "    load_time_ms: 1.545\n",
      "    num_steps_sampled: 8000000\n",
      "    num_steps_trained: 8000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5427928566932678\n",
      "      kl: 0.018740125000476837\n",
      "      policy_loss: 0.004886288661509752\n",
      "      total_loss: 54.07976531982422\n",
      "      vf_explained_var: 0.8975962400436401\n",
      "      vf_loss: 54.072998046875\n",
      "    sample_time_ms: 18135.168\n",
      "    update_time_ms: 4.944\n",
      "  iterations_since_restore: 800\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.938310058077633\n",
      "  time_since_restore: 17585.657695055008\n",
      "  time_this_iter_s: 22.543636322021484\n",
      "  time_total_s: 17585.657695055008\n",
      "  timestamp: 1553139413\n",
      "  timesteps_since_restore: 8000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8000000\n",
      "  training_iteration: 800\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17585 s, 800 iter, 8000000 ts, 47.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-37-15\n",
      "  done: false\n",
      "  episode_len_mean: 76.97674418604652\n",
      "  episode_reward_max: 388.3683261634037\n",
      "  episode_reward_mean: 72.76566826741534\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 101531\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.793\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 8010000\n",
      "    num_steps_trained: 8010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5173166990280151\n",
      "      kl: 0.021566271781921387\n",
      "      policy_loss: 0.004773378372192383\n",
      "      total_loss: 49.624298095703125\n",
      "      vf_explained_var: 0.8943405151367188\n",
      "      vf_loss: 49.61736297607422\n",
      "    sample_time_ms: 18250.725\n",
      "    update_time_ms: 5.586\n",
      "  iterations_since_restore: 801\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.38283413370767\n",
      "  time_since_restore: 17608.16988492012\n",
      "  time_this_iter_s: 22.512189865112305\n",
      "  time_total_s: 17608.16988492012\n",
      "  timestamp: 1553139435\n",
      "  timesteps_since_restore: 8010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8010000\n",
      "  training_iteration: 801\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17608 s, 801 iter, 8010000 ts, 72.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-37-37\n",
      "  done: false\n",
      "  episode_len_mean: 75.4812030075188\n",
      "  episode_reward_max: 390.6013752909484\n",
      "  episode_reward_mean: 65.71546445683549\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 101664\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.9\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 8020000\n",
      "    num_steps_trained: 8020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5231972932815552\n",
      "      kl: 0.015581772662699223\n",
      "      policy_loss: 0.0004865490773227066\n",
      "      total_loss: 52.27196502685547\n",
      "      vf_explained_var: 0.8935995697975159\n",
      "      vf_loss: 52.269920349121094\n",
      "    sample_time_ms: 18185.457\n",
      "    update_time_ms: 5.547\n",
      "  iterations_since_restore: 802\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.857732228417746\n",
      "  time_since_restore: 17629.780912399292\n",
      "  time_this_iter_s: 21.611027479171753\n",
      "  time_total_s: 17629.780912399292\n",
      "  timestamp: 1553139457\n",
      "  timesteps_since_restore: 8020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8020000\n",
      "  training_iteration: 802\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17629 s, 802 iter, 8020000 ts, 65.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-37-59\n",
      "  done: false\n",
      "  episode_len_mean: 77.41538461538461\n",
      "  episode_reward_max: 388.29783653052795\n",
      "  episode_reward_mean: 72.72669825301611\n",
      "  episode_reward_min: -166.75761621519567\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 101794\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.079\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 8030000\n",
      "    num_steps_trained: 8030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5069366693496704\n",
      "      kl: 0.01685739867389202\n",
      "      policy_loss: 0.002274927217513323\n",
      "      total_loss: 43.39607238769531\n",
      "      vf_explained_var: 0.9104310870170593\n",
      "      vf_loss: 43.3921012878418\n",
      "    sample_time_ms: 18149.874\n",
      "    update_time_ms: 5.692\n",
      "  iterations_since_restore: 803\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.36334912650805\n",
      "  time_since_restore: 17651.64342212677\n",
      "  time_this_iter_s: 21.862509727478027\n",
      "  time_total_s: 17651.64342212677\n",
      "  timestamp: 1553139479\n",
      "  timesteps_since_restore: 8030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8030000\n",
      "  training_iteration: 803\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17651 s, 803 iter, 8030000 ts, 72.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-38-21\n",
      "  done: false\n",
      "  episode_len_mean: 75.53076923076924\n",
      "  episode_reward_max: 388.3795751026942\n",
      "  episode_reward_mean: 61.104161012522475\n",
      "  episode_reward_min: -166.79539581259726\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 101924\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.209\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 8040000\n",
      "    num_steps_trained: 8040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5213527083396912\n",
      "      kl: 0.02460634708404541\n",
      "      policy_loss: 0.005321214906871319\n",
      "      total_loss: 51.22876739501953\n",
      "      vf_explained_var: 0.8941613435745239\n",
      "      vf_loss: 51.22097396850586\n",
      "    sample_time_ms: 18194.644\n",
      "    update_time_ms: 5.588\n",
      "  iterations_since_restore: 804\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.55208050626123\n",
      "  time_since_restore: 17673.854061841965\n",
      "  time_this_iter_s: 22.210639715194702\n",
      "  time_total_s: 17673.854061841965\n",
      "  timestamp: 1553139501\n",
      "  timesteps_since_restore: 8040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8040000\n",
      "  training_iteration: 804\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17673 s, 804 iter, 8040000 ts, 61.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-38-43\n",
      "  done: false\n",
      "  episode_len_mean: 73.57246376811594\n",
      "  episode_reward_max: 387.5418387488968\n",
      "  episode_reward_mean: 47.09051704433618\n",
      "  episode_reward_min: -166.70062981530666\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 102062\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.607\n",
      "    load_time_ms: 1.652\n",
      "    num_steps_sampled: 8050000\n",
      "    num_steps_trained: 8050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5029202699661255\n",
      "      kl: 0.018759509548544884\n",
      "      policy_loss: 0.0028727559838443995\n",
      "      total_loss: 50.78189468383789\n",
      "      vf_explained_var: 0.9017552137374878\n",
      "      vf_loss: 50.77714157104492\n",
      "    sample_time_ms: 18266.194\n",
      "    update_time_ms: 5.706\n",
      "  iterations_since_restore: 805\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.54525852216809\n",
      "  time_since_restore: 17695.591295957565\n",
      "  time_this_iter_s: 21.737234115600586\n",
      "  time_total_s: 17695.591295957565\n",
      "  timestamp: 1553139523\n",
      "  timesteps_since_restore: 8050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8050000\n",
      "  training_iteration: 805\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17695 s, 805 iter, 8050000 ts, 47.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-39-05\n",
      "  done: false\n",
      "  episode_len_mean: 72.70588235294117\n",
      "  episode_reward_max: 386.3739942173723\n",
      "  episode_reward_mean: 40.66941320112382\n",
      "  episode_reward_min: -162.5995786599779\n",
      "  episodes_this_iter: 136\n",
      "  episodes_total: 102198\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.068\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 8060000\n",
      "    num_steps_trained: 8060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5496194362640381\n",
      "      kl: 0.01712937466800213\n",
      "      policy_loss: 0.0024948788341134787\n",
      "      total_loss: 51.89160919189453\n",
      "      vf_explained_var: 0.9017268419265747\n",
      "      vf_loss: 51.88739013671875\n",
      "    sample_time_ms: 18280.013\n",
      "    update_time_ms: 5.73\n",
      "  iterations_since_restore: 806\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.334706600561905\n",
      "  time_since_restore: 17717.306008577347\n",
      "  time_this_iter_s: 21.714712619781494\n",
      "  time_total_s: 17717.306008577347\n",
      "  timestamp: 1553139545\n",
      "  timesteps_since_restore: 8060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8060000\n",
      "  training_iteration: 806\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17717 s, 806 iter, 8060000 ts, 40.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 77.69767441860465\n",
      "  episode_reward_max: 387.95877649045246\n",
      "  episode_reward_mean: 80.51921693340421\n",
      "  episode_reward_min: -166.69190331455707\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 102327\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.865\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 8070000\n",
      "    num_steps_trained: 8070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5269816517829895\n",
      "      kl: 0.014995691366493702\n",
      "      policy_loss: 0.0031510312110185623\n",
      "      total_loss: 49.1104850769043\n",
      "      vf_explained_var: 0.8950527906417847\n",
      "      vf_loss: 49.105831146240234\n",
      "    sample_time_ms: 18302.52\n",
      "    update_time_ms: 5.807\n",
      "  iterations_since_restore: 807\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.25960846670209\n",
      "  time_since_restore: 17739.54213619232\n",
      "  time_this_iter_s: 22.236127614974976\n",
      "  time_total_s: 17739.54213619232\n",
      "  timestamp: 1553139567\n",
      "  timesteps_since_restore: 8070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8070000\n",
      "  training_iteration: 807\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17739 s, 807 iter, 8070000 ts, 80.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-39-50\n",
      "  done: false\n",
      "  episode_len_mean: 76.09848484848484\n",
      "  episode_reward_max: 390.659601464162\n",
      "  episode_reward_mean: 70.56218143849935\n",
      "  episode_reward_min: -166.7104790399933\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 102459\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.033\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 8080000\n",
      "    num_steps_trained: 8080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5477297902107239\n",
      "      kl: 0.0208189208060503\n",
      "      policy_loss: 0.005153258331120014\n",
      "      total_loss: 48.909149169921875\n",
      "      vf_explained_var: 0.9007841944694519\n",
      "      vf_loss: 48.90189743041992\n",
      "    sample_time_ms: 18405.495\n",
      "    update_time_ms: 5.729\n",
      "  iterations_since_restore: 808\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.281090719249676\n",
      "  time_since_restore: 17762.33810687065\n",
      "  time_this_iter_s: 22.795970678329468\n",
      "  time_total_s: 17762.33810687065\n",
      "  timestamp: 1553139590\n",
      "  timesteps_since_restore: 8080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8080000\n",
      "  training_iteration: 808\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17762 s, 808 iter, 8080000 ts, 70.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-40-12\n",
      "  done: false\n",
      "  episode_len_mean: 74.12592592592593\n",
      "  episode_reward_max: 392.61315940712524\n",
      "  episode_reward_mean: 56.24097316458017\n",
      "  episode_reward_min: -164.6682393587494\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 102594\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.861\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 8090000\n",
      "    num_steps_trained: 8090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5794323682785034\n",
      "      kl: 0.01849909871816635\n",
      "      policy_loss: 0.003828279208391905\n",
      "      total_loss: 58.58338165283203\n",
      "      vf_explained_var: 0.8881022334098816\n",
      "      vf_loss: 58.57770538330078\n",
      "    sample_time_ms: 18378.86\n",
      "    update_time_ms: 5.788\n",
      "  iterations_since_restore: 809\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.120486582290084\n",
      "  time_since_restore: 17784.253655910492\n",
      "  time_this_iter_s: 21.9155490398407\n",
      "  time_total_s: 17784.253655910492\n",
      "  timestamp: 1553139612\n",
      "  timesteps_since_restore: 8090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8090000\n",
      "  training_iteration: 809\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17784 s, 809 iter, 8090000 ts, 56.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-40-34\n",
      "  done: false\n",
      "  episode_len_mean: 81.23577235772358\n",
      "  episode_reward_max: 389.55787752381946\n",
      "  episode_reward_mean: 108.4802499140899\n",
      "  episode_reward_min: -164.66453656610489\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 102717\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.975\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 8100000\n",
      "    num_steps_trained: 8100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5172374248504639\n",
      "      kl: 0.015772048383951187\n",
      "      policy_loss: 0.0013496378669515252\n",
      "      total_loss: 47.87697982788086\n",
      "      vf_explained_var: 0.8828935623168945\n",
      "      vf_loss: 47.87405014038086\n",
      "    sample_time_ms: 18304.227\n",
      "    update_time_ms: 5.811\n",
      "  iterations_since_restore: 810\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.240124957044934\n",
      "  time_since_restore: 17806.01197695732\n",
      "  time_this_iter_s: 21.758321046829224\n",
      "  time_total_s: 17806.01197695732\n",
      "  timestamp: 1553139634\n",
      "  timesteps_since_restore: 8100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8100000\n",
      "  training_iteration: 810\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17806 s, 810 iter, 8100000 ts, 108 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-40-56\n",
      "  done: false\n",
      "  episode_len_mean: 78.234375\n",
      "  episode_reward_max: 386.99906890623083\n",
      "  episode_reward_mean: 81.36770361242222\n",
      "  episode_reward_min: -167.00250582381724\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 102845\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.382\n",
      "    load_time_ms: 1.677\n",
      "    num_steps_sampled: 8110000\n",
      "    num_steps_trained: 8110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5200297832489014\n",
      "      kl: 0.012498138472437859\n",
      "      policy_loss: 0.0026812239084392786\n",
      "      total_loss: 50.760440826416016\n",
      "      vf_explained_var: 0.8899453282356262\n",
      "      vf_loss: 50.75650405883789\n",
      "    sample_time_ms: 18295.819\n",
      "    update_time_ms: 5.167\n",
      "  iterations_since_restore: 811\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.6838518062111\n",
      "  time_since_restore: 17828.44116806984\n",
      "  time_this_iter_s: 22.42919111251831\n",
      "  time_total_s: 17828.44116806984\n",
      "  timestamp: 1553139656\n",
      "  timesteps_since_restore: 8110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8110000\n",
      "  training_iteration: 811\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17828 s, 811 iter, 8110000 ts, 81.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-41-18\n",
      "  done: false\n",
      "  episode_len_mean: 86.16379310344827\n",
      "  episode_reward_max: 388.1492287488292\n",
      "  episode_reward_mean: 143.02642716444146\n",
      "  episode_reward_min: -164.71426056679724\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 102961\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.488\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 8120000\n",
      "    num_steps_trained: 8120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5027238130569458\n",
      "      kl: 0.01893521659076214\n",
      "      policy_loss: 0.0072363330982625484\n",
      "      total_loss: 39.98838424682617\n",
      "      vf_explained_var: 0.8886772394180298\n",
      "      vf_loss: 39.979244232177734\n",
      "    sample_time_ms: 18321.661\n",
      "    update_time_ms: 5.261\n",
      "  iterations_since_restore: 812\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.5132135822207\n",
      "  time_since_restore: 17850.303017139435\n",
      "  time_this_iter_s: 21.861849069595337\n",
      "  time_total_s: 17850.303017139435\n",
      "  timestamp: 1553139678\n",
      "  timesteps_since_restore: 8120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8120000\n",
      "  training_iteration: 812\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17850 s, 812 iter, 8120000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-41-40\n",
      "  done: false\n",
      "  episode_len_mean: 77.5891472868217\n",
      "  episode_reward_max: 386.7623931257263\n",
      "  episode_reward_mean: 78.73570331473148\n",
      "  episode_reward_min: -168.68732329114914\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 103090\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.643\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 8130000\n",
      "    num_steps_trained: 8130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5488327145576477\n",
      "      kl: 0.017201468348503113\n",
      "      policy_loss: 0.001230503898113966\n",
      "      total_loss: 41.75663375854492\n",
      "      vf_explained_var: 0.9120448231697083\n",
      "      vf_loss: 41.7536735534668\n",
      "    sample_time_ms: 18307.072\n",
      "    update_time_ms: 5.298\n",
      "  iterations_since_restore: 813\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.367851657365726\n",
      "  time_since_restore: 17872.26744246483\n",
      "  time_this_iter_s: 21.964425325393677\n",
      "  time_total_s: 17872.26744246483\n",
      "  timestamp: 1553139700\n",
      "  timesteps_since_restore: 8130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8130000\n",
      "  training_iteration: 813\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17872 s, 813 iter, 8130000 ts, 78.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-42-02\n",
      "  done: false\n",
      "  episode_len_mean: 74.83458646616542\n",
      "  episode_reward_max: 387.6442109450448\n",
      "  episode_reward_mean: 53.90783119109667\n",
      "  episode_reward_min: -165.39043672665596\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 103223\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.957\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 8140000\n",
      "    num_steps_trained: 8140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5472221970558167\n",
      "      kl: 0.01988033764064312\n",
      "      policy_loss: 0.0033828597515821457\n",
      "      total_loss: 57.53249740600586\n",
      "      vf_explained_var: 0.8852174282073975\n",
      "      vf_loss: 57.52711868286133\n",
      "    sample_time_ms: 18292.938\n",
      "    update_time_ms: 5.254\n",
      "  iterations_since_restore: 814\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.953915595548327\n",
      "  time_since_restore: 17894.34879374504\n",
      "  time_this_iter_s: 22.081351280212402\n",
      "  time_total_s: 17894.34879374504\n",
      "  timestamp: 1553139722\n",
      "  timesteps_since_restore: 8140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8140000\n",
      "  training_iteration: 814\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17894 s, 814 iter, 8140000 ts, 53.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-42-24\n",
      "  done: false\n",
      "  episode_len_mean: 76.72519083969466\n",
      "  episode_reward_max: 391.4918382794804\n",
      "  episode_reward_mean: 65.99086528284654\n",
      "  episode_reward_min: -166.75788088044166\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 103354\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.668\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 8150000\n",
      "    num_steps_trained: 8150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5488812327384949\n",
      "      kl: 0.018349651247262955\n",
      "      policy_loss: 0.0028810666408389807\n",
      "      total_loss: 57.30260467529297\n",
      "      vf_explained_var: 0.8820503354072571\n",
      "      vf_loss: 57.29787826538086\n",
      "    sample_time_ms: 18302.04\n",
      "    update_time_ms: 5.15\n",
      "  iterations_since_restore: 815\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.99543264142328\n",
      "  time_since_restore: 17916.00075316429\n",
      "  time_this_iter_s: 21.65195941925049\n",
      "  time_total_s: 17916.00075316429\n",
      "  timestamp: 1553139744\n",
      "  timesteps_since_restore: 8150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8150000\n",
      "  training_iteration: 815\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17916 s, 815 iter, 8150000 ts, 66 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-42-46\n",
      "  done: false\n",
      "  episode_len_mean: 75.29323308270676\n",
      "  episode_reward_max: 392.7145418295964\n",
      "  episode_reward_mean: 64.83104540195397\n",
      "  episode_reward_min: -168.7178522141838\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 103487\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.347\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 8160000\n",
      "    num_steps_trained: 8160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5432238578796387\n",
      "      kl: 0.02271757833659649\n",
      "      policy_loss: 0.007130053360015154\n",
      "      total_loss: 44.90321350097656\n",
      "      vf_explained_var: 0.9105290174484253\n",
      "      vf_loss: 44.89380645751953\n",
      "    sample_time_ms: 18367.753\n",
      "    update_time_ms: 5.543\n",
      "  iterations_since_restore: 816\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 32.415522700976986\n",
      "  time_since_restore: 17938.393569469452\n",
      "  time_this_iter_s: 22.392816305160522\n",
      "  time_total_s: 17938.393569469452\n",
      "  timestamp: 1553139766\n",
      "  timesteps_since_restore: 8160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8160000\n",
      "  training_iteration: 816\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17938 s, 816 iter, 8160000 ts, 64.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-43-08\n",
      "  done: false\n",
      "  episode_len_mean: 75.15789473684211\n",
      "  episode_reward_max: 392.29981973239984\n",
      "  episode_reward_mean: 61.8504800719768\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 103620\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.074\n",
      "    load_time_ms: 1.65\n",
      "    num_steps_sampled: 8170000\n",
      "    num_steps_trained: 8170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5507338643074036\n",
      "      kl: 0.020653782412409782\n",
      "      policy_loss: 0.0016242843121290207\n",
      "      total_loss: 50.23905563354492\n",
      "      vf_explained_var: 0.8986477851867676\n",
      "      vf_loss: 50.23535919189453\n",
      "    sample_time_ms: 18357.073\n",
      "    update_time_ms: 5.444\n",
      "  iterations_since_restore: 817\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.925240035988384\n",
      "  time_since_restore: 17960.531767845154\n",
      "  time_this_iter_s: 22.138198375701904\n",
      "  time_total_s: 17960.531767845154\n",
      "  timestamp: 1553139788\n",
      "  timesteps_since_restore: 8170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8170000\n",
      "  training_iteration: 817\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17960 s, 817 iter, 8170000 ts, 61.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-43-31\n",
      "  done: false\n",
      "  episode_len_mean: 79.04761904761905\n",
      "  episode_reward_max: 392.07386225716294\n",
      "  episode_reward_mean: 90.43976092633403\n",
      "  episode_reward_min: -166.71841949626446\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 103746\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.356\n",
      "    load_time_ms: 1.657\n",
      "    num_steps_sampled: 8180000\n",
      "    num_steps_trained: 8180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5255333185195923\n",
      "      kl: 0.018472271040081978\n",
      "      policy_loss: 0.0051922849379479885\n",
      "      total_loss: 39.95798873901367\n",
      "      vf_explained_var: 0.910314679145813\n",
      "      vf_loss: 39.9509391784668\n",
      "    sample_time_ms: 18294.508\n",
      "    update_time_ms: 5.587\n",
      "  iterations_since_restore: 818\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.219880463167016\n",
      "  time_since_restore: 17982.722982645035\n",
      "  time_this_iter_s: 22.19121479988098\n",
      "  time_total_s: 17982.722982645035\n",
      "  timestamp: 1553139811\n",
      "  timesteps_since_restore: 8180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8180000\n",
      "  training_iteration: 818\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 17982 s, 818 iter, 8180000 ts, 90.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-43-53\n",
      "  done: false\n",
      "  episode_len_mean: 78.65625\n",
      "  episode_reward_max: 384.2999635475171\n",
      "  episode_reward_mean: 83.89782625566545\n",
      "  episode_reward_min: -164.66834896680353\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 103874\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.354\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 8190000\n",
      "    num_steps_trained: 8190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.52261883020401\n",
      "      kl: 0.01619846187531948\n",
      "      policy_loss: 0.0026341460179537535\n",
      "      total_loss: 41.53388977050781\n",
      "      vf_explained_var: 0.9087551832199097\n",
      "      vf_loss: 41.52962875366211\n",
      "    sample_time_ms: 18330.035\n",
      "    update_time_ms: 5.843\n",
      "  iterations_since_restore: 819\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.94891312783272\n",
      "  time_since_restore: 18004.792513370514\n",
      "  time_this_iter_s: 22.069530725479126\n",
      "  time_total_s: 18004.792513370514\n",
      "  timestamp: 1553139833\n",
      "  timesteps_since_restore: 8190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8190000\n",
      "  training_iteration: 819\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18004 s, 819 iter, 8190000 ts, 83.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-44-15\n",
      "  done: false\n",
      "  episode_len_mean: 82.80672268907563\n",
      "  episode_reward_max: 391.98956552716743\n",
      "  episode_reward_mean: 117.57636104403498\n",
      "  episode_reward_min: -168.7337486087942\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 103993\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.53\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 8200000\n",
      "    num_steps_trained: 8200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5236087441444397\n",
      "      kl: 0.01859520561993122\n",
      "      policy_loss: 0.00396806001663208\n",
      "      total_loss: 32.04385757446289\n",
      "      vf_explained_var: 0.9200347661972046\n",
      "      vf_loss: 32.038021087646484\n",
      "    sample_time_ms: 18328.782\n",
      "    update_time_ms: 5.9\n",
      "  iterations_since_restore: 820\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.788180522017484\n",
      "  time_since_restore: 18026.58034825325\n",
      "  time_this_iter_s: 21.787834882736206\n",
      "  time_total_s: 18026.58034825325\n",
      "  timestamp: 1553139855\n",
      "  timesteps_since_restore: 8200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8200000\n",
      "  training_iteration: 820\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18026 s, 820 iter, 8200000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-44-36\n",
      "  done: false\n",
      "  episode_len_mean: 72.97101449275362\n",
      "  episode_reward_max: 388.58175347817314\n",
      "  episode_reward_mean: 41.82511150609012\n",
      "  episode_reward_min: -166.75782888111115\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 104131\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.886\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 8210000\n",
      "    num_steps_trained: 8210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5802992582321167\n",
      "      kl: 0.027152415364980698\n",
      "      policy_loss: 0.005252541042864323\n",
      "      total_loss: 38.358524322509766\n",
      "      vf_explained_var: 0.9274377226829529\n",
      "      vf_loss: 38.350547790527344\n",
      "    sample_time_ms: 18246.255\n",
      "    update_time_ms: 5.823\n",
      "  iterations_since_restore: 821\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.91255575304506\n",
      "  time_since_restore: 18048.193584918976\n",
      "  time_this_iter_s: 21.613236665725708\n",
      "  time_total_s: 18048.193584918976\n",
      "  timestamp: 1553139876\n",
      "  timesteps_since_restore: 8210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8210000\n",
      "  training_iteration: 821\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18048 s, 821 iter, 8210000 ts, 41.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-44-58\n",
      "  done: false\n",
      "  episode_len_mean: 79.768\n",
      "  episode_reward_max: 387.60400993047585\n",
      "  episode_reward_mean: 95.75685515916453\n",
      "  episode_reward_min: -166.85069757172107\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 104256\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.645\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 8220000\n",
      "    num_steps_trained: 8220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.551566481590271\n",
      "      kl: 0.014825516380369663\n",
      "      policy_loss: 0.0011397665366530418\n",
      "      total_loss: 46.0344352722168\n",
      "      vf_explained_var: 0.89621502161026\n",
      "      vf_loss: 46.03180694580078\n",
      "    sample_time_ms: 18248.135\n",
      "    update_time_ms: 5.671\n",
      "  iterations_since_restore: 822\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.87842757958225\n",
      "  time_since_restore: 18070.047413110733\n",
      "  time_this_iter_s: 21.853828191757202\n",
      "  time_total_s: 18070.047413110733\n",
      "  timestamp: 1553139898\n",
      "  timesteps_since_restore: 8220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8220000\n",
      "  training_iteration: 822\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18070 s, 822 iter, 8220000 ts, 95.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-45-20\n",
      "  done: false\n",
      "  episode_len_mean: 78.2734375\n",
      "  episode_reward_max: 390.82345838687286\n",
      "  episode_reward_mean: 82.99986133015325\n",
      "  episode_reward_min: -166.7769516093397\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 104384\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3676.761\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 8230000\n",
      "    num_steps_trained: 8230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5646926760673523\n",
      "      kl: 0.020830895751714706\n",
      "      policy_loss: 0.0034144562669098377\n",
      "      total_loss: 44.41273498535156\n",
      "      vf_explained_var: 0.9042727947235107\n",
      "      vf_loss: 44.407222747802734\n",
      "    sample_time_ms: 18222.235\n",
      "    update_time_ms: 5.586\n",
      "  iterations_since_restore: 823\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.49993066507662\n",
      "  time_since_restore: 18091.506416082382\n",
      "  time_this_iter_s: 21.45900297164917\n",
      "  time_total_s: 18091.506416082382\n",
      "  timestamp: 1553139920\n",
      "  timesteps_since_restore: 8230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8230000\n",
      "  training_iteration: 823\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18091 s, 823 iter, 8230000 ts, 83 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-45-42\n",
      "  done: false\n",
      "  episode_len_mean: 75.00751879699249\n",
      "  episode_reward_max: 390.97349561009196\n",
      "  episode_reward_mean: 61.606396401666274\n",
      "  episode_reward_min: -162.8347758854294\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 104517\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.64\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 8240000\n",
      "    num_steps_trained: 8240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5671601891517639\n",
      "      kl: 0.021841855719685555\n",
      "      policy_loss: 0.008184898644685745\n",
      "      total_loss: 43.54700469970703\n",
      "      vf_explained_var: 0.9123681783676147\n",
      "      vf_loss: 43.53662109375\n",
      "    sample_time_ms: 18221.503\n",
      "    update_time_ms: 5.625\n",
      "  iterations_since_restore: 824\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.803198200833137\n",
      "  time_since_restore: 18113.68932700157\n",
      "  time_this_iter_s: 22.182910919189453\n",
      "  time_total_s: 18113.68932700157\n",
      "  timestamp: 1553139942\n",
      "  timesteps_since_restore: 8240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8240000\n",
      "  training_iteration: 824\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18113 s, 824 iter, 8240000 ts, 61.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-46-03\n",
      "  done: false\n",
      "  episode_len_mean: 77.57364341085271\n",
      "  episode_reward_max: 387.66143833143127\n",
      "  episode_reward_mean: 80.80172189049354\n",
      "  episode_reward_min: -164.71742184599879\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 104646\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.623\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 8250000\n",
      "    num_steps_trained: 8250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5651195049285889\n",
      "      kl: 0.01587153784930706\n",
      "      policy_loss: 0.003356550820171833\n",
      "      total_loss: 46.6025505065918\n",
      "      vf_explained_var: 0.9015089869499207\n",
      "      vf_loss: 46.597599029541016\n",
      "    sample_time_ms: 18190.603\n",
      "    update_time_ms: 5.641\n",
      "  iterations_since_restore: 825\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.40086094524677\n",
      "  time_since_restore: 18135.07257461548\n",
      "  time_this_iter_s: 21.38324761390686\n",
      "  time_total_s: 18135.07257461548\n",
      "  timestamp: 1553139963\n",
      "  timesteps_since_restore: 8250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8250000\n",
      "  training_iteration: 825\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18135 s, 825 iter, 8250000 ts, 80.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-46-25\n",
      "  done: false\n",
      "  episode_len_mean: 83.43333333333334\n",
      "  episode_reward_max: 388.69702231154525\n",
      "  episode_reward_mean: 121.5136528563382\n",
      "  episode_reward_min: -165.58060859551668\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 104766\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.948\n",
      "    load_time_ms: 1.428\n",
      "    num_steps_sampled: 8260000\n",
      "    num_steps_trained: 8260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49469611048698425\n",
      "      kl: 0.018360210582613945\n",
      "      policy_loss: 0.0032810301054269075\n",
      "      total_loss: 43.259220123291016\n",
      "      vf_explained_var: 0.8911903500556946\n",
      "      vf_loss: 43.254093170166016\n",
      "    sample_time_ms: 18153.001\n",
      "    update_time_ms: 5.321\n",
      "  iterations_since_restore: 826\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.75682642816909\n",
      "  time_since_restore: 18157.11091852188\n",
      "  time_this_iter_s: 22.038343906402588\n",
      "  time_total_s: 18157.11091852188\n",
      "  timestamp: 1553139985\n",
      "  timesteps_since_restore: 8260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8260000\n",
      "  training_iteration: 826\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18157 s, 826 iter, 8260000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-46-48\n",
      "  done: false\n",
      "  episode_len_mean: 78.35658914728683\n",
      "  episode_reward_max: 388.3076997883326\n",
      "  episode_reward_mean: 81.62563365152329\n",
      "  episode_reward_min: -166.8150006719494\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 104895\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.963\n",
      "    load_time_ms: 1.387\n",
      "    num_steps_sampled: 8270000\n",
      "    num_steps_trained: 8270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5456571578979492\n",
      "      kl: 0.012469063512980938\n",
      "      policy_loss: 0.002554330974817276\n",
      "      total_loss: 38.33599090576172\n",
      "      vf_explained_var: 0.9164121747016907\n",
      "      vf_loss: 38.332183837890625\n",
      "    sample_time_ms: 18202.788\n",
      "    update_time_ms: 5.372\n",
      "  iterations_since_restore: 827\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.812816825761644\n",
      "  time_since_restore: 18179.746953248978\n",
      "  time_this_iter_s: 22.636034727096558\n",
      "  time_total_s: 18179.746953248978\n",
      "  timestamp: 1553140008\n",
      "  timesteps_since_restore: 8270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8270000\n",
      "  training_iteration: 827\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18179 s, 827 iter, 8270000 ts, 81.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-47-10\n",
      "  done: false\n",
      "  episode_len_mean: 75.12121212121212\n",
      "  episode_reward_max: 388.4598532706462\n",
      "  episode_reward_mean: 63.28824035783104\n",
      "  episode_reward_min: -166.7232322241926\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 105027\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.506\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 8280000\n",
      "    num_steps_trained: 8280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5414128303527832\n",
      "      kl: 0.022188326343894005\n",
      "      policy_loss: 0.0025636013597249985\n",
      "      total_loss: 54.88083267211914\n",
      "      vf_explained_var: 0.8902547955513\n",
      "      vf_loss: 54.87604522705078\n",
      "    sample_time_ms: 18126.725\n",
      "    update_time_ms: 5.877\n",
      "  iterations_since_restore: 828\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.64412017891552\n",
      "  time_since_restore: 18201.195294618607\n",
      "  time_this_iter_s: 21.448341369628906\n",
      "  time_total_s: 18201.195294618607\n",
      "  timestamp: 1553140030\n",
      "  timesteps_since_restore: 8280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8280000\n",
      "  training_iteration: 828\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18201 s, 828 iter, 8280000 ts, 63.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-47-31\n",
      "  done: false\n",
      "  episode_len_mean: 77.59375\n",
      "  episode_reward_max: 388.2478411927592\n",
      "  episode_reward_mean: 80.18472937243425\n",
      "  episode_reward_min: -168.8152699377203\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 105155\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.833\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 8290000\n",
      "    num_steps_trained: 8290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5237971544265747\n",
      "      kl: 0.022069916129112244\n",
      "      policy_loss: 0.0035015291068702936\n",
      "      total_loss: 49.677547454833984\n",
      "      vf_explained_var: 0.8949839472770691\n",
      "      vf_loss: 49.67183303833008\n",
      "    sample_time_ms: 18081.891\n",
      "    update_time_ms: 5.985\n",
      "  iterations_since_restore: 829\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.09236468621712\n",
      "  time_since_restore: 18222.840260982513\n",
      "  time_this_iter_s: 21.64496636390686\n",
      "  time_total_s: 18222.840260982513\n",
      "  timestamp: 1553140051\n",
      "  timesteps_since_restore: 8290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8290000\n",
      "  training_iteration: 829\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18222 s, 829 iter, 8290000 ts, 80.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-47-53\n",
      "  done: false\n",
      "  episode_len_mean: 72.7956204379562\n",
      "  episode_reward_max: 387.9047434904133\n",
      "  episode_reward_mean: 46.38402400904685\n",
      "  episode_reward_min: -166.8106732544565\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 105292\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.524\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 8300000\n",
      "    num_steps_trained: 8300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5690728425979614\n",
      "      kl: 0.020935669541358948\n",
      "      policy_loss: 0.0027888184413313866\n",
      "      total_loss: 47.265525817871094\n",
      "      vf_explained_var: 0.9117337465286255\n",
      "      vf_loss: 47.26062774658203\n",
      "    sample_time_ms: 18109.469\n",
      "    update_time_ms: 5.981\n",
      "  iterations_since_restore: 830\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 23.192012004523423\n",
      "  time_since_restore: 18244.902570962906\n",
      "  time_this_iter_s: 22.062309980392456\n",
      "  time_total_s: 18244.902570962906\n",
      "  timestamp: 1553140073\n",
      "  timesteps_since_restore: 8300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8300000\n",
      "  training_iteration: 830\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18244 s, 830 iter, 8300000 ts, 46.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-48-15\n",
      "  done: false\n",
      "  episode_len_mean: 76.46212121212122\n",
      "  episode_reward_max: 387.84893714025776\n",
      "  episode_reward_mean: 67.86432755722932\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 105424\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.579\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 8310000\n",
      "    num_steps_trained: 8310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5571595430374146\n",
      "      kl: 0.014006073586642742\n",
      "      policy_loss: 0.002740316791459918\n",
      "      total_loss: 48.18087387084961\n",
      "      vf_explained_var: 0.9023106098175049\n",
      "      vf_loss: 48.176727294921875\n",
      "    sample_time_ms: 18142.115\n",
      "    update_time_ms: 6.167\n",
      "  iterations_since_restore: 831\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.93216377861466\n",
      "  time_since_restore: 18266.80347800255\n",
      "  time_this_iter_s: 21.900907039642334\n",
      "  time_total_s: 18266.80347800255\n",
      "  timestamp: 1553140095\n",
      "  timesteps_since_restore: 8310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8310000\n",
      "  training_iteration: 831\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18266 s, 831 iter, 8310000 ts, 67.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-48-37\n",
      "  done: false\n",
      "  episode_len_mean: 78.1015625\n",
      "  episode_reward_max: 388.6754208405051\n",
      "  episode_reward_mean: 78.49289822688485\n",
      "  episode_reward_min: -164.67628842290878\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 105552\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.33\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 8320000\n",
      "    num_steps_trained: 8320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5452485680580139\n",
      "      kl: 0.01836167834699154\n",
      "      policy_loss: 0.002848637755960226\n",
      "      total_loss: 44.12939453125\n",
      "      vf_explained_var: 0.9053633213043213\n",
      "      vf_loss: 44.12470245361328\n",
      "    sample_time_ms: 18166.457\n",
      "    update_time_ms: 6.215\n",
      "  iterations_since_restore: 832\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.24644911344241\n",
      "  time_since_restore: 18288.940054416656\n",
      "  time_this_iter_s: 22.136576414108276\n",
      "  time_total_s: 18288.940054416656\n",
      "  timestamp: 1553140117\n",
      "  timesteps_since_restore: 8320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8320000\n",
      "  training_iteration: 832\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18288 s, 832 iter, 8320000 ts, 78.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-49-00\n",
      "  done: false\n",
      "  episode_len_mean: 81.72131147540983\n",
      "  episode_reward_max: 390.57647740323347\n",
      "  episode_reward_mean: 104.7217047170187\n",
      "  episode_reward_min: -166.75142063733577\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 105674\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.219\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 8330000\n",
      "    num_steps_trained: 8330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5323041081428528\n",
      "      kl: 0.023679841309785843\n",
      "      policy_loss: 0.003266417421400547\n",
      "      total_loss: 44.779380798339844\n",
      "      vf_explained_var: 0.8965402245521545\n",
      "      vf_loss: 44.773738861083984\n",
      "    sample_time_ms: 18247.375\n",
      "    update_time_ms: 6.265\n",
      "  iterations_since_restore: 833\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.360852358509334\n",
      "  time_since_restore: 18311.246889829636\n",
      "  time_this_iter_s: 22.306835412979126\n",
      "  time_total_s: 18311.246889829636\n",
      "  timestamp: 1553140140\n",
      "  timesteps_since_restore: 8330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8330000\n",
      "  training_iteration: 833\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18311 s, 833 iter, 8330000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-49-22\n",
      "  done: false\n",
      "  episode_len_mean: 75.06015037593986\n",
      "  episode_reward_max: 386.2539101774612\n",
      "  episode_reward_mean: 56.516199867083834\n",
      "  episode_reward_min: -166.75683915671348\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 105807\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.528\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 8340000\n",
      "    num_steps_trained: 8340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.562575101852417\n",
      "      kl: 0.013698041439056396\n",
      "      policy_loss: 0.001629972830414772\n",
      "      total_loss: 67.98847198486328\n",
      "      vf_explained_var: 0.8625067472457886\n",
      "      vf_loss: 67.98546600341797\n",
      "    sample_time_ms: 18289.659\n",
      "    update_time_ms: 6.183\n",
      "  iterations_since_restore: 834\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.258099933541917\n",
      "  time_since_restore: 18333.715065956116\n",
      "  time_this_iter_s: 22.468176126480103\n",
      "  time_total_s: 18333.715065956116\n",
      "  timestamp: 1553140162\n",
      "  timesteps_since_restore: 8340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8340000\n",
      "  training_iteration: 834\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18333 s, 834 iter, 8340000 ts, 56.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-49-45\n",
      "  done: false\n",
      "  episode_len_mean: 75.16541353383458\n",
      "  episode_reward_max: 389.41596330802474\n",
      "  episode_reward_mean: 63.98627324465583\n",
      "  episode_reward_min: -166.73535175236702\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 105940\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.851\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 8350000\n",
      "    num_steps_trained: 8350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5666993260383606\n",
      "      kl: 0.01678658463060856\n",
      "      policy_loss: 0.003200395032763481\n",
      "      total_loss: 49.33465576171875\n",
      "      vf_explained_var: 0.899974524974823\n",
      "      vf_loss: 49.32976531982422\n",
      "    sample_time_ms: 18388.025\n",
      "    update_time_ms: 6.347\n",
      "  iterations_since_restore: 835\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.993136622327906\n",
      "  time_since_restore: 18356.05831503868\n",
      "  time_this_iter_s: 22.343249082565308\n",
      "  time_total_s: 18356.05831503868\n",
      "  timestamp: 1553140185\n",
      "  timesteps_since_restore: 8350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8350000\n",
      "  training_iteration: 835\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18356 s, 835 iter, 8350000 ts, 64 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-50-07\n",
      "  done: false\n",
      "  episode_len_mean: 72.09352517985612\n",
      "  episode_reward_max: 392.09154028889304\n",
      "  episode_reward_mean: 34.77896895590776\n",
      "  episode_reward_min: -166.72282554503917\n",
      "  episodes_this_iter: 139\n",
      "  episodes_total: 106079\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3679.951\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 8360000\n",
      "    num_steps_trained: 8360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5929059982299805\n",
      "      kl: 0.01865852065384388\n",
      "      policy_loss: 0.001974208513274789\n",
      "      total_loss: 68.15816497802734\n",
      "      vf_explained_var: 0.8764796257019043\n",
      "      vf_loss: 68.1543197631836\n",
      "    sample_time_ms: 18419.307\n",
      "    update_time_ms: 6.293\n",
      "  iterations_since_restore: 836\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 17.38948447795387\n",
      "  time_since_restore: 18378.368594408035\n",
      "  time_this_iter_s: 22.310279369354248\n",
      "  time_total_s: 18378.368594408035\n",
      "  timestamp: 1553140207\n",
      "  timesteps_since_restore: 8360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8360000\n",
      "  training_iteration: 836\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18378 s, 836 iter, 8360000 ts, 34.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-50-29\n",
      "  done: false\n",
      "  episode_len_mean: 82.56557377049181\n",
      "  episode_reward_max: 387.1092446588612\n",
      "  episode_reward_mean: 112.09575227424517\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 106201\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3679.271\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 8370000\n",
      "    num_steps_trained: 8370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5475593209266663\n",
      "      kl: 0.013491720892488956\n",
      "      policy_loss: 0.0014162888983264565\n",
      "      total_loss: 40.64777755737305\n",
      "      vf_explained_var: 0.9019020199775696\n",
      "      vf_loss: 40.6450080871582\n",
      "    sample_time_ms: 18391.434\n",
      "    update_time_ms: 6.284\n",
      "  iterations_since_restore: 837\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.047876137122586\n",
      "  time_since_restore: 18400.71657848358\n",
      "  time_this_iter_s: 22.347984075546265\n",
      "  time_total_s: 18400.71657848358\n",
      "  timestamp: 1553140229\n",
      "  timesteps_since_restore: 8370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8370000\n",
      "  training_iteration: 837\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18400 s, 837 iter, 8370000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-50-51\n",
      "  done: false\n",
      "  episode_len_mean: 84.37606837606837\n",
      "  episode_reward_max: 386.50919868409244\n",
      "  episode_reward_mean: 129.18948232129407\n",
      "  episode_reward_min: -166.81283326646326\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 106318\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3677.9\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 8380000\n",
      "    num_steps_trained: 8380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5186499357223511\n",
      "      kl: 0.017916239798069\n",
      "      policy_loss: 0.002367578912526369\n",
      "      total_loss: 37.89463806152344\n",
      "      vf_explained_var: 0.8988476991653442\n",
      "      vf_loss: 37.89046859741211\n",
      "    sample_time_ms: 18420.389\n",
      "    update_time_ms: 5.693\n",
      "  iterations_since_restore: 838\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.59474116064705\n",
      "  time_since_restore: 18422.427051067352\n",
      "  time_this_iter_s: 21.710472583770752\n",
      "  time_total_s: 18422.427051067352\n",
      "  timestamp: 1553140251\n",
      "  timesteps_since_restore: 8380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8380000\n",
      "  training_iteration: 838\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18422 s, 838 iter, 8380000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-51-13\n",
      "  done: false\n",
      "  episode_len_mean: 76.24812030075188\n",
      "  episode_reward_max: 390.69855459592\n",
      "  episode_reward_mean: 67.73094761807215\n",
      "  episode_reward_min: -166.8691016995573\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 106451\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.828\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 8390000\n",
      "    num_steps_trained: 8390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5679063200950623\n",
      "      kl: 0.024887997657060623\n",
      "      policy_loss: 0.0059331245720386505\n",
      "      total_loss: 58.93928527832031\n",
      "      vf_explained_var: 0.877905011177063\n",
      "      vf_loss: 58.930850982666016\n",
      "    sample_time_ms: 18433.242\n",
      "    update_time_ms: 5.554\n",
      "  iterations_since_restore: 839\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.86547380903606\n",
      "  time_since_restore: 18444.338514328003\n",
      "  time_this_iter_s: 21.911463260650635\n",
      "  time_total_s: 18444.338514328003\n",
      "  timestamp: 1553140273\n",
      "  timesteps_since_restore: 8390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8390000\n",
      "  training_iteration: 839\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18444 s, 839 iter, 8390000 ts, 67.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-51-34\n",
      "  done: false\n",
      "  episode_len_mean: 82.3305785123967\n",
      "  episode_reward_max: 388.4813209157055\n",
      "  episode_reward_mean: 110.07836925455165\n",
      "  episode_reward_min: -161.52278687610865\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 106572\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.293\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 8400000\n",
      "    num_steps_trained: 8400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5291466116905212\n",
      "      kl: 0.01971513219177723\n",
      "      policy_loss: 0.003326599719002843\n",
      "      total_loss: 49.61166000366211\n",
      "      vf_explained_var: 0.8769322037696838\n",
      "      vf_loss: 49.60634994506836\n",
      "    sample_time_ms: 18316.682\n",
      "    update_time_ms: 5.547\n",
      "  iterations_since_restore: 840\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.03918462727581\n",
      "  time_since_restore: 18465.245492219925\n",
      "  time_this_iter_s: 20.906977891921997\n",
      "  time_total_s: 18465.245492219925\n",
      "  timestamp: 1553140294\n",
      "  timesteps_since_restore: 8400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8400000\n",
      "  training_iteration: 840\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18465 s, 840 iter, 8400000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-51-56\n",
      "  done: false\n",
      "  episode_len_mean: 80.0\n",
      "  episode_reward_max: 386.4534990863939\n",
      "  episode_reward_mean: 99.06547396162031\n",
      "  episode_reward_min: -166.71145448168755\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 106696\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.654\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 8410000\n",
      "    num_steps_trained: 8410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5422335863113403\n",
      "      kl: 0.016159016638994217\n",
      "      policy_loss: 0.004371696151793003\n",
      "      total_loss: 51.822715759277344\n",
      "      vf_explained_var: 0.8804937601089478\n",
      "      vf_loss: 51.81671905517578\n",
      "    sample_time_ms: 18278.753\n",
      "    update_time_ms: 5.362\n",
      "  iterations_since_restore: 841\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.53273698081017\n",
      "  time_since_restore: 18486.77145600319\n",
      "  time_this_iter_s: 21.52596378326416\n",
      "  time_total_s: 18486.77145600319\n",
      "  timestamp: 1553140316\n",
      "  timesteps_since_restore: 8410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8410000\n",
      "  training_iteration: 841\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18486 s, 841 iter, 8410000 ts, 99.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-52-18\n",
      "  done: false\n",
      "  episode_len_mean: 79.33858267716535\n",
      "  episode_reward_max: 386.6956358237893\n",
      "  episode_reward_mean: 93.3044606529171\n",
      "  episode_reward_min: -166.75090157517434\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 106823\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.404\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 8420000\n",
      "    num_steps_trained: 8420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5401593446731567\n",
      "      kl: 0.019894639030098915\n",
      "      policy_loss: 0.0025630255695432425\n",
      "      total_loss: 46.17878723144531\n",
      "      vf_explained_var: 0.8973814845085144\n",
      "      vf_loss: 46.17422103881836\n",
      "    sample_time_ms: 18268.657\n",
      "    update_time_ms: 5.401\n",
      "  iterations_since_restore: 842\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.65223032645854\n",
      "  time_since_restore: 18508.786340236664\n",
      "  time_this_iter_s: 22.01488423347473\n",
      "  time_total_s: 18508.786340236664\n",
      "  timestamp: 1553140338\n",
      "  timesteps_since_restore: 8420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8420000\n",
      "  training_iteration: 842\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18508 s, 842 iter, 8420000 ts, 93.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-52-39\n",
      "  done: false\n",
      "  episode_len_mean: 80.464\n",
      "  episode_reward_max: 390.3029156913493\n",
      "  episode_reward_mean: 96.1974845678664\n",
      "  episode_reward_min: -164.71648577805996\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 106948\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.396\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 8430000\n",
      "    num_steps_trained: 8430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5571652054786682\n",
      "      kl: 0.016730310395359993\n",
      "      policy_loss: 0.004948308691382408\n",
      "      total_loss: 54.11185836791992\n",
      "      vf_explained_var: 0.8740138411521912\n",
      "      vf_loss: 54.10523223876953\n",
      "    sample_time_ms: 18209.096\n",
      "    update_time_ms: 6.113\n",
      "  iterations_since_restore: 843\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.09874228393321\n",
      "  time_since_restore: 18530.518360853195\n",
      "  time_this_iter_s: 21.732020616531372\n",
      "  time_total_s: 18530.518360853195\n",
      "  timestamp: 1553140359\n",
      "  timesteps_since_restore: 8430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8430000\n",
      "  training_iteration: 843\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18530 s, 843 iter, 8430000 ts, 96.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-53-01\n",
      "  done: false\n",
      "  episode_len_mean: 79.776\n",
      "  episode_reward_max: 386.1178348149473\n",
      "  episode_reward_mean: 99.27730691519564\n",
      "  episode_reward_min: -166.8382142799759\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 107073\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.346\n",
      "    load_time_ms: 1.618\n",
      "    num_steps_sampled: 8440000\n",
      "    num_steps_trained: 8440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5506431460380554\n",
      "      kl: 0.017819857224822044\n",
      "      policy_loss: 0.005372059065848589\n",
      "      total_loss: 44.3000602722168\n",
      "      vf_explained_var: 0.8981289863586426\n",
      "      vf_loss: 44.29290008544922\n",
      "    sample_time_ms: 18127.874\n",
      "    update_time_ms: 6.303\n",
      "  iterations_since_restore: 844\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.638653457597826\n",
      "  time_since_restore: 18552.176397800446\n",
      "  time_this_iter_s: 21.658036947250366\n",
      "  time_total_s: 18552.176397800446\n",
      "  timestamp: 1553140381\n",
      "  timesteps_since_restore: 8440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8440000\n",
      "  training_iteration: 844\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18552 s, 844 iter, 8440000 ts, 99.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-53-24\n",
      "  done: false\n",
      "  episode_len_mean: 74.52985074626865\n",
      "  episode_reward_max: 388.60577839528156\n",
      "  episode_reward_mean: 60.651430718400945\n",
      "  episode_reward_min: -168.73196736129762\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 107207\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.809\n",
      "    load_time_ms: 1.613\n",
      "    num_steps_sampled: 8450000\n",
      "    num_steps_trained: 8450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5764126777648926\n",
      "      kl: 0.018879098817706108\n",
      "      policy_loss: 0.0031981086358428\n",
      "      total_loss: 61.68549728393555\n",
      "      vf_explained_var: 0.8763102889060974\n",
      "      vf_loss: 61.68041229248047\n",
      "    sample_time_ms: 18131.737\n",
      "    update_time_ms: 6.046\n",
      "  iterations_since_restore: 845\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.325715359200473\n",
      "  time_since_restore: 18574.5484457016\n",
      "  time_this_iter_s: 22.372047901153564\n",
      "  time_total_s: 18574.5484457016\n",
      "  timestamp: 1553140404\n",
      "  timesteps_since_restore: 8450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8450000\n",
      "  training_iteration: 845\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18574 s, 845 iter, 8450000 ts, 60.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-53-45\n",
      "  done: false\n",
      "  episode_len_mean: 84.8135593220339\n",
      "  episode_reward_max: 392.1474155876082\n",
      "  episode_reward_mean: 132.58066560545888\n",
      "  episode_reward_min: -164.694423263278\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 107325\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.606\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 8460000\n",
      "    num_steps_trained: 8460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5515072345733643\n",
      "      kl: 0.01840498484671116\n",
      "      policy_loss: 0.002264622366055846\n",
      "      total_loss: 45.18376159667969\n",
      "      vf_explained_var: 0.8836022615432739\n",
      "      vf_loss: 45.179649353027344\n",
      "    sample_time_ms: 18031.956\n",
      "    update_time_ms: 6.34\n",
      "  iterations_since_restore: 846\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.29033280272942\n",
      "  time_since_restore: 18595.830793857574\n",
      "  time_this_iter_s: 21.282348155975342\n",
      "  time_total_s: 18595.830793857574\n",
      "  timestamp: 1553140425\n",
      "  timesteps_since_restore: 8460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8460000\n",
      "  training_iteration: 846\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18595 s, 846 iter, 8460000 ts, 133 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-54-07\n",
      "  done: false\n",
      "  episode_len_mean: 74.85074626865672\n",
      "  episode_reward_max: 382.31774351187613\n",
      "  episode_reward_mean: 60.77486244646211\n",
      "  episode_reward_min: -168.80063347753526\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 107459\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.87\n",
      "    load_time_ms: 1.61\n",
      "    num_steps_sampled: 8470000\n",
      "    num_steps_trained: 8470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5617529153823853\n",
      "      kl: 0.01724107190966606\n",
      "      policy_loss: 0.002712282817810774\n",
      "      total_loss: 53.55926513671875\n",
      "      vf_explained_var: 0.8919251561164856\n",
      "      vf_loss: 53.55481719970703\n",
      "    sample_time_ms: 17980.184\n",
      "    update_time_ms: 6.391\n",
      "  iterations_since_restore: 847\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.387431223231058\n",
      "  time_since_restore: 18617.667320728302\n",
      "  time_this_iter_s: 21.83652687072754\n",
      "  time_total_s: 18617.667320728302\n",
      "  timestamp: 1553140447\n",
      "  timesteps_since_restore: 8470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8470000\n",
      "  training_iteration: 847\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18617 s, 847 iter, 8470000 ts, 60.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-54-29\n",
      "  done: false\n",
      "  episode_len_mean: 75.80152671755725\n",
      "  episode_reward_max: 388.92540271922724\n",
      "  episode_reward_mean: 68.07912410862367\n",
      "  episode_reward_min: -168.74251726027967\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 107590\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.002\n",
      "    load_time_ms: 1.613\n",
      "    num_steps_sampled: 8480000\n",
      "    num_steps_trained: 8480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5895736813545227\n",
      "      kl: 0.023918844759464264\n",
      "      policy_loss: 0.006275109946727753\n",
      "      total_loss: 53.628543853759766\n",
      "      vf_explained_var: 0.8876533508300781\n",
      "      vf_loss: 53.61986541748047\n",
      "    sample_time_ms: 17999.612\n",
      "    update_time_ms: 6.38\n",
      "  iterations_since_restore: 848\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.039562054311844\n",
      "  time_since_restore: 18639.555901288986\n",
      "  time_this_iter_s: 21.888580560684204\n",
      "  time_total_s: 18639.555901288986\n",
      "  timestamp: 1553140469\n",
      "  timesteps_since_restore: 8480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8480000\n",
      "  training_iteration: 848\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18639 s, 848 iter, 8480000 ts, 68.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-54-51\n",
      "  done: false\n",
      "  episode_len_mean: 81.71311475409836\n",
      "  episode_reward_max: 388.056098631601\n",
      "  episode_reward_mean: 112.01169188569037\n",
      "  episode_reward_min: -166.77584485241414\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 107712\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3673.306\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 8490000\n",
      "    num_steps_trained: 8490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5459953546524048\n",
      "      kl: 0.021835103631019592\n",
      "      policy_loss: 0.006907198578119278\n",
      "      total_loss: 51.41930389404297\n",
      "      vf_explained_var: 0.8743603229522705\n",
      "      vf_loss: 51.41020584106445\n",
      "    sample_time_ms: 18005.831\n",
      "    update_time_ms: 6.221\n",
      "  iterations_since_restore: 849\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.00584594284515\n",
      "  time_since_restore: 18661.40354204178\n",
      "  time_this_iter_s: 21.84764075279236\n",
      "  time_total_s: 18661.40354204178\n",
      "  timestamp: 1553140491\n",
      "  timesteps_since_restore: 8490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8490000\n",
      "  training_iteration: 849\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18661 s, 849 iter, 8490000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-55-13\n",
      "  done: false\n",
      "  episode_len_mean: 77.08527131782945\n",
      "  episode_reward_max: 388.5175880601936\n",
      "  episode_reward_mean: 82.92139963117356\n",
      "  episode_reward_min: -166.70499709483624\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 107841\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.887\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 8500000\n",
      "    num_steps_trained: 8500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5686918497085571\n",
      "      kl: 0.022150930017232895\n",
      "      policy_loss: 0.004353321623057127\n",
      "      total_loss: 43.65622329711914\n",
      "      vf_explained_var: 0.9060813784599304\n",
      "      vf_loss: 43.64965057373047\n",
      "    sample_time_ms: 18104.575\n",
      "    update_time_ms: 6.135\n",
      "  iterations_since_restore: 850\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.46069981558678\n",
      "  time_since_restore: 18683.404226064682\n",
      "  time_this_iter_s: 22.000684022903442\n",
      "  time_total_s: 18683.404226064682\n",
      "  timestamp: 1553140513\n",
      "  timesteps_since_restore: 8500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8500000\n",
      "  training_iteration: 850\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18683 s, 850 iter, 8500000 ts, 82.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-55-34\n",
      "  done: false\n",
      "  episode_len_mean: 77.82307692307693\n",
      "  episode_reward_max: 388.367100142618\n",
      "  episode_reward_mean: 82.82764349607264\n",
      "  episode_reward_min: -168.7761800144577\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 107971\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.807\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 8510000\n",
      "    num_steps_trained: 8510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5907115936279297\n",
      "      kl: 0.021106084808707237\n",
      "      policy_loss: 0.004736836068332195\n",
      "      total_loss: 51.7746467590332\n",
      "      vf_explained_var: 0.8914284110069275\n",
      "      vf_loss: 51.76778793334961\n",
      "    sample_time_ms: 18081.907\n",
      "    update_time_ms: 6.301\n",
      "  iterations_since_restore: 851\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.41382174803632\n",
      "  time_since_restore: 18704.712090730667\n",
      "  time_this_iter_s: 21.307864665985107\n",
      "  time_total_s: 18704.712090730667\n",
      "  timestamp: 1553140534\n",
      "  timesteps_since_restore: 8510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8510000\n",
      "  training_iteration: 851\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18704 s, 851 iter, 8510000 ts, 82.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-55-56\n",
      "  done: false\n",
      "  episode_len_mean: 69.24137931034483\n",
      "  episode_reward_max: 387.34697576927846\n",
      "  episode_reward_mean: 23.557696466067895\n",
      "  episode_reward_min: -166.76782076844216\n",
      "  episodes_this_iter: 145\n",
      "  episodes_total: 108116\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.584\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 8520000\n",
      "    num_steps_trained: 8520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5908597707748413\n",
      "      kl: 0.020106865093111992\n",
      "      policy_loss: 0.0026890754234045744\n",
      "      total_loss: 43.910221099853516\n",
      "      vf_explained_var: 0.9230673313140869\n",
      "      vf_loss: 43.905517578125\n",
      "    sample_time_ms: 18085.43\n",
      "    update_time_ms: 6.269\n",
      "  iterations_since_restore: 852\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 11.778848233033944\n",
      "  time_since_restore: 18726.769093751907\n",
      "  time_this_iter_s: 22.057003021240234\n",
      "  time_total_s: 18726.769093751907\n",
      "  timestamp: 1553140556\n",
      "  timesteps_since_restore: 8520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8520000\n",
      "  training_iteration: 852\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18726 s, 852 iter, 8520000 ts, 23.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-56-19\n",
      "  done: false\n",
      "  episode_len_mean: 79.31746031746032\n",
      "  episode_reward_max: 387.3450968730613\n",
      "  episode_reward_mean: 90.44830868372468\n",
      "  episode_reward_min: -168.70343219563006\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 108242\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.681\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 8530000\n",
      "    num_steps_trained: 8530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5442313551902771\n",
      "      kl: 0.01956385001540184\n",
      "      policy_loss: 0.004154699854552746\n",
      "      total_loss: 41.80030059814453\n",
      "      vf_explained_var: 0.9083103537559509\n",
      "      vf_loss: 41.7941780090332\n",
      "    sample_time_ms: 18161.974\n",
      "    update_time_ms: 5.556\n",
      "  iterations_since_restore: 853\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.224154341862345\n",
      "  time_since_restore: 18749.235788345337\n",
      "  time_this_iter_s: 22.466694593429565\n",
      "  time_total_s: 18749.235788345337\n",
      "  timestamp: 1553140579\n",
      "  timesteps_since_restore: 8530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8530000\n",
      "  training_iteration: 853\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18749 s, 853 iter, 8530000 ts, 90.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-56-40\n",
      "  done: false\n",
      "  episode_len_mean: 80.82113821138212\n",
      "  episode_reward_max: 388.87385754793956\n",
      "  episode_reward_mean: 104.53491548528484\n",
      "  episode_reward_min: -165.24790804060936\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 108365\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.743\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 8540000\n",
      "    num_steps_trained: 8540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5710362195968628\n",
      "      kl: 0.025538142770528793\n",
      "      policy_loss: 0.0032878119964152575\n",
      "      total_loss: 46.92485809326172\n",
      "      vf_explained_var: 0.8897586464881897\n",
      "      vf_loss: 46.919002532958984\n",
      "    sample_time_ms: 18173.504\n",
      "    update_time_ms: 5.945\n",
      "  iterations_since_restore: 854\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.26745774264242\n",
      "  time_since_restore: 18771.06375837326\n",
      "  time_this_iter_s: 21.827970027923584\n",
      "  time_total_s: 18771.06375837326\n",
      "  timestamp: 1553140600\n",
      "  timesteps_since_restore: 8540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8540000\n",
      "  training_iteration: 854\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18771 s, 854 iter, 8540000 ts, 105 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-57-02\n",
      "  done: false\n",
      "  episode_len_mean: 74.34328358208955\n",
      "  episode_reward_max: 387.94809966231094\n",
      "  episode_reward_mean: 59.17067947322344\n",
      "  episode_reward_min: -166.70655927380562\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 108499\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.535\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 8550000\n",
      "    num_steps_trained: 8550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.618185818195343\n",
      "      kl: 0.022863978520035744\n",
      "      policy_loss: 0.0026535792276263237\n",
      "      total_loss: 53.25832748413086\n",
      "      vf_explained_var: 0.8937581181526184\n",
      "      vf_loss: 53.253379821777344\n",
      "    sample_time_ms: 18104.883\n",
      "    update_time_ms: 5.998\n",
      "  iterations_since_restore: 855\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 29.585339736611715\n",
      "  time_since_restore: 18792.77650618553\n",
      "  time_this_iter_s: 21.712747812271118\n",
      "  time_total_s: 18792.77650618553\n",
      "  timestamp: 1553140622\n",
      "  timesteps_since_restore: 8550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8550000\n",
      "  training_iteration: 855\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18792 s, 855 iter, 8550000 ts, 59.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-57-24\n",
      "  done: false\n",
      "  episode_len_mean: 76.94656488549619\n",
      "  episode_reward_max: 392.45723810910454\n",
      "  episode_reward_mean: 77.05295869709374\n",
      "  episode_reward_min: -164.7652938682699\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 108630\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.581\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 8560000\n",
      "    num_steps_trained: 8560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6153541207313538\n",
      "      kl: 0.020793285220861435\n",
      "      policy_loss: 0.0021896283142268658\n",
      "      total_loss: 49.546932220458984\n",
      "      vf_explained_var: 0.8979967832565308\n",
      "      vf_loss: 49.54264831542969\n",
      "    sample_time_ms: 18175.734\n",
      "    update_time_ms: 5.638\n",
      "  iterations_since_restore: 856\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.526479348546864\n",
      "  time_since_restore: 18814.805678129196\n",
      "  time_this_iter_s: 22.02917194366455\n",
      "  time_total_s: 18814.805678129196\n",
      "  timestamp: 1553140644\n",
      "  timesteps_since_restore: 8560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8560000\n",
      "  training_iteration: 856\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18814 s, 856 iter, 8560000 ts, 77.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-57-46\n",
      "  done: false\n",
      "  episode_len_mean: 80.19354838709677\n",
      "  episode_reward_max: 391.2091515621302\n",
      "  episode_reward_mean: 101.55122174395278\n",
      "  episode_reward_min: -164.9653383319044\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 108754\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.846\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 8570000\n",
      "    num_steps_trained: 8570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5821883678436279\n",
      "      kl: 0.022603945806622505\n",
      "      policy_loss: 0.00915915984660387\n",
      "      total_loss: 40.98744201660156\n",
      "      vf_explained_var: 0.9034329652786255\n",
      "      vf_loss: 40.97601318359375\n",
      "    sample_time_ms: 18191.626\n",
      "    update_time_ms: 5.634\n",
      "  iterations_since_restore: 857\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.77561087197638\n",
      "  time_since_restore: 18836.760810136795\n",
      "  time_this_iter_s: 21.955132007598877\n",
      "  time_total_s: 18836.760810136795\n",
      "  timestamp: 1553140666\n",
      "  timesteps_since_restore: 8570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8570000\n",
      "  training_iteration: 857\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18836 s, 857 iter, 8570000 ts, 102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-58-09\n",
      "  done: false\n",
      "  episode_len_mean: 74.07407407407408\n",
      "  episode_reward_max: 386.66601717055227\n",
      "  episode_reward_mean: 53.49666752099224\n",
      "  episode_reward_min: -166.76425022527218\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 108889\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.246\n",
      "    load_time_ms: 1.348\n",
      "    num_steps_sampled: 8580000\n",
      "    num_steps_trained: 8580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5941214561462402\n",
      "      kl: 0.016383294016122818\n",
      "      policy_loss: 0.004518008790910244\n",
      "      total_loss: 50.82802200317383\n",
      "      vf_explained_var: 0.8992117047309875\n",
      "      vf_loss: 50.82186508178711\n",
      "    sample_time_ms: 18219.966\n",
      "    update_time_ms: 5.703\n",
      "  iterations_since_restore: 858\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.74833376049612\n",
      "  time_since_restore: 18858.958268642426\n",
      "  time_this_iter_s: 22.197458505630493\n",
      "  time_total_s: 18858.958268642426\n",
      "  timestamp: 1553140689\n",
      "  timesteps_since_restore: 8580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8580000\n",
      "  training_iteration: 858\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18858 s, 858 iter, 8580000 ts, 53.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 78.91338582677166\n",
      "  episode_reward_max: 391.50726714218314\n",
      "  episode_reward_mean: 91.60153117931867\n",
      "  episode_reward_min: -164.80232609423638\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 109016\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.343\n",
      "    load_time_ms: 1.412\n",
      "    num_steps_sampled: 8590000\n",
      "    num_steps_trained: 8590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5825616717338562\n",
      "      kl: 0.026105757802724838\n",
      "      policy_loss: 0.0073743960820138454\n",
      "      total_loss: 50.105770111083984\n",
      "      vf_explained_var: 0.8887485861778259\n",
      "      vf_loss: 50.09577941894531\n",
      "    sample_time_ms: 18253.399\n",
      "    update_time_ms: 5.649\n",
      "  iterations_since_restore: 859\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.80076558965933\n",
      "  time_since_restore: 18881.130356550217\n",
      "  time_this_iter_s: 22.172087907791138\n",
      "  time_total_s: 18881.130356550217\n",
      "  timestamp: 1553140711\n",
      "  timesteps_since_restore: 8590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8590000\n",
      "  training_iteration: 859\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18881 s, 859 iter, 8590000 ts, 91.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 72.26811594202898\n",
      "  episode_reward_max: 391.73218601710363\n",
      "  episode_reward_mean: 42.63970556968337\n",
      "  episode_reward_min: -168.78116568180562\n",
      "  episodes_this_iter: 138\n",
      "  episodes_total: 109154\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.983\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 8600000\n",
      "    num_steps_trained: 8600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6187829375267029\n",
      "      kl: 0.018850918859243393\n",
      "      policy_loss: 0.0030700594652444124\n",
      "      total_loss: 51.017677307128906\n",
      "      vf_explained_var: 0.9043639898300171\n",
      "      vf_loss: 51.012718200683594\n",
      "    sample_time_ms: 18198.522\n",
      "    update_time_ms: 5.543\n",
      "  iterations_since_restore: 860\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 21.31985278484169\n",
      "  time_since_restore: 18902.46781873703\n",
      "  time_this_iter_s: 21.337462186813354\n",
      "  time_total_s: 18902.46781873703\n",
      "  timestamp: 1553140732\n",
      "  timesteps_since_restore: 8600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8600000\n",
      "  training_iteration: 860\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18902 s, 860 iter, 8600000 ts, 42.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-59-14\n",
      "  done: false\n",
      "  episode_len_mean: 77.78125\n",
      "  episode_reward_max: 387.2290443951544\n",
      "  episode_reward_mean: 82.50581851187602\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 109282\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.121\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 8610000\n",
      "    num_steps_trained: 8610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5825195908546448\n",
      "      kl: 0.023935748264193535\n",
      "      policy_loss: 0.004952972289174795\n",
      "      total_loss: 35.859073638916016\n",
      "      vf_explained_var: 0.9193688631057739\n",
      "      vf_loss: 35.85171890258789\n",
      "    sample_time_ms: 18265.589\n",
      "    update_time_ms: 5.709\n",
      "  iterations_since_restore: 861\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.252909255938\n",
      "  time_since_restore: 18924.482070207596\n",
      "  time_this_iter_s: 22.014251470565796\n",
      "  time_total_s: 18924.482070207596\n",
      "  timestamp: 1553140754\n",
      "  timesteps_since_restore: 8610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8610000\n",
      "  training_iteration: 861\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18924 s, 861 iter, 8610000 ts, 82.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-59-35\n",
      "  done: false\n",
      "  episode_len_mean: 75.93939393939394\n",
      "  episode_reward_max: 387.489183423085\n",
      "  episode_reward_mean: 72.37877435056352\n",
      "  episode_reward_min: -168.6938736366892\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 109414\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.886\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 8620000\n",
      "    num_steps_trained: 8620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5976275205612183\n",
      "      kl: 0.020700527355074883\n",
      "      policy_loss: 0.005552188493311405\n",
      "      total_loss: 48.46849822998047\n",
      "      vf_explained_var: 0.9006475806236267\n",
      "      vf_loss: 48.46086120605469\n",
      "    sample_time_ms: 18178.605\n",
      "    update_time_ms: 5.722\n",
      "  iterations_since_restore: 862\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.189387175281766\n",
      "  time_since_restore: 18945.687680721283\n",
      "  time_this_iter_s: 21.205610513687134\n",
      "  time_total_s: 18945.687680721283\n",
      "  timestamp: 1553140775\n",
      "  timesteps_since_restore: 8620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8620000\n",
      "  training_iteration: 862\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18945 s, 862 iter, 8620000 ts, 72.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_04-59-57\n",
      "  done: false\n",
      "  episode_len_mean: 83.50413223140495\n",
      "  episode_reward_max: 388.6106659749964\n",
      "  episode_reward_mean: 126.56690106682026\n",
      "  episode_reward_min: -166.81338081130028\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 109535\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.623\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 8630000\n",
      "    num_steps_trained: 8630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5342849493026733\n",
      "      kl: 0.020591378211975098\n",
      "      policy_loss: 0.0039997040294110775\n",
      "      total_loss: 42.66141891479492\n",
      "      vf_explained_var: 0.8912996053695679\n",
      "      vf_loss: 42.65535354614258\n",
      "    sample_time_ms: 18135.47\n",
      "    update_time_ms: 5.58\n",
      "  iterations_since_restore: 863\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.28345053341012\n",
      "  time_since_restore: 18967.678044319153\n",
      "  time_this_iter_s: 21.990363597869873\n",
      "  time_total_s: 18967.678044319153\n",
      "  timestamp: 1553140797\n",
      "  timesteps_since_restore: 8630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8630000\n",
      "  training_iteration: 863\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18967 s, 863 iter, 8630000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-00-20\n",
      "  done: false\n",
      "  episode_len_mean: 78.5952380952381\n",
      "  episode_reward_max: 388.9618336549012\n",
      "  episode_reward_mean: 85.17326267935933\n",
      "  episode_reward_min: -159.36679201820135\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 109661\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3678.492\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 8640000\n",
      "    num_steps_trained: 8640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5930754542350769\n",
      "      kl: 0.01590079627931118\n",
      "      policy_loss: 0.0024352450855076313\n",
      "      total_loss: 47.301124572753906\n",
      "      vf_explained_var: 0.8944354057312012\n",
      "      vf_loss: 47.29709243774414\n",
      "    sample_time_ms: 18184.373\n",
      "    update_time_ms: 5.019\n",
      "  iterations_since_restore: 864\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.58663133967965\n",
      "  time_since_restore: 18989.93934392929\n",
      "  time_this_iter_s: 22.26129961013794\n",
      "  time_total_s: 18989.93934392929\n",
      "  timestamp: 1553140820\n",
      "  timesteps_since_restore: 8640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8640000\n",
      "  training_iteration: 864\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 18989 s, 864 iter, 8640000 ts, 85.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-00-41\n",
      "  done: false\n",
      "  episode_len_mean: 80.544\n",
      "  episode_reward_max: 388.57935940897545\n",
      "  episode_reward_mean: 99.87060646665822\n",
      "  episode_reward_min: -164.72749520870684\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 109786\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.189\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 8650000\n",
      "    num_steps_trained: 8650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5740380883216858\n",
      "      kl: 0.014008323661983013\n",
      "      policy_loss: 0.0024072001688182354\n",
      "      total_loss: 49.193241119384766\n",
      "      vf_explained_var: 0.8886523842811584\n",
      "      vf_loss: 49.18942642211914\n",
      "    sample_time_ms: 18144.074\n",
      "    update_time_ms: 5.753\n",
      "  iterations_since_restore: 865\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.93530323332909\n",
      "  time_since_restore: 19011.33846282959\n",
      "  time_this_iter_s: 21.399118900299072\n",
      "  time_total_s: 19011.33846282959\n",
      "  timestamp: 1553140841\n",
      "  timesteps_since_restore: 8650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8650000\n",
      "  training_iteration: 865\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19011 s, 865 iter, 8650000 ts, 99.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-01-04\n",
      "  done: false\n",
      "  episode_len_mean: 73.12408759124088\n",
      "  episode_reward_max: 392.02052477450013\n",
      "  episode_reward_mean: 44.7646080976401\n",
      "  episode_reward_min: -166.87570546897888\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 109923\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.106\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 8660000\n",
      "    num_steps_trained: 8660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6001242399215698\n",
      "      kl: 0.02555657923221588\n",
      "      policy_loss: 0.006259356625378132\n",
      "      total_loss: 54.21207809448242\n",
      "      vf_explained_var: 0.8960466384887695\n",
      "      vf_loss: 54.20325469970703\n",
      "    sample_time_ms: 18192.257\n",
      "    update_time_ms: 5.732\n",
      "  iterations_since_restore: 866\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.38230404882005\n",
      "  time_since_restore: 19033.87581014633\n",
      "  time_this_iter_s: 22.537347316741943\n",
      "  time_total_s: 19033.87581014633\n",
      "  timestamp: 1553140864\n",
      "  timesteps_since_restore: 8660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8660000\n",
      "  training_iteration: 866\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19033 s, 866 iter, 8660000 ts, 44.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-01-26\n",
      "  done: false\n",
      "  episode_len_mean: 80.016\n",
      "  episode_reward_max: 389.01084003452326\n",
      "  episode_reward_mean: 96.68160258645898\n",
      "  episode_reward_min: -166.7162318757439\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 110048\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.869\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 8670000\n",
      "    num_steps_trained: 8670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5834851264953613\n",
      "      kl: 0.012805352918803692\n",
      "      policy_loss: 0.003573562018573284\n",
      "      total_loss: 52.03487014770508\n",
      "      vf_explained_var: 0.8782041668891907\n",
      "      vf_loss: 52.03001022338867\n",
      "    sample_time_ms: 18178.342\n",
      "    update_time_ms: 5.693\n",
      "  iterations_since_restore: 867\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.34080129322949\n",
      "  time_since_restore: 19055.72086763382\n",
      "  time_this_iter_s: 21.845057487487793\n",
      "  time_total_s: 19055.72086763382\n",
      "  timestamp: 1553140886\n",
      "  timesteps_since_restore: 8670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8670000\n",
      "  training_iteration: 867\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19055 s, 867 iter, 8670000 ts, 96.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-01-47\n",
      "  done: false\n",
      "  episode_len_mean: 78.81889763779527\n",
      "  episode_reward_max: 392.5928121352565\n",
      "  episode_reward_mean: 86.06300583860792\n",
      "  episode_reward_min: -164.71216868719102\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 110175\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.028\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 8680000\n",
      "    num_steps_trained: 8680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5808225870132446\n",
      "      kl: 0.0183359794318676\n",
      "      policy_loss: 0.003994159400463104\n",
      "      total_loss: 55.366512298583984\n",
      "      vf_explained_var: 0.8760797381401062\n",
      "      vf_loss: 55.36067581176758\n",
      "    sample_time_ms: 18131.318\n",
      "    update_time_ms: 5.617\n",
      "  iterations_since_restore: 868\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.03150291930396\n",
      "  time_since_restore: 19077.458019018173\n",
      "  time_this_iter_s: 21.737151384353638\n",
      "  time_total_s: 19077.458019018173\n",
      "  timestamp: 1553140907\n",
      "  timesteps_since_restore: 8680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8680000\n",
      "  training_iteration: 868\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19077 s, 868 iter, 8680000 ts, 86.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-02-09\n",
      "  done: false\n",
      "  episode_len_mean: 76.96124031007751\n",
      "  episode_reward_max: 393.11149197993586\n",
      "  episode_reward_mean: 76.88570341024571\n",
      "  episode_reward_min: -168.71511962887286\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 110304\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.247\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 8690000\n",
      "    num_steps_trained: 8690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6016144156455994\n",
      "      kl: 0.017140207812190056\n",
      "      policy_loss: 0.0028841812163591385\n",
      "      total_loss: 49.90456008911133\n",
      "      vf_explained_var: 0.8928909301757812\n",
      "      vf_loss: 49.899959564208984\n",
      "    sample_time_ms: 18067.555\n",
      "    update_time_ms: 5.892\n",
      "  iterations_since_restore: 869\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.442851705122855\n",
      "  time_since_restore: 19098.984551906586\n",
      "  time_this_iter_s: 21.526532888412476\n",
      "  time_total_s: 19098.984551906586\n",
      "  timestamp: 1553140929\n",
      "  timesteps_since_restore: 8690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8690000\n",
      "  training_iteration: 869\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19098 s, 869 iter, 8690000 ts, 76.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-02-31\n",
      "  done: false\n",
      "  episode_len_mean: 77.23255813953489\n",
      "  episode_reward_max: 389.07036545224463\n",
      "  episode_reward_mean: 81.18165255780606\n",
      "  episode_reward_min: -168.68574122663975\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 110433\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.397\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 8700000\n",
      "    num_steps_trained: 8700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6007664799690247\n",
      "      kl: 0.025606069713830948\n",
      "      policy_loss: 0.00588793633505702\n",
      "      total_loss: 50.0576171875\n",
      "      vf_explained_var: 0.8902981281280518\n",
      "      vf_loss: 50.049156188964844\n",
      "    sample_time_ms: 18112.139\n",
      "    update_time_ms: 6.003\n",
      "  iterations_since_restore: 870\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.59082627890302\n",
      "  time_since_restore: 19120.781159877777\n",
      "  time_this_iter_s: 21.796607971191406\n",
      "  time_total_s: 19120.781159877777\n",
      "  timestamp: 1553140951\n",
      "  timesteps_since_restore: 8700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8700000\n",
      "  training_iteration: 870\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19120 s, 870 iter, 8700000 ts, 81.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-02-53\n",
      "  done: false\n",
      "  episode_len_mean: 75.14179104477611\n",
      "  episode_reward_max: 387.7015230713763\n",
      "  episode_reward_mean: 62.89224177364796\n",
      "  episode_reward_min: -166.76159924563407\n",
      "  episodes_this_iter: 134\n",
      "  episodes_total: 110567\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.45\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 8710000\n",
      "    num_steps_trained: 8710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6073499321937561\n",
      "      kl: 0.015919841825962067\n",
      "      policy_loss: -0.00011833518510684371\n",
      "      total_loss: 49.29901123046875\n",
      "      vf_explained_var: 0.8992378115653992\n",
      "      vf_loss: 49.29752731323242\n",
      "    sample_time_ms: 18112.03\n",
      "    update_time_ms: 5.818\n",
      "  iterations_since_restore: 871\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.446120886823987\n",
      "  time_since_restore: 19142.741792678833\n",
      "  time_this_iter_s: 21.960632801055908\n",
      "  time_total_s: 19142.741792678833\n",
      "  timestamp: 1553140973\n",
      "  timesteps_since_restore: 8710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8710000\n",
      "  training_iteration: 871\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19142 s, 871 iter, 8710000 ts, 62.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-03-15\n",
      "  done: false\n",
      "  episode_len_mean: 76.56923076923077\n",
      "  episode_reward_max: 388.95966495873034\n",
      "  episode_reward_mean: 75.98188001331064\n",
      "  episode_reward_min: -166.75910496088505\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 110697\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.361\n",
      "    load_time_ms: 1.635\n",
      "    num_steps_sampled: 8720000\n",
      "    num_steps_trained: 8720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5956335067749023\n",
      "      kl: 0.018955281004309654\n",
      "      policy_loss: 0.0029453278984874487\n",
      "      total_loss: 53.40050506591797\n",
      "      vf_explained_var: 0.8893213272094727\n",
      "      vf_loss: 53.395652770996094\n",
      "    sample_time_ms: 18166.653\n",
      "    update_time_ms: 5.903\n",
      "  iterations_since_restore: 872\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.99094000665531\n",
      "  time_since_restore: 19164.496088266373\n",
      "  time_this_iter_s: 21.754295587539673\n",
      "  time_total_s: 19164.496088266373\n",
      "  timestamp: 1553140995\n",
      "  timesteps_since_restore: 8720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8720000\n",
      "  training_iteration: 872\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19164 s, 872 iter, 8720000 ts, 76 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-03-36\n",
      "  done: false\n",
      "  episode_len_mean: 80.296\n",
      "  episode_reward_max: 392.7490465782787\n",
      "  episode_reward_mean: 99.43928837911614\n",
      "  episode_reward_min: -164.71214696952342\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 110822\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.878\n",
      "    load_time_ms: 1.675\n",
      "    num_steps_sampled: 8730000\n",
      "    num_steps_trained: 8730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5528399348258972\n",
      "      kl: 0.014505600556731224\n",
      "      policy_loss: 0.0015008809277787805\n",
      "      total_loss: 44.352054595947266\n",
      "      vf_explained_var: 0.8944857716560364\n",
      "      vf_loss: 44.34909439086914\n",
      "    sample_time_ms: 18115.643\n",
      "    update_time_ms: 5.994\n",
      "  iterations_since_restore: 873\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.71964418955807\n",
      "  time_since_restore: 19185.985669374466\n",
      "  time_this_iter_s: 21.48958110809326\n",
      "  time_total_s: 19185.985669374466\n",
      "  timestamp: 1553141016\n",
      "  timesteps_since_restore: 8730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8730000\n",
      "  training_iteration: 873\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19185 s, 873 iter, 8730000 ts, 99.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-03-58\n",
      "  done: false\n",
      "  episode_len_mean: 80.66129032258064\n",
      "  episode_reward_max: 389.0962019975027\n",
      "  episode_reward_mean: 106.91323999433025\n",
      "  episode_reward_min: -166.80482420143127\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 110946\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.596\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 8740000\n",
      "    num_steps_trained: 8740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5717484951019287\n",
      "      kl: 0.03224986791610718\n",
      "      policy_loss: 0.0075885881669819355\n",
      "      total_loss: 46.65085983276367\n",
      "      vf_explained_var: 0.8915039300918579\n",
      "      vf_loss: 46.64002990722656\n",
      "    sample_time_ms: 18024.413\n",
      "    update_time_ms: 6.151\n",
      "  iterations_since_restore: 874\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.45661999716513\n",
      "  time_since_restore: 19207.341667175293\n",
      "  time_this_iter_s: 21.355997800827026\n",
      "  time_total_s: 19207.341667175293\n",
      "  timestamp: 1553141038\n",
      "  timesteps_since_restore: 8740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8740000\n",
      "  training_iteration: 874\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19207 s, 874 iter, 8740000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 83.83193277310924\n",
      "  episode_reward_max: 387.86171212952\n",
      "  episode_reward_mean: 123.91762075476396\n",
      "  episode_reward_min: -166.7271437965298\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 111065\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3680.529\n",
      "    load_time_ms: 1.621\n",
      "    num_steps_sampled: 8750000\n",
      "    num_steps_trained: 8750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5548130869865417\n",
      "      kl: 0.0190201997756958\n",
      "      policy_loss: -0.001504903077147901\n",
      "      total_loss: 51.92335891723633\n",
      "      vf_explained_var: 0.8691784739494324\n",
      "      vf_loss: 51.92295455932617\n",
      "    sample_time_ms: 18051.025\n",
      "    update_time_ms: 5.376\n",
      "  iterations_since_restore: 875\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.95881037738198\n",
      "  time_since_restore: 19228.907277822495\n",
      "  time_this_iter_s: 21.565610647201538\n",
      "  time_total_s: 19228.907277822495\n",
      "  timestamp: 1553141059\n",
      "  timesteps_since_restore: 8750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8750000\n",
      "  training_iteration: 875\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19228 s, 875 iter, 8750000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-04-41\n",
      "  done: false\n",
      "  episode_len_mean: 80.33870967741936\n",
      "  episode_reward_max: 389.126439046353\n",
      "  episode_reward_mean: 106.16387662362139\n",
      "  episode_reward_min: -164.6796513080263\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 111189\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.445\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 8760000\n",
      "    num_steps_trained: 8760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5537821054458618\n",
      "      kl: 0.026735378429293633\n",
      "      policy_loss: 0.005797367077320814\n",
      "      total_loss: 39.264923095703125\n",
      "      vf_explained_var: 0.9089238047599792\n",
      "      vf_loss: 39.25644302368164\n",
      "    sample_time_ms: 17940.405\n",
      "    update_time_ms: 5.789\n",
      "  iterations_since_restore: 876\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.081938311810696\n",
      "  time_since_restore: 19250.53336954117\n",
      "  time_this_iter_s: 21.626091718673706\n",
      "  time_total_s: 19250.53336954117\n",
      "  timestamp: 1553141081\n",
      "  timesteps_since_restore: 8760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8760000\n",
      "  training_iteration: 876\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19250 s, 876 iter, 8760000 ts, 106 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-05-03\n",
      "  done: false\n",
      "  episode_len_mean: 75.64661654135338\n",
      "  episode_reward_max: 388.9509923993705\n",
      "  episode_reward_mean: 66.5259114393285\n",
      "  episode_reward_min: -166.81796621569634\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 111322\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.721\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 8770000\n",
      "    num_steps_trained: 8770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5947169661521912\n",
      "      kl: 0.014524193480610847\n",
      "      policy_loss: 0.001281958888284862\n",
      "      total_loss: 43.80884552001953\n",
      "      vf_explained_var: 0.9105324149131775\n",
      "      vf_loss: 43.80611038208008\n",
      "    sample_time_ms: 17937.092\n",
      "    update_time_ms: 5.877\n",
      "  iterations_since_restore: 877\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.26295571966425\n",
      "  time_since_restore: 19272.395666360855\n",
      "  time_this_iter_s: 21.86229681968689\n",
      "  time_total_s: 19272.395666360855\n",
      "  timestamp: 1553141103\n",
      "  timesteps_since_restore: 8770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8770000\n",
      "  training_iteration: 877\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19272 s, 877 iter, 8770000 ts, 66.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-05-25\n",
      "  done: false\n",
      "  episode_len_mean: 81.6639344262295\n",
      "  episode_reward_max: 388.97456407710337\n",
      "  episode_reward_mean: 105.01566354059622\n",
      "  episode_reward_min: -164.668251039114\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 111444\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.297\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 8780000\n",
      "    num_steps_trained: 8780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5751433968544006\n",
      "      kl: 0.02280082367360592\n",
      "      policy_loss: 0.0042227888479828835\n",
      "      total_loss: 47.6322021484375\n",
      "      vf_explained_var: 0.8846015930175781\n",
      "      vf_loss: 47.62569046020508\n",
      "    sample_time_ms: 17951.678\n",
      "    update_time_ms: 5.907\n",
      "  iterations_since_restore: 878\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.50783177029812\n",
      "  time_since_restore: 19294.264788627625\n",
      "  time_this_iter_s: 21.86912226676941\n",
      "  time_total_s: 19294.264788627625\n",
      "  timestamp: 1553141125\n",
      "  timesteps_since_restore: 8780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8780000\n",
      "  training_iteration: 878\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19294 s, 878 iter, 8780000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-05-47\n",
      "  done: false\n",
      "  episode_len_mean: 80.94354838709677\n",
      "  episode_reward_max: 388.9937495784368\n",
      "  episode_reward_mean: 106.31414594101722\n",
      "  episode_reward_min: -166.79656711884974\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 111568\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.26\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 8790000\n",
      "    num_steps_trained: 8790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5730071663856506\n",
      "      kl: 0.017236456274986267\n",
      "      policy_loss: 0.001756681827828288\n",
      "      total_loss: 45.327110290527344\n",
      "      vf_explained_var: 0.8934783935546875\n",
      "      vf_loss: 45.3236198425293\n",
      "    sample_time_ms: 17992.974\n",
      "    update_time_ms: 5.731\n",
      "  iterations_since_restore: 879\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.1570729705086\n",
      "  time_since_restore: 19316.206016540527\n",
      "  time_this_iter_s: 21.941227912902832\n",
      "  time_total_s: 19316.206016540527\n",
      "  timestamp: 1553141147\n",
      "  timesteps_since_restore: 8790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8790000\n",
      "  training_iteration: 879\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19316 s, 879 iter, 8790000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-06-09\n",
      "  done: false\n",
      "  episode_len_mean: 78.11811023622047\n",
      "  episode_reward_max: 388.6406222384142\n",
      "  episode_reward_mean: 86.0248891569946\n",
      "  episode_reward_min: -164.7539000219965\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 111695\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.83\n",
      "    load_time_ms: 1.645\n",
      "    num_steps_sampled: 8800000\n",
      "    num_steps_trained: 8800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5716371536254883\n",
      "      kl: 0.02226671762764454\n",
      "      policy_loss: 0.007723853923380375\n",
      "      total_loss: 35.93526077270508\n",
      "      vf_explained_var: 0.9216543436050415\n",
      "      vf_loss: 35.92530059814453\n",
      "    sample_time_ms: 18028.412\n",
      "    update_time_ms: 5.707\n",
      "  iterations_since_restore: 880\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.01244457849729\n",
      "  time_since_restore: 19338.3642642498\n",
      "  time_this_iter_s: 22.158247709274292\n",
      "  time_total_s: 19338.3642642498\n",
      "  timestamp: 1553141169\n",
      "  timesteps_since_restore: 8800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8800000\n",
      "  training_iteration: 880\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19338 s, 880 iter, 8800000 ts, 86 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-06-31\n",
      "  done: false\n",
      "  episode_len_mean: 77.7\n",
      "  episode_reward_max: 393.01795027671994\n",
      "  episode_reward_mean: 81.28482279710408\n",
      "  episode_reward_min: -168.8247574683094\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 111825\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.026\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 8810000\n",
      "    num_steps_trained: 8810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.589506208896637\n",
      "      kl: 0.021132417023181915\n",
      "      policy_loss: 0.0031676862854510546\n",
      "      total_loss: 49.833518981933594\n",
      "      vf_explained_var: 0.8969039916992188\n",
      "      vf_loss: 49.828224182128906\n",
      "    sample_time_ms: 18004.834\n",
      "    update_time_ms: 5.505\n",
      "  iterations_since_restore: 881\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 40.64241139855204\n",
      "  time_since_restore: 19360.109837770462\n",
      "  time_this_iter_s: 21.7455735206604\n",
      "  time_total_s: 19360.109837770462\n",
      "  timestamp: 1553141191\n",
      "  timesteps_since_restore: 8810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8810000\n",
      "  training_iteration: 881\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19360 s, 881 iter, 8810000 ts, 81.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-06-53\n",
      "  done: false\n",
      "  episode_len_mean: 76.31297709923665\n",
      "  episode_reward_max: 388.0021155646874\n",
      "  episode_reward_mean: 77.39591221718258\n",
      "  episode_reward_min: -168.8221008435154\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 111956\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.435\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 8820000\n",
      "    num_steps_trained: 8820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5683023929595947\n",
      "      kl: 0.016186479479074478\n",
      "      policy_loss: 0.003866838989779353\n",
      "      total_loss: 48.95388412475586\n",
      "      vf_explained_var: 0.8979811072349548\n",
      "      vf_loss: 48.948387145996094\n",
      "    sample_time_ms: 18048.952\n",
      "    update_time_ms: 5.45\n",
      "  iterations_since_restore: 882\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.69795610859129\n",
      "  time_since_restore: 19382.297911405563\n",
      "  time_this_iter_s: 22.18807363510132\n",
      "  time_total_s: 19382.297911405563\n",
      "  timestamp: 1553141213\n",
      "  timesteps_since_restore: 8820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8820000\n",
      "  training_iteration: 882\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19382 s, 882 iter, 8820000 ts, 77.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-07-15\n",
      "  done: false\n",
      "  episode_len_mean: 80.91056910569105\n",
      "  episode_reward_max: 388.7987788215266\n",
      "  episode_reward_mean: 99.11234309454211\n",
      "  episode_reward_min: -166.7331469627285\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 112079\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.638\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 8830000\n",
      "    num_steps_trained: 8830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5885044932365417\n",
      "      kl: 0.026941534131765366\n",
      "      policy_loss: 0.006762979086488485\n",
      "      total_loss: 45.41161346435547\n",
      "      vf_explained_var: 0.8955322504043579\n",
      "      vf_loss: 45.40214157104492\n",
      "    sample_time_ms: 18098.764\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 883\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.55617154727108\n",
      "  time_since_restore: 19404.28711271286\n",
      "  time_this_iter_s: 21.989201307296753\n",
      "  time_total_s: 19404.28711271286\n",
      "  timestamp: 1553141235\n",
      "  timesteps_since_restore: 8830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8830000\n",
      "  training_iteration: 883\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19404 s, 883 iter, 8830000 ts, 99.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-07-37\n",
      "  done: false\n",
      "  episode_len_mean: 77.890625\n",
      "  episode_reward_max: 385.82934226530887\n",
      "  episode_reward_mean: 82.76676968138585\n",
      "  episode_reward_min: -166.6920069329405\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 112207\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.178\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 8840000\n",
      "    num_steps_trained: 8840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5785475373268127\n",
      "      kl: 0.022075152024626732\n",
      "      policy_loss: 0.0028400395531207323\n",
      "      total_loss: 51.117706298828125\n",
      "      vf_explained_var: 0.8892597556114197\n",
      "      vf_loss: 51.11265182495117\n",
      "    sample_time_ms: 18181.593\n",
      "    update_time_ms: 5.327\n",
      "  iterations_since_restore: 884\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.383384840692905\n",
      "  time_since_restore: 19426.45422935486\n",
      "  time_this_iter_s: 22.16711664199829\n",
      "  time_total_s: 19426.45422935486\n",
      "  timestamp: 1553141257\n",
      "  timesteps_since_restore: 8840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8840000\n",
      "  training_iteration: 884\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19426 s, 884 iter, 8840000 ts, 82.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-07-59\n",
      "  done: false\n",
      "  episode_len_mean: 80.53225806451613\n",
      "  episode_reward_max: 391.9164963554842\n",
      "  episode_reward_mean: 103.74354447335904\n",
      "  episode_reward_min: -168.7035808798933\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 112331\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.873\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 8850000\n",
      "    num_steps_trained: 8850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5734941363334656\n",
      "      kl: 0.018375562503933907\n",
      "      policy_loss: 0.005399197340011597\n",
      "      total_loss: 30.42854118347168\n",
      "      vf_explained_var: 0.9280278086662292\n",
      "      vf_loss: 30.42129898071289\n",
      "    sample_time_ms: 18254.396\n",
      "    update_time_ms: 5.407\n",
      "  iterations_since_restore: 885\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.87177223667949\n",
      "  time_since_restore: 19448.733150959015\n",
      "  time_this_iter_s: 22.278921604156494\n",
      "  time_total_s: 19448.733150959015\n",
      "  timestamp: 1553141279\n",
      "  timesteps_since_restore: 8850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8850000\n",
      "  training_iteration: 885\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19448 s, 885 iter, 8850000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-08-22\n",
      "  done: false\n",
      "  episode_len_mean: 76.56488549618321\n",
      "  episode_reward_max: 388.2395886009878\n",
      "  episode_reward_mean: 73.41044530961767\n",
      "  episode_reward_min: -166.71513040312766\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 112462\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.469\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 8860000\n",
      "    num_steps_trained: 8860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6127625107765198\n",
      "      kl: 0.017814192920923233\n",
      "      policy_loss: 0.0016054526204243302\n",
      "      total_loss: 49.49144744873047\n",
      "      vf_explained_var: 0.8952178955078125\n",
      "      vf_loss: 49.4880485534668\n",
      "    sample_time_ms: 18349.921\n",
      "    update_time_ms: 5.134\n",
      "  iterations_since_restore: 886\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.70522265480884\n",
      "  time_since_restore: 19471.097817659378\n",
      "  time_this_iter_s: 22.36466670036316\n",
      "  time_total_s: 19471.097817659378\n",
      "  timestamp: 1553141302\n",
      "  timesteps_since_restore: 8860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8860000\n",
      "  training_iteration: 886\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19471 s, 886 iter, 8860000 ts, 73.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-08-44\n",
      "  done: false\n",
      "  episode_len_mean: 78.06976744186046\n",
      "  episode_reward_max: 389.12417727504334\n",
      "  episode_reward_mean: 86.01493094778982\n",
      "  episode_reward_min: -163.5545813319349\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 112591\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3678.879\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 8870000\n",
      "    num_steps_trained: 8870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6228070259094238\n",
      "      kl: 0.016883062198758125\n",
      "      policy_loss: 0.0027584945783019066\n",
      "      total_loss: 54.39340591430664\n",
      "      vf_explained_var: 0.8800264000892639\n",
      "      vf_loss: 54.388954162597656\n",
      "    sample_time_ms: 18375.361\n",
      "    update_time_ms: 5.532\n",
      "  iterations_since_restore: 887\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.007465473894904\n",
      "  time_since_restore: 19493.19468331337\n",
      "  time_this_iter_s: 22.0968656539917\n",
      "  time_total_s: 19493.19468331337\n",
      "  timestamp: 1553141324\n",
      "  timesteps_since_restore: 8870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8870000\n",
      "  training_iteration: 887\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19493 s, 887 iter, 8870000 ts, 86 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-09-06\n",
      "  done: false\n",
      "  episode_len_mean: 81.23577235772358\n",
      "  episode_reward_max: 388.6786357753131\n",
      "  episode_reward_mean: 108.20750730727157\n",
      "  episode_reward_min: -168.72691931661606\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 112714\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.767\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 8880000\n",
      "    num_steps_trained: 8880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5793481469154358\n",
      "      kl: 0.026119807735085487\n",
      "      policy_loss: 0.006532586645334959\n",
      "      total_loss: 41.239837646484375\n",
      "      vf_explained_var: 0.9008387923240662\n",
      "      vf_loss: 41.230682373046875\n",
      "    sample_time_ms: 18357.105\n",
      "    update_time_ms: 5.466\n",
      "  iterations_since_restore: 888\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.10375365363576\n",
      "  time_since_restore: 19514.92713689804\n",
      "  time_this_iter_s: 21.73245358467102\n",
      "  time_total_s: 19514.92713689804\n",
      "  timestamp: 1553141346\n",
      "  timesteps_since_restore: 8880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8880000\n",
      "  training_iteration: 888\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19514 s, 888 iter, 8880000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-09-28\n",
      "  done: false\n",
      "  episode_len_mean: 76.09848484848484\n",
      "  episode_reward_max: 387.1619805349041\n",
      "  episode_reward_mean: 67.72460757848805\n",
      "  episode_reward_min: -166.7946168987417\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 112846\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.533\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 8890000\n",
      "    num_steps_trained: 8890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.610928475856781\n",
      "      kl: 0.02685512602329254\n",
      "      policy_loss: 0.005691213998943567\n",
      "      total_loss: 50.92866516113281\n",
      "      vf_explained_var: 0.8971776962280273\n",
      "      vf_loss: 50.9202766418457\n",
      "    sample_time_ms: 18345.154\n",
      "    update_time_ms: 5.301\n",
      "  iterations_since_restore: 889\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.86230378924402\n",
      "  time_since_restore: 19536.72336244583\n",
      "  time_this_iter_s: 21.796225547790527\n",
      "  time_total_s: 19536.72336244583\n",
      "  timestamp: 1553141368\n",
      "  timesteps_since_restore: 8890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8890000\n",
      "  training_iteration: 889\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19536 s, 889 iter, 8890000 ts, 67.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-09-50\n",
      "  done: false\n",
      "  episode_len_mean: 83.54621848739495\n",
      "  episode_reward_max: 387.5270326698907\n",
      "  episode_reward_mean: 122.04197336602714\n",
      "  episode_reward_min: -164.70749621984004\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 112965\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3677.139\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 8900000\n",
      "    num_steps_trained: 8900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5975655913352966\n",
      "      kl: 0.017446141690015793\n",
      "      policy_loss: 0.003696777857840061\n",
      "      total_loss: 38.133087158203125\n",
      "      vf_explained_var: 0.9020965695381165\n",
      "      vf_loss: 38.12764358520508\n",
      "    sample_time_ms: 18332.407\n",
      "    update_time_ms: 5.496\n",
      "  iterations_since_restore: 890\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.02098668301357\n",
      "  time_since_restore: 19558.712287187576\n",
      "  time_this_iter_s: 21.988924741744995\n",
      "  time_total_s: 19558.712287187576\n",
      "  timestamp: 1553141390\n",
      "  timesteps_since_restore: 8900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8900000\n",
      "  training_iteration: 890\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19558 s, 890 iter, 8900000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-10-12\n",
      "  done: false\n",
      "  episode_len_mean: 79.608\n",
      "  episode_reward_max: 384.7731086821906\n",
      "  episode_reward_mean: 94.78983595124556\n",
      "  episode_reward_min: -166.91770535847186\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 113090\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.832\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 8910000\n",
      "    num_steps_trained: 8910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5861818194389343\n",
      "      kl: 0.03048745170235634\n",
      "      policy_loss: 0.005161066073924303\n",
      "      total_loss: 44.94388961791992\n",
      "      vf_explained_var: 0.8968865871429443\n",
      "      vf_loss: 44.9356689453125\n",
      "    sample_time_ms: 18340.911\n",
      "    update_time_ms: 5.813\n",
      "  iterations_since_restore: 891\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.39491797562277\n",
      "  time_since_restore: 19580.653124332428\n",
      "  time_this_iter_s: 21.940837144851685\n",
      "  time_total_s: 19580.653124332428\n",
      "  timestamp: 1553141412\n",
      "  timesteps_since_restore: 8910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8910000\n",
      "  training_iteration: 891\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19580 s, 891 iter, 8910000 ts, 94.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-10-34\n",
      "  done: false\n",
      "  episode_len_mean: 75.43609022556392\n",
      "  episode_reward_max: 387.6026577249419\n",
      "  episode_reward_mean: 66.72025380404058\n",
      "  episode_reward_min: -168.7029863545561\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 113223\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.549\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 8920000\n",
      "    num_steps_trained: 8920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6331964135169983\n",
      "      kl: 0.017758356407284737\n",
      "      policy_loss: 0.003762038191780448\n",
      "      total_loss: 39.89059066772461\n",
      "      vf_explained_var: 0.9169485569000244\n",
      "      vf_loss: 39.885047912597656\n",
      "    sample_time_ms: 18322.98\n",
      "    update_time_ms: 5.827\n",
      "  iterations_since_restore: 892\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.36012690202028\n",
      "  time_since_restore: 19602.669282197952\n",
      "  time_this_iter_s: 22.016157865524292\n",
      "  time_total_s: 19602.669282197952\n",
      "  timestamp: 1553141434\n",
      "  timesteps_since_restore: 8920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8920000\n",
      "  training_iteration: 892\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19602 s, 892 iter, 8920000 ts, 66.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-10-56\n",
      "  done: false\n",
      "  episode_len_mean: 80.74193548387096\n",
      "  episode_reward_max: 386.09884854651705\n",
      "  episode_reward_mean: 102.5457071011743\n",
      "  episode_reward_min: -166.88108923312663\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 113347\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.72\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 8930000\n",
      "    num_steps_trained: 8930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5873920321464539\n",
      "      kl: 0.015010048635303974\n",
      "      policy_loss: 0.0036322749219834805\n",
      "      total_loss: 38.82798385620117\n",
      "      vf_explained_var: 0.9095818996429443\n",
      "      vf_loss: 38.822845458984375\n",
      "    sample_time_ms: 18352.514\n",
      "    update_time_ms: 5.739\n",
      "  iterations_since_restore: 893\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.27285355058716\n",
      "  time_since_restore: 19624.954492092133\n",
      "  time_this_iter_s: 22.285209894180298\n",
      "  time_total_s: 19624.954492092133\n",
      "  timestamp: 1553141456\n",
      "  timesteps_since_restore: 8930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8930000\n",
      "  training_iteration: 893\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19624 s, 893 iter, 8930000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-11-18\n",
      "  done: false\n",
      "  episode_len_mean: 83.74166666666666\n",
      "  episode_reward_max: 389.1234673199797\n",
      "  episode_reward_mean: 127.39388635081168\n",
      "  episode_reward_min: -166.82165143796445\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 113467\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.828\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 8940000\n",
      "    num_steps_trained: 8940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5930453538894653\n",
      "      kl: 0.01848115585744381\n",
      "      policy_loss: 0.003188805654644966\n",
      "      total_loss: 44.834381103515625\n",
      "      vf_explained_var: 0.885703444480896\n",
      "      vf_loss: 44.8293342590332\n",
      "    sample_time_ms: 18307.025\n",
      "    update_time_ms: 5.628\n",
      "  iterations_since_restore: 894\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.696943175405856\n",
      "  time_since_restore: 19646.67892408371\n",
      "  time_this_iter_s: 21.72443199157715\n",
      "  time_total_s: 19646.67892408371\n",
      "  timestamp: 1553141478\n",
      "  timesteps_since_restore: 8940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8940000\n",
      "  training_iteration: 894\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19646 s, 894 iter, 8940000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-11-39\n",
      "  done: false\n",
      "  episode_len_mean: 73.72592592592592\n",
      "  episode_reward_max: 388.58207242580687\n",
      "  episode_reward_mean: 54.30476141955731\n",
      "  episode_reward_min: -166.76681525703907\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 113602\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.018\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 8950000\n",
      "    num_steps_trained: 8950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.651178777217865\n",
      "      kl: 0.01567578688263893\n",
      "      policy_loss: 0.003019599709659815\n",
      "      total_loss: 54.2853889465332\n",
      "      vf_explained_var: 0.8915880918502808\n",
      "      vf_loss: 54.280792236328125\n",
      "    sample_time_ms: 18234.183\n",
      "    update_time_ms: 5.615\n",
      "  iterations_since_restore: 895\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.152380709778647\n",
      "  time_since_restore: 19668.406856775284\n",
      "  time_this_iter_s: 21.727932691574097\n",
      "  time_total_s: 19668.406856775284\n",
      "  timestamp: 1553141499\n",
      "  timesteps_since_restore: 8950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8950000\n",
      "  training_iteration: 895\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19668 s, 895 iter, 8950000 ts, 54.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-12-01\n",
      "  done: false\n",
      "  episode_len_mean: 76.0\n",
      "  episode_reward_max: 392.07245887643165\n",
      "  episode_reward_mean: 67.5128775773488\n",
      "  episode_reward_min: -162.9298455938959\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 113734\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.944\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 8960000\n",
      "    num_steps_trained: 8960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.630449652671814\n",
      "      kl: 0.020986871793866158\n",
      "      policy_loss: 0.004348428454250097\n",
      "      total_loss: 54.63838577270508\n",
      "      vf_explained_var: 0.8900761008262634\n",
      "      vf_loss: 54.631935119628906\n",
      "    sample_time_ms: 18170.659\n",
      "    update_time_ms: 5.769\n",
      "  iterations_since_restore: 896\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 33.756438788674394\n",
      "  time_since_restore: 19690.114342689514\n",
      "  time_this_iter_s: 21.707485914230347\n",
      "  time_total_s: 19690.114342689514\n",
      "  timestamp: 1553141521\n",
      "  timesteps_since_restore: 8960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8960000\n",
      "  training_iteration: 896\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19690 s, 896 iter, 8960000 ts, 67.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-12-23\n",
      "  done: false\n",
      "  episode_len_mean: 73.36296296296297\n",
      "  episode_reward_max: 388.1572077072683\n",
      "  episode_reward_mean: 49.04478136750892\n",
      "  episode_reward_min: -163.13443225153924\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 113869\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.159\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 8970000\n",
      "    num_steps_trained: 8970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6327775716781616\n",
      "      kl: 0.02411719784140587\n",
      "      policy_loss: 0.0034454972483217716\n",
      "      total_loss: 46.58485794067383\n",
      "      vf_explained_var: 0.9101892113685608\n",
      "      vf_loss: 46.57899475097656\n",
      "    sample_time_ms: 18158.213\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 897\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 24.52239068375446\n",
      "  time_since_restore: 19712.07450246811\n",
      "  time_this_iter_s: 21.96015977859497\n",
      "  time_total_s: 19712.07450246811\n",
      "  timestamp: 1553141543\n",
      "  timesteps_since_restore: 8970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8970000\n",
      "  training_iteration: 897\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19712 s, 897 iter, 8970000 ts, 49 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-12-45\n",
      "  done: false\n",
      "  episode_len_mean: 80.136\n",
      "  episode_reward_max: 392.6090507795014\n",
      "  episode_reward_mean: 98.45965272600529\n",
      "  episode_reward_min: -168.75226747628687\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 113994\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.653\n",
      "    load_time_ms: 1.454\n",
      "    num_steps_sampled: 8980000\n",
      "    num_steps_trained: 8980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5710079669952393\n",
      "      kl: 0.026179637759923935\n",
      "      policy_loss: 0.009098703972995281\n",
      "      total_loss: 44.4597282409668\n",
      "      vf_explained_var: 0.8963664174079895\n",
      "      vf_loss: 44.44800567626953\n",
      "    sample_time_ms: 18143.005\n",
      "    update_time_ms: 5.435\n",
      "  iterations_since_restore: 898\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.22982636300265\n",
      "  time_since_restore: 19733.605527877808\n",
      "  time_this_iter_s: 21.531025409698486\n",
      "  time_total_s: 19733.605527877808\n",
      "  timestamp: 1553141565\n",
      "  timesteps_since_restore: 8980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8980000\n",
      "  training_iteration: 898\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19733 s, 898 iter, 8980000 ts, 98.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-13-06\n",
      "  done: false\n",
      "  episode_len_mean: 78.81746031746032\n",
      "  episode_reward_max: 386.3778248014832\n",
      "  episode_reward_mean: 90.59371171580156\n",
      "  episode_reward_min: -168.72367157312868\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 114120\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.53\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 8990000\n",
      "    num_steps_trained: 8990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.587530255317688\n",
      "      kl: 0.016632571816444397\n",
      "      policy_loss: 0.00526631623506546\n",
      "      total_loss: 50.43157196044922\n",
      "      vf_explained_var: 0.8895982503890991\n",
      "      vf_loss: 50.42463684082031\n",
      "    sample_time_ms: 18125.808\n",
      "    update_time_ms: 5.807\n",
      "  iterations_since_restore: 899\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.29685585790077\n",
      "  time_since_restore: 19755.230482578278\n",
      "  time_this_iter_s: 21.62495470046997\n",
      "  time_total_s: 19755.230482578278\n",
      "  timestamp: 1553141586\n",
      "  timesteps_since_restore: 8990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8990000\n",
      "  training_iteration: 899\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19755 s, 899 iter, 8990000 ts, 90.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-13-28\n",
      "  done: false\n",
      "  episode_len_mean: 81.98373983739837\n",
      "  episode_reward_max: 388.0561815327036\n",
      "  episode_reward_mean: 117.07349403591463\n",
      "  episode_reward_min: -168.66385220417024\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 114243\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.07\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 9000000\n",
      "    num_steps_trained: 9000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5749216079711914\n",
      "      kl: 0.02674478478729725\n",
      "      policy_loss: 0.005811717361211777\n",
      "      total_loss: 42.02368927001953\n",
      "      vf_explained_var: 0.8990175127983093\n",
      "      vf_loss: 42.01519012451172\n",
      "    sample_time_ms: 18113.836\n",
      "    update_time_ms: 5.573\n",
      "  iterations_since_restore: 900\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.5367470179573\n",
      "  time_since_restore: 19777.11822938919\n",
      "  time_this_iter_s: 21.887746810913086\n",
      "  time_total_s: 19777.11822938919\n",
      "  timestamp: 1553141608\n",
      "  timesteps_since_restore: 9000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9000000\n",
      "  training_iteration: 900\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19777 s, 900 iter, 9000000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-13-50\n",
      "  done: false\n",
      "  episode_len_mean: 71.37142857142857\n",
      "  episode_reward_max: 391.58206489075747\n",
      "  episode_reward_mean: 39.74135579280143\n",
      "  episode_reward_min: -166.74693250593185\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 114383\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.682\n",
      "    load_time_ms: 1.449\n",
      "    num_steps_sampled: 9010000\n",
      "    num_steps_trained: 9010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6199751496315002\n",
      "      kl: 0.0181333739310503\n",
      "      policy_loss: 0.003440570319071412\n",
      "      total_loss: 45.14519119262695\n",
      "      vf_explained_var: 0.9151415824890137\n",
      "      vf_loss: 45.139930725097656\n",
      "    sample_time_ms: 18122.348\n",
      "    update_time_ms: 5.419\n",
      "  iterations_since_restore: 901\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 19.87067789640071\n",
      "  time_since_restore: 19799.02673482895\n",
      "  time_this_iter_s: 21.9085054397583\n",
      "  time_total_s: 19799.02673482895\n",
      "  timestamp: 1553141630\n",
      "  timesteps_since_restore: 9010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9010000\n",
      "  training_iteration: 901\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19799 s, 901 iter, 9010000 ts, 39.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-14-12\n",
      "  done: false\n",
      "  episode_len_mean: 77.52713178294573\n",
      "  episode_reward_max: 393.2279600359259\n",
      "  episode_reward_mean: 85.30681705830555\n",
      "  episode_reward_min: -166.7648921503687\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 114512\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.475\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 9020000\n",
      "    num_steps_trained: 9020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5865378975868225\n",
      "      kl: 0.022905120626091957\n",
      "      policy_loss: 0.006172604393213987\n",
      "      total_loss: 43.86635971069336\n",
      "      vf_explained_var: 0.9068679809570312\n",
      "      vf_loss: 43.85789108276367\n",
      "    sample_time_ms: 18117.23\n",
      "    update_time_ms: 5.402\n",
      "  iterations_since_restore: 902\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.65340852915276\n",
      "  time_since_restore: 19821.06957244873\n",
      "  time_this_iter_s: 22.042837619781494\n",
      "  time_total_s: 19821.06957244873\n",
      "  timestamp: 1553141652\n",
      "  timesteps_since_restore: 9020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9020000\n",
      "  training_iteration: 902\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19821 s, 902 iter, 9020000 ts, 85.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-14-34\n",
      "  done: false\n",
      "  episode_len_mean: 75.96946564885496\n",
      "  episode_reward_max: 386.4154194548139\n",
      "  episode_reward_mean: 68.085764494432\n",
      "  episode_reward_min: -168.69573148437976\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 114643\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.803\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 9030000\n",
      "    num_steps_trained: 9030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6295100450515747\n",
      "      kl: 0.022524237632751465\n",
      "      policy_loss: 0.0049730208702385426\n",
      "      total_loss: 41.43096923828125\n",
      "      vf_explained_var: 0.9150010943412781\n",
      "      vf_loss: 41.42373275756836\n",
      "    sample_time_ms: 18044.708\n",
      "    update_time_ms: 5.714\n",
      "  iterations_since_restore: 903\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.042882247216\n",
      "  time_since_restore: 19842.65416789055\n",
      "  time_this_iter_s: 21.584595441818237\n",
      "  time_total_s: 19842.65416789055\n",
      "  timestamp: 1553141674\n",
      "  timesteps_since_restore: 9030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9030000\n",
      "  training_iteration: 903\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19842 s, 903 iter, 9030000 ts, 68.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-14-56\n",
      "  done: false\n",
      "  episode_len_mean: 77.12213740458016\n",
      "  episode_reward_max: 387.35152636988704\n",
      "  episode_reward_mean: 82.05492560419638\n",
      "  episode_reward_min: -164.78349801525115\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 114774\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.721\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 9040000\n",
      "    num_steps_trained: 9040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5970821380615234\n",
      "      kl: 0.018225012347102165\n",
      "      policy_loss: 0.004377365577965975\n",
      "      total_loss: 46.939090728759766\n",
      "      vf_explained_var: 0.90469890832901\n",
      "      vf_loss: 46.93288803100586\n",
      "    sample_time_ms: 18080.24\n",
      "    update_time_ms: 5.84\n",
      "  iterations_since_restore: 904\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.02746280209819\n",
      "  time_since_restore: 19864.70711994171\n",
      "  time_this_iter_s: 22.05295205116272\n",
      "  time_total_s: 19864.70711994171\n",
      "  timestamp: 1553141696\n",
      "  timesteps_since_restore: 9040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9040000\n",
      "  training_iteration: 904\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19864 s, 904 iter, 9040000 ts, 82.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-15-19\n",
      "  done: false\n",
      "  episode_len_mean: 83.6470588235294\n",
      "  episode_reward_max: 388.54831666009244\n",
      "  episode_reward_mean: 130.11473575389684\n",
      "  episode_reward_min: -164.65345563920977\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 114893\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.388\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 9050000\n",
      "    num_steps_trained: 9050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5973852872848511\n",
      "      kl: 0.020045805722475052\n",
      "      policy_loss: 0.004367303568869829\n",
      "      total_loss: 45.64955520629883\n",
      "      vf_explained_var: 0.8795042037963867\n",
      "      vf_loss: 45.6431770324707\n",
      "    sample_time_ms: 18158.95\n",
      "    update_time_ms: 5.757\n",
      "  iterations_since_restore: 905\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.0573678769484\n",
      "  time_since_restore: 19887.091325759888\n",
      "  time_this_iter_s: 22.38420581817627\n",
      "  time_total_s: 19887.091325759888\n",
      "  timestamp: 1553141719\n",
      "  timesteps_since_restore: 9050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9050000\n",
      "  training_iteration: 905\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19887 s, 905 iter, 9050000 ts, 130 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-15-41\n",
      "  done: false\n",
      "  episode_len_mean: 81.54918032786885\n",
      "  episode_reward_max: 391.88589902010375\n",
      "  episode_reward_mean: 112.71375560993327\n",
      "  episode_reward_min: -168.6541970921421\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 115015\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.448\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 9060000\n",
      "    num_steps_trained: 9060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6113045811653137\n",
      "      kl: 0.018128737807273865\n",
      "      policy_loss: 0.005545506719499826\n",
      "      total_loss: 37.510459899902344\n",
      "      vf_explained_var: 0.9074548482894897\n",
      "      vf_loss: 37.50309371948242\n",
      "    sample_time_ms: 18165.751\n",
      "    update_time_ms: 5.799\n",
      "  iterations_since_restore: 906\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.35687780496664\n",
      "  time_since_restore: 19909.08859848976\n",
      "  time_this_iter_s: 21.997272729873657\n",
      "  time_total_s: 19909.08859848976\n",
      "  timestamp: 1553141741\n",
      "  timesteps_since_restore: 9060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9060000\n",
      "  training_iteration: 906\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19909 s, 906 iter, 9060000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-16-02\n",
      "  done: false\n",
      "  episode_len_mean: 87.44347826086957\n",
      "  episode_reward_max: 390.30398713921994\n",
      "  episode_reward_mean: 157.51871569162205\n",
      "  episode_reward_min: -166.769094283309\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 115130\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.536\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 9070000\n",
      "    num_steps_trained: 9070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5903284549713135\n",
      "      kl: 0.021291499957442284\n",
      "      policy_loss: 0.0050245425663888454\n",
      "      total_loss: 45.518516540527344\n",
      "      vf_explained_var: 0.8638095259666443\n",
      "      vf_loss: 45.511356353759766\n",
      "    sample_time_ms: 18129.521\n",
      "    update_time_ms: 5.768\n",
      "  iterations_since_restore: 907\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.75935784581101\n",
      "  time_since_restore: 19930.686556339264\n",
      "  time_this_iter_s: 21.597957849502563\n",
      "  time_total_s: 19930.686556339264\n",
      "  timestamp: 1553141762\n",
      "  timesteps_since_restore: 9070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9070000\n",
      "  training_iteration: 907\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19930 s, 907 iter, 9070000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-16-24\n",
      "  done: false\n",
      "  episode_len_mean: 79.30952380952381\n",
      "  episode_reward_max: 389.0335832014004\n",
      "  episode_reward_mean: 94.13016987564208\n",
      "  episode_reward_min: -166.76482655116558\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 115256\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.635\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 9080000\n",
      "    num_steps_trained: 9080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6353978514671326\n",
      "      kl: 0.016804980114102364\n",
      "      policy_loss: 0.005140111315995455\n",
      "      total_loss: 37.98349380493164\n",
      "      vf_explained_var: 0.9111607670783997\n",
      "      vf_loss: 37.97666931152344\n",
      "    sample_time_ms: 18170.752\n",
      "    update_time_ms: 5.678\n",
      "  iterations_since_restore: 908\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.06508493782105\n",
      "  time_since_restore: 19952.669266939163\n",
      "  time_this_iter_s: 21.982710599899292\n",
      "  time_total_s: 19952.669266939163\n",
      "  timestamp: 1553141784\n",
      "  timesteps_since_restore: 9080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9080000\n",
      "  training_iteration: 908\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19952 s, 908 iter, 9080000 ts, 94.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-16-46\n",
      "  done: false\n",
      "  episode_len_mean: 80.9758064516129\n",
      "  episode_reward_max: 386.92657871357284\n",
      "  episode_reward_mean: 110.10930949735854\n",
      "  episode_reward_min: -166.79196588369848\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 115380\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.453\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 9090000\n",
      "    num_steps_trained: 9090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6258675456047058\n",
      "      kl: 0.018058568239212036\n",
      "      policy_loss: 0.0038052797317504883\n",
      "      total_loss: 44.30419158935547\n",
      "      vf_explained_var: 0.8914499282836914\n",
      "      vf_loss: 44.2985725402832\n",
      "    sample_time_ms: 18152.33\n",
      "    update_time_ms: 5.455\n",
      "  iterations_since_restore: 909\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.054654748679276\n",
      "  time_since_restore: 19974.145880937576\n",
      "  time_this_iter_s: 21.476613998413086\n",
      "  time_total_s: 19974.145880937576\n",
      "  timestamp: 1553141806\n",
      "  timesteps_since_restore: 9090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9090000\n",
      "  training_iteration: 909\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19974 s, 909 iter, 9090000 ts, 110 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-17-08\n",
      "  done: false\n",
      "  episode_len_mean: 81.87704918032787\n",
      "  episode_reward_max: 392.97742250519246\n",
      "  episode_reward_mean: 109.1331723758971\n",
      "  episode_reward_min: -160.48783945545196\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 115502\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.863\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 9100000\n",
      "    num_steps_trained: 9100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5994777083396912\n",
      "      kl: 0.021168289706110954\n",
      "      policy_loss: 0.000520438130479306\n",
      "      total_loss: 45.69647216796875\n",
      "      vf_explained_var: 0.8917245864868164\n",
      "      vf_loss: 45.69382095336914\n",
      "    sample_time_ms: 18171.968\n",
      "    update_time_ms: 5.478\n",
      "  iterations_since_restore: 910\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.566586187948545\n",
      "  time_since_restore: 19996.246585845947\n",
      "  time_this_iter_s: 22.10070490837097\n",
      "  time_total_s: 19996.246585845947\n",
      "  timestamp: 1553141828\n",
      "  timesteps_since_restore: 9100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9100000\n",
      "  training_iteration: 910\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 19996 s, 910 iter, 9100000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-17-30\n",
      "  done: false\n",
      "  episode_len_mean: 82.18852459016394\n",
      "  episode_reward_max: 392.4662745833174\n",
      "  episode_reward_mean: 118.39242309030037\n",
      "  episode_reward_min: -164.70931895276547\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 115624\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.261\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 9110000\n",
      "    num_steps_trained: 9110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6091041564941406\n",
      "      kl: 0.016782501712441444\n",
      "      policy_loss: 0.004428046755492687\n",
      "      total_loss: 42.459842681884766\n",
      "      vf_explained_var: 0.8950340151786804\n",
      "      vf_loss: 42.453731536865234\n",
      "    sample_time_ms: 18165.69\n",
      "    update_time_ms: 5.541\n",
      "  iterations_since_restore: 911\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.196211545150184\n",
      "  time_since_restore: 20018.117381811142\n",
      "  time_this_iter_s: 21.870795965194702\n",
      "  time_total_s: 20018.117381811142\n",
      "  timestamp: 1553141850\n",
      "  timesteps_since_restore: 9110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9110000\n",
      "  training_iteration: 911\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20018 s, 911 iter, 9110000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-17-52\n",
      "  done: false\n",
      "  episode_len_mean: 77.5813953488372\n",
      "  episode_reward_max: 386.37074228733576\n",
      "  episode_reward_mean: 83.63620358708994\n",
      "  episode_reward_min: -168.75058899947643\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 115753\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.161\n",
      "    load_time_ms: 1.407\n",
      "    num_steps_sampled: 9120000\n",
      "    num_steps_trained: 9120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5988935828208923\n",
      "      kl: 0.025236625224351883\n",
      "      policy_loss: 0.004033640492707491\n",
      "      total_loss: 44.14365005493164\n",
      "      vf_explained_var: 0.9045642018318176\n",
      "      vf_loss: 44.137081146240234\n",
      "    sample_time_ms: 18181.473\n",
      "    update_time_ms: 5.582\n",
      "  iterations_since_restore: 912\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.81810179354496\n",
      "  time_since_restore: 20040.205362558365\n",
      "  time_this_iter_s: 22.0879807472229\n",
      "  time_total_s: 20040.205362558365\n",
      "  timestamp: 1553141872\n",
      "  timesteps_since_restore: 9120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9120000\n",
      "  training_iteration: 912\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20040 s, 912 iter, 9120000 ts, 83.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-18-14\n",
      "  done: false\n",
      "  episode_len_mean: 70.47857142857143\n",
      "  episode_reward_max: 386.6692853480353\n",
      "  episode_reward_mean: 33.59142723629964\n",
      "  episode_reward_min: -168.67328096326827\n",
      "  episodes_this_iter: 140\n",
      "  episodes_total: 115893\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.056\n",
      "    load_time_ms: 1.401\n",
      "    num_steps_sampled: 9130000\n",
      "    num_steps_trained: 9130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6327475309371948\n",
      "      kl: 0.021841635927557945\n",
      "      policy_loss: 0.0045898971147835255\n",
      "      total_loss: 59.90776443481445\n",
      "      vf_explained_var: 0.8897212147712708\n",
      "      vf_loss: 59.900978088378906\n",
      "    sample_time_ms: 18237.778\n",
      "    update_time_ms: 5.695\n",
      "  iterations_since_restore: 913\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.79571361814981\n",
      "  time_since_restore: 20062.325065374374\n",
      "  time_this_iter_s: 22.11970281600952\n",
      "  time_total_s: 20062.325065374374\n",
      "  timestamp: 1553141894\n",
      "  timesteps_since_restore: 9130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9130000\n",
      "  training_iteration: 913\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20062 s, 913 iter, 9130000 ts, 33.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-18-36\n",
      "  done: false\n",
      "  episode_len_mean: 82.82644628099173\n",
      "  episode_reward_max: 391.2669591992619\n",
      "  episode_reward_mean: 117.54686038881226\n",
      "  episode_reward_min: -162.57560590800284\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 116014\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.156\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 9140000\n",
      "    num_steps_trained: 9140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5896815061569214\n",
      "      kl: 0.020754652097821236\n",
      "      policy_loss: 0.006842026952654123\n",
      "      total_loss: 47.5036735534668\n",
      "      vf_explained_var: 0.8804176449775696\n",
      "      vf_loss: 47.494747161865234\n",
      "    sample_time_ms: 18171.971\n",
      "    update_time_ms: 5.605\n",
      "  iterations_since_restore: 914\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.77343019440613\n",
      "  time_since_restore: 20083.72873187065\n",
      "  time_this_iter_s: 21.403666496276855\n",
      "  time_total_s: 20083.72873187065\n",
      "  timestamp: 1553141916\n",
      "  timesteps_since_restore: 9140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9140000\n",
      "  training_iteration: 914\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20083 s, 914 iter, 9140000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-18-57\n",
      "  done: false\n",
      "  episode_len_mean: 77.44615384615385\n",
      "  episode_reward_max: 386.1802769406875\n",
      "  episode_reward_mean: 86.19210111014742\n",
      "  episode_reward_min: -166.7381532865429\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 116144\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.47\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 9150000\n",
      "    num_steps_trained: 9150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6108111143112183\n",
      "      kl: 0.026355434209108353\n",
      "      policy_loss: 0.00972719956189394\n",
      "      total_loss: 46.840023040771484\n",
      "      vf_explained_var: 0.8989874124526978\n",
      "      vf_loss: 46.82764434814453\n",
      "    sample_time_ms: 18097.856\n",
      "    update_time_ms: 5.663\n",
      "  iterations_since_restore: 915\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.0960505550737\n",
      "  time_since_restore: 20105.344559192657\n",
      "  time_this_iter_s: 21.615827322006226\n",
      "  time_total_s: 20105.344559192657\n",
      "  timestamp: 1553141937\n",
      "  timesteps_since_restore: 9150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9150000\n",
      "  training_iteration: 915\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20105 s, 915 iter, 9150000 ts, 86.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 77.765625\n",
      "  episode_reward_max: 392.36455244358814\n",
      "  episode_reward_mean: 85.1841852235168\n",
      "  episode_reward_min: -166.73389320096015\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 116272\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.282\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 9160000\n",
      "    num_steps_trained: 9160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6024499535560608\n",
      "      kl: 0.01966950297355652\n",
      "      policy_loss: 0.0029789870604872704\n",
      "      total_loss: 45.99393844604492\n",
      "      vf_explained_var: 0.8987151980400085\n",
      "      vf_loss: 45.988983154296875\n",
      "    sample_time_ms: 18088.665\n",
      "    update_time_ms: 5.353\n",
      "  iterations_since_restore: 916\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.5920926117584\n",
      "  time_since_restore: 20127.045302152634\n",
      "  time_this_iter_s: 21.700742959976196\n",
      "  time_total_s: 20127.045302152634\n",
      "  timestamp: 1553141959\n",
      "  timesteps_since_restore: 9160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9160000\n",
      "  training_iteration: 916\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20127 s, 916 iter, 9160000 ts, 85.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-19-41\n",
      "  done: false\n",
      "  episode_len_mean: 80.0079365079365\n",
      "  episode_reward_max: 389.064886246682\n",
      "  episode_reward_mean: 102.53767396408954\n",
      "  episode_reward_min: -168.7094647960329\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 116398\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.776\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 9170000\n",
      "    num_steps_trained: 9170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6164059638977051\n",
      "      kl: 0.017800744622945786\n",
      "      policy_loss: 0.0019191706087440252\n",
      "      total_loss: 43.28915786743164\n",
      "      vf_explained_var: 0.8994964361190796\n",
      "      vf_loss: 43.28544616699219\n",
      "    sample_time_ms: 18111.504\n",
      "    update_time_ms: 5.527\n",
      "  iterations_since_restore: 917\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.268836982044775\n",
      "  time_since_restore: 20149.16898560524\n",
      "  time_this_iter_s: 22.1236834526062\n",
      "  time_total_s: 20149.16898560524\n",
      "  timestamp: 1553141981\n",
      "  timesteps_since_restore: 9170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9170000\n",
      "  training_iteration: 917\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20149 s, 917 iter, 9170000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-20-03\n",
      "  done: false\n",
      "  episode_len_mean: 76.54615384615384\n",
      "  episode_reward_max: 387.89396265229317\n",
      "  episode_reward_mean: 77.26772212501976\n",
      "  episode_reward_min: -168.72315501173972\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 116528\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.82\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 9180000\n",
      "    num_steps_trained: 9180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6194691061973572\n",
      "      kl: 0.022179385647177696\n",
      "      policy_loss: 0.005045031663030386\n",
      "      total_loss: 41.800987243652344\n",
      "      vf_explained_var: 0.9111378192901611\n",
      "      vf_loss: 41.7937126159668\n",
      "    sample_time_ms: 18066.319\n",
      "    update_time_ms: 5.621\n",
      "  iterations_since_restore: 918\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.63386106250988\n",
      "  time_since_restore: 20170.680679559708\n",
      "  time_this_iter_s: 21.511693954467773\n",
      "  time_total_s: 20170.680679559708\n",
      "  timestamp: 1553142003\n",
      "  timesteps_since_restore: 9180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9180000\n",
      "  training_iteration: 918\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20170 s, 918 iter, 9180000 ts, 77.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-20-25\n",
      "  done: false\n",
      "  episode_len_mean: 79.07142857142857\n",
      "  episode_reward_max: 392.25338548669555\n",
      "  episode_reward_mean: 94.19039976908259\n",
      "  episode_reward_min: -168.73354216953754\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 116654\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.939\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 9190000\n",
      "    num_steps_trained: 9190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6043573021888733\n",
      "      kl: 0.01857093907892704\n",
      "      policy_loss: 0.002550350036472082\n",
      "      total_loss: 52.6074333190918\n",
      "      vf_explained_var: 0.8811439871788025\n",
      "      vf_loss: 52.60302734375\n",
      "    sample_time_ms: 18105.445\n",
      "    update_time_ms: 5.465\n",
      "  iterations_since_restore: 919\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.09519988454129\n",
      "  time_since_restore: 20192.56095767021\n",
      "  time_this_iter_s: 21.88027811050415\n",
      "  time_total_s: 20192.56095767021\n",
      "  timestamp: 1553142025\n",
      "  timesteps_since_restore: 9190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9190000\n",
      "  training_iteration: 919\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20192 s, 919 iter, 9190000 ts, 94.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-20-46\n",
      "  done: false\n",
      "  episode_len_mean: 79.832\n",
      "  episode_reward_max: 387.9381573019769\n",
      "  episode_reward_mean: 97.96900142713332\n",
      "  episode_reward_min: -162.61291892656328\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 116779\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.026\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 9200000\n",
      "    num_steps_trained: 9200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6238614320755005\n",
      "      kl: 0.018057502806186676\n",
      "      policy_loss: 0.004081680439412594\n",
      "      total_loss: 47.532466888427734\n",
      "      vf_explained_var: 0.8906430006027222\n",
      "      vf_loss: 47.52656936645508\n",
      "    sample_time_ms: 18074.669\n",
      "    update_time_ms: 5.551\n",
      "  iterations_since_restore: 920\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.98450071356667\n",
      "  time_since_restore: 20214.317934513092\n",
      "  time_this_iter_s: 21.75697684288025\n",
      "  time_total_s: 20214.317934513092\n",
      "  timestamp: 1553142046\n",
      "  timesteps_since_restore: 9200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9200000\n",
      "  training_iteration: 920\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20214 s, 920 iter, 9200000 ts, 98 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-21-08\n",
      "  done: false\n",
      "  episode_len_mean: 82.49180327868852\n",
      "  episode_reward_max: 392.054126959256\n",
      "  episode_reward_mean: 118.24388730604883\n",
      "  episode_reward_min: -164.66215227505208\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 116901\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.67\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 9210000\n",
      "    num_steps_trained: 9210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5886408686637878\n",
      "      kl: 0.01741313561797142\n",
      "      policy_loss: 0.0024819006212055683\n",
      "      total_loss: 47.35818099975586\n",
      "      vf_explained_var: 0.8813668489456177\n",
      "      vf_loss: 47.353946685791016\n",
      "    sample_time_ms: 18043.521\n",
      "    update_time_ms: 5.426\n",
      "  iterations_since_restore: 921\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.121943653024395\n",
      "  time_since_restore: 20235.865676403046\n",
      "  time_this_iter_s: 21.547741889953613\n",
      "  time_total_s: 20235.865676403046\n",
      "  timestamp: 1553142068\n",
      "  timesteps_since_restore: 9210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9210000\n",
      "  training_iteration: 921\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20235 s, 921 iter, 9210000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-21-30\n",
      "  done: false\n",
      "  episode_len_mean: 77.6124031007752\n",
      "  episode_reward_max: 385.33174043153707\n",
      "  episode_reward_mean: 82.05673218160766\n",
      "  episode_reward_min: -164.68579981657507\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 117030\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.243\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 9220000\n",
      "    num_steps_trained: 9220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5976165533065796\n",
      "      kl: 0.01948114112019539\n",
      "      policy_loss: 0.0033931767102330923\n",
      "      total_loss: 37.776771545410156\n",
      "      vf_explained_var: 0.9190284609794617\n",
      "      vf_loss: 37.77142333984375\n",
      "    sample_time_ms: 17992.188\n",
      "    update_time_ms: 5.423\n",
      "  iterations_since_restore: 922\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 41.02836609080382\n",
      "  time_since_restore: 20257.464645147324\n",
      "  time_this_iter_s: 21.598968744277954\n",
      "  time_total_s: 20257.464645147324\n",
      "  timestamp: 1553142090\n",
      "  timesteps_since_restore: 9220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9220000\n",
      "  training_iteration: 922\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20257 s, 922 iter, 9220000 ts, 82.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-21-52\n",
      "  done: false\n",
      "  episode_len_mean: 79.384\n",
      "  episode_reward_max: 388.8861545145695\n",
      "  episode_reward_mean: 100.21066024764434\n",
      "  episode_reward_min: -164.65894837388038\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 117155\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.065\n",
      "    load_time_ms: 1.638\n",
      "    num_steps_sampled: 9230000\n",
      "    num_steps_trained: 9230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6044591069221497\n",
      "      kl: 0.014917743392288685\n",
      "      policy_loss: 0.004881323780864477\n",
      "      total_loss: 45.44265365600586\n",
      "      vf_explained_var: 0.8933340311050415\n",
      "      vf_loss: 45.436279296875\n",
      "    sample_time_ms: 17974.016\n",
      "    update_time_ms: 4.985\n",
      "  iterations_since_restore: 923\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.105330123822164\n",
      "  time_since_restore: 20279.41794347763\n",
      "  time_this_iter_s: 21.953298330307007\n",
      "  time_total_s: 20279.41794347763\n",
      "  timestamp: 1553142112\n",
      "  timesteps_since_restore: 9230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9230000\n",
      "  training_iteration: 923\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20279 s, 923 iter, 9230000 ts, 100 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-22-13\n",
      "  done: false\n",
      "  episode_len_mean: 81.81147540983606\n",
      "  episode_reward_max: 389.1992902495516\n",
      "  episode_reward_mean: 115.8039231111682\n",
      "  episode_reward_min: -164.65380378028394\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 117277\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.446\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 9240000\n",
      "    num_steps_trained: 9240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5929651260375977\n",
      "      kl: 0.02167218178510666\n",
      "      policy_loss: 0.005808348301798105\n",
      "      total_loss: 46.162296295166016\n",
      "      vf_explained_var: 0.887978196144104\n",
      "      vf_loss: 46.15431594848633\n",
      "    sample_time_ms: 18006.966\n",
      "    update_time_ms: 5.113\n",
      "  iterations_since_restore: 924\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 57.90196155558411\n",
      "  time_since_restore: 20301.182647705078\n",
      "  time_this_iter_s: 21.76470422744751\n",
      "  time_total_s: 20301.182647705078\n",
      "  timestamp: 1553142133\n",
      "  timesteps_since_restore: 9240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9240000\n",
      "  training_iteration: 924\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20301 s, 924 iter, 9240000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-22-36\n",
      "  done: false\n",
      "  episode_len_mean: 84.42857142857143\n",
      "  episode_reward_max: 386.7886012857439\n",
      "  episode_reward_mean: 128.40377252303432\n",
      "  episode_reward_min: -166.80838439461232\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 117396\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.034\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 9250000\n",
      "    num_steps_trained: 9250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5749995112419128\n",
      "      kl: 0.025259779766201973\n",
      "      policy_loss: 0.007734527345746756\n",
      "      total_loss: 40.39897918701172\n",
      "      vf_explained_var: 0.8958465456962585\n",
      "      vf_loss: 40.388710021972656\n",
      "    sample_time_ms: 18063.791\n",
      "    update_time_ms: 5.158\n",
      "  iterations_since_restore: 925\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.20188626151717\n",
      "  time_since_restore: 20323.348890066147\n",
      "  time_this_iter_s: 22.166242361068726\n",
      "  time_total_s: 20323.348890066147\n",
      "  timestamp: 1553142156\n",
      "  timesteps_since_restore: 9250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9250000\n",
      "  training_iteration: 925\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20323 s, 925 iter, 9250000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-22-57\n",
      "  done: false\n",
      "  episode_len_mean: 78.1953125\n",
      "  episode_reward_max: 385.61873704505945\n",
      "  episode_reward_mean: 88.97296774662183\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 117524\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.419\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 9260000\n",
      "    num_steps_trained: 9260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6113618016242981\n",
      "      kl: 0.0169865470379591\n",
      "      policy_loss: 0.002664815401658416\n",
      "      total_loss: 43.20022201538086\n",
      "      vf_explained_var: 0.9052491784095764\n",
      "      vf_loss: 43.19585418701172\n",
      "    sample_time_ms: 18065.662\n",
      "    update_time_ms: 5.239\n",
      "  iterations_since_restore: 926\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.48648387331091\n",
      "  time_since_restore: 20345.061879634857\n",
      "  time_this_iter_s: 21.712989568710327\n",
      "  time_total_s: 20345.061879634857\n",
      "  timestamp: 1553142177\n",
      "  timesteps_since_restore: 9260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9260000\n",
      "  training_iteration: 926\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20345 s, 926 iter, 9260000 ts, 89 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-23-19\n",
      "  done: false\n",
      "  episode_len_mean: 76.06870229007633\n",
      "  episode_reward_max: 388.49248897509557\n",
      "  episode_reward_mean: 70.13682579959345\n",
      "  episode_reward_min: -168.72177194186688\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 117655\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.131\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 9270000\n",
      "    num_steps_trained: 9270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6103790402412415\n",
      "      kl: 0.01687874086201191\n",
      "      policy_loss: 0.004044742789119482\n",
      "      total_loss: 47.20370101928711\n",
      "      vf_explained_var: 0.9011995196342468\n",
      "      vf_loss: 47.197959899902344\n",
      "    sample_time_ms: 18070.24\n",
      "    update_time_ms: 5.161\n",
      "  iterations_since_restore: 927\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.06841289979672\n",
      "  time_since_restore: 20366.94685268402\n",
      "  time_this_iter_s: 21.88497304916382\n",
      "  time_total_s: 20366.94685268402\n",
      "  timestamp: 1553142199\n",
      "  timesteps_since_restore: 9270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9270000\n",
      "  training_iteration: 927\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20366 s, 927 iter, 9270000 ts, 70.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-23-42\n",
      "  done: false\n",
      "  episode_len_mean: 81.29032258064517\n",
      "  episode_reward_max: 391.6107005974317\n",
      "  episode_reward_mean: 112.35882701006466\n",
      "  episode_reward_min: -164.70514639398098\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 117779\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.768\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 9280000\n",
      "    num_steps_trained: 9280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5839845538139343\n",
      "      kl: 0.018697666004300117\n",
      "      policy_loss: 0.007035990711301565\n",
      "      total_loss: 39.12887191772461\n",
      "      vf_explained_var: 0.9044817686080933\n",
      "      vf_loss: 39.11996078491211\n",
      "    sample_time_ms: 18219.4\n",
      "    update_time_ms: 5.223\n",
      "  iterations_since_restore: 928\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.17941350503233\n",
      "  time_since_restore: 20390.094594478607\n",
      "  time_this_iter_s: 23.14774179458618\n",
      "  time_total_s: 20390.094594478607\n",
      "  timestamp: 1553142222\n",
      "  timesteps_since_restore: 9280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9280000\n",
      "  training_iteration: 928\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20390 s, 928 iter, 9280000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-24-04\n",
      "  done: false\n",
      "  episode_len_mean: 81.44715447154472\n",
      "  episode_reward_max: 387.5606152134816\n",
      "  episode_reward_mean: 110.68145135541526\n",
      "  episode_reward_min: -168.66600399264337\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 117902\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.587\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 9290000\n",
      "    num_steps_trained: 9290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5727798342704773\n",
      "      kl: 0.03053915873169899\n",
      "      policy_loss: 0.006744008045643568\n",
      "      total_loss: 33.694305419921875\n",
      "      vf_explained_var: 0.9177406430244446\n",
      "      vf_loss: 33.68449401855469\n",
      "    sample_time_ms: 18168.024\n",
      "    update_time_ms: 5.242\n",
      "  iterations_since_restore: 929\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.340725677707624\n",
      "  time_since_restore: 20411.47869992256\n",
      "  time_this_iter_s: 21.384105443954468\n",
      "  time_total_s: 20411.47869992256\n",
      "  timestamp: 1553142244\n",
      "  timesteps_since_restore: 9290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9290000\n",
      "  training_iteration: 929\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20411 s, 929 iter, 9290000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-24-26\n",
      "  done: false\n",
      "  episode_len_mean: 80.8780487804878\n",
      "  episode_reward_max: 389.0678303558483\n",
      "  episode_reward_mean: 110.01788976759094\n",
      "  episode_reward_min: -166.71701628276347\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 118025\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.262\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 9300000\n",
      "    num_steps_trained: 9300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5865671038627625\n",
      "      kl: 0.026281185448169708\n",
      "      policy_loss: 0.008138896897435188\n",
      "      total_loss: 46.34750747680664\n",
      "      vf_explained_var: 0.8894267678260803\n",
      "      vf_loss: 46.336727142333984\n",
      "    sample_time_ms: 18214.541\n",
      "    update_time_ms: 5.132\n",
      "  iterations_since_restore: 930\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.00894488379547\n",
      "  time_since_restore: 20433.735183238983\n",
      "  time_this_iter_s: 22.25648331642151\n",
      "  time_total_s: 20433.735183238983\n",
      "  timestamp: 1553142266\n",
      "  timesteps_since_restore: 9300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9300000\n",
      "  training_iteration: 930\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20433 s, 930 iter, 9300000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-24-48\n",
      "  done: false\n",
      "  episode_len_mean: 78.7421875\n",
      "  episode_reward_max: 388.3854503371038\n",
      "  episode_reward_mean: 88.29606827871807\n",
      "  episode_reward_min: -166.70714055201054\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 118153\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.908\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 9310000\n",
      "    num_steps_trained: 9310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.600743293762207\n",
      "      kl: 0.019533945247530937\n",
      "      policy_loss: 0.005181134678423405\n",
      "      total_loss: 56.01960754394531\n",
      "      vf_explained_var: 0.8786871433258057\n",
      "      vf_loss: 56.01244354248047\n",
      "    sample_time_ms: 18278.439\n",
      "    update_time_ms: 5.142\n",
      "  iterations_since_restore: 931\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.148034139359034\n",
      "  time_since_restore: 20455.92903828621\n",
      "  time_this_iter_s: 22.193855047225952\n",
      "  time_total_s: 20455.92903828621\n",
      "  timestamp: 1553142288\n",
      "  timesteps_since_restore: 9310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9310000\n",
      "  training_iteration: 931\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20455 s, 931 iter, 9310000 ts, 88.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-25-10\n",
      "  done: false\n",
      "  episode_len_mean: 81.21487603305785\n",
      "  episode_reward_max: 388.69110521258443\n",
      "  episode_reward_mean: 106.02057467141154\n",
      "  episode_reward_min: -166.67861106904985\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 118274\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.118\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 9320000\n",
      "    num_steps_trained: 9320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.588280975818634\n",
      "      kl: 0.01985028199851513\n",
      "      policy_loss: 0.00554549228399992\n",
      "      total_loss: 51.00493240356445\n",
      "      vf_explained_var: 0.8772667050361633\n",
      "      vf_loss: 50.99739074707031\n",
      "    sample_time_ms: 18243.151\n",
      "    update_time_ms: 5.516\n",
      "  iterations_since_restore: 932\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.010287335705776\n",
      "  time_since_restore: 20477.33241057396\n",
      "  time_this_iter_s: 21.403372287750244\n",
      "  time_total_s: 20477.33241057396\n",
      "  timestamp: 1553142310\n",
      "  timesteps_since_restore: 9320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9320000\n",
      "  training_iteration: 932\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20477 s, 932 iter, 9320000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-25-32\n",
      "  done: false\n",
      "  episode_len_mean: 81.31451612903226\n",
      "  episode_reward_max: 386.6822336024297\n",
      "  episode_reward_mean: 107.78384711817806\n",
      "  episode_reward_min: -161.82247628220557\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 118398\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.825\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 9330000\n",
      "    num_steps_trained: 9330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5966373085975647\n",
      "      kl: 0.01847553811967373\n",
      "      policy_loss: 0.0031791336368769407\n",
      "      total_loss: 51.21056365966797\n",
      "      vf_explained_var: 0.8807606101036072\n",
      "      vf_loss: 51.20552444458008\n",
      "    sample_time_ms: 18243.811\n",
      "    update_time_ms: 5.652\n",
      "  iterations_since_restore: 933\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.89192355908902\n",
      "  time_since_restore: 20499.275636196136\n",
      "  time_this_iter_s: 21.943225622177124\n",
      "  time_total_s: 20499.275636196136\n",
      "  timestamp: 1553142332\n",
      "  timesteps_since_restore: 9330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9330000\n",
      "  training_iteration: 933\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20499 s, 933 iter, 9330000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-25-54\n",
      "  done: false\n",
      "  episode_len_mean: 76.12213740458016\n",
      "  episode_reward_max: 385.71112240652883\n",
      "  episode_reward_mean: 75.38853519249878\n",
      "  episode_reward_min: -166.67444447084904\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 118529\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.622\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 9340000\n",
      "    num_steps_trained: 9340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5964932441711426\n",
      "      kl: 0.027788473293185234\n",
      "      policy_loss: 0.007876258343458176\n",
      "      total_loss: 46.02433776855469\n",
      "      vf_explained_var: 0.902475893497467\n",
      "      vf_loss: 46.013668060302734\n",
      "    sample_time_ms: 18311.689\n",
      "    update_time_ms: 5.618\n",
      "  iterations_since_restore: 934\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.69426759624938\n",
      "  time_since_restore: 20521.69197702408\n",
      "  time_this_iter_s: 22.416340827941895\n",
      "  time_total_s: 20521.69197702408\n",
      "  timestamp: 1553142354\n",
      "  timesteps_since_restore: 9340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9340000\n",
      "  training_iteration: 934\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20521 s, 934 iter, 9340000 ts, 75.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-26-17\n",
      "  done: false\n",
      "  episode_len_mean: 78.35658914728683\n",
      "  episode_reward_max: 387.8711873327943\n",
      "  episode_reward_mean: 87.34134153604965\n",
      "  episode_reward_min: -166.7121713784599\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 118658\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.468\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 9350000\n",
      "    num_steps_trained: 9350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5758387446403503\n",
      "      kl: 0.019826510921120644\n",
      "      policy_loss: 0.0036414999049156904\n",
      "      total_loss: 46.54964828491211\n",
      "      vf_explained_var: 0.8990431427955627\n",
      "      vf_loss: 46.54402542114258\n",
      "    sample_time_ms: 18336.94\n",
      "    update_time_ms: 5.706\n",
      "  iterations_since_restore: 935\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 43.67067076802483\n",
      "  time_since_restore: 20544.126535892487\n",
      "  time_this_iter_s: 22.434558868408203\n",
      "  time_total_s: 20544.126535892487\n",
      "  timestamp: 1553142377\n",
      "  timesteps_since_restore: 9350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9350000\n",
      "  training_iteration: 935\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20544 s, 935 iter, 9350000 ts, 87.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-26-38\n",
      "  done: false\n",
      "  episode_len_mean: 82.43333333333334\n",
      "  episode_reward_max: 386.4364800164906\n",
      "  episode_reward_mean: 116.77237139392496\n",
      "  episode_reward_min: -162.5920694552326\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 118778\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.401\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 9360000\n",
      "    num_steps_trained: 9360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5765164494514465\n",
      "      kl: 0.01818472519516945\n",
      "      policy_loss: 0.004744305741041899\n",
      "      total_loss: 34.58259582519531\n",
      "      vf_explained_var: 0.9154176115989685\n",
      "      vf_loss: 34.576026916503906\n",
      "    sample_time_ms: 18295.983\n",
      "    update_time_ms: 5.636\n",
      "  iterations_since_restore: 936\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.38618569696247\n",
      "  time_since_restore: 20565.441571235657\n",
      "  time_this_iter_s: 21.315035343170166\n",
      "  time_total_s: 20565.441571235657\n",
      "  timestamp: 1553142398\n",
      "  timesteps_since_restore: 9360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9360000\n",
      "  training_iteration: 936\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20565 s, 936 iter, 9360000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-27-00\n",
      "  done: false\n",
      "  episode_len_mean: 79.9047619047619\n",
      "  episode_reward_max: 384.3409064721107\n",
      "  episode_reward_mean: 100.26649052641204\n",
      "  episode_reward_min: -168.763477265563\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 118904\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.956\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 9370000\n",
      "    num_steps_trained: 9370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5635614395141602\n",
      "      kl: 0.01835777796804905\n",
      "      policy_loss: 0.0031211499590426683\n",
      "      total_loss: 44.98734664916992\n",
      "      vf_explained_var: 0.8965438604354858\n",
      "      vf_loss: 44.98238754272461\n",
      "    sample_time_ms: 18317.007\n",
      "    update_time_ms: 5.534\n",
      "  iterations_since_restore: 937\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.133245263206014\n",
      "  time_since_restore: 20587.549929380417\n",
      "  time_this_iter_s: 22.108358144760132\n",
      "  time_total_s: 20587.549929380417\n",
      "  timestamp: 1553142420\n",
      "  timesteps_since_restore: 9370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9370000\n",
      "  training_iteration: 937\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20587 s, 937 iter, 9370000 ts, 100 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-27-23\n",
      "  done: false\n",
      "  episode_len_mean: 78.1953125\n",
      "  episode_reward_max: 388.7349000940876\n",
      "  episode_reward_mean: 90.87577514972432\n",
      "  episode_reward_min: -168.7358112456465\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 119032\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.431\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 9380000\n",
      "    num_steps_trained: 9380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5719671845436096\n",
      "      kl: 0.017236748710274696\n",
      "      policy_loss: 0.003171738237142563\n",
      "      total_loss: 38.782283782958984\n",
      "      vf_explained_var: 0.9129323959350586\n",
      "      vf_loss: 38.777381896972656\n",
      "    sample_time_ms: 18238.667\n",
      "    update_time_ms: 5.4\n",
      "  iterations_since_restore: 938\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.43788757486216\n",
      "  time_since_restore: 20609.751064538956\n",
      "  time_this_iter_s: 22.20113515853882\n",
      "  time_total_s: 20609.751064538956\n",
      "  timestamp: 1553142443\n",
      "  timesteps_since_restore: 9380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9380000\n",
      "  training_iteration: 938\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20609 s, 938 iter, 9380000 ts, 90.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-27-45\n",
      "  done: false\n",
      "  episode_len_mean: 77.13846153846154\n",
      "  episode_reward_max: 380.79709262155563\n",
      "  episode_reward_mean: 77.75679391042584\n",
      "  episode_reward_min: -168.83928861793518\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 119162\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.394\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 9390000\n",
      "    num_steps_trained: 9390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5778915882110596\n",
      "      kl: 0.015536820515990257\n",
      "      policy_loss: 0.003768847556784749\n",
      "      total_loss: 46.99887466430664\n",
      "      vf_explained_var: 0.9001917839050293\n",
      "      vf_loss: 46.99354553222656\n",
      "    sample_time_ms: 18298.575\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 939\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 38.87839695521293\n",
      "  time_since_restore: 20631.697786092758\n",
      "  time_this_iter_s: 21.94672155380249\n",
      "  time_total_s: 20631.697786092758\n",
      "  timestamp: 1553142465\n",
      "  timesteps_since_restore: 9390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9390000\n",
      "  training_iteration: 939\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20631 s, 939 iter, 9390000 ts, 77.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-28-07\n",
      "  done: false\n",
      "  episode_len_mean: 74.92481203007519\n",
      "  episode_reward_max: 388.73897628702696\n",
      "  episode_reward_mean: 62.84895959314104\n",
      "  episode_reward_min: -164.9080088951254\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 119295\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.23\n",
      "    load_time_ms: 1.638\n",
      "    num_steps_sampled: 9400000\n",
      "    num_steps_trained: 9400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6035532355308533\n",
      "      kl: 0.016136031597852707\n",
      "      policy_loss: 0.001309501356445253\n",
      "      total_loss: 42.319091796875\n",
      "      vf_explained_var: 0.9137591123580933\n",
      "      vf_loss: 42.316158294677734\n",
      "    sample_time_ms: 18290.567\n",
      "    update_time_ms: 5.439\n",
      "  iterations_since_restore: 940\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 31.424479796570512\n",
      "  time_since_restore: 20653.892709493637\n",
      "  time_this_iter_s: 22.194923400878906\n",
      "  time_total_s: 20653.892709493637\n",
      "  timestamp: 1553142487\n",
      "  timesteps_since_restore: 9400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9400000\n",
      "  training_iteration: 940\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20653 s, 940 iter, 9400000 ts, 62.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-28-28\n",
      "  done: false\n",
      "  episode_len_mean: 80.416\n",
      "  episode_reward_max: 388.1444060536511\n",
      "  episode_reward_mean: 101.6869433867069\n",
      "  episode_reward_min: -168.77443873080253\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 119420\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.448\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 9410000\n",
      "    num_steps_trained: 9410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5746751427650452\n",
      "      kl: 0.019613368436694145\n",
      "      policy_loss: 0.004181094001978636\n",
      "      total_loss: 56.45871353149414\n",
      "      vf_explained_var: 0.8664460778236389\n",
      "      vf_loss: 56.45256805419922\n",
      "    sample_time_ms: 18225.781\n",
      "    update_time_ms: 5.583\n",
      "  iterations_since_restore: 941\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.84347169335344\n",
      "  time_since_restore: 20675.442429304123\n",
      "  time_this_iter_s: 21.54971981048584\n",
      "  time_total_s: 20675.442429304123\n",
      "  timestamp: 1553142508\n",
      "  timesteps_since_restore: 9410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9410000\n",
      "  training_iteration: 941\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20675 s, 941 iter, 9410000 ts, 102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-28-50\n",
      "  done: false\n",
      "  episode_len_mean: 83.10924369747899\n",
      "  episode_reward_max: 386.8366907727047\n",
      "  episode_reward_mean: 117.04538646195967\n",
      "  episode_reward_min: -164.73945626541615\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 119539\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3680.827\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 9420000\n",
      "    num_steps_trained: 9420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.541692852973938\n",
      "      kl: 0.019906645640730858\n",
      "      policy_loss: 0.0032412188593298197\n",
      "      total_loss: 33.65522766113281\n",
      "      vf_explained_var: 0.9155492782592773\n",
      "      vf_loss: 33.649986267089844\n",
      "    sample_time_ms: 18295.488\n",
      "    update_time_ms: 5.214\n",
      "  iterations_since_restore: 942\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.522693230979826\n",
      "  time_since_restore: 20697.349989652634\n",
      "  time_this_iter_s: 21.907560348510742\n",
      "  time_total_s: 20697.349989652634\n",
      "  timestamp: 1553142530\n",
      "  timesteps_since_restore: 9420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9420000\n",
      "  training_iteration: 942\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20697 s, 942 iter, 9420000 ts, 117 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-29-13\n",
      "  done: false\n",
      "  episode_len_mean: 78.2265625\n",
      "  episode_reward_max: 385.83301896978446\n",
      "  episode_reward_mean: 91.23756627722818\n",
      "  episode_reward_min: -166.75966990062236\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 119667\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.118\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 9430000\n",
      "    num_steps_trained: 9430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5586663484573364\n",
      "      kl: 0.017798949033021927\n",
      "      policy_loss: 0.00312678050249815\n",
      "      total_loss: 51.71112060546875\n",
      "      vf_explained_var: 0.8857490420341492\n",
      "      vf_loss: 51.70620346069336\n",
      "    sample_time_ms: 18332.805\n",
      "    update_time_ms: 5.282\n",
      "  iterations_since_restore: 943\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.618783138614084\n",
      "  time_since_restore: 20719.772869110107\n",
      "  time_this_iter_s: 22.422879457473755\n",
      "  time_total_s: 20719.772869110107\n",
      "  timestamp: 1553142553\n",
      "  timesteps_since_restore: 9430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9430000\n",
      "  training_iteration: 943\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20719 s, 943 iter, 9430000 ts, 91.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-29-35\n",
      "  done: false\n",
      "  episode_len_mean: 85.28813559322033\n",
      "  episode_reward_max: 388.94644437366844\n",
      "  episode_reward_mean: 137.2148472335129\n",
      "  episode_reward_min: -166.84307274207114\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 119785\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.703\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 9440000\n",
      "    num_steps_trained: 9440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5284519791603088\n",
      "      kl: 0.017217811197042465\n",
      "      policy_loss: 0.004002359230071306\n",
      "      total_loss: 37.738067626953125\n",
      "      vf_explained_var: 0.8996722102165222\n",
      "      vf_loss: 37.732337951660156\n",
      "    sample_time_ms: 18270.811\n",
      "    update_time_ms: 5.329\n",
      "  iterations_since_restore: 944\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.60742361675644\n",
      "  time_since_restore: 20741.55298113823\n",
      "  time_this_iter_s: 21.78011202812195\n",
      "  time_total_s: 20741.55298113823\n",
      "  timestamp: 1553142575\n",
      "  timesteps_since_restore: 9440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9440000\n",
      "  training_iteration: 944\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20741 s, 944 iter, 9440000 ts, 137 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-29-57\n",
      "  done: false\n",
      "  episode_len_mean: 80.99180327868852\n",
      "  episode_reward_max: 391.0453461632014\n",
      "  episode_reward_mean: 107.01116508865753\n",
      "  episode_reward_min: -166.76673120078087\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 119907\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.818\n",
      "    load_time_ms: 1.624\n",
      "    num_steps_sampled: 9450000\n",
      "    num_steps_trained: 9450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5823578238487244\n",
      "      kl: 0.016035279259085655\n",
      "      policy_loss: 0.0026360924821347\n",
      "      total_loss: 53.89152526855469\n",
      "      vf_explained_var: 0.8688014149665833\n",
      "      vf_loss: 53.88728332519531\n",
      "    sample_time_ms: 18257.789\n",
      "    update_time_ms: 5.148\n",
      "  iterations_since_restore: 945\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.505582544328774\n",
      "  time_since_restore: 20763.84680390358\n",
      "  time_this_iter_s: 22.293822765350342\n",
      "  time_total_s: 20763.84680390358\n",
      "  timestamp: 1553142597\n",
      "  timesteps_since_restore: 9450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9450000\n",
      "  training_iteration: 945\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20763 s, 945 iter, 9450000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-30-19\n",
      "  done: false\n",
      "  episode_len_mean: 80.72\n",
      "  episode_reward_max: 389.11555561826094\n",
      "  episode_reward_mean: 101.82642480052199\n",
      "  episode_reward_min: -164.75719839807988\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 120032\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.408\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 9460000\n",
      "    num_steps_trained: 9460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5727853178977966\n",
      "      kl: 0.016237910836935043\n",
      "      policy_loss: 0.0027617360465228558\n",
      "      total_loss: 46.36309814453125\n",
      "      vf_explained_var: 0.8945686221122742\n",
      "      vf_loss: 46.35870361328125\n",
      "    sample_time_ms: 18302.735\n",
      "    update_time_ms: 5.241\n",
      "  iterations_since_restore: 946\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.913212400261\n",
      "  time_since_restore: 20785.58651638031\n",
      "  time_this_iter_s: 21.739712476730347\n",
      "  time_total_s: 20785.58651638031\n",
      "  timestamp: 1553142619\n",
      "  timesteps_since_restore: 9460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9460000\n",
      "  training_iteration: 946\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20785 s, 946 iter, 9460000 ts, 102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-30-41\n",
      "  done: false\n",
      "  episode_len_mean: 81.54471544715447\n",
      "  episode_reward_max: 392.3817702055454\n",
      "  episode_reward_mean: 113.85113168861182\n",
      "  episode_reward_min: -166.70325194295884\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 120155\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.264\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 9470000\n",
      "    num_steps_trained: 9470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5486710667610168\n",
      "      kl: 0.01804346591234207\n",
      "      policy_loss: 0.0040040272288024426\n",
      "      total_loss: 48.08634948730469\n",
      "      vf_explained_var: 0.8841520547866821\n",
      "      vf_loss: 48.08053207397461\n",
      "    sample_time_ms: 18269.103\n",
      "    update_time_ms: 5.376\n",
      "  iterations_since_restore: 947\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.925565844305886\n",
      "  time_since_restore: 20807.418879508972\n",
      "  time_this_iter_s: 21.83236312866211\n",
      "  time_total_s: 20807.418879508972\n",
      "  timestamp: 1553142641\n",
      "  timesteps_since_restore: 9470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9470000\n",
      "  training_iteration: 947\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20807 s, 947 iter, 9470000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-31-02\n",
      "  done: false\n",
      "  episode_len_mean: 87.69298245614036\n",
      "  episode_reward_max: 388.7019257343702\n",
      "  episode_reward_mean: 150.19302543477437\n",
      "  episode_reward_min: -166.69229420610904\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 120269\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.682\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 9480000\n",
      "    num_steps_trained: 9480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5507401823997498\n",
      "      kl: 0.023318253457546234\n",
      "      policy_loss: 0.0017338430043309927\n",
      "      total_loss: 32.891151428222656\n",
      "      vf_explained_var: 0.9128184914588928\n",
      "      vf_loss: 32.88707733154297\n",
      "    sample_time_ms: 18185.319\n",
      "    update_time_ms: 5.311\n",
      "  iterations_since_restore: 948\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.09651271738718\n",
      "  time_since_restore: 20828.80554175377\n",
      "  time_this_iter_s: 21.386662244796753\n",
      "  time_total_s: 20828.80554175377\n",
      "  timestamp: 1553142662\n",
      "  timesteps_since_restore: 9480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9480000\n",
      "  training_iteration: 948\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20828 s, 948 iter, 9480000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-31-23\n",
      "  done: false\n",
      "  episode_len_mean: 75.81060606060606\n",
      "  episode_reward_max: 385.490016921086\n",
      "  episode_reward_mean: 68.36558117959548\n",
      "  episode_reward_min: -164.66250250431537\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 120401\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.788\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 9490000\n",
      "    num_steps_trained: 9490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5702182054519653\n",
      "      kl: 0.016995644196867943\n",
      "      policy_loss: 0.00256623444147408\n",
      "      total_loss: 50.68287658691406\n",
      "      vf_explained_var: 0.8955273628234863\n",
      "      vf_loss: 50.67860794067383\n",
      "    sample_time_ms: 18129.082\n",
      "    update_time_ms: 5.364\n",
      "  iterations_since_restore: 949\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.18279058979773\n",
      "  time_since_restore: 20850.189599990845\n",
      "  time_this_iter_s: 21.384058237075806\n",
      "  time_total_s: 20850.189599990845\n",
      "  timestamp: 1553142683\n",
      "  timesteps_since_restore: 9490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9490000\n",
      "  training_iteration: 949\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20850 s, 949 iter, 9490000 ts, 68.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-31-46\n",
      "  done: false\n",
      "  episode_len_mean: 82.91596638655462\n",
      "  episode_reward_max: 389.0151309161945\n",
      "  episode_reward_mean: 124.61950011480586\n",
      "  episode_reward_min: -166.8060578940773\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 120520\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.889\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 9500000\n",
      "    num_steps_trained: 9500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5255897641181946\n",
      "      kl: 0.01940244249999523\n",
      "      policy_loss: 0.005654165521264076\n",
      "      total_loss: 40.43794631958008\n",
      "      vf_explained_var: 0.8946406245231628\n",
      "      vf_loss: 40.43034362792969\n",
      "    sample_time_ms: 18133.7\n",
      "    update_time_ms: 5.337\n",
      "  iterations_since_restore: 950\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.30975005740294\n",
      "  time_since_restore: 20872.371843338013\n",
      "  time_this_iter_s: 22.18224334716797\n",
      "  time_total_s: 20872.371843338013\n",
      "  timestamp: 1553142706\n",
      "  timesteps_since_restore: 9500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9500000\n",
      "  training_iteration: 950\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20872 s, 950 iter, 9500000 ts, 125 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-32-07\n",
      "  done: false\n",
      "  episode_len_mean: 83.89256198347107\n",
      "  episode_reward_max: 392.19254551710105\n",
      "  episode_reward_mean: 125.3460398724112\n",
      "  episode_reward_min: -160.43563321336745\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 120641\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.53\n",
      "    load_time_ms: 1.647\n",
      "    num_steps_sampled: 9510000\n",
      "    num_steps_trained: 9510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5542218089103699\n",
      "      kl: 0.021950675174593925\n",
      "      policy_loss: 0.0047424365766346455\n",
      "      total_loss: 46.19086837768555\n",
      "      vf_explained_var: 0.8833796977996826\n",
      "      vf_loss: 46.18391799926758\n",
      "    sample_time_ms: 18090.771\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 951\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.67301993620559\n",
      "  time_since_restore: 20893.514089107513\n",
      "  time_this_iter_s: 21.142245769500732\n",
      "  time_total_s: 20893.514089107513\n",
      "  timestamp: 1553142727\n",
      "  timesteps_since_restore: 9510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9510000\n",
      "  training_iteration: 951\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20893 s, 951 iter, 9510000 ts, 125 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-32-29\n",
      "  done: false\n",
      "  episode_len_mean: 75.93076923076923\n",
      "  episode_reward_max: 388.15260391188565\n",
      "  episode_reward_mean: 70.49915106975135\n",
      "  episode_reward_min: -164.86776735362054\n",
      "  episodes_this_iter: 130\n",
      "  episodes_total: 120771\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.658\n",
      "    load_time_ms: 1.738\n",
      "    num_steps_sampled: 9520000\n",
      "    num_steps_trained: 9520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.566575288772583\n",
      "      kl: 0.015880538150668144\n",
      "      policy_loss: 0.00523347407579422\n",
      "      total_loss: 53.00792694091797\n",
      "      vf_explained_var: 0.8878004550933838\n",
      "      vf_loss: 53.001094818115234\n",
      "    sample_time_ms: 18072.512\n",
      "    update_time_ms: 5.357\n",
      "  iterations_since_restore: 952\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.249575534875675\n",
      "  time_since_restore: 20915.312282562256\n",
      "  time_this_iter_s: 21.79819345474243\n",
      "  time_total_s: 20915.312282562256\n",
      "  timestamp: 1553142749\n",
      "  timesteps_since_restore: 9520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9520000\n",
      "  training_iteration: 952\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20915 s, 952 iter, 9520000 ts, 70.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-32-50\n",
      "  done: false\n",
      "  episode_len_mean: 79.07086614173228\n",
      "  episode_reward_max: 389.15710819903717\n",
      "  episode_reward_mean: 89.56812944536227\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 120898\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.074\n",
      "    load_time_ms: 1.717\n",
      "    num_steps_sampled: 9530000\n",
      "    num_steps_trained: 9530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5681405663490295\n",
      "      kl: 0.016036931425333023\n",
      "      policy_loss: 0.002446162048727274\n",
      "      total_loss: 53.23577117919922\n",
      "      vf_explained_var: 0.8816038370132446\n",
      "      vf_loss: 53.231719970703125\n",
      "    sample_time_ms: 17950.097\n",
      "    update_time_ms: 5.218\n",
      "  iterations_since_restore: 953\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.78406472268113\n",
      "  time_since_restore: 20936.411482334137\n",
      "  time_this_iter_s: 21.099199771881104\n",
      "  time_total_s: 20936.411482334137\n",
      "  timestamp: 1553142770\n",
      "  timesteps_since_restore: 9530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9530000\n",
      "  training_iteration: 953\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20936 s, 953 iter, 9530000 ts, 89.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-33-11\n",
      "  done: false\n",
      "  episode_len_mean: 80.01587301587301\n",
      "  episode_reward_max: 388.77830615320727\n",
      "  episode_reward_mean: 104.17593350403365\n",
      "  episode_reward_min: -166.7524261186981\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 121024\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.935\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 9540000\n",
      "    num_steps_trained: 9540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5430192947387695\n",
      "      kl: 0.014367153868079185\n",
      "      policy_loss: 0.004173894412815571\n",
      "      total_loss: 37.68292999267578\n",
      "      vf_explained_var: 0.9132270812988281\n",
      "      vf_loss: 37.67731475830078\n",
      "    sample_time_ms: 17910.083\n",
      "    update_time_ms: 5.289\n",
      "  iterations_since_restore: 954\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.087966752016825\n",
      "  time_since_restore: 20957.89935708046\n",
      "  time_this_iter_s: 21.487874746322632\n",
      "  time_total_s: 20957.89935708046\n",
      "  timestamp: 1553142791\n",
      "  timesteps_since_restore: 9540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9540000\n",
      "  training_iteration: 954\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20957 s, 954 iter, 9540000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-33-33\n",
      "  done: false\n",
      "  episode_len_mean: 74.06666666666666\n",
      "  episode_reward_max: 385.8738747031811\n",
      "  episode_reward_mean: 60.32751802436436\n",
      "  episode_reward_min: -166.7373037515545\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 121159\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.194\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 9550000\n",
      "    num_steps_trained: 9550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5776536464691162\n",
      "      kl: 0.019121669232845306\n",
      "      policy_loss: 0.0035248477943241596\n",
      "      total_loss: 40.905059814453125\n",
      "      vf_explained_var: 0.9230601191520691\n",
      "      vf_loss: 40.89961624145508\n",
      "    sample_time_ms: 17874.377\n",
      "    update_time_ms: 5.32\n",
      "  iterations_since_restore: 955\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.163759012182183\n",
      "  time_since_restore: 20979.848788022995\n",
      "  time_this_iter_s: 21.9494309425354\n",
      "  time_total_s: 20979.848788022995\n",
      "  timestamp: 1553142813\n",
      "  timesteps_since_restore: 9550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9550000\n",
      "  training_iteration: 955\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 20979 s, 955 iter, 9550000 ts, 60.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-33-55\n",
      "  done: false\n",
      "  episode_len_mean: 83.1\n",
      "  episode_reward_max: 392.01213124880394\n",
      "  episode_reward_mean: 123.6222522725403\n",
      "  episode_reward_min: -164.69377415784834\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 121279\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.992\n",
      "    load_time_ms: 1.746\n",
      "    num_steps_sampled: 9560000\n",
      "    num_steps_trained: 9560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5517852902412415\n",
      "      kl: 0.01487420778721571\n",
      "      policy_loss: 0.005094201769679785\n",
      "      total_loss: 42.43871307373047\n",
      "      vf_explained_var: 0.8946545720100403\n",
      "      vf_loss: 42.43212890625\n",
      "    sample_time_ms: 17906.419\n",
      "    update_time_ms: 5.242\n",
      "  iterations_since_restore: 956\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.81112613627014\n",
      "  time_since_restore: 21001.91754603386\n",
      "  time_this_iter_s: 22.068758010864258\n",
      "  time_total_s: 21001.91754603386\n",
      "  timestamp: 1553142835\n",
      "  timesteps_since_restore: 9560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9560000\n",
      "  training_iteration: 956\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21001 s, 956 iter, 9560000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-34-17\n",
      "  done: false\n",
      "  episode_len_mean: 81.48360655737704\n",
      "  episode_reward_max: 388.4402758357793\n",
      "  episode_reward_mean: 112.27057166461891\n",
      "  episode_reward_min: -164.73049246033668\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 121401\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.546\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 9570000\n",
      "    num_steps_trained: 9570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5405135750770569\n",
      "      kl: 0.01162831299006939\n",
      "      policy_loss: 0.00252963462844491\n",
      "      total_loss: 46.27299880981445\n",
      "      vf_explained_var: 0.8888930082321167\n",
      "      vf_loss: 46.26930236816406\n",
      "    sample_time_ms: 17938.103\n",
      "    update_time_ms: 5.197\n",
      "  iterations_since_restore: 957\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.13528583230945\n",
      "  time_since_restore: 21023.953553676605\n",
      "  time_this_iter_s: 22.03600764274597\n",
      "  time_total_s: 21023.953553676605\n",
      "  timestamp: 1553142857\n",
      "  timesteps_since_restore: 9570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9570000\n",
      "  training_iteration: 957\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21023 s, 957 iter, 9570000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-34-39\n",
      "  done: false\n",
      "  episode_len_mean: 80.784\n",
      "  episode_reward_max: 388.720514611884\n",
      "  episode_reward_mean: 106.46204472967842\n",
      "  episode_reward_min: -164.9969280948305\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 121526\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.293\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 9580000\n",
      "    num_steps_trained: 9580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.535092294216156\n",
      "      kl: 0.01591973751783371\n",
      "      policy_loss: 0.0006498197908513248\n",
      "      total_loss: 52.89664077758789\n",
      "      vf_explained_var: 0.8744624257087708\n",
      "      vf_loss: 52.89439392089844\n",
      "    sample_time_ms: 17952.223\n",
      "    update_time_ms: 5.394\n",
      "  iterations_since_restore: 958\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.2310223648392\n",
      "  time_since_restore: 21045.488487005234\n",
      "  time_this_iter_s: 21.53493332862854\n",
      "  time_total_s: 21045.488487005234\n",
      "  timestamp: 1553142879\n",
      "  timesteps_since_restore: 9580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9580000\n",
      "  training_iteration: 958\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21045 s, 958 iter, 9580000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-35-01\n",
      "  done: false\n",
      "  episode_len_mean: 79.296\n",
      "  episode_reward_max: 386.46394701981336\n",
      "  episode_reward_mean: 89.7266468165769\n",
      "  episode_reward_min: -163.4688433470392\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 121651\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.571\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 9590000\n",
      "    num_steps_trained: 9590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5413373112678528\n",
      "      kl: 0.01519075594842434\n",
      "      policy_loss: -0.0012233990710228682\n",
      "      total_loss: 58.4692497253418\n",
      "      vf_explained_var: 0.867753267288208\n",
      "      vf_loss: 58.46894454956055\n",
      "    sample_time_ms: 18020.81\n",
      "    update_time_ms: 5.397\n",
      "  iterations_since_restore: 959\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.86332340828845\n",
      "  time_since_restore: 21067.60856103897\n",
      "  time_this_iter_s: 22.120074033737183\n",
      "  time_total_s: 21067.60856103897\n",
      "  timestamp: 1553142901\n",
      "  timesteps_since_restore: 9590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9590000\n",
      "  training_iteration: 959\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21067 s, 959 iter, 9590000 ts, 89.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-35-24\n",
      "  done: false\n",
      "  episode_len_mean: 79.72\n",
      "  episode_reward_max: 385.8876638938212\n",
      "  episode_reward_mean: 98.6169011706662\n",
      "  episode_reward_min: -166.82097414037227\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 121776\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.266\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 9600000\n",
      "    num_steps_trained: 9600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5398631691932678\n",
      "      kl: 0.013949938118457794\n",
      "      policy_loss: 0.0023296582512557507\n",
      "      total_loss: 42.84606170654297\n",
      "      vf_explained_var: 0.8995866179466248\n",
      "      vf_loss: 42.84233093261719\n",
      "    sample_time_ms: 18039.434\n",
      "    update_time_ms: 5.46\n",
      "  iterations_since_restore: 960\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.30845058533309\n",
      "  time_since_restore: 21089.983906269073\n",
      "  time_this_iter_s: 22.37534523010254\n",
      "  time_total_s: 21089.983906269073\n",
      "  timestamp: 1553142924\n",
      "  timesteps_since_restore: 9600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9600000\n",
      "  training_iteration: 960\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21089 s, 960 iter, 9600000 ts, 98.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-35-46\n",
      "  done: false\n",
      "  episode_len_mean: 84.89915966386555\n",
      "  episode_reward_max: 388.5978825317139\n",
      "  episode_reward_mean: 136.60940226540347\n",
      "  episode_reward_min: -166.73489353665352\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 121895\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.169\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 9610000\n",
      "    num_steps_trained: 9610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48286232352256775\n",
      "      kl: 0.016942506656050682\n",
      "      policy_loss: 0.002162935445085168\n",
      "      total_loss: 38.6604118347168\n",
      "      vf_explained_var: 0.8973210453987122\n",
      "      vf_loss: 38.656551361083984\n",
      "    sample_time_ms: 18155.02\n",
      "    update_time_ms: 5.345\n",
      "  iterations_since_restore: 961\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.30470113270172\n",
      "  time_since_restore: 21112.25825238228\n",
      "  time_this_iter_s: 22.274346113204956\n",
      "  time_total_s: 21112.25825238228\n",
      "  timestamp: 1553142946\n",
      "  timesteps_since_restore: 9610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9610000\n",
      "  training_iteration: 961\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21112 s, 961 iter, 9610000 ts, 137 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-36-08\n",
      "  done: false\n",
      "  episode_len_mean: 81.19672131147541\n",
      "  episode_reward_max: 387.35486907498137\n",
      "  episode_reward_mean: 112.0948979089505\n",
      "  episode_reward_min: -166.73608632251262\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 122017\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.861\n",
      "    load_time_ms: 1.438\n",
      "    num_steps_sampled: 9620000\n",
      "    num_steps_trained: 9620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5409494042396545\n",
      "      kl: 0.012651892378926277\n",
      "      policy_loss: 0.0009326625149697065\n",
      "      total_loss: 39.92972183227539\n",
      "      vf_explained_var: 0.9029710292816162\n",
      "      vf_loss: 39.927520751953125\n",
      "    sample_time_ms: 18142.818\n",
      "    update_time_ms: 5.386\n",
      "  iterations_since_restore: 962\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.04744895447524\n",
      "  time_since_restore: 21133.879521608353\n",
      "  time_this_iter_s: 21.62126922607422\n",
      "  time_total_s: 21133.879521608353\n",
      "  timestamp: 1553142968\n",
      "  timesteps_since_restore: 9620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9620000\n",
      "  training_iteration: 962\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21133 s, 962 iter, 9620000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-36-30\n",
      "  done: false\n",
      "  episode_len_mean: 80.648\n",
      "  episode_reward_max: 389.09482113139285\n",
      "  episode_reward_mean: 106.71532678704459\n",
      "  episode_reward_min: -168.66969900676253\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 122142\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.799\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 9630000\n",
      "    num_steps_trained: 9630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.539719820022583\n",
      "      kl: 0.01826883852481842\n",
      "      policy_loss: 0.0014288180973380804\n",
      "      total_loss: 51.14979934692383\n",
      "      vf_explained_var: 0.8793596029281616\n",
      "      vf_loss: 51.14653396606445\n",
      "    sample_time_ms: 18264.522\n",
      "    update_time_ms: 5.418\n",
      "  iterations_since_restore: 963\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.357663393522294\n",
      "  time_since_restore: 21156.221338033676\n",
      "  time_this_iter_s: 22.341816425323486\n",
      "  time_total_s: 21156.221338033676\n",
      "  timestamp: 1553142990\n",
      "  timesteps_since_restore: 9630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9630000\n",
      "  training_iteration: 963\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21156 s, 963 iter, 9630000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-36-52\n",
      "  done: false\n",
      "  episode_len_mean: 80.58064516129032\n",
      "  episode_reward_max: 387.89459880523805\n",
      "  episode_reward_mean: 103.2641899832487\n",
      "  episode_reward_min: -166.79906383773329\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 122266\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.344\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 9640000\n",
      "    num_steps_trained: 9640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5258193612098694\n",
      "      kl: 0.015404687263071537\n",
      "      policy_loss: 0.0013452366692945361\n",
      "      total_loss: 37.474552154541016\n",
      "      vf_explained_var: 0.9132506251335144\n",
      "      vf_loss: 37.471656799316406\n",
      "    sample_time_ms: 18306.349\n",
      "    update_time_ms: 5.261\n",
      "  iterations_since_restore: 964\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.63209499162436\n",
      "  time_since_restore: 21178.06477046013\n",
      "  time_this_iter_s: 21.843432426452637\n",
      "  time_total_s: 21178.06477046013\n",
      "  timestamp: 1553143012\n",
      "  timesteps_since_restore: 9640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9640000\n",
      "  training_iteration: 964\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21178 s, 964 iter, 9640000 ts, 103 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-37-14\n",
      "  done: false\n",
      "  episode_len_mean: 76.3969465648855\n",
      "  episode_reward_max: 388.80196502597346\n",
      "  episode_reward_mean: 75.1160104042144\n",
      "  episode_reward_min: -162.57424737581255\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 122397\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.806\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 9650000\n",
      "    num_steps_trained: 9650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5835044980049133\n",
      "      kl: 0.02195315808057785\n",
      "      policy_loss: 0.00556908966973424\n",
      "      total_loss: 59.80921936035156\n",
      "      vf_explained_var: 0.8820710778236389\n",
      "      vf_loss: 59.80144500732422\n",
      "    sample_time_ms: 18366.247\n",
      "    update_time_ms: 5.478\n",
      "  iterations_since_restore: 965\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.558005202107196\n",
      "  time_since_restore: 21200.609435796738\n",
      "  time_this_iter_s: 22.544665336608887\n",
      "  time_total_s: 21200.609435796738\n",
      "  timestamp: 1553143034\n",
      "  timesteps_since_restore: 9650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9650000\n",
      "  training_iteration: 965\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21200 s, 965 iter, 9650000 ts, 75.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-37-36\n",
      "  done: false\n",
      "  episode_len_mean: 75.82575757575758\n",
      "  episode_reward_max: 387.5617486504211\n",
      "  episode_reward_mean: 70.48847986188417\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 132\n",
      "  episodes_total: 122529\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.072\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 9660000\n",
      "    num_steps_trained: 9660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5438443422317505\n",
      "      kl: 0.019875383004546165\n",
      "      policy_loss: 0.0031764875166118145\n",
      "      total_loss: 54.8608512878418\n",
      "      vf_explained_var: 0.8908798098564148\n",
      "      vf_loss: 54.855674743652344\n",
      "    sample_time_ms: 18321.689\n",
      "    update_time_ms: 5.439\n",
      "  iterations_since_restore: 966\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.244239930942086\n",
      "  time_since_restore: 21222.2433757782\n",
      "  time_this_iter_s: 21.63393998146057\n",
      "  time_total_s: 21222.2433757782\n",
      "  timestamp: 1553143056\n",
      "  timesteps_since_restore: 9660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9660000\n",
      "  training_iteration: 966\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21222 s, 966 iter, 9660000 ts, 70.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-37-58\n",
      "  done: false\n",
      "  episode_len_mean: 78.84126984126983\n",
      "  episode_reward_max: 388.35351643154394\n",
      "  episode_reward_mean: 97.05713279558016\n",
      "  episode_reward_min: -166.76039147242545\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 122655\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.352\n",
      "    load_time_ms: 1.471\n",
      "    num_steps_sampled: 9670000\n",
      "    num_steps_trained: 9670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.555733323097229\n",
      "      kl: 0.01603625901043415\n",
      "      policy_loss: 0.0047716717235744\n",
      "      total_loss: 39.1408576965332\n",
      "      vf_explained_var: 0.9111781716346741\n",
      "      vf_loss: 39.13447189331055\n",
      "    sample_time_ms: 18298.071\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 967\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.52856639779006\n",
      "  time_since_restore: 21244.083432912827\n",
      "  time_this_iter_s: 21.840057134628296\n",
      "  time_total_s: 21244.083432912827\n",
      "  timestamp: 1553143078\n",
      "  timesteps_since_restore: 9670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9670000\n",
      "  training_iteration: 967\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21244 s, 967 iter, 9670000 ts, 97.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-38-20\n",
      "  done: false\n",
      "  episode_len_mean: 81.44715447154472\n",
      "  episode_reward_max: 386.6080416405521\n",
      "  episode_reward_mean: 109.09315063040333\n",
      "  episode_reward_min: -166.7629135241175\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 122778\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.396\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 9680000\n",
      "    num_steps_trained: 9680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5119328498840332\n",
      "      kl: 0.013244213536381721\n",
      "      policy_loss: 0.006209877785295248\n",
      "      total_loss: 34.448204040527344\n",
      "      vf_explained_var: 0.9146611094474792\n",
      "      vf_loss: 34.44066619873047\n",
      "    sample_time_ms: 18343.193\n",
      "    update_time_ms: 5.203\n",
      "  iterations_since_restore: 968\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.54657531520165\n",
      "  time_since_restore: 21266.050676822662\n",
      "  time_this_iter_s: 21.967243909835815\n",
      "  time_total_s: 21266.050676822662\n",
      "  timestamp: 1553143100\n",
      "  timesteps_since_restore: 9680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9680000\n",
      "  training_iteration: 968\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21266 s, 968 iter, 9680000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-38-41\n",
      "  done: false\n",
      "  episode_len_mean: 78.68253968253968\n",
      "  episode_reward_max: 392.1393714204033\n",
      "  episode_reward_mean: 84.68611244353542\n",
      "  episode_reward_min: -164.73027302524088\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 122904\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.382\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 9690000\n",
      "    num_steps_trained: 9690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5251467823982239\n",
      "      kl: 0.021299561485648155\n",
      "      policy_loss: 0.003315909532830119\n",
      "      total_loss: 58.710506439208984\n",
      "      vf_explained_var: 0.8701694011688232\n",
      "      vf_loss: 58.70505142211914\n",
      "    sample_time_ms: 18211.909\n",
      "    update_time_ms: 5.195\n",
      "  iterations_since_restore: 969\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 42.34305622176769\n",
      "  time_since_restore: 21286.887493371964\n",
      "  time_this_iter_s: 20.836816549301147\n",
      "  time_total_s: 21286.887493371964\n",
      "  timestamp: 1553143121\n",
      "  timesteps_since_restore: 9690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9690000\n",
      "  training_iteration: 969\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21286 s, 969 iter, 9690000 ts, 84.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-39-02\n",
      "  done: false\n",
      "  episode_len_mean: 75.00740740740741\n",
      "  episode_reward_max: 386.5097762739583\n",
      "  episode_reward_mean: 61.65029883652804\n",
      "  episode_reward_min: -168.66444015904904\n",
      "  episodes_this_iter: 135\n",
      "  episodes_total: 123039\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.218\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 9700000\n",
      "    num_steps_trained: 9700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5852434039115906\n",
      "      kl: 0.031529705971479416\n",
      "      policy_loss: 0.009726605378091335\n",
      "      total_loss: 51.30340576171875\n",
      "      vf_explained_var: 0.8971717953681946\n",
      "      vf_loss: 51.29051208496094\n",
      "    sample_time_ms: 18124.329\n",
      "    update_time_ms: 5.064\n",
      "  iterations_since_restore: 970\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 30.82514941826401\n",
      "  time_since_restore: 21308.403452396393\n",
      "  time_this_iter_s: 21.51595902442932\n",
      "  time_total_s: 21308.403452396393\n",
      "  timestamp: 1553143142\n",
      "  timesteps_since_restore: 9700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9700000\n",
      "  training_iteration: 970\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21308 s, 970 iter, 9700000 ts, 61.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-39-24\n",
      "  done: false\n",
      "  episode_len_mean: 79.44354838709677\n",
      "  episode_reward_max: 388.6316028403785\n",
      "  episode_reward_mean: 100.12856243272931\n",
      "  episode_reward_min: -168.70907987638952\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 123163\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.676\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 9710000\n",
      "    num_steps_trained: 9710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5597949028015137\n",
      "      kl: 0.018322167918086052\n",
      "      policy_loss: 0.0026467915158718824\n",
      "      total_loss: 45.8291130065918\n",
      "      vf_explained_var: 0.8941357135772705\n",
      "      vf_loss: 45.82463073730469\n",
      "    sample_time_ms: 18047.598\n",
      "    update_time_ms: 4.946\n",
      "  iterations_since_restore: 971\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.06428121636466\n",
      "  time_since_restore: 21329.90408039093\n",
      "  time_this_iter_s: 21.500627994537354\n",
      "  time_total_s: 21329.90408039093\n",
      "  timestamp: 1553143164\n",
      "  timesteps_since_restore: 9710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9710000\n",
      "  training_iteration: 971\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21329 s, 971 iter, 9710000 ts, 100 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-39-46\n",
      "  done: false\n",
      "  episode_len_mean: 80.968\n",
      "  episode_reward_max: 387.6823573017987\n",
      "  episode_reward_mean: 111.8243048961172\n",
      "  episode_reward_min: -166.75465280457973\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 123288\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.72\n",
      "    load_time_ms: 1.647\n",
      "    num_steps_sampled: 9720000\n",
      "    num_steps_trained: 9720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5219883322715759\n",
      "      kl: 0.016801685094833374\n",
      "      policy_loss: 0.002741739619523287\n",
      "      total_loss: 41.8343620300293\n",
      "      vf_explained_var: 0.9000765681266785\n",
      "      vf_loss: 41.829933166503906\n",
      "    sample_time_ms: 18085.603\n",
      "    update_time_ms: 4.817\n",
      "  iterations_since_restore: 972\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.91215244805859\n",
      "  time_since_restore: 21351.950987815857\n",
      "  time_this_iter_s: 22.046907424926758\n",
      "  time_total_s: 21351.950987815857\n",
      "  timestamp: 1553143186\n",
      "  timesteps_since_restore: 9720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9720000\n",
      "  training_iteration: 972\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21351 s, 972 iter, 9720000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-40-08\n",
      "  done: false\n",
      "  episode_len_mean: 80.62903225806451\n",
      "  episode_reward_max: 388.18665160690733\n",
      "  episode_reward_mean: 103.85039433065874\n",
      "  episode_reward_min: -164.71395328005792\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 123412\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.511\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 9730000\n",
      "    num_steps_trained: 9730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5394187569618225\n",
      "      kl: 0.019352367147803307\n",
      "      policy_loss: 0.005778370890766382\n",
      "      total_loss: 58.366737365722656\n",
      "      vf_explained_var: 0.8670662045478821\n",
      "      vf_loss: 58.35902404785156\n",
      "    sample_time_ms: 18041.208\n",
      "    update_time_ms: 4.85\n",
      "  iterations_since_restore: 973\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.92519716532936\n",
      "  time_since_restore: 21373.830770730972\n",
      "  time_this_iter_s: 21.879782915115356\n",
      "  time_total_s: 21373.830770730972\n",
      "  timestamp: 1553143208\n",
      "  timesteps_since_restore: 9730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9730000\n",
      "  training_iteration: 973\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21373 s, 973 iter, 9730000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-40-29\n",
      "  done: false\n",
      "  episode_len_mean: 72.01459854014598\n",
      "  episode_reward_max: 388.52730848680505\n",
      "  episode_reward_mean: 44.60905552477769\n",
      "  episode_reward_min: -166.74036214503286\n",
      "  episodes_this_iter: 137\n",
      "  episodes_total: 123549\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.787\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 9740000\n",
      "    num_steps_trained: 9740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5817556381225586\n",
      "      kl: 0.015828145667910576\n",
      "      policy_loss: 0.005356747191399336\n",
      "      total_loss: 39.44195556640625\n",
      "      vf_explained_var: 0.923424243927002\n",
      "      vf_loss: 39.43501663208008\n",
      "    sample_time_ms: 17973.351\n",
      "    update_time_ms: 4.939\n",
      "  iterations_since_restore: 974\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.304527762388844\n",
      "  time_since_restore: 21394.95614552498\n",
      "  time_this_iter_s: 21.125374794006348\n",
      "  time_total_s: 21394.95614552498\n",
      "  timestamp: 1553143229\n",
      "  timesteps_since_restore: 9740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9740000\n",
      "  training_iteration: 974\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21394 s, 974 iter, 9740000 ts, 44.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-40-52\n",
      "  done: false\n",
      "  episode_len_mean: 84.04166666666667\n",
      "  episode_reward_max: 388.5688871263484\n",
      "  episode_reward_mean: 128.1520436005909\n",
      "  episode_reward_min: -166.70529858812333\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 123669\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.852\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 9750000\n",
      "    num_steps_trained: 9750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5164759755134583\n",
      "      kl: 0.021690549328923225\n",
      "      policy_loss: 0.004821726121008396\n",
      "      total_loss: 49.0996208190918\n",
      "      vf_explained_var: 0.8740535378456116\n",
      "      vf_loss: 49.09262466430664\n",
      "    sample_time_ms: 17958.661\n",
      "    update_time_ms: 4.748\n",
      "  iterations_since_restore: 975\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.07602180029545\n",
      "  time_since_restore: 21417.332939863205\n",
      "  time_this_iter_s: 22.37679433822632\n",
      "  time_total_s: 21417.332939863205\n",
      "  timestamp: 1553143252\n",
      "  timesteps_since_restore: 9750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9750000\n",
      "  training_iteration: 975\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21417 s, 975 iter, 9750000 ts, 128 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-41-13\n",
      "  done: false\n",
      "  episode_len_mean: 78.2734375\n",
      "  episode_reward_max: 393.6716915941062\n",
      "  episode_reward_mean: 89.34154047660667\n",
      "  episode_reward_min: -162.97310084494592\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 123797\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.574\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 9760000\n",
      "    num_steps_trained: 9760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5630508661270142\n",
      "      kl: 0.017911629751324654\n",
      "      policy_loss: 0.006028824020177126\n",
      "      total_loss: 43.29407501220703\n",
      "      vf_explained_var: 0.9028006196022034\n",
      "      vf_loss: 43.286251068115234\n",
      "    sample_time_ms: 17921.944\n",
      "    update_time_ms: 4.834\n",
      "  iterations_since_restore: 976\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.670770238303334\n",
      "  time_since_restore: 21438.676010370255\n",
      "  time_this_iter_s: 21.34307050704956\n",
      "  time_total_s: 21438.676010370255\n",
      "  timestamp: 1553143273\n",
      "  timesteps_since_restore: 9760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9760000\n",
      "  training_iteration: 976\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21438 s, 976 iter, 9760000 ts, 89.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-41-34\n",
      "  done: false\n",
      "  episode_len_mean: 77.50387596899225\n",
      "  episode_reward_max: 387.93313712223613\n",
      "  episode_reward_mean: 78.75449813121615\n",
      "  episode_reward_min: -164.7152846465969\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 123926\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.074\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 9770000\n",
      "    num_steps_trained: 9770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5593589544296265\n",
      "      kl: 0.0142056280747056\n",
      "      policy_loss: 0.0032393985893577337\n",
      "      total_loss: 49.629520416259766\n",
      "      vf_explained_var: 0.8979777693748474\n",
      "      vf_loss: 49.62485122680664\n",
      "    sample_time_ms: 17890.341\n",
      "    update_time_ms: 4.885\n",
      "  iterations_since_restore: 977\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.37724906560807\n",
      "  time_since_restore: 21460.164617061615\n",
      "  time_this_iter_s: 21.488606691360474\n",
      "  time_total_s: 21460.164617061615\n",
      "  timestamp: 1553143294\n",
      "  timesteps_since_restore: 9770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9770000\n",
      "  training_iteration: 977\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21460 s, 977 iter, 9770000 ts, 78.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-41-57\n",
      "  done: false\n",
      "  episode_len_mean: 83.4873949579832\n",
      "  episode_reward_max: 388.015716263679\n",
      "  episode_reward_mean: 126.24096371606663\n",
      "  episode_reward_min: -168.7379236149454\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 124045\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3693.349\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 9780000\n",
      "    num_steps_trained: 9780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5169186592102051\n",
      "      kl: 0.015267680399119854\n",
      "      policy_loss: 0.003258446464315057\n",
      "      total_loss: 34.3450813293457\n",
      "      vf_explained_var: 0.911479651927948\n",
      "      vf_loss: 34.34029006958008\n",
      "    sample_time_ms: 17909.892\n",
      "    update_time_ms: 4.884\n",
      "  iterations_since_restore: 978\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.120481858033315\n",
      "  time_since_restore: 21482.330740213394\n",
      "  time_this_iter_s: 22.166123151779175\n",
      "  time_total_s: 21482.330740213394\n",
      "  timestamp: 1553143317\n",
      "  timesteps_since_restore: 9780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9780000\n",
      "  training_iteration: 978\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21482 s, 978 iter, 9780000 ts, 126 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-42-18\n",
      "  done: false\n",
      "  episode_len_mean: 78.10852713178295\n",
      "  episode_reward_max: 387.443762690328\n",
      "  episode_reward_mean: 89.45166676497274\n",
      "  episode_reward_min: -168.6852904840374\n",
      "  episodes_this_iter: 129\n",
      "  episodes_total: 124174\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.001\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 9790000\n",
      "    num_steps_trained: 9790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5363391041755676\n",
      "      kl: 0.019731270149350166\n",
      "      policy_loss: 0.003972090780735016\n",
      "      total_loss: 52.12191390991211\n",
      "      vf_explained_var: 0.883246123790741\n",
      "      vf_loss: 52.115962982177734\n",
      "    sample_time_ms: 17961.921\n",
      "    update_time_ms: 4.867\n",
      "  iterations_since_restore: 979\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.72583338248636\n",
      "  time_since_restore: 21503.616317749023\n",
      "  time_this_iter_s: 21.285577535629272\n",
      "  time_total_s: 21503.616317749023\n",
      "  timestamp: 1553143338\n",
      "  timesteps_since_restore: 9790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9790000\n",
      "  training_iteration: 979\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21503 s, 979 iter, 9790000 ts, 89.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-42-40\n",
      "  done: false\n",
      "  episode_len_mean: 79.504\n",
      "  episode_reward_max: 392.5715722981177\n",
      "  episode_reward_mean: 98.6259645380376\n",
      "  episode_reward_min: -162.61482939025402\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 124299\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.322\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 9800000\n",
      "    num_steps_trained: 9800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5472601652145386\n",
      "      kl: 0.019797731190919876\n",
      "      policy_loss: 0.003598974784836173\n",
      "      total_loss: 36.454689025878906\n",
      "      vf_explained_var: 0.9158473610877991\n",
      "      vf_loss: 36.44910430908203\n",
      "    sample_time_ms: 18007.921\n",
      "    update_time_ms: 5.148\n",
      "  iterations_since_restore: 980\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.31298226901879\n",
      "  time_since_restore: 21525.64875435829\n",
      "  time_this_iter_s: 22.03243660926819\n",
      "  time_total_s: 21525.64875435829\n",
      "  timestamp: 1553143360\n",
      "  timesteps_since_restore: 9800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9800000\n",
      "  training_iteration: 980\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21525 s, 980 iter, 9800000 ts, 98.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-43-02\n",
      "  done: false\n",
      "  episode_len_mean: 82.51639344262296\n",
      "  episode_reward_max: 388.4870575860545\n",
      "  episode_reward_mean: 118.27675001509387\n",
      "  episode_reward_min: -162.89623837872983\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 124421\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.472\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 9810000\n",
      "    num_steps_trained: 9810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5303994417190552\n",
      "      kl: 0.020125847309827805\n",
      "      policy_loss: 0.003024863312020898\n",
      "      total_loss: 35.54100036621094\n",
      "      vf_explained_var: 0.914953351020813\n",
      "      vf_loss: 35.535953521728516\n",
      "    sample_time_ms: 18092.316\n",
      "    update_time_ms: 5.254\n",
      "  iterations_since_restore: 981\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.13837500754693\n",
      "  time_since_restore: 21548.007397174835\n",
      "  time_this_iter_s: 22.35864281654358\n",
      "  time_total_s: 21548.007397174835\n",
      "  timestamp: 1553143382\n",
      "  timesteps_since_restore: 9810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9810000\n",
      "  training_iteration: 981\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21548 s, 981 iter, 9810000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-43-24\n",
      "  done: false\n",
      "  episode_len_mean: 80.76612903225806\n",
      "  episode_reward_max: 388.25657571649805\n",
      "  episode_reward_mean: 113.09439791993184\n",
      "  episode_reward_min: -168.6737335123682\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 124545\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.245\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 9820000\n",
      "    num_steps_trained: 9820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5172299146652222\n",
      "      kl: 0.022144366055727005\n",
      "      policy_loss: 0.005538512486964464\n",
      "      total_loss: 43.758460998535156\n",
      "      vf_explained_var: 0.8957175016403198\n",
      "      vf_loss: 43.750694274902344\n",
      "    sample_time_ms: 18011.417\n",
      "    update_time_ms: 5.212\n",
      "  iterations_since_restore: 982\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.5471989599659\n",
      "  time_since_restore: 21569.21185851097\n",
      "  time_this_iter_s: 21.204461336135864\n",
      "  time_total_s: 21569.21185851097\n",
      "  timestamp: 1553143404\n",
      "  timesteps_since_restore: 9820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9820000\n",
      "  training_iteration: 982\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21569 s, 982 iter, 9820000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-43-46\n",
      "  done: false\n",
      "  episode_len_mean: 75.98473282442748\n",
      "  episode_reward_max: 386.0878643506766\n",
      "  episode_reward_mean: 72.42432569006026\n",
      "  episode_reward_min: -166.70523904904366\n",
      "  episodes_this_iter: 131\n",
      "  episodes_total: 124676\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.934\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 9830000\n",
      "    num_steps_trained: 9830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5436731576919556\n",
      "      kl: 0.014350058510899544\n",
      "      policy_loss: 0.003670906415209174\n",
      "      total_loss: 50.832550048828125\n",
      "      vf_explained_var: 0.8945357203483582\n",
      "      vf_loss: 50.82744216918945\n",
      "    sample_time_ms: 18048.546\n",
      "    update_time_ms: 5.284\n",
      "  iterations_since_restore: 983\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 36.21216284503013\n",
      "  time_since_restore: 21591.462947130203\n",
      "  time_this_iter_s: 22.251088619232178\n",
      "  time_total_s: 21591.462947130203\n",
      "  timestamp: 1553143426\n",
      "  timesteps_since_restore: 9830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9830000\n",
      "  training_iteration: 983\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21591 s, 983 iter, 9830000 ts, 72.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-44-08\n",
      "  done: false\n",
      "  episode_len_mean: 83.9\n",
      "  episode_reward_max: 385.9838363888949\n",
      "  episode_reward_mean: 123.92291788646072\n",
      "  episode_reward_min: -164.72269933673383\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 124796\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.362\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 9840000\n",
      "    num_steps_trained: 9840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5221695303916931\n",
      "      kl: 0.01774047315120697\n",
      "      policy_loss: 0.005375430453568697\n",
      "      total_loss: 31.64168930053711\n",
      "      vf_explained_var: 0.9198166131973267\n",
      "      vf_loss: 31.6345272064209\n",
      "    sample_time_ms: 18140.869\n",
      "    update_time_ms: 5.173\n",
      "  iterations_since_restore: 984\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.961458943230355\n",
      "  time_since_restore: 21613.534183740616\n",
      "  time_this_iter_s: 22.071236610412598\n",
      "  time_total_s: 21613.534183740616\n",
      "  timestamp: 1553143448\n",
      "  timesteps_since_restore: 9840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9840000\n",
      "  training_iteration: 984\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21613 s, 984 iter, 9840000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-44-30\n",
      "  done: false\n",
      "  episode_len_mean: 78.67716535433071\n",
      "  episode_reward_max: 389.1110971306617\n",
      "  episode_reward_mean: 91.33324200466016\n",
      "  episode_reward_min: -166.6960722858572\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 124923\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3689.589\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 9850000\n",
      "    num_steps_trained: 9850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5389509201049805\n",
      "      kl: 0.01430824026465416\n",
      "      policy_loss: 5.5680957302683964e-05\n",
      "      total_loss: 49.14830780029297\n",
      "      vf_explained_var: 0.8871827721595764\n",
      "      vf_loss: 49.14682388305664\n",
      "    sample_time_ms: 18077.864\n",
      "    update_time_ms: 5.141\n",
      "  iterations_since_restore: 985\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.666621002330075\n",
      "  time_since_restore: 21635.263305664062\n",
      "  time_this_iter_s: 21.729121923446655\n",
      "  time_total_s: 21635.263305664062\n",
      "  timestamp: 1553143470\n",
      "  timesteps_since_restore: 9850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9850000\n",
      "  training_iteration: 985\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21635 s, 985 iter, 9850000 ts, 91.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-44-51\n",
      "  done: false\n",
      "  episode_len_mean: 83.49166666666666\n",
      "  episode_reward_max: 388.16499667879606\n",
      "  episode_reward_mean: 125.8317320678755\n",
      "  episode_reward_min: -164.73579145869257\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 125043\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.181\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 9860000\n",
      "    num_steps_trained: 9860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5157467722892761\n",
      "      kl: 0.014327914454042912\n",
      "      policy_loss: 0.00493979686871171\n",
      "      total_loss: 37.134796142578125\n",
      "      vf_explained_var: 0.9024478197097778\n",
      "      vf_loss: 37.12841796875\n",
      "    sample_time_ms: 18101.879\n",
      "    update_time_ms: 5.112\n",
      "  iterations_since_restore: 986\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.91586603393775\n",
      "  time_since_restore: 21656.765820264816\n",
      "  time_this_iter_s: 21.502514600753784\n",
      "  time_total_s: 21656.765820264816\n",
      "  timestamp: 1553143491\n",
      "  timesteps_since_restore: 9860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9860000\n",
      "  training_iteration: 986\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21656 s, 986 iter, 9860000 ts, 126 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-45-14\n",
      "  done: false\n",
      "  episode_len_mean: 84.45299145299145\n",
      "  episode_reward_max: 385.73578708079395\n",
      "  episode_reward_mean: 133.8345763581821\n",
      "  episode_reward_min: -160.4611939071083\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 125160\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3680.385\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 9870000\n",
      "    num_steps_trained: 9870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5269858241081238\n",
      "      kl: 0.015564343892037868\n",
      "      policy_loss: 0.003117077983915806\n",
      "      total_loss: 38.76171112060547\n",
      "      vf_explained_var: 0.8970364332199097\n",
      "      vf_loss: 38.75703048706055\n",
      "    sample_time_ms: 18173.204\n",
      "    update_time_ms: 5.165\n",
      "  iterations_since_restore: 987\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.91728817909105\n",
      "  time_since_restore: 21678.950131893158\n",
      "  time_this_iter_s: 22.184311628341675\n",
      "  time_total_s: 21678.950131893158\n",
      "  timestamp: 1553143514\n",
      "  timesteps_since_restore: 9870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9870000\n",
      "  training_iteration: 987\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21678 s, 987 iter, 9870000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-45-35\n",
      "  done: false\n",
      "  episode_len_mean: 84.03333333333333\n",
      "  episode_reward_max: 386.85828865552674\n",
      "  episode_reward_mean: 137.51918675933683\n",
      "  episode_reward_min: -166.72424683925152\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 125280\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3677.888\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 9880000\n",
      "    num_steps_trained: 9880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.484701007604599\n",
      "      kl: 0.01710767112672329\n",
      "      policy_loss: 0.0038408238906413317\n",
      "      total_loss: 35.12299728393555\n",
      "      vf_explained_var: 0.9025071263313293\n",
      "      vf_loss: 35.11743927001953\n",
      "    sample_time_ms: 18085.279\n",
      "    update_time_ms: 5.322\n",
      "  iterations_since_restore: 988\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.75959337966842\n",
      "  time_since_restore: 21700.211517095566\n",
      "  time_this_iter_s: 21.261385202407837\n",
      "  time_total_s: 21700.211517095566\n",
      "  timestamp: 1553143535\n",
      "  timesteps_since_restore: 9880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9880000\n",
      "  training_iteration: 988\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21700 s, 988 iter, 9880000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-45-58\n",
      "  done: false\n",
      "  episode_len_mean: 82.41803278688525\n",
      "  episode_reward_max: 392.50933562153693\n",
      "  episode_reward_mean: 122.19958895933355\n",
      "  episode_reward_min: -164.8421712815428\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 125402\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3679.629\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 9890000\n",
      "    num_steps_trained: 9890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5143353343009949\n",
      "      kl: 0.01686100848019123\n",
      "      policy_loss: 0.0058325049467384815\n",
      "      total_loss: 35.42365264892578\n",
      "      vf_explained_var: 0.912858247756958\n",
      "      vf_loss: 35.41613006591797\n",
      "    sample_time_ms: 18207.836\n",
      "    update_time_ms: 5.348\n",
      "  iterations_since_restore: 989\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.09979447966678\n",
      "  time_since_restore: 21722.739354372025\n",
      "  time_this_iter_s: 22.52783727645874\n",
      "  time_total_s: 21722.739354372025\n",
      "  timestamp: 1553143558\n",
      "  timesteps_since_restore: 9890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9890000\n",
      "  training_iteration: 989\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21722 s, 989 iter, 9890000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-46-19\n",
      "  done: false\n",
      "  episode_len_mean: 82.11475409836065\n",
      "  episode_reward_max: 388.6735776322569\n",
      "  episode_reward_mean: 115.23028589643094\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 125524\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3671.722\n",
      "    load_time_ms: 1.675\n",
      "    num_steps_sampled: 9900000\n",
      "    num_steps_trained: 9900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5205432176589966\n",
      "      kl: 0.013010798022150993\n",
      "      policy_loss: 0.0032498950604349375\n",
      "      total_loss: 34.41989517211914\n",
      "      vf_explained_var: 0.9153119325637817\n",
      "      vf_loss: 34.41533279418945\n",
      "    sample_time_ms: 18188.282\n",
      "    update_time_ms: 5.174\n",
      "  iterations_since_restore: 990\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 57.615142948215464\n",
      "  time_since_restore: 21744.496758937836\n",
      "  time_this_iter_s: 21.757404565811157\n",
      "  time_total_s: 21744.496758937836\n",
      "  timestamp: 1553143579\n",
      "  timesteps_since_restore: 9900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9900000\n",
      "  training_iteration: 990\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21744 s, 990 iter, 9900000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-46-42\n",
      "  done: false\n",
      "  episode_len_mean: 77.5\n",
      "  episode_reward_max: 387.48287208702413\n",
      "  episode_reward_mean: 90.09014855746307\n",
      "  episode_reward_min: -166.70696654650212\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 125652\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3679.041\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 9910000\n",
      "    num_steps_trained: 9910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5452193021774292\n",
      "      kl: 0.018245769664645195\n",
      "      policy_loss: 0.0016788819339126348\n",
      "      total_loss: 47.58506393432617\n",
      "      vf_explained_var: 0.8971389532089233\n",
      "      vf_loss: 47.5815544128418\n",
      "    sample_time_ms: 18162.234\n",
      "    update_time_ms: 5.116\n",
      "  iterations_since_restore: 991\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.04507427873153\n",
      "  time_since_restore: 21766.666825294495\n",
      "  time_this_iter_s: 22.170066356658936\n",
      "  time_total_s: 21766.666825294495\n",
      "  timestamp: 1553143602\n",
      "  timesteps_since_restore: 9910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9910000\n",
      "  training_iteration: 991\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21766 s, 991 iter, 9910000 ts, 90.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-47-04\n",
      "  done: false\n",
      "  episode_len_mean: 78.3828125\n",
      "  episode_reward_max: 388.54222117384415\n",
      "  episode_reward_mean: 92.91517872971306\n",
      "  episode_reward_min: -164.80663868769645\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 125780\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3680.262\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 9920000\n",
      "    num_steps_trained: 9920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5350419878959656\n",
      "      kl: 0.02043617144227028\n",
      "      policy_loss: 0.0039051957428455353\n",
      "      total_loss: 46.06161117553711\n",
      "      vf_explained_var: 0.8939939737319946\n",
      "      vf_loss: 46.0556526184082\n",
      "    sample_time_ms: 18243.678\n",
      "    update_time_ms: 5.143\n",
      "  iterations_since_restore: 992\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.45758936485652\n",
      "  time_since_restore: 21788.69577050209\n",
      "  time_this_iter_s: 22.028945207595825\n",
      "  time_total_s: 21788.69577050209\n",
      "  timestamp: 1553143624\n",
      "  timesteps_since_restore: 9920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9920000\n",
      "  training_iteration: 992\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21788 s, 992 iter, 9920000 ts, 92.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-47-26\n",
      "  done: false\n",
      "  episode_len_mean: 81.00813008130082\n",
      "  episode_reward_max: 388.83289275340127\n",
      "  episode_reward_mean: 111.22601706087224\n",
      "  episode_reward_min: -164.71392959388731\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 125903\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3678.499\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 9930000\n",
      "    num_steps_trained: 9930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5443569421768188\n",
      "      kl: 0.019891388714313507\n",
      "      policy_loss: 0.004040536005049944\n",
      "      total_loss: 43.03156661987305\n",
      "      vf_explained_var: 0.8979945778846741\n",
      "      vf_loss: 43.0255241394043\n",
      "    sample_time_ms: 18258.277\n",
      "    update_time_ms: 5.034\n",
      "  iterations_since_restore: 993\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.61300853043611\n",
      "  time_since_restore: 21811.071583032608\n",
      "  time_this_iter_s: 22.375812530517578\n",
      "  time_total_s: 21811.071583032608\n",
      "  timestamp: 1553143646\n",
      "  timesteps_since_restore: 9930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9930000\n",
      "  training_iteration: 993\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21811 s, 993 iter, 9930000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-47-48\n",
      "  done: false\n",
      "  episode_len_mean: 81.79508196721312\n",
      "  episode_reward_max: 389.0454054588753\n",
      "  episode_reward_mean: 114.42099606527421\n",
      "  episode_reward_min: -168.65538904019832\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 126025\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3677.394\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 9940000\n",
      "    num_steps_trained: 9940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5416621565818787\n",
      "      kl: 0.01690937578678131\n",
      "      policy_loss: 0.0013689001789316535\n",
      "      total_loss: 56.62609100341797\n",
      "      vf_explained_var: 0.8602367043495178\n",
      "      vf_loss: 56.62302017211914\n",
      "    sample_time_ms: 18204.258\n",
      "    update_time_ms: 4.987\n",
      "  iterations_since_restore: 994\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 57.21049803263709\n",
      "  time_since_restore: 21832.59034729004\n",
      "  time_this_iter_s: 21.51876425743103\n",
      "  time_total_s: 21832.59034729004\n",
      "  timestamp: 1553143668\n",
      "  timesteps_since_restore: 9940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9940000\n",
      "  training_iteration: 994\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 8.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21832 s, 994 iter, 9940000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-48-09\n",
      "  done: false\n",
      "  episode_len_mean: 83.17355371900827\n",
      "  episode_reward_max: 388.6631660122435\n",
      "  episode_reward_mean: 128.78404628863788\n",
      "  episode_reward_min: -166.69452658721445\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 126146\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3681.834\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 9950000\n",
      "    num_steps_trained: 9950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.501278817653656\n",
      "      kl: 0.018610848113894463\n",
      "      policy_loss: 0.0039316872134804726\n",
      "      total_loss: 44.16162109375\n",
      "      vf_explained_var: 0.8861126899719238\n",
      "      vf_loss: 44.155818939208984\n",
      "    sample_time_ms: 18171.412\n",
      "    update_time_ms: 5.057\n",
      "  iterations_since_restore: 995\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.39202314431893\n",
      "  time_since_restore: 21854.040329933167\n",
      "  time_this_iter_s: 21.44998264312744\n",
      "  time_total_s: 21854.040329933167\n",
      "  timestamp: 1553143689\n",
      "  timesteps_since_restore: 9950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9950000\n",
      "  training_iteration: 995\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21854 s, 995 iter, 9950000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-48-31\n",
      "  done: false\n",
      "  episode_len_mean: 78.2109375\n",
      "  episode_reward_max: 388.788453364411\n",
      "  episode_reward_mean: 92.08027879672835\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 126274\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.107\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 9960000\n",
      "    num_steps_trained: 9960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5469546914100647\n",
      "      kl: 0.014672375284135342\n",
      "      policy_loss: 0.0027395100332796574\n",
      "      total_loss: 41.86137390136719\n",
      "      vf_explained_var: 0.9079029560089111\n",
      "      vf_loss: 41.85716247558594\n",
      "    sample_time_ms: 18180.059\n",
      "    update_time_ms: 5.148\n",
      "  iterations_since_restore: 996\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.040139398364175\n",
      "  time_since_restore: 21875.632266521454\n",
      "  time_this_iter_s: 21.591936588287354\n",
      "  time_total_s: 21875.632266521454\n",
      "  timestamp: 1553143711\n",
      "  timesteps_since_restore: 9960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9960000\n",
      "  training_iteration: 996\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21875 s, 996 iter, 9960000 ts, 92.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-48-52\n",
      "  done: false\n",
      "  episode_len_mean: 82.37190082644628\n",
      "  episode_reward_max: 388.99798301565045\n",
      "  episode_reward_mean: 121.93789434383135\n",
      "  episode_reward_min: -168.6932262464428\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 126395\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.521\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 9970000\n",
      "    num_steps_trained: 9970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5286756753921509\n",
      "      kl: 0.01476365141570568\n",
      "      policy_loss: 0.004983353894203901\n",
      "      total_loss: 47.17892837524414\n",
      "      vf_explained_var: 0.8784306645393372\n",
      "      vf_loss: 47.172462463378906\n",
      "    sample_time_ms: 18133.575\n",
      "    update_time_ms: 4.981\n",
      "  iterations_since_restore: 997\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.96894717191567\n",
      "  time_since_restore: 21897.38298010826\n",
      "  time_this_iter_s: 21.75071358680725\n",
      "  time_total_s: 21897.38298010826\n",
      "  timestamp: 1553143732\n",
      "  timesteps_since_restore: 9970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9970000\n",
      "  training_iteration: 997\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21897 s, 997 iter, 9970000 ts, 122 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-49-14\n",
      "  done: false\n",
      "  episode_len_mean: 81.91803278688525\n",
      "  episode_reward_max: 381.78698660900255\n",
      "  episode_reward_mean: 116.56326085406232\n",
      "  episode_reward_min: -166.6732580035591\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 126517\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3687.746\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 9980000\n",
      "    num_steps_trained: 9980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5273405313491821\n",
      "      kl: 0.01697000488638878\n",
      "      policy_loss: 0.0053238580003380775\n",
      "      total_loss: 38.95095443725586\n",
      "      vf_explained_var: 0.9049514532089233\n",
      "      vf_loss: 38.94392776489258\n",
      "    sample_time_ms: 18192.862\n",
      "    update_time_ms: 4.908\n",
      "  iterations_since_restore: 998\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.281630427031146\n",
      "  time_since_restore: 21919.259534835815\n",
      "  time_this_iter_s: 21.87655472755432\n",
      "  time_total_s: 21919.259534835815\n",
      "  timestamp: 1553143754\n",
      "  timesteps_since_restore: 9980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9980000\n",
      "  training_iteration: 998\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21919 s, 998 iter, 9980000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-49-36\n",
      "  done: false\n",
      "  episode_len_mean: 83.68067226890756\n",
      "  episode_reward_max: 388.7766549446079\n",
      "  episode_reward_mean: 129.92460100673262\n",
      "  episode_reward_min: -166.68502280529975\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 126636\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.238\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 9990000\n",
      "    num_steps_trained: 9990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5335174202919006\n",
      "      kl: 0.01565324328839779\n",
      "      policy_loss: 0.004646355751901865\n",
      "      total_loss: 37.508914947509766\n",
      "      vf_explained_var: 0.9005142450332642\n",
      "      vf_loss: 37.5026969909668\n",
      "    sample_time_ms: 18067.729\n",
      "    update_time_ms: 4.84\n",
      "  iterations_since_restore: 999\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.96230050336632\n",
      "  time_since_restore: 21940.509002685547\n",
      "  time_this_iter_s: 21.249467849731445\n",
      "  time_total_s: 21940.509002685547\n",
      "  timestamp: 1553143776\n",
      "  timesteps_since_restore: 9990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9990000\n",
      "  training_iteration: 999\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tRUNNING [pid=12721], 21940 s, 999 iter, 9990000 ts, 130 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-21_05-49-57\n",
      "  done: true\n",
      "  episode_len_mean: 83.90833333333333\n",
      "  episode_reward_max: 388.47551955773355\n",
      "  episode_reward_mean: 131.2241490085494\n",
      "  episode_reward_min: -164.67938616892337\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 126756\n",
      "  experiment_id: d110021820ee4abd9ffac6de3e7266c0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3688.852\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 10000000\n",
      "    num_steps_trained: 10000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10041848570108414\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5249948501586914\n",
      "      kl: 0.019634610041975975\n",
      "      policy_loss: 0.007241226267069578\n",
      "      total_loss: 40.041446685791016\n",
      "      vf_explained_var: 0.8945150375366211\n",
      "      vf_loss: 40.03223419189453\n",
      "    sample_time_ms: 18060.435\n",
      "    update_time_ms: 4.846\n",
      "  iterations_since_restore: 1000\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12721\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.6120745042747\n",
      "  time_since_restore: 21962.23333120346\n",
      "  time_this_iter_s: 21.72432851791382\n",
      "  time_total_s: 21962.23333120346\n",
      "  timestamp: 1553143797\n",
      "  timesteps_since_restore: 10000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000000\n",
      "  training_iteration: 1000\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tTERMINATED [pid=12721], 21962 s, 1000 iter, 10000000 ts, 131 rew\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_MultiAgentIntersectionEnv-v0_0:\tTERMINATED [pid=12721], 21962 s, 1000 iter, 10000000 ts, 131 rew\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,  # RL algorithm to run\n",
    "        \"env\": gym_name,  # environment name generated earlier\n",
    "        \"config\": {  # configuration params (must match \"run\" value)\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 1,  # number of iterations between checkpoints\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 1000,  # number of iterations to stop after\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flow_2)",
   "language": "python",
   "name": "flow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
